<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>不会写代码的架构师不是好程序猿</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.ccao.cc/"/>
  <updated>2020-03-05T05:53:45.678Z</updated>
  <id>http://blog.ccao.cc/</id>
  
  <author>
    <name>老曹同学</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>About This Blog</title>
    <link href="http://blog.ccao.cc/2020/03/05/hello-world/"/>
    <id>http://blog.ccao.cc/2020/03/05/hello-world/</id>
    <published>2020-03-05T05:53:45.678Z</published>
    <updated>2020-03-05T05:53:45.678Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Cmake</title>
    <link href="http://blog.ccao.cc/2018/09/28/Cmake/"/>
    <id>http://blog.ccao.cc/2018/09/28/Cmake/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>1999年，国家医学图书馆雇用了一个叫Kitware的小公司来开发一个能更好配置，构建和发布复杂跨平台软件的方法。这项工作是ITK(the Insight Segmentation and Registration Toolkit，一种软件)项目的一部分。作为这个项目的工程领导，Kitware负责开发一个可供ITK项目的研究人员和开发人员使用的软件构建体系。这个系统必须使用简单，并且尽量不占用开发员推进主项目的时间。基于上述指导思想，CMake作为过去的软件构建工具autoconf/libtool的替代品，它应该扬其长避其短。 经过多年的发展，CMake从最初的软件构建体系发展成为了一系列的开发工具：CMake, CTest, CPack和CDash。CMake是软件构建工具，CTest是一个测试驱动工具，用来做回归测试。CPack是打包工具，它能为用CMake构建的软件创造各个平台的安装包。CDash是一个网页应用，能够持续执行集成测试并且展示测试结果。</p><h1 id="5-1CMake的历史和需求"><a href="#5-1CMake的历史和需求" class="headerlink" title="5.1CMake的历史和需求"></a>5.1CMake的历史和需求</h1><p>在开始开发CMake时，项目管理常见的做法是，对于Unix平台使用configure脚本和Makefile文件，对于Windows平台使用Visual Studio工程文件。这种构建系统的二重性使得跨平台开发对许多项目来说变得非常乏味：即使是简单地在一个项目中添加新的源文件都是痛苦的。对开发者而言，显而易见的目标就是拥有一个统一软件构建系统。CMake的开发者们有着通过两种方法来解决这个问题的经验。</p><p>一种方法是1999年开发的VTK构建系统。在这个系统中，Unix系统下使用configure脚本，而在Window系统中使用一个叫做pcmaker的可执行文件。pcmaker是一个C程序，它通过解析Unix Makefile文件来生成Windows下的NMake文件。 pcmaker的二进制可执行文件被嵌入了VTK 的CVS系统仓库中。类似于添加新库这样的几种常见情况需要修改源码，再更新系统仓库的可执行文件。尽管这从某种程度上讲是一个统一的构建系统，但它仍有许多缺点。</p><p>开发者们采用过的另一种方法是为TargetJr开发的基于gmake的构建系统。TargetJr是用C++编写的计算机可视化环境，最初在Sun工作站上开发。一开始，TargetJr使用imake构建系统来创建Makefile文件。然而为了满足有些时候Window下的需要，便开发出了gmake构建系统。gmake构建系统同时支持Unix编译器和Windows编译器。在运行gmake之前系统需要设置一些环境变量。没有正确的环境将导致系统产生一些难以调试的错误，特别是终端用户。</p><p>这两种方法都有一个严重的缺陷: 它们要求Windows开发者使用命令行。然而，熟练的Windows开发者更倾向于使用集成开发环境(IDE)，他们还是会选择手动生成IDE文件然后添加到工程中去，相当于又产生了双构建系统。除了缺乏对IDE的支持，上述两种方法也使得合并软件的项目变得极其困难。比如，VTK中罕有图片加载模块，主要是因为它的构建系统非常难以利用类似libtiff和libjpeg的第三方库。</p><p>因此，为了ITK和一般的C++软件，需要开发一个新的软件构建系统。 这个新构建系统必须满足的基本限制条件如下：</p><p>唯一的依赖平台: </p><p>·安装了C++编译器的操作系统</p><p>·能够生成Visual Studio IDE输入文件</p><p>·易于创建基本的构建系统的目标文件，包括静态库，共享库（动态），可执行文件，插件</p><p>·能够运行构建时的代码生成器</p><p>·支持源码树和构建树的分离</p><p>·能够执行系统”自省”(introspection)，即能够自动判断目标系统能够做什么和不能够做什么</p><p>·能够自动扫描C/C++头文件的依赖关系</p><p>·所有特性对所支持的平台一视同仁</p><p>为了避免依赖于第三方软件库和语法分析器，CMake在设计时只考虑了一个主要的依赖：C++编译器(当要构建的是C++代码时，我们可以放心地假设系统中已经安装好C++编译器)。当时，在许多流行的UNIX和Windows操作系统上构建和安装Tcl之类的脚本语言是非常困难的。即便到如今，给超级计算机和没联网的安全计算机安装软件也还是个问题，所以编译第三方软件库一直都是比较困难的。由于软件构建系统是一个基本工具，因此CMake的设计不应再引入其它的依赖关系。这确实限制了CMake提供自己的简单的语言，导致至今仍有人不喜欢CMake。然而，当时最流行的嵌入式语言是Tcl。如果CMake是基于Tcl语言的构建系统，那么它大概不会达到今天这样的流行程度。</p><p>生成IDE工程文件的能力是CMake的重要卖点，但这也限制了CMake只能提供本地IDE支持之外的特性。不过，支持本地IDE工程文件的好处完全能弥补它的局限性。尽管这个决定使得CMake的发展变得困难，却令ITK和其他使用CMake的项目的开发更为容易。因为开发者使用自己熟悉的工具，不仅更快乐，效率也更高。允许开发者选择自己偏爱的工具, 项目就能充分利用它最宝贵的资源，即开发者。</p><p>所有的C/C++程序都需要以下的一个或多个软件的基本构建单元：可执行文件，静态库，共享库和插件。 CMake必须具备在所有支持的平台上生成这些结果的能力。 虽然所有的平台上都支持生成这些结果, 但不同的平台和不同的编译器会导致编译器选项变化很大。 CMake将实现过程中的复杂性和差异性掩盖在一条条简单的命令之下，从而开发者能够同时在Windows, Unix和Mac上创建这些目标的本地版本。这样，开发人员得以专心于工程本身，而不是在如何编译一个这样的细节上纠结。</p><p>代码生成器为构建系统增加了额外的复杂性。最开始，VTK提供了一个系统，它可以通过解析C++头文件，自动地将C++代码封装成Tcl,Python和Java代码，然后自动地生成一个封装层。这要求构建系统先生成一个C/C++程序(封装生成器)，然后在编译时运行此程序以生成更多的C/C++源码(特定模块的封装代码)。生成的源码接着将被编译成可执行文件或动态链接库。所有这些过程必须在IDE环境和生成的Makefile中实现。 当开发灵活的跨平台C/C++软件时，很重要的一点是面向功能编程，而不是面向特定的平台。autotool工具支持系统”自省”(introspection)，即通过编译少量的代码来检查并存储编译的结果。由于跨平台的需要，CMake也采用了类似系统自省的技术，使得开发者只需针对标准平台编码，而不需要考虑特定的平台。随着编译器和操作系统不断地变化，这个策略对于代码的可移植性非常重要。比如，下面的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    #ifdef linux  </span><br><span class="line">    * do some linux stuff  </span><br><span class="line">    #endif</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">对比如下，就显得更脆弱：</span><br></pre></td></tr></table></figure></p><pre><code>#ifdef HAS_FEATURE  * do something with a feature  #endif</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">另一个CMake早期的需求也来自于autotool: 生成与源码树分开的构建树的能力。这个使从同一个源码树得到的构建类型多样化，同时防止源码树与构建文件之间经常混淆了版本控制系统的冲突。</span><br><span class="line"></span><br><span class="line">构建系统一个最更要的功能是对依赖关系的管理能力。如果一个源码文件发生变化，那么所有使用了这个源码文件的生成结果都必须重新构建。对于C/C++代码，被.c和.cpp文件包含的头文件也需要检查部分依赖关系。如果依赖关系理解错误，只有部分修改的代码有可能导致全部重新编译，从而浪费大量时间。</span><br><span class="line"></span><br><span class="line">这个新构建系统的所有需求和功能都必须对所有支持的平台一视同仁。CMake需要为开发者提供一个简单的API，以便于在不用了解平台细节的情况下就可以创建复杂的软件系统。事实上，使用CMake的软件只不过是把构建复杂性转移给了CMake开发组。一旦构建工具的愿景随着基本需求而产生，实现的过程则需要灵活的方式。ITK几乎是从第一天开始就需要一个构建系统。而第一个版本的CMake并没有满足陈述在愿景中的所有需求，但是他们已经能够在Windows和Unix下构建软件。</span><br><span class="line"></span><br><span class="line"># 5.2 CMake是怎样实现的 #</span><br><span class="line"></span><br><span class="line">正如之前提到过的一样，CMake的创建语言是C和C++。为了解释它内部的构造，这个小节首先从用户的角度来描述CMake的执行过程，然后再检查它的结构。</span><br><span class="line">    </span><br><span class="line">## 5.2.1 CMake的过程 ##</span><br><span class="line"></span><br><span class="line">CMake有两个阶段。第一个是配置，在这个阶段CMake会将其获得的所有的输入，创建软件构建过程中所需的内部表达。</span><br><span class="line"></span><br><span class="line">### 环境变量和缓冲 ###</span><br><span class="line"></span><br><span class="line">不管是1999年，还是今天，许多软件构建系统的过程，shell级别的环境变量经常被用到。典型的情况是，用PROJECT_ROOT环境变量指向源代码树的根目录。环境变量是用来指向可选和外部的软件包的。这种方法的弊端在于，它每次构建的时候都需要重新设置外部变量。为了解决这个问题，CMake用缓冲文件来存储构建过程中需要用到的所有变量。但它们并不是shell或者环境变量，只是CMake的变量。当CMake在对一个特定的构建树第一次运行的时候，它会创建一个CMakeCache.txt文件，存储过程中所有的变量。因为这个文件是构建树的一部分，所以这些变量在每次CMake重建的时候也是可用的。</span><br><span class="line"></span><br><span class="line">### 配置阶段 ###</span><br><span class="line"></span><br><span class="line">在配置阶段，CMake首先会读取CMakeCache.txt，这个文件在第一次运行时生成。然后CMake读取源码根目录下的CMakeLists.txt文件，然后使用CMake语言词法分析器对其进行分析。CMakeLists.txt文件中的每一个CMake命令都由一个命令模式对象执行。通过include和add_subdirectory能执行CMakeLists.t来处理。xt文件中更多的命令。每条命令都有一个C++对象来处理。实际上，整个CMake语言都是以命令调用的方式来实现的。词法分析器只是将CMake转化为命令和命令参数而已。</span><br><span class="line"></span><br><span class="line">配置阶段主要是执行用户提供的CMake代码。等到执行完之后，所有缓冲区变量的值都被计算出来了，CMake在内存中得到一个项目的内部表达。。这个内存中的内部表达包括了所有的库文件，可执行文件，定制的命令，以及生成指定generator(指特定的编译环境)所需的其他必要信息。至此，CMakeCach.txt这个包含着CMake以后要用到的所有信息的文件就被存储在了磁盘中。</span><br><span class="line"></span><br><span class="line">项目在内存中的表达式一些未生成对象的集合，包含基本的库文件和可执行文件。CMake也支持自定义的对象：用户可以定义它们的输入和输出，和定制构建过程中需要的可执行文件和脚本。CMake将每个对象都存储在一个cmTarget对象中。而多个cmTarget对象构成一个cmMakefile对象，cmMakefile对象是用来存储源码树中所有构建的对象的。这最终形成了一个cmMakefile对象树，它包含着cmTarget对象的映射。</span><br><span class="line"></span><br><span class="line">### 生成阶段 ###</span><br><span class="line"></span><br><span class="line">一旦配置阶段完成，生成阶段就开始了。生成阶段将用户指定类型的构建文件。此时目标的内部表达（库，可执行文件，定制目标）转化为本地工具的构建工具比如：Visual Studio和Makefiles文件。Cmake在配置阶段之后生成的内部表达，要尽可能的普遍跟通用，这样才会有更多的代码和数据结构能够被不同的构建工具所共享。</span><br><span class="line"></span><br><span class="line">CMake处理过程简图如5.1</span><br><span class="line">![](/cdn/images/aosabook/42.png)</span><br><span class="line"></span><br><span class="line">## 5.2.2 CMake的代码 ## </span><br><span class="line"></span><br><span class="line">CMake中的对象</span><br><span class="line">  </span><br><span class="line">CMake是一种使用了继承，封装等面向对象技术。它的主要对象和它们之间的关系如下图：</span><br><span class="line">  </span><br><span class="line">![](/cdn/images/aosabook/43.png)</span><br><span class="line">  </span><br><span class="line">每个CMakeLists.txt的解析结果存储在一个cmMakefile里面。除了这个目录的信息，cmMakefile对象也控制着对CMakeLists.txt的解析。解析函数会调用基于lex/yacc的分析器。由于CMake的语法很少发生变化，而且lex和yacc有可能并不在CMake建立的地方，所以将lex和yacc的输出结果被处理和保存到了Source目录中，和其他的文件一起加入到版本控制系统中。</span><br><span class="line">  </span><br><span class="line">CMake另一个重要的类就是cmcommand。这是CMake语言中所有命令的实现类的积累，每个子类不仅提供命令的实现，还包括其文档，比如，下面cmUnsetCommand类的方法的作用是提供文档：</span><br><span class="line">```  </span><br><span class="line">virtual const char* GetTerseDocumentation()</span><br><span class="line">&#123;</span><br><span class="line">    return &quot;Unset a variable, cache variable, or environment variable.&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * More documentation</span><br><span class="line">  */</span><br><span class="line">virtual const char* GetFullDocumentation()</span><br><span class="line">&#123;</span><br><span class="line">    return</span><br><span class="line">        &quot; unset(&lt;variable&gt; [CACHE])\n&quot;</span><br><span class="line">        &quot;Removes the specified variable causing it to become undefined.&quot;</span><br><span class="line">        &quot;If CACHE is present then the variable is removed from the cache&quot;</span><br><span class="line">        &quot;instaead of the current scope. \n&quot;</span><br><span class="line">        &quot;&lt;variable&gt; can be an environment variable such as:\n&quot;</span><br><span class="line">        &quot;  unset(ENV&#123;LD_LIBRARY_PATH&#125;)\n&quot;</span><br><span class="line">        &quot;in which case the variable will be removed from the current &quot;</span><br><span class="line">        &quot;environment.&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="依赖性分析"><a href="#依赖性分析" class="headerlink" title="依赖性分析"></a>依赖性分析</h3><p>CMake内置有强大的独立分析的能力来支持单个Fortran，C和C++源码。因为集成开发环境（IDE）能够支持和维护文件的以来信息，对于这些本地系统CMake将忽略依赖分析步骤，只是创建一个本地IDE输入文件，并且让IDE自行处理文件层次的依赖信息。目标层次的依赖信息则转换为IDE所支持的依赖信息格式。</p><p>对于基于Makefile的本地构建工具，其make程序并不知道自动如何计算和更新依赖信息。对与这样的本地构建系统CMake自动为C,C++和Fortran计算依赖信息。这些依赖关系的生成和维护都是由CMake自动完成的。一旦一个程序最初由CMake配置，那么用户只需要运行make，CMake会解决剩下的工作。</p><p>虽然用户不需要知道CMake是怎样工作的，查看一个项目的依赖信息还是很有用的。在CMake中，每个目标的依赖信息存储在四个文件中：depend.make, flags.make, build.make和DependInfo.make。depend.make存储指定目录中所有对象文件的依赖信息。flags.make包含了源码文件的编译选项，如果它们发生了改变，目标文件将被重新编译。DependInfo.make用来更新和维护依赖信息，它还存储了工程中包含了哪些文件和使用哪一种编码语言等信息。最后，建立依赖的规则存储在build.make中。如果一个目标的依赖信息过时了，那么依赖信息就会被重新计算，始终维护当下的依赖信息。这个过程存在的意义在于当a.h文件发生改变时，坑能回增加新的依赖关系。</p><h3 id="CTest和CPack"><a href="#CTest和CPack" class="headerlink" title="CTest和CPack"></a>CTest和CPack</h3><p>随着CMake的发展，它从一个构建系统成长为了一个带构建，测试，打包软件的工具家族。除了命令行cmake，和CMake图形界面（GUI）程序。CMake还包含了测试工具CTest和打包工具CPack。CTest和CPack共享CMake的底层代码，但是它们又是相对独立的，不依赖于基本的构建过程。</p><p>ctest可执行程序用于回归测试。简单的使用add_test命令，项目就可以使用CTest来创建测试。这些测试能够用CTest运行，测试结果可以发送到CDash程序并且显示在网络应用中。CTest和CDash加在一起就像是Hudson测试工具。它们有很明显的区别：CTest允许面向分布式的测试环境。客户可以从版本控制系统中获取代码，运行测试并且将测试结果发送到CDash。而Hubson，客户机器必须给予Hudson足够的ssh权限来访问目标机器，测试才能进行。</p><p>cpack可执行程序用来生成项目的安装程序。CPack的执行和CMake的构建过程非常类似：它也依赖于本地的其他打包工具。比如，在Windows下使用的NSIS打包工具来生成项目的安装程序。CPack运行项目的安装规则来创建安装树，然后安装树被发送给像NSIS这样的安装包生成程序。CPack还支持创建RPM，Debian .deb文件，.tar, .tar.gz文件和一些自解压文件。</p><h2 id="5-2-3-图形界面"><a href="#5-2-3-图形界面" class="headerlink" title="5.2.3 图形界面"></a>5.2.3 图形界面</h2><p>通常用户们对于CMake的第一印象就是CMake的用户界面。CMake有两个用户交互程序：基于Qt的窗口型图形界面程序和基于命令行的图形界面应用。这些GUI都是CMakeCache.txt文件的可视化编辑器。它们都各自通过两个按钮进行交互，配置和生成——对应于两个主要的阶段。命令行的图形及面用于Unix的TTY类型的平台和Cygwin。而Qt的图形界面对于所有的平台都适用。下面图5.3和5.4展示了两种图形界面</p><p><img src="/cdn/images/aosabook/44.png" alt=""></p><p>图5.3</p><p><img src="/cdn/images/aosabook/45.png" alt=""></p><p>图5.4</p><p>两个图形界面都在左边显示缓存变量的名字，具体的值显示在右边。右边的变量值可以由用户修改。一共还有两种变量，普通变量和高级变量。默认情况下只将普通变量展示给用户看。在CMakeLists.txt文件中决定这一个变量是否是高级变量。这项功能可以让界面变得更简单，用户配置时只需要考虑必要的选项。</p><p>由于缓存变量的值可以随着CMake命令的执行而变化，整个生成的过程是递归的。例如，打开一个选项可能会引入更多的选项。因此，GUI使generate这个按钮无效，直到所有的选项都至少出现了一次。一旦配置按钮被点击，新的缓存变量（即未显示过的）就会显示为红色。只要在配置过程中没有新的缓存变量出现了，generate按钮就会变为有效。</p><h2 id="5-2-4-测试CMake"><a href="#5-2-4-测试CMake" class="headerlink" title="5.2.4 测试CMake"></a>5.2.4 测试CMake</h2><p>任何一个新的CMake开发人员都会先被介绍CMake开发的测试过程，这个过程使用了多个CMake家族中的工具(CMake, CTest, CPack和CDash)。当代码经过开发及检验到版本控制系统中，持续的集成测试机器将用CTest自动构建和测试新的CMake代码。结果将送到CDash服务器上，如果存在任何的构建错误、编译警告或测试失败的情况，将通过邮件通知开发者。</p><p>这个过程是一个典型的持续集成测试系统。当新代码检入到CMake仓库时，它将自动在CMake支持的平台上测试。考虑到CMake支持了大量的编译器和平台，这种类型的测试系统对一个稳定的构建系统是必不可少的。</p><p>比如, 如果一个新的开发者希望添加对一个新的平台的支持, 他(她)第一个被问到的问题是能否为那个系统提供一个夜间仪表盘？？客户端。 没有不断的测试, 新系统将在一段时间后停止工作，这是不可避免的。</p><h1 id="5-3经验教训"><a href="#5-3经验教训" class="headerlink" title="5.3经验教训"></a>5.3经验教训</h1><p>CMake从第一天开始就已经成功地建立了ITK。这是整个工程最重要的部分。如果我们可以重新开发CMake，不会有太多的东西需要改变。然而，总是有一些事情，本可以做得更好。</p><h2 id="5-3-1后向兼容性"><a href="#5-3-1后向兼容性" class="headerlink" title="5.3.1后向兼容性"></a>5.3.1后向兼容性</h2><p>维护后向兼容对CMake开发团队而言是很重要的。这个工程主要目标是为了使构建软件更容易。当一个工程或开发者选择CMake作为构建工具时，尊重他们的选择尽最大的努力不去破坏即将构建未来版本的CMake。CMake2.6完成了一个策略系统，使CMake会破坏现有行为的变化产生警告，但仍然执行原来的行为。每一个CMakeLists.txt文件需要指定哪个版本的CMake是希望被使用的。新的CMake版本也许会产生警告，但仍会像旧版本一样构建工程。</p><h2 id="5-3-2-语言-语言-语言"><a href="#5-3-2-语言-语言-语言" class="headerlink" title="5.3.2 语言,语言,语言"></a>5.3.2 语言,语言,语言</h2><p>CMake语言尽量设计得简单。然而，当一个新工程考虑CMake时，它是被采用的主要障碍之一。考虑到它的有机增长，CMake语言确实有一些怪癖。第一个语法分析器甚至不是基于lex/yacc而仅仅是一个简单的字符分析器。若是有再次做这个语言的机会，我们将花时间寻找一个现有的好的嵌入式语言。Lua是能生效的最适合的。它非常小而且诶干净。即使不使用一个类似Lua的外部语言，我在一开始也仍会考虑现有的语言。</p><h2 id="5-3-3-插件不能工作"><a href="#5-3-3-插件不能工作" class="headerlink" title="5.3.3 插件不能工作"></a>5.3.3 插件不能工作</h2><p>为了通过工程提供CMake语言的扩展能力，CMake有一个插件类。这使工程可以用C语言创建新的CMake命令。这在当时听起来是个不错的想法，而且为C语言定义了接口以便不同编译器都可以使用。然而，随着类似32/64位Windows和Linux的多种应用程序接口系统的出现，插件的兼容性开始变得难以维护。虽然用CMake语言延伸CMake没有那么强大，但它避免了CMake崩溃和由于一个出错或者加载失败的插件而不能构建工程的情况。</p><h2 id="5-3-4-减少外部接口"><a href="#5-3-4-减少外部接口" class="headerlink" title="5.3.4 减少外部接口"></a>5.3.4 减少外部接口</h2><p>在CMake工程的开发中学到了一个重大的经验，就是你不必维护用户访问不到的后向兼容性。有时候用户和客户要求CMake做成库以便于其他语言可以绑定使用CMAke的功能。这不仅会使通过许多不同方式使用CMake的用户社区分裂开，还将是CMake工程一项巨大的维护成本。</p><p>== Footnotes ==</p><p>1.<a href="http://www.itk.org/" target="_blank" rel="noopener">http://www.itk.org/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h1&gt;&lt;p&gt;1999年，国家医学图书馆雇用了一个叫Kitware的小公司来开发一个能更好配置，构建和发布复杂跨平台软件的方法。这项工作是
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>FreeRTOS</title>
    <link href="http://blog.ccao.cc/2018/09/28/FreeRTOS/"/>
    <id>http://blog.ccao.cc/2018/09/28/FreeRTOS/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FreeRTOS"><a href="#FreeRTOS" class="headerlink" title="FreeRTOS"></a>FreeRTOS</h1><p>FreeRTOS(读作”free-arr-toss”)是一个嵌入式系统使用的开源实时操作系统(RTOS)。FreeRTOS能支持许多不同硬件架构以及交叉编译器,被设计为“小巧，简单，和易用”。</p><p>自2002年Richard Barry开始开发以来，FreeRTOS一直都在积极开发中。至于我，我不是FreeRTOS的开发人员或贡献者，我只不过是一个最终用户和爱好者。因此，这章将着重与FreeRTOS架构之“是什么”和“怎么做”，而相对本书其他章节来说，较少去讲“为什么”。</p><p>就像所有操作系统一样，FreeRTOS的主要工作是执行任务。大部分FreeRTOS的代码都涉及优先权、调度以及执行用户自定义任务。但又与所有其他操作系统不同，FreeRTOS是一款运行在嵌入式系统上的实时操作系统。</p><p>到本章结束，我希望你可以了解FreeRTOS的基本架构。大部分FreeRTOS致力于执行任务，所以你可以很好地看到它究竟是如何做到的。</p><p>如果这是你首次去深入了解一个操作系统，我还是希望你可以学习到最基本的操作系统是如何工作的。FreeRTOS是相对简单的，特别是相比Windows，linux，或者OS X而言，不过所有操作系统都有着相同的概念和目标，所以不论学习哪个操作系统都是有启发和有趣的。</p><h2 id="3-1什么是“嵌入式”和“实时”"><a href="#3-1什么是“嵌入式”和“实时”" class="headerlink" title="3.1什么是“嵌入式”和“实时”"></a>3.1什么是“嵌入式”和“实时”</h2><p>“嵌入式”和“实时”对于不同的人来说代表不同的理解，所以让我们像FreeRTOS用户那样来定义它们。</p><p>嵌入式系统就是一个专门设计用来做一些简单事情的计算机系统，就像是电视遥控器，车载GPS，电子手表，或者起搏器这类。嵌入式系统比通用计算机系统显著的区别在于更小和更慢，通常也更便宜。一个典型的低端嵌入式系统可能有一个运行速度为25MHz的8位CPU，几KB的内存，和也许32KB的闪存。一个高端的嵌入式系统可能有一个运行速度为750MHz的32位CPU，一个GB左右的内存，和几个GB的闪存。</p><p>实时系统是设计去完成一定时间内的事，它们保证这些事是在应该做的时候去做。</p><p>心脏起搏器是实时嵌入式系统的一个极好例子。起搏器必须在正确的时间收缩心肌，以挽救你的生命；它不能够太忙而没有及时响应。心脏起搏器以及其他的实时嵌入式系统都必须精心设计，以便在任何时刻都能及时执行它们的任务。</p><h2 id="3-2架构概述"><a href="#3-2架构概述" class="headerlink" title="3.2架构概述"></a>3.2架构概述</h2><p>FreeRTOS是一个相对较小的应用程序。最小化的FreeRTOS内核仅包括3个（’’.c’’）文件和少数头文件，总共不到9000行代码，还包括了注释和空行。一个典型的编译后（二进制）代码映像小于10KB。</p><p>FreeRTOS的代码可以分解为三个主要区块：任务，通讯，和硬件接口。</p><ul><li>任务：大约有一半的FreeRTOS的核心代码用来处理多数操作系统首要关注的问题：任务。任务是给定优先级的用户定义的C函数。’’task.c’’和’’task.h’’完成了所有有关创建，调度，和维护任务的繁重工作。</li><li>通讯：任务很重要，不过任务间可以互相通讯则更为重要！它给我们带来FreeRTOS的第二项任务：通讯。大约40%的FreeRTOS核心代码是用来处理通讯的。’’queue.c’’和’’queue.h’’是负责处理FreeRTOS的通讯的。任务和中断使用队列互相发送数据，并且使用信号灯和互斥来发送临界资源的使用情况。</li><li>硬件接口：接近9000行的代码拼凑起基本的FreeRTOS，是硬件无关的；相同的代码都能够运行，不论FreeRTOS是运行在不起眼的8051，还是最新、最炫的ARM内核上。大约有6%的FreeRTOS的核心代码，在硬件无关的FreeRTOS内核与硬件相关的代码间扮演着垫片的角色。我们将在下个部分讨论硬件相关的代码。</li></ul><h3 id="硬件注意事项"><a href="#硬件注意事项" class="headerlink" title="硬件注意事项"></a>硬件注意事项</h3><p>硬件无关的FreeRTOS层在硬件相关层之上。硬件相关层声明了你选择什么样的芯片架构。图3.1显示了FreeRTOS的各层。</p><p><img src="/cdn/images/aosabook/74.png" alt=""></p><p>图3.1：FreeRTOS的软件层</p><p>FreeRTOS包含所有你需要用来启动很运行系统的硬件无关以及硬件相关的代码。它支持许多编译器（CodeWarrior，GCC，IAR等）也支持许多处理器架构（ARM7，ARM Cortex-M3，PICs各系列，Silicon Labs 8051, x86等）。请参阅FreeRTOS网站，可以看到处理器和编译器支持列表。</p><p>FreeRTOS是高可配置设计。FreeRTOS可以被编译成为适合单CPU，极简RTOS，只支持少数任务的操作系统，也可以被编译成为适合多核功能强大的结合了TCP/IP，文件系统，和USB的怪兽。</p><p>配置选项可以通过设置不同的’’#defines’’，在’’FreeRTOSConfig.h’’文件里选择。时钟速度，堆大小，互斥，和API子集，连同其他许多选项，都可以在这个文件中配置。这里是几个例子，设置了任务优先级的最大数量，CPU的频率，系统节拍器的频率，最小的堆栈大小和总的堆大小：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define configMAX_PRIORITIES      ( ( unsigned portBASE_TYPE ) 5 ) //任务优先级的最大数量</span><br><span class="line">#define configCPU_CLOCK_HZ        ( 12000000UL )                   //CPU的频率</span><br><span class="line">#define configTICK_RATE_HZ        ( ( portTickType ) 1000 )        //系统节拍器的频率     </span><br><span class="line">#define configMINIMAL_STACK_SIZE  ( ( unsigned short ) 100 )       //最小的堆栈大小  </span><br><span class="line">#define configTOTAL_HEAP_SIZE     ( ( size_t ) ( 4 * 1024 ) )      //总的堆大小</span><br></pre></td></tr></table></figure></p><p>对于不同的交叉编译器和CPU架构，硬件相关代码分布在多个文件中。举例来说，如果你使用ARM Cortex-M3芯片，IAR编译器工作，那么硬件相关的代码就存在’’FreeRTOS/Source/portable/IAR/ARM_CM3’’/目录下。’’portmacro.h’’文件声明了所有硬件特定功能，’’port.c’’和’’portasm.s ‘’包含了所有实际硬件相关的代码。硬件无关的头文件’’portable.h’’在编译的时候用’’#include’’’s引入正确的’’portmacro.h’’文件。FreeRTOS使用’’#define’’’d调用在’’portmacro.h’’中声明的硬件特定功能。 </p><p>让我们来看一个例子，FreeRTOS是如何调用一个硬件相关功能的。硬件无关的文件’’tasks.c’’常常需要插入一个代码的临界区，以防止抢占。在不同架构上，插入一个临界区的表现也不同，并且硬件无关的’’task.c’’不需要了解硬件相关的细节。所以’’task.c’’调用全局宏指令’’portENTER_CRITICAL()’’, 忽略它实际上是如何做到的。假设我们使用IAR编译器在ARM Crotex-M3芯片上编译生成FreeRTOS，使用那个定义了’’portENTER_CRITICAL()’’的文件’’/Source/portable/IAR/ARM_CM3/portmacro.h’’，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">  #define portENTER_CRITICAL()   vPortEnterCritical()</span><br><span class="line">```  </span><br><span class="line">&apos;&apos;vPortEnterCritical()&apos;&apos;实际上是在&apos;&apos;FreeRTOS/Source/portable/IAR/ARM_CM3/port.c&apos;&apos;中定义的。这个&apos;&apos;port.c&apos;&apos;文件是一个硬件相关的文件，同时包含了对IAR编译器和Cortex-M3芯片认识的代码文件。&apos;&apos;vPortEnterCritical()&apos;&apos;函数利用这些硬件特定的知识进入临界区，又返回到与硬件无关的&apos;&apos;tasks.c&apos;&apos;中。</span><br><span class="line"></span><br><span class="line">&apos;&apos;protmacro.h&apos;&apos;文件也定义了一个数据类型的基本架构。这个数据类型中包括了基本整型变量，指针，以及系统时钟节拍器的数据类型，在ARM Cortex-M3 chips上使用IAR编译器时，就采用如下定义：</span><br><span class="line"></span><br><span class="line">  #define portBASE_TYPE  long              // 基本整型变量</span><br><span class="line">  #define portSTACK_TYPE unsigned long     //指向内存位置的指针</span><br><span class="line">  typedef unsigned portLONG portTickType;  // 系统时钟节拍器的数据类型</span><br><span class="line">  </span><br><span class="line">这样使用数据类型的方法，和函数透过小层的&apos;&apos;#defines&apos;&apos;，看上去略微有点复杂，不过它允许了FreeRTOS能够被重新编译在一个完全不同的系统架构上，仅仅只需要通过修改这些硬件相关的文件。同时，如果你想要让FreeRTOS运行在一个当前尚未被支持的架构上，你只仅仅需要去实现硬件相关的功能，这要比在FreeRTOS上去实现硬件无关的部分，要少得多。</span><br><span class="line"></span><br><span class="line">就如同我们已经见到的，FreeRTOS用C的预处理宏&apos;&apos;#define&apos;&apos;来实现硬件相关的功能。FreeRTOS也同样用&apos;&apos;#define&apos;&apos;来应对大量的硬件无关的代码。对于非嵌入式应用程序这样频繁使用&apos;&apos;#define&apos;&apos;是一个严重的错误，不过在许多小型嵌入式系统中这点开销比起“实时”所提供的功能来说就微不足道了。</span><br><span class="line">   </span><br><span class="line"> ## 3.3.调度任务：快速概述 ## </span><br><span class="line">### 任务优先级和就绪列表 ###</span><br><span class="line">所有任务都有一个用户指定优先级，从0（最低优先级）到 &apos;&apos;configMAX_PRIORITIES-1&apos;&apos;（最高优先级）的编译时间值。例如，如果&apos;&apos;configMAX_PRIORITIES&apos;&apos;设置为5，当FreeRTOS使用5个优先等级时：0(最低优先级)，1，2，3，和4（最高优先级）。</span><br><span class="line"></span><br><span class="line">FreeRTOS使用一个“就绪列表”来跟踪所有已经准备好运行的任务。它像一个任务列表数组来实现就绪列表，如下所示：</span><br></pre></td></tr></table></figure></p><p>  static xList pxReadyTasksLists[ configMAX_PRIORITIES ];  //就绪列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> &apos;&apos;pxReadyTasksLists[0] &apos;&apos;是所有准备好的优先级为0的任务列表， &apos;&apos;pxReadyTasksLists[1] &apos;&apos;是所有准备好的优先级为1的任务列表，以此类推，直到 &apos;&apos;pxReadyTasksLists[configMAX_PRIORITIES-1] &apos;&apos;。</span><br><span class="line"></span><br><span class="line">### 系统节拍器（时钟） ###</span><br><span class="line">FreeRTOS系统的心跳就是被称为系统节拍器（时钟）。FreeRTOS配置这个系统生成一个定期的节拍（时钟）中断。用户可以配置的节拍中断频率，通常是在毫秒范围。  &apos;&apos;vTaskSwitchContext() &apos;&apos;函数在每次的节拍中断释放的时候被调用。 &apos;&apos;vTaskSwitchContext() &apos;&apos;选择优先级最高的就绪任务并将它赋予 &apos;&apos;pxCurrentTCB &apos;&apos;变量，如下所示：</span><br></pre></td></tr></table></figure></p><p>  /<em>从优先级最高的队列中找到就绪任务. </em>/<br>  while( listLIST_IS_EMPTY( &amp;( pxReadyTasksLists[ uxTopReadyPriority ] ) ) )<br>  {<br>      configASSERT( uxTopReadyPriority );<br>      –uxTopReadyPriority;<br>  }</p><p>  /<em> listGET_OWNER_OF_NEXT_ENTRY walks through the list, so the tasks of the same<br>  priority get an equal share of the processor time. </em>/<br>  listGET_OWNER_OF_NEXT_ENTRY( pxCurrentTCB, &amp;( pxReadyTasksLists[ uxTopReadyPriority ] ) );<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">在当型循环（while loop）开始之前，&apos;&apos;uxTopReadyPriority&apos;&apos;就被确保大于或等于优先级最高的就绪任务。while()循环从优先级&apos;&apos;uxTopReadyPriority&apos;&apos;开始，循环走下去从&apos;&apos;pxReadyTasksLists[]&apos;&apos;数组里找到就绪任务优先级最高的那个。接着&apos;&apos;listGET_OWNER_OF_NEXT_ENTRY()&apos;&apos;就抢占那个就绪列表中优先级最高的下一个就绪任务。</span><br><span class="line"></span><br><span class="line">现在&apos;&apos;pxCurrentTCB&apos;&apos;指向了优先级最高的任务，并且当&apos;&apos;vTaskSwitchContext()&apos;&apos;返回硬件相关代码时开始运行那个任务。</span><br><span class="line"></span><br><span class="line">**那九行代码是FreeRTOS的绝对核心。其余FreeRTOS的8900+行代码都是用来确保那九行代码，全都是用来保持优先级最高任务的运行的。**</span><br><span class="line"></span><br><span class="line">图3.2是一个大致的就绪列表看起来像什么的图。这个例子有三个优先级，有一个优先级为0的任务，没有优先级为1的任务，和三个优先级为2的任务。这张图是准确的，但不完整的；它的少掉一些细节，我们稍后将补充。</span><br><span class="line"></span><br><span class="line">![](/cdn/images/aosabook/75.png)</span><br><span class="line"></span><br><span class="line">图3.2：FreeRTOS的就绪列表的基本视图</span><br><span class="line"></span><br><span class="line">现在我们有了大致概述的方式，让我们去深究它的细节。我们将着眼于三个主要FreeRTOS的数据结构：任务，列表和队列。</span><br><span class="line"></span><br><span class="line">## 3.4.任务 ##</span><br><span class="line">所有操作系统的主要工作是运行和协调用户任务。像多数操作系统一样，FreeRTOS中的基本工作单元是任务。FreeRTOS的使用任务控制块（TCB）来表示每个任务。</span><br><span class="line">### 任务控制块（TCB) ###</span><br><span class="line">TCB的在&apos;&apos;tasks.c&apos;&apos;定义是这样的：</span><br></pre></td></tr></table></figure></p><p>  typedef struct tskTaskControlBlock<br>  {<br>    volatile portSTACK_TYPE *pxTopOfStack;         //指向任务堆栈的上一次项目位置，这必须是第一个成员结构</p><pre><code>xListItem    xGenericListItem;                 //用来放置就绪和阻塞队列中的TCB的列表项xListItem    xEventListItem;                  //用来放置事件列表中的TCB的列表项unsigned portBASE_TYPE uxPriority;            //任务的优先级，其中0是最低优先级portSTACK_TYPE *pxStack;                       //指向栈的开始位置signed char    pcTaskName[ configMAX_TASK_NAME_LEN ];  *任务创建时的描述性名称，只是为了便于调试#if ( portSTACK_GROWTH &gt; 0 )  portSTACK_TYPE *pxEndOfStack;                         *用于栈溢出时检查体系结构，当栈从低内存中长大时#endif#if ( configUSE_MUTEXES == 1 )  unsigned portBASE_TYPE uxBasePriority;                /* The priority last                                                            assigned to the task -                                                            used by the priority                                                            inheritance mechanism. */#endif</code></pre><p>  } tskTCB;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">TCB在&apos;&apos;pxStack&apos;&apos;里存储堆栈的起始地址，以及在&apos;&apos;pxTopOfStack&apos;&apos;里存储当前堆栈的顶部。如果堆栈“向上”增长到更高的地址，它还在&apos;&apos;pxEndOfStack&apos;&apos;存储堆栈的结束的指针来检查堆栈溢出。如果堆栈“向下”增长到更低的地址，那么通过比较当前堆栈的顶部与&apos;&apos;pxStack&apos;&apos;中的堆内存起始位置来检查溢出。</span><br><span class="line"></span><br><span class="line">TCB在&apos;&apos;uxPriority&apos;&apos;和&apos;&apos;uxBasePriority&apos;&apos;中存储任务的初始优先级。一个任务在它创建的时候被赋予优先级，同时任务的优先级是可以被改变的。如果FreeRTOS实现了优先级继承，那么当任务临时提升到“继承的”优先级时，它使用&apos;&apos;uxBasePriority&apos;&apos;去记住原来的优先级。（优先级继承，请参见下面关于互斥的讨论。）</span><br><span class="line"></span><br><span class="line">每个任务有两个清单项目给FreeRTOS操作系统的各种调度列表使用。当一个任务被插入到FreeRTOS的一个列表中，不会直接向TCB插入一个指针。取而代之的是，它向TCB的&apos;&apos;xGenericListItem&apos;&apos;或&apos;&apos;xEventListItem&apos;&apos;插入一个指针。这些&apos;&apos;xListItem&apos;&apos;变量，比起若是仅仅获得一个指向TCB的指针来说，让FreeRTOS的列表变得更加灵活。</span><br><span class="line"></span><br><span class="line">任务可以在以下四种状态之一：运行，准备运行，挂起或阻塞。你可能希望每个任务都有一个变量来告诉FreeRTOS它正处于什么状态，但事实上并非如此。相反，FreeRTOS通过把任务放入相应的列表：就绪列表，挂起列表等，隐式地跟踪任务状态。随着任务的变化，从一个状态到另一个，FreeRTOS的只是简单的将它从一个列表移动到另一个。</span><br><span class="line"></span><br><span class="line">### 任务设置 ###</span><br><span class="line">我们已经触及如何利用&apos;&apos;pxReadyTasksLists&apos;&apos;数组来选择和调度一个任务的；现在让我们来看一看一个任务最初是如何被创建的。当&apos;&apos;xTaskCreate()&apos;&apos;函数被调用的时候，一个任务被创建。FreeRTOS为一个任务新分配一个TCB对象，来记录它的名称，优先级，和其他细节，接着分配用户请求的总的堆栈（假设有足够使用的内存）和在TCB的&apos;&apos;pxStack&apos;&apos;成员中记录堆内存的开始。</span><br><span class="line"></span><br><span class="line">堆栈被初始化看起来就像一个已经在运行的新任务被上下文切换所中断。这就是任务调度处理最新创建的任务的方法，同样也是处理运行了一段时间的任务的方法；任务调度在不需要任何特殊（case）代码的情况下去处理新的任务。</span><br><span class="line"></span><br><span class="line">任务的堆栈建立看起来像是它通过上下文切换来被中断，这个方法是取决于FreeRTOS正在运行的架构，但这个ARM Cortex-M3处理器的实现是一个很好的例子：</span><br></pre></td></tr></table></figure></p><p>  unsigned int <em>pxPortInitialiseStack( unsigned int </em>pxTopOfStack,<br>                                       pdTASK_CODE pxCode,<br>                                       void <em>pvParameters )<br>  {<br>    /</em> Simulate the stack frame as it would be created by a context switch interrupt. <em>/<br>    pxTopOfStack–; /</em> Offset added to account for the way the MCU uses the stack on<br>                       entry/exit of interrupts. <em>/    </em>pxTopOfStack = portINITIAL_XPSR;  /<em> xPSR </em>/<br>    pxTopOfStack–;<br>    <em>pxTopOfStack = ( portSTACK_TYPE ) pxCode;  /</em> PC <em>/<br>    pxTopOfStack–;    </em>pxTopOfStack = 0;  /<em> LR </em>/<br>    pxTopOfStack -= 5;  /<em> R12, R3, R2 and R1. </em>/<br>    <em>pxTopOfStack = ( portSTACK_TYPE ) pvParameters;  /</em> R0 <em>/<br>    pxTopOfStack -= 8;  /</em> R11, R10, R9, R8, R7, R6, R5 and R4. */</p><pre><code>return pxTopOfStack;</code></pre><p>  }<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">当一个任务被中断的时候，ARM Cortex-M3处理器就压寄存器入堆栈。&apos;&apos;pxPortInitialiseStack()&apos;&apos;修改堆栈使之看来像是即便任务实际上还未开始运行，寄存器就已经被压入了。已知的值被存储到堆栈，赋给ARM寄存器xPSR，PC，LR，和R0。剩余的寄存器R1-R12获得由栈顶指针递减分配给它们的寄存器空间，但没有具体的数据存储在这些寄存器堆栈内。ARM架构告诉我们那些寄存器在复位的时候未被定义，所以一个（非弱智的）程序将不依赖于已知的值。</span><br><span class="line"></span><br><span class="line">堆栈准备好后，任务几乎是同时准备运行。首先，FreeRTOS禁用中断：我们将开始使用就绪列表和其他任务调度的数据结构，同时我们不希望它们被其他人背着我们私底下修改。</span><br><span class="line"></span><br><span class="line">如果这是被创建的第一个任务，FreeRTOS将初始化调度的任务列表。FreeRTOS操作系统的调度有一个就绪列表的数组，&apos;&apos;pxReadyTasksLists []&apos;&apos;为每一个可能的优先级提供一个就绪列表。FreeRTOS也有一些其他的列表用来跟踪任务的挂起，终止和延时。现在这些也都是初始化的。</span><br><span class="line"></span><br><span class="line">任何第一次初始化完成后，新的任务以它指定的优先级被加入就绪列表。中断被重新启用，同时新任务的创建完成。     </span><br><span class="line">## 3.5.列表 ##</span><br><span class="line">任务之后，最常用的FreeRTOS数据结构是列表。FreeRTOS使用列表结构来跟踪调度任务，并执行队列。</span><br><span class="line"></span><br><span class="line">![](/cdn/images/aosabook/77.png)</span><br><span class="line">图3.3：就绪列表全貌</span><br><span class="line"></span><br><span class="line">这个FreeRTOS的列表是一个有着几个有趣的补充的标准循环双链表。下面就是列表元素：</span><br></pre></td></tr></table></figure></p><p>  struct xLIST_ITEM<br>  {<br>    portTickType xItemValue;                   //被列出来的xListItem值，大部分情况下按照降序排列</p><pre><code>volatile struct xLIST_ITEM * pxNext;       //在列表中指向下一个xListItem的指针volatile struct xLIST_ITEM * pxPrevious;   //在列表中指向前一个xListItem的指针void * pvOwner;                            //包含列表项的指向对象的指针（通常是一个TCB对象）。因而是一个包含列表项和列表项本身的对象的双向连接。 void * pvContainer;                        // 指向列表项位置的指针（如果存在的话）</code></pre><p>  };<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">每个元素持有一个数字，&apos;&apos;xItemValue&apos;&apos;，这通常是一个被跟踪的任务优先级或者是一个调度事件的计时器值。列表保存从高到低的优先级指令，这意味着最高的优先级&apos;&apos;xItemValue&apos;&apos;（最大数）在列表的最前端，而最低的优先级&apos;&apos;xItemValue&apos;&apos;（最小数）在列表的末尾。</span><br><span class="line"></span><br><span class="line">&apos;&apos;pxNext&apos;&apos;和&apos;&apos;pxPrevious&apos;&apos;指针是标准链表指针。&apos;&apos;pvOwner &apos;&apos;列表元素所有者的指针。这通常是任务的TCB对象的指针。&apos;&apos;pvOwner&apos;&apos;被用来在&apos;&apos;vTaskSwitchContext()&apos;&apos;中加快任务切换：当最高优先级任务元素在&apos;&apos;pxReadyTasksLists[]&apos;&apos;中被发现，这个列表元素的&apos;&apos;pvOwner&apos;&apos;指针直接连接到需要任务调度的TCB。</span><br><span class="line"></span><br><span class="line">&apos;&apos;pvContainer&apos;&apos;指向自己所在的这个列表。若列表项处于一个特定列表它被用作快速终止。任意列表元素可以被置于一个列表，如下所定义：</span><br></pre></td></tr></table></figure></p><p>  typedef struct xLIST<br>  {<br>    volatile unsigned portBASE_TYPE uxNumberOfItems;<br>    volatile xListItem <em> pxIndex;           /</em> Used to walk through the list.  Points to<br>                                               the last item returned by a call to<br>                                               pvListGetOwnerOfNextEntry (). <em>/<br>    volatile xMiniListItem xListEnd;        /</em> List item that contains the maximum<br>                                               possible item value, meaning it is always<br>                                               at the end of the list and is therefore<br>                                               used as a marker. */<br>  } xList;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">列表的大小任何时候都是被存储在&apos;&apos;uxNumberOfItems&apos;&apos;中，用于快速列表大小操作。所有的列表都被初始化为容纳一个元素：&apos;&apos;xListEnd&apos;&apos;元素。&apos;&apos;xListEnd.xItemValue&apos;&apos;是一个定点值，当&apos;&apos;portTickType&apos;&apos;是16位数时，它等于&apos;&apos;xItemValue&apos;&apos;变量的最大值：0xffff，&apos;&apos;portTickType&apos;&apos;是32位数时为0xffffffff。其他的列表元素也可以使用相同的值；插入算法保证了&apos;&apos;xListEnd&apos;&apos;总是列表项中最后一个值。</span><br><span class="line"></span><br><span class="line">自列表从高到低排序后，&apos;&apos;xListEnd&apos;&apos;被用作列表开始的记号。并且，自循环开始，&apos;&apos;xListEnd&apos;&apos;也被用作列表结束的记号。</span><br><span class="line"></span><br><span class="line">你也许可以用一个单独的for()循环或者是函数调用来访问大多数“传统的”列表，去做所有的工作，就像这样：</span><br></pre></td></tr></table></figure></p><p>  for (listPtr = listStart; listPtr != NULL; listPtr = listPtr-&gt;next) {</p><pre><code>* Do something with listPtr here...</code></pre><p>  }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FreeRTOS经常需要通过多个for()和while()循环，也包括函数调用来访问列表，因此它使用操纵&apos;&apos;pxIndex&apos;&apos;指针的列表函数来遍历这个列表。这个列表函数&apos;&apos;listGET_OWNER_OF_NEXT_ENTRY()&apos;&apos;执行&apos;&apos;pxIndex = pxIndex-&gt;pxNext;&apos;&apos;并且返回&apos;&apos;pxIndex&apos;&apos;。（当然它也会正确检测列尾环绕。）这种，当执行遍历的时候使用&apos;&apos;pxIndex&apos;&apos;，由列表自己负责跟踪“在哪里”的方法，使FreeRTOS可以休息而不用关心这方面的事。</span><br><span class="line"></span><br><span class="line">![](/cdn/images/aosabook/76.png)</span><br><span class="line"></span><br><span class="line">图3.4：系统节拍计时器下的FreeRTOS就绪列表全貌</span><br><span class="line"></span><br><span class="line">&apos;&apos;pxReadyTasksLists[]&apos;&apos;列出了在&apos;&apos;vTaskSwitchContext()&apos;&apos;中已经操纵完成的内容，是如何使用&apos;&apos;pxIndex&apos;&apos;的一个很好的例子。让我们假设我们仅有一个优先级，优先级0，并且有三个任务在此优先级上。这与我们之前看到的基本就绪列表图相似，但这一次我们将包括所有的数据结构和字段。</span><br><span class="line"></span><br><span class="line">就如你在图3.3中所见，&apos;&apos;pxCurrentTCB&apos;&apos;显示我们当前正在运行任务B。下一个时刻，&apos;&apos;vTaskSwitchContext()&apos;&apos;运行，它调用&apos;&apos;listGET_OWNER_OF_NEXT_ENTRY()&apos;&apos;载入下一个任务来运行。如图3.4所示，这个函数使用&apos;&apos;pxIndex-&gt;pxNext&apos;&apos;找出下一个任务是任务C，并且&apos;&apos;pxIndex&apos;&apos;指向任务C的列表元素，同时&apos;&apos;pxCurrentTCB&apos;&apos;指向任务C的TCB。</span><br><span class="line"></span><br><span class="line">请注意，每个&apos;&apos;struct xlistitem&apos;&apos;对象实际上都是来自相关TCB的&apos;&apos;xGenericListItem&apos;&apos;对象。</span><br><span class="line"></span><br><span class="line">## 3.6.队列 ##</span><br><span class="line">FreeRTOS允许任务使用队列来互相间通信和同步。中断服务程序（ISRs）同样使用队列来通信和同步。</span><br><span class="line"></span><br><span class="line">基本队列数据结构如下：</span><br></pre></td></tr></table></figure></p><p>  typedef struct QueueDefinition<br>  {<br>    signed char <em>pcHead;                      /</em> Points to the beginning of the queue<br>                                                 storage area. <em>/<br>    signed char </em>pcTail;                      /<em> Points to the byte at the end of the<br>                                                 queue storage area. One more byte is<br>                                                 allocated than necessary to store the<br>                                               queue items; this is used as a marker. </em>/<br>    signed char <em>pcWriteTo;                   /</em> Points to the free next place in the<br>                                                 storage area. <em>/<br>    signed char </em>pcReadFrom;                  /<em> Points to the last place that a queued<br>                                                 item was read from. </em>/</p><pre><code>xList xTasksWaitingToSend;                /* List of tasks that are blocked waiting                                              to post onto this queue.  Stored in                                              priority order. */xList xTasksWaitingToReceive;             /* List of tasks that are blocked waiting                                              to read from this queue. Stored in                                              priority order. */volatile unsigned portBASE_TYPE uxMessagesWaiting;  /* The number of items currently                                                       in the queue. */unsigned portBASE_TYPE uxLength;                    /* The length of the queue                                                        defined as the number of                                                        items it will hold, not the                                                        number of bytes. */unsigned portBASE_TYPE uxItemSize;                  /* The size of each items that                                                        the queue will hold. */</code></pre><p>  } xQUEUE;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">这是一个颇为标准的队列，不但包括了头部和尾部指针，而且指针指向我们刚刚读过或者写过的位置。</span><br><span class="line"></span><br><span class="line">当刚刚创建一个队列，用户指定了队列的长度和需要队列跟踪的项目大小。&apos;&apos;pcHead&apos;&apos;和&apos;&apos;pcTail&apos;&apos;被用来跟踪队列的内部存储器。加入一个项目到队列就对队列内部存储器进行一次深拷贝。</span><br><span class="line"></span><br><span class="line">FreeRTOS用深拷贝替代在项目中存放一个指针是因为有可能项目插入的生命周期要比队列的生命周期短。例如，试想一个简单的整数队列使用局部变量，跨几个函数调用的插入和删除。如果这个队列在局部变量里存储这些整数的指针，当整数的局部变量离开作用域时指针将会失效，同时局部变量的存储空间将被新的数值使用。</span><br><span class="line"></span><br><span class="line">什么需要用户选择使用队列。若内容很少，用户可以把复制的内容进行排列，就像上图中简单整数的例子，或者，若内容很多，用户可以排列内容的指针。请注意，在这两种情况下FreeRTOS都是在做深拷贝：如果用户选择排列复制的内容，那么这个队列存储了每项内容的一份深拷贝；如果用户选择了排列指针，队列存储了指针的一份深拷贝。当然，用户在队列里存储了指针，那么用户有责任管理与内存相关的指针。队列并不关心你存储了什么样的数据，它只需要知道数据的大小。</span><br><span class="line"></span><br><span class="line">FreeRTOS支持阻塞和非阻塞队列的插入和移除。非阻塞队列操作会立即返回&quot;队列的插入是否完成?&quot;或者 &quot;队列的移除是否完成？&quot;的状态。阻塞操作则根据特定的超时。一个任务可以无限期地阻塞或者在有限时间里阻塞。</span><br><span class="line"></span><br><span class="line">一个阻塞任务——叫它任务A——将保持阻塞只要它的插入/移除操作没有完成，并且它的超时（如果存在）没有过期。如果一个中断或者另一个任务编辑了这个队列以便任务A的操作能够完成，任务A将被解除阻塞。如果此时任务A的队列操作仍然是允许的，那么它实际上会执行操作，于是任务A会完成它的队列操作，并且返回“成功”的状态。不过，任务A正在执行的那个时间，有可能同时有一个高优先级任务或者中断也在同一个队列上执行另一个操作，这会阻止任务A正在执行的操作。在这种情况下任务A将检查它的超时，同时，如果它未超时就恢复阻塞，否则就返回队列操作“失败”的状态。</span><br><span class="line"></span><br><span class="line">特别需要注意的是，当任务被阻塞在一个队列时，系统保持运行所带来的风险；以及当任务被阻塞在一个队列时，有其他任务或中断在继续运行。这种阻塞任务的方法能不浪费CPU周期，使其他任务和中断可以有效地使用CPU周期。</span><br><span class="line"></span><br><span class="line">FreeRTOS使用&apos;&apos;xTasksWaitingToSend&apos;&apos;列表来保持对正阻塞在插入队列里的任务的跟踪。每当有一个元素被移出队列，&apos;&apos;xTasksWaitingToSend&apos;&apos;列表就会被检查。如果有个任务在那个列表中等待，那个是未阻塞任务。同样的，&apos;&apos;xTasksWaitingToReceive&apos;&apos;保持对那些正阻塞在移除队列里的任务的跟踪。每当有一个新元素被插入到队列，&apos;&apos;xTasksWaitingToReceive&apos;&apos;列表就会被检查。如果有个任务在那个列表中等待，那个是未阻塞任务。</span><br><span class="line"></span><br><span class="line">### 信号灯和互斥 ###</span><br><span class="line">FreeRTOS使用它的队列与任务通信，也在任务间通信。FreeRTOS也使用它的队列来实现信号灯与互斥。</span><br><span class="line">#### 有什么区别 ####</span><br><span class="line">信号灯与互斥听上去像一回事，但它们不是。FreeRTOS同样地实现了它们，但本来它们以不同的方式被使用。它们是如何不同地被使用？嵌入式系统宗师Michael Barr说这是在他文章中写得最好的，“http://www.barrgroup.com/Embedded-Systems/How-To/RTOS-Mutex-Semaphore 信号灯与互斥揭秘”：</span><br><span class="line"></span><br><span class="line">&gt;正确使用的一个信号是从一个任务向另一个发信号。从每个使用被保护共享资源的任务来看，总是认为，一个互斥意味着获得和释放。相比之下，使用信号灯的任务不是发信号[在FreeRTOS里“发送”]就是在等信号[在FreeRTOS里“接收”]——不能同时。</span><br><span class="line"></span><br><span class="line">互斥被用来保护共享资源。一个使用共享资源的任务获得互斥，接着释放互斥。当有另一个任务占据互斥时，没有一个任务可以获得这个互斥。这就是保证，在同一时刻仅有一个任务可以使用共享资源。</span><br><span class="line"></span><br><span class="line">一个任务向另一个任务发信号时使用信号灯。以下引用Barr的文章：</span><br><span class="line"></span><br><span class="line">&gt;举例来说，任务一可能包含当“电源”按钮被按下时，发布（即，发信号或增加信号量）一个特定的信号灯的代码，并且唤醒显示屏的任务二，取决于同一个信号灯。在这种情况下，一个任务是发信号事件的制造者；另一个是消费者。</span><br><span class="line"></span><br><span class="line">如果你是在信号灯和互斥有任何疑问，请查阅Michael的文章。</span><br><span class="line"></span><br><span class="line">#### 实现 ####</span><br><span class="line"></span><br><span class="line">FreeRTOS像队列一样来实现一个N元素的信号灯，这样就可以控制N个项。它没有去存储队列每项的任何实际数据；信号灯只关心有多少在队列的&apos;&apos;uxMessagesWaiting&apos;&apos;字段中被跟踪的队列记录，目前正被占用。当FreeRTOS的头文件&apos;&apos;semphr.h&apos;&apos;调用它的时候，它正在做“纯同步”。因此这个队列有一个零字节的项 (&apos;&apos;uxItemSize == 0&apos;&apos;)。每个信号灯&apos;&apos;uxMessagesWaiting&apos;&apos;字段递增或递减；没有项或数据的复制是需要的。</span><br><span class="line"></span><br><span class="line">同信号灯一样，互斥也被实现为一个队列，不过有几个xQUEUE结构字段被用#defines重载：</span><br></pre></td></tr></table></figure></p><p>  /<em> Effectively make a union out of the xQUEUE structure. </em>/</p><p>  #define uxQueueType           pcHead</p><p>  #define pxMutexHolder         pcTail<br><code>`</code><br>当互斥没有在队列中存储任何数据时，它不需要任何内部存储器，同样’’pcHead’’和’’pcTail’’字段也不需要。FreeRTOS设置’’uxQueueType’’字段（实际上的’’pcHead’’字段）为0来表明，这个队列正在被一个互斥使用。FreeRTOS使用重载的’’pcTail’’字段来实现互斥的优先级继承。</p><p>万一你不熟悉优先级继承，我将再次引用Michael Barr的话来定义它，这次是来自他的文章，“ 优先级倒置 ”：</p><blockquote><p>[优先级继承]要求低优先级任务继承任何高优先级任务的优先级，取决于它们共享的资源。这个优先级的改变应当在高优先级任务一开始挂起时就发生；资源被释放时就结束。</p></blockquote><p>FreeRTOS使用’’pxMutexHolder’’字段（实际上是’’#define’’重载的’’pcTail’’字段）来实现优先级继承。FreeRTOS记录在’’pxMutexHolder’’字段里包含一个互斥的任务。当一个高优先级任务正在等待一个由低优先级任务取得的互斥，FreeRTOS“更新”低优先级任务到高优先级任务的优先级，直至这个互斥再次可用。</p><h2 id="3-7-结论"><a href="#3-7-结论" class="headerlink" title="3.7.结论"></a>3.7.结论</h2><p>我们完成了对FreeRTOS架构的一览。希望你现在对于FreeRTOS的任务是如何执行以及通信有一个好的感觉。如果之前你从未了解过操作系统的内在，我希望现在你对于它们是如何工作的有一个基本的思路。</p><p>显然，本章没有覆盖FreeRTOS架构的全部。值得注意的是，我没有提到的内存分配，中断服务，调试，或MPU支持。本章也没有讨论如何设置或使用FreeRTOS。Richard Barry已经写了一本极好的书， 使用FreeRTOS实时内核：实用指南 ，这本书就是讲这些内容的；如果你要使用FreeRTOS的话，我强烈推荐它。</p><h2 id="3-8-致谢"><a href="#3-8-致谢" class="headerlink" title="3.8.致谢"></a>3.8.致谢</h2><p>我想感谢Richard Barry创造和维护了FreeRTOS，并选择将它开源。在写这一章的时候Richard给予了极大的帮助，提供了关于FreeRTOS的历史以及非常有价值的技术回顾。</p><p>也感谢Amy Brown和Greg Wilson共同拉动这整个AOSA的事情。</p><p>最后也是最（最多），感谢我的妻子Sarah共同承担了我对本章的研究和写作。幸运的是，她在嫁给我的时候就知道我是一名极客。</p><h4 id="The-end"><a href="#The-end" class="headerlink" title="The end"></a>The end</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FreeRTOS&quot;&gt;&lt;a href=&quot;#FreeRTOS&quot; class=&quot;headerlink&quot; title=&quot;FreeRTOS&quot;&gt;&lt;/a&gt;FreeRTOS&lt;/h1&gt;&lt;p&gt;FreeRTOS(读作”free-arr-toss”)是一个嵌入式系统使用的开源实时操作系统
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Git</title>
    <link href="http://blog.ccao.cc/2018/09/28/Git/"/>
    <id>http://blog.ccao.cc/2018/09/28/Git/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h1 id="6-1-Git概述"><a href="#6-1-Git概述" class="headerlink" title="6.1 Git概述"></a>6.1 Git概述</h1><p>Git能够让不同的协作者通过一个点对点的仓库网络对数据内容（通常是代码，当然不仅限于代码）进行维护。它支持分布式的工作流程，能够让数据内容随时形成分支，并且最终可以合并。</p><p>本章将阐述Git的内部实现是如何提供以上功能的，以及它和其他版本控制系统（VCS）的区别。</p><h1 id="6-2-Git起源"><a href="#6-2-Git起源" class="headerlink" title="6.2 Git起源"></a>6.2 Git起源</h1><p>为了更好地理解Git的设计思想，了解一下Git项目的发源地——Linux内核开发社区——当时所面临的情况是很有益的。<br>Linux内核开发与同时期的其他商业软件项目有很大不同，因为它的开发者众多，且每个开发者的参与程度和对Linux内核代码的理解有很大差异。多年以来，内核代码一直都是以Tar压缩文件以及补丁的形式维护的，而当时的核心开发团队一直在寻找一个能够满足他们各方面需求的版本控制系统。</p><p>Git就是在这样的背景下于2005年作为一款开源软件诞生的。当时，Linux内核代码通过两种版本控制系统进行维护，BitKeeper和CVS，分别由两组核心开发团队开发。BitKeeper相较于当时颇为流行的CVS，提供了一种不同的历史展示方式。</p><p>当BitKeeper的所有者BitMover决定收回Linux内核开发人员的使用许可时，Linux Torvalds紧急开启了一个项目，也就是后来的Git。一开始，他通过编写一组Shell脚本来帮助他将邮件中的补丁按顺序应用到代码中。这组原始脚本能够在代码合并过程中迅速中断，让维护者能够进行人工干预，修改代码，然后继续合并。</p><p>从项目开始之初，Torvalds就为Git制定了一个目标——要和CVS的做法完全相反——同时还包含了以下三条设计目标：</p><ul><li>支持分布式的协作流程，类似BitKeeper</li><li>预防代码错乱</li><li>高性能<br>这些设计目标都被实现了，我会在下文中通过解析Git的各种做法来阐述，包括在内容管理中使用有向无环图（DAG），头指针引用，对象模型，远程协议，以及Git如何追踪树的合并。</li></ul><p>虽然Git设计之初受到了很多BitKeeper的影响，但是两者还是有根本上的区别的，如Git提供了更多分布式和本地开发流程，这点是BitKeeper做不到的。Monotone，2003年启动的一个开源分布式版本控制系统，也对Git的早期开发产生了影响。</p><p>分布式版本控制系统在提供更灵活的工作流程的同时，往往会使它的简易程度降低。分布式模型的独特优点有：</p><ul><li>能够线下进行增量提交</li><li>开发者可以决定自己的代码何时能够开放出来</li><li>能够线下浏览历史</li><li>可以将工作成果发布到不同的仓库，以不同的分支、不同的提交粒度展现出来<br>在Git项目的开发期间，诞生了其他三个开源分布式版本控制系统（其中Mercurial可以参见《开源软件架构》的第一卷）。这些分布式版本控制系统（dVCS）都提供了非常灵活的工作流程，这是先前的集中式版本控制系统做不到的。注意：Subversion有一款插件名为SVK，由不同的开发者维护，提供了服务器之间的同步功能。</li></ul><p>目前流行的dVCS包括Bazaar, Darcs, Fossil, Git, Mercurial, 以及Veracity。</p><h1 id="6-3-版本控制系统的设计"><a href="#6-3-版本控制系统的设计" class="headerlink" title="6.3 版本控制系统的设计"></a>6.3 版本控制系统的设计</h1><p>现在让我们回过头来看看Git之外的其他版本控制系统是如何设计的。通过比较他们和Git之间的区别，可以帮助我们去理解Git在架构设计中的选择。</p><p>版本控制系统通常有三项核心功能（需求）：</p><ul><li>保存内容</li><li>记录变更历史（包括具体的合并信息）</li><li>向协作者分发内容和变更历史<br>注意：第三项并不是所有版本控制系统的核心功能。</li></ul><h3 id="保存内容"><a href="#保存内容" class="headerlink" title="保存内容"></a>保存内容</h3><p>在VCS中保存内容，最普遍的做法是保存增量的修改，或使用有向无环图进行内容表示（DAG）。</p><p>增量修改可以反映出两个版本之间的内容差异，以及一些额外的元数据。有向无环图进行内容表示的方法则是指将对象形成一个层级结构，这个层级反映了文件系统的树状结构，会作为某一次提交的快照保存下来（树状结构中未发生变化的对象是可以重用的）。Git使用有向无环图来保存内容，有向无环图中使用的不同对象类型会在本文的“对象数据库”一节中有所描述。</p><h3 id="提交和合并的历史"><a href="#提交和合并的历史" class="headerlink" title="提交和合并的历史"></a>提交和合并的历史</h3><p>在保存历史、记录变化方面，大部分VCS使用以下方式之一：</p><ul><li>线性历史</li><li>有向无环图<br>Git使用的还是有向无环图，这次则是用来保存历史。每次提交包含了它父节点的元信息——Git中的一次提交可以拥有0个或多个父节点（理论上没有个数限制）。例如，Git仓库的第一次提交就没有父节点，而一次三头合并则有三个父节点。</li></ul><p>Git和SVN线性历史的另一个重要区别是Git可以直接进行分支的创建，并记录下大部分合并历史。</p><p><img src="/cdn/images/aosabook/71.png" alt=""><br>图6.1：Git中有向无环图示例</p><p>通过采用有向无环图保存内容，Git能够提供完整的分支功能。一个文件的历史会通过它所处的目录结构位置和根节点关联起来，并最终和一个提交节点关联。这个提交节点又会有一个或多个父节点。这种组织方式提供了以下两个特性，让我们能够更好地在Git浏览文件历史和内容：</p><ul><li>当内容节点（文件或目录）在有向无环图中有相同的标识（Git中以SHA码表示），即使它们处于不同的提交节点，也能保证它们的内容是一致的，从而使得Git在差异比对时更为高效。</li><li>在对两个分支进行合并时，实质上是在对两个有向无环图节点中的内容进行合并。有向无环图能够让Git更为高效地判断出他们共同的父节点。<h3 id="内容分发"><a href="#内容分发" class="headerlink" title="内容分发"></a>内容分发</h3></li></ul><p>版本控制系统在向协作者分发内容时通常有以下三种做法：</p><ul><li>仅限本地：某些版本控制系统没有上文提到的第三项需求。</li><li>中央服务器：版本库的所有改动都必须在一个中央版本库中进行，也只有这个版本库会记录历史。</li><li>分布式模型：虽然分布式模型中也会有一个中央仓库供协作者“推送”自己的改动，但协作者可以在本地进行提交，并稍后再推送到远程。<br>为了展示以上设计模式的优点和不足，我们设想这样一个应用场景：一个SVN仓库和一个Git仓库，有着相同的内容（即Git默认分支的头指针指向的内容和SVN仓库最新的trunk分支的最新版本一致）。一个名叫Alex的开发者在本地检出了一份SVN代码，以及克隆了一个Git版本库。</li></ul><p>假设Alex在本地SVN中对一个1M大小的文件进行了修改，并进行了提交。提交后本地更新了最近改变和本地元信息，远程服务器则是将文件的差异记录了下来。</p><p>Git下则有所不同。Alex对文件的变动首先会在本地进行记录，然后再“推送”到远程的公共仓库，这样文件的改动就能被其他开发者看到了。文件内容的变动记录在不同的版本库之中的表示方式是完全一致的。除了本地提交之外，Git会为变动后的文件创建一个对象来保存它（包括其完整的内容），然后用新的标识符逐层为该文件的父目录创建对象，直至仓库根目录。接下来Git会创建一个有向无环图，从刚才新创建的根目录节点开始，指向各个二进制单元（期间会重用那些内容没有改变的二进制单元），并使用新创建的二进制单元去替代那些变动的部分（一个二进制单元通常用来表示一个文件）。</p><p>到此为止，本次提交还是只保存在Alex克隆下来的本地仓库中。当Alex将这个提交推送到远程仓库后，远程仓库会验证这次提交是否能应用到当前分支中，然后这些对象将会按照原样保存下来，如同在本地仓库中创建的一样。</p><p>在Git中会有很多可变动的部分，有些对用户是透明的，有些则需要用户显示地指定这些内容是否需要分享出来，或是只在本地保存。虽然增加了复杂性，但也提供给团队开发者更大的自由度，得以更好地控制工作流程和发布内容，这在“Git起源”一节中已经有所阐述。</p><p>在SVN中，开发者不会忘记将变动内容提交至远程仓库。从效率上讲，SVN仅保存文件变动的方式会比Git保存文件每个版本的完整内容要来得高效，但是之后我们会讲述Git其实已经通过某种方式对此进行了优化。</p><h1 id="6-4-工具包"><a href="#6-4-工具包" class="headerlink" title="6.4 工具包"></a>6.4 工具包</h1><p>如今，Git已然形成一个生态系统，在各种操作系统上（包括Windows）都开发出了大量命令行和图界面工具，而他们大部分都是构建在Git核心工具包之上的。</p><p>由于Git是Linus发起和开发的，它又立足于Linux社区，因此Git工具包的设计理念和传统的Unix命令行工具相仿。</p><p>Git工具包分为两个部分：底层命令和上层命令。底层命令提供了基本的内容追踪手段，以及直接操纵有向无环图。上层命令则是用户主要接触的命令，用以维护仓库，以及在多个仓库间进行协作。</p><p>虽然Git工具包提供了足够多的命令来操纵仓库，但是开发者们还是抱怨Git没有提供类库以供调用。Git命令最终会执行die()方法，使得GUI和Web界面在使用它时必须启动一个新的进程，效率较低。</p><p>不过这一问题已经得到处理，将会在本文的“当前进展和未来规划”一节加以阐述。</p><h1 id="6-5-版本库、暂存区、工作区"><a href="#6-5-版本库、暂存区、工作区" class="headerlink" title="6.5 版本库、暂存区、工作区"></a>6.5 版本库、暂存区、工作区</h1><p>让我们开始深入研究一下Git吧，了解其中几个关键概念。</p><p>首先让我们在本地创建一个Git版本库。在类Unix系统下，我们可以执行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir testgit</span><br><span class="line">$ cd testgit</span><br><span class="line">$ git init</span><br></pre></td></tr></table></figure></p><p>这样我们就在testgit目录中初始化了一个新的版本库。我们可以建立分支、提交、创建标签、和远程Git仓库进行交互。我们甚至可以和其他类型的版本控制系统进行交互，只需要借助若干git命令即可。</p><p>git init命令会在testgit目录下创建一个名为.git的子目录。我们来看一下这个目录的结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">tree .git/</span><br><span class="line">.git/</span><br><span class="line"> |-- HEAD</span><br><span class="line"> |-- config</span><br><span class="line"> |-- description</span><br><span class="line"> |-- hooks</span><br><span class="line"> |    |-- applypatch-msg.sample</span><br><span class="line"> |    |-- commit-msg.sample</span><br><span class="line"> |    |-- post-commit.sample</span><br><span class="line"> |    |-- post-receive.sample</span><br><span class="line"> |    |-- post-update.sample</span><br><span class="line"> |    |-- pre-applypatch.sample</span><br><span class="line"> |    |-- pre-commit.sample</span><br><span class="line"> |    |-- pre-rebase.sample</span><br><span class="line"> |    |-- prepare-commit-msg.sample</span><br><span class="line"> |    |-- update.sample</span><br><span class="line"> |-- info</span><br><span class="line"> |    |-- exclude</span><br><span class="line"> |-- objects</span><br><span class="line"> |    |-- info</span><br><span class="line"> |    |-- pack</span><br><span class="line"> |-- refs</span><br><span class="line">     |-- heads</span><br><span class="line">     |-- tags</span><br></pre></td></tr></table></figure></p><p>.git目录默认创建在工作区的根目录下，也就是testgit。它包含了以下几种类型的文件和目录：</p><ul><li>配置文件： .git/config、.git/description、.git/info/exclude，这些文件会用来配置本地仓库。</li><li>钩子： .git/hooks目录下的脚本可以在Git运作的各个环节中得到执行。</li><li>暂存区： .git/index文件（它并没有在上述目录结构中显示出来）会用来保存工作区准备提交的内容。</li><li>对象数据库： .git/objects是默认的Git对象数据库存放目录，囊括了本地仓库的所有文件内容和指针。对象一经创建则不能修改。</li><li>引用：.git/refs目录用来存放本地和远程仓库的分支、标签、头指针等信息。“引用”表示指向某个对象指针，通常是tag和commit类型。引用之所以放置在对象数据库之外，是为了让他们能够随版本库的演进而变化。特殊的引用可以指向其他引用，如HEAD。<br>.git目录是真正意义上的版本库。工作区指的是包含所有工作文件的目录，它通常是.git目录的父目录。如果你需要创建一个没有工作区的远程仓库，可以使用git init –bare命令。它会直接在根目录下生成Git仓库的各类文件，而不是放置在一个子目录中。</li></ul><p>另一个较为重要的文件是Git暂存区：.git/index。它在工作区和本地版本库之间增加了一个缓冲区，可以将需要提交的内容暂存在这里，最后一起提交。即使你对很多文件进行了修改，通过暂存区可以将它们作为一次完整的提交，并加注合理的注释。如果想将工作区某些文件的部分修改保存至暂存区，可以使用git add -p命令。</p><p>Git暂存区里的内容默认保存在单个文件中。版本库、暂存区、工作区的存放位置都是可以通过环境变量来进行配置的。</p><p>我们有必要了解一下以上三个区域的文件是如何进行交互的，以几个核心的Git命令举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout [branch]</span><br></pre></td></tr></table></figure></p><p>这条命令会将HEAD引用指向指定分支的引用（如refs/heads/master），并用该引用指向的内容替换掉暂存区和工作区中的内容。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add [files]</span><br></pre></td></tr></table></figure></p><p>这条命令会检验工作区中指定的文件和暂存区是否一致，若不一致则更新暂存区。版本库不会发生变化。</p><p>为了深入挖掘其中的原理，让我们看看.git目录下的文件都发生了哪些变化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ GIT_DIR=$PWD/.git</span><br><span class="line">$ cat $GIT_DIR/HEAD</span><br><span class="line"></span><br><span class="line">ref: refs/heads/master</span><br><span class="line"></span><br><span class="line">$ MY_CURRENT_BRANCH=$(cat .git/HEAD  | sed &apos;s/ref: *g&apos;)</span><br><span class="line">$ cat $GIT_DIR/$MY_CURRENT_BRANCH</span><br><span class="line"></span><br><span class="line">cat: .git/refs/heads/master: No such file or directory</span><br></pre></td></tr></table></figure></p><p>这里会返回一个错误信息，因为我们还没有在Git仓库中进行过任何提交，因此不会存在任何分支，包括默认分支master。</p><p>让我们进行一次提交，这时master分支会自动创建：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ git commit -m &quot;Initial empty commit&quot; --allow-empty</span><br><span class="line">$ git branch</span><br><span class="line"></span><br><span class="line">* master</span><br><span class="line"></span><br><span class="line">$ cat $GIT_DIR/$MY_CURRENT_BRANCH</span><br><span class="line"></span><br><span class="line">3bce5b130b17b7ce2f98d17b2998e32b1bc29d68</span><br><span class="line"></span><br><span class="line">$ git cat-file -p $(cat $GIT_DIR/$MY_CURRENT_BRANCH)</span><br></pre></td></tr></table></figure></p><p>输出的内容就是Git对象数据库中保存的信息了。</p><h1 id="6-6-对象数据库"><a href="#6-6-对象数据库" class="headerlink" title="6.6 对象数据库"></a>6.6 对象数据库</h1><p><img src="/cdn/images/aosabook/72.png" alt=""><br>图6.2：Git对象</p><p>Git有四种基本对象类型，版本库中的所有内容都是由这些基本对象类型构成的。每种对象类型包含以下属性：类型、大小、内容。这四种基本对象类型是：</p><ul><li>树：用来表示目录结构，树中的元素可以是另一棵树或是一个二进制单元。</li><li>二进制单元：表示一个存储在版本库中的文件。</li><li>Commit：提交会指向一个根节点树对象，并保存父提交的信息和其他基本属性。</li><li><p>tag：tag有一个名称，并指向版本库中的一个提交对象。<br>所有的基本对象类型使用SHA码来标识，它是一种40位的十六进制字符串，含有以下特性：</p></li><li><p>如果两个对象是一致的，则SHA码一致。</p></li><li>如果两个对象不一致，则SHA码也不一致。</li><li>如果只是拷贝了对象的一部分，或者对象的数据发生了其他更改，只需重新计算其SHA码就能区别开来。</li></ul><p>SHA的前两个与标识有关的特性使得Git能够实施它的分布式模型（Git的第二个目标），第三种属性则是杜绝了数据混乱（第三个目标）。<br>使用基于DAG的内容存储与合并历史会有不错的效果，但仍然有很多增量存储仓库在空间消耗上会比使用松散的DAG对象高效。</p><h1 id="6-7-存储和压缩技术"><a href="#6-7-存储和压缩技术" class="headerlink" title="6.7 存储和压缩技术"></a>6.7 存储和压缩技术</h1><p>Git是通过压缩数据内容来解决存储大小的问题的，它使用一个索引文件来标识对象内容在压缩文件中的实际位置。</p><p><img src="/cdn/images/aosabook/73.png" alt=""><br>图6.3：压缩文件和它对应的索引文件</p><p>我们可以使用’git count-objects’来查看版本库中未经压缩的对象数量，然后让Git对未压缩的对象进行压缩，删除已经被压缩过的松散对象,需要的话用git探测(plumbing)命令找到冗余压缩文件。</p><p>Git对象的压缩方式进行过升级。过去，压缩文件和索引文件的CRC校验码会全部保存在索引文件中，这就无法检测出压缩对象中存在的数据混乱，因为再次压缩时不会再进行校验。新版本（Version 2）的压缩格式中将每个压缩对象的CRC校验码都保存在压缩索引文件，从而解决了这一问题。同时，新版格式允许压缩文件大于4GB，这在以前是不支持的。为了更快地检测压缩文件是否损坏，文件末尾会保存一个20个字节的SHA1码，对压缩文件中所有对象的SHA码进行排序和校验。新版压缩格式的主要目的是为了满足Git设计目标中的杜绝数据混乱。</p><p>对于远程传输，Git会计算同步版本库（或分支）需要传输的提交和文件内容，生成相应的压缩文件，通过客户端的指定协议进行传输。</p><h1 id="6-8-记录合并历史"><a href="#6-8-记录合并历史" class="headerlink" title="6.8 记录合并历史"></a>6.8 记录合并历史</h1><p>上文提到，Git和其它类RCS的版本控制系统的根本区别在于对合并历史的记录。如SVN将文件和目录结构的改动用线性提交来表示，版本号高的内容一定会覆盖版本号低的内容。因此，SVN不能直接提供分支功能，而是使用一种人为规定的目录结构来实现：</p><p><img src="/cdn/images/aosabook/71.png" alt=""></p><p>图6.4：合并历史的图形表示</p><p>首先让我们用一个示例来说明要维护多个分支会多么麻烦，而且在某些场景下是有局限性的。</p><p>SVN中的“分支”通常放置在branches/branch-name，它和主干分支trunk（相当于 master ）目录同级。我们假设这个分支和主干分支trunk是并行开发的。</p><p>举例来说，我们可能需要修改代码库使用一个不同的数据库。在此过程中，我们想要将其他分支（非trunk）的内容合并到当前分支branches/branch-name中。合并完成后（可能需要手工合并），我们继续修改。全部完成数据库迁移代码后，我们需要将当前分支branches/branch-name分支合并到trunk中。在类似SVN的线性历史版本控制系统中，我们无法得知其他分支的内容是否已经包含在trunk中了。</p><p>而对于以有向无环图为基础的版本控制系统（如Git）来说，就能很好地处理这种应用场景。如果某个分支不含没有合并至当前分支（如db-migration）的“提交”，我们就可以通过“提交”对象的继承关系来确定db-migration分支包含了那个分支的HEAD引用。由于“提交”对象可以包含零个或多个父提交，因此就能通过db-migration中的那次合并提交的信息来确定当前HEAD包含了两个分支中的内容。同理，当将db-migration合并至master分支时也能确认这些关系。</p><p>然而有一个问题无论是使用有向无环图还是线性提交都无法解决的，就是判断某个提交是否存在于每个分支中。例如上述例子中，我们假设已经将每个分支的提交都合并到各个分支去了。并不是所有情况下都是如此。</p><p>对于较为简单的情况，Git可以将其它分支的“提交”拣选（cherry-pick）到当前分支中，当然前提是这次提交必须是能够直接应用的。</p><h1 id="6-9-下一步做什么？"><a href="#6-9-下一步做什么？" class="headerlink" title="6.9 下一步做什么？"></a>6.9 下一步做什么？</h1><p>上文提到，Git核心采用来自Unix世界的工具包设计理念，因此非常适合用来编写脚本。但是，当需要在长时间运行的应用程序或服务中内嵌Git工具库的话就不太容易了。虽然目前流行的IDE都提供了Git图形化界面，但开发这些工具所需花费的精力还是比其他版本控制系统要多，因为它们提供了便于跨平台使用的链接分享库。</p><p>为了解决这个问题，Shawn Pearce（来自谷歌开源程序办公室）率先实现了一个可供链接的Git类库，且发布协议较为宽松，方便了该类库的推广。这个类库的名字是libgit2。一开始它并不流行，直到一个名叫Vincent Marti的学生在谷歌编程夏令营中使用了它。从那以后，Vincent和Github的工程师持续对libgit2类库贡献代码，并为其他语言编写了相应类库，包括Ruby，Python，PHP，.NET，Lua，Object-C等。</p><p>Shawn Pearce还开启了一个名为JGit的BSD项目，使用纯Java语言实现，能够对Git版本库进行基本的操作。该类库现在由Eclipse基金会维护，用于Eclipse IDE的Git插件中。</p><p>还有其他一些有趣的周边项目，带有实验性质，使用各类数据源来保存Git对象，如：</p><ul><li>jgit_cassandra 使用Apache Cassandra作为Git对象数据库。它是一种混合型的数据源，提供了动态的BigTable式的数据模型。 </li><li>jgit_hbase 能够将Git对象保存在HBase中，一种KV型分布式数据库。</li><li>libgit2-backends 由libgit2项目衍生而来，致力于提供其他种类的数据源，如Memcached，Redis，SQLite，MySQL。<br>以上这些都是独立于Git核心工具包之外的项目。</li></ul><p>如你所见，我们可以用各种方式来使用Git，它的表现形式不再只有命令行这一种了，而是成为一种版本控制系统的协议。</p><p>在本文撰写之时，这些项目都还没有发布稳定版本，所以还是有很多工作要做，但整体看来未来是光明的。</p><h1 id="6-10-经验教训"><a href="#6-10-经验教训" class="headerlink" title="6.10 经验教训"></a>6.10 经验教训</h1><p>在软件设计中，任何一个决定都有正反两面。作为一个在日常工作中大量使用Git，并且还为Git对象数据库开发了周边软件的程序员，我觉得Git目前的组织方式非常棒。因此，下文提到的“经验教训”更多的是来自其他开发者对于Git目前设计方式的不满，主要归咎于Git核心开发者当初做出的决定。</p><p>最常见的问题在于Git相较于其他CVS不能很好地和IDE进行整合，因为Git是基于工具包设计的，整合起来会比较具有挑战性。</p><p>早期Git的实现是采用shell脚本的方式，不能很好地跨平台，特别是对于Windows操作系统。虽然我相信Git开发者不会因为这个问题而寝食难安，但这的确阻碍了Git在大型公司内的推广。现在，有一个名为Git for Windows的项目由志愿者发起，及时地将最新的Git开发成果移植到Windows平台上。</p><p>Git工具包的设计方式所带来的另一个间接影响是，他的底层命令繁多，会让初学者陷入困境，难以理解Git出错时抛出的异常信息，最后无可适从。这就使得Git在某些开发团队中的推广受到阻碍。</p><p>即便如此，我仍然对Git核心项目以及其周边项目的开发充满信心。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Git&quot;&gt;&lt;a href=&quot;#Git&quot; class=&quot;headerlink&quot; title=&quot;Git&quot;&gt;&lt;/a&gt;Git&lt;/h1&gt;&lt;h1 id=&quot;6-1-Git概述&quot;&gt;&lt;a href=&quot;#6-1-Git概述&quot; class=&quot;headerlink&quot; title=&quot;6.1
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Graphite</title>
    <link href="http://blog.ccao.cc/2018/09/28/Graphite/"/>
    <id>http://blog.ccao.cc/2018/09/28/Graphite/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Graphite"><a href="#Graphite" class="headerlink" title="Graphite"></a>Graphite</h1><p>Graphite<sup>1</sup>执行两个相当简单的任务：存储随时间变化的数字并绘制它们。多年以来有许许多多的软件能做到同样的事情，Graphite能脱颖而出是因为它以易使用并且可扩展的网络服务的形式提供这个功能。向Graphite输送数据的协议简单到你能在几分钟内学会该怎么做（并不是因为你会想这么做，而是因为这是检测简单性的有效方法）。绘制图形和检索数据点容易的像获取一个网址。这使得Graphite和其它软件的结合非常自然并且让用户能够在Graphite的基础上建造出更强大的软件。Graphite最常见的用途是建造基于网络的用于监视和分析的仪表盘。Graphite诞生在高流量的电子商务环境下，它的设计也体现这一点。可扩展性和实时数据访问是主要目标。</p><p>让Graphite得已实现这些目标的部件包括一个专门的数据库及其存储结构、一个优化I/O操作的缓存机制和一个简单但有效的Graphite服务器聚集的方法。比起简单的描述Graphite现在是如何工作的，我更愿意解释Graphite最初是如何实现的（相当天真）、我遇到了什么问题以及我是如何解决这些问题的。</p><h2 id="7-1-数据库：存储时间序列数据"><a href="#7-1-数据库：存储时间序列数据" class="headerlink" title="7.1. 数据库：存储时间序列数据"></a>7.1. 数据库：存储时间序列数据</h2><p>Graphite完全用Python写成，它由三个主要部分构成：一个名为 <strong>whisper</strong> 的数据库，一个名为 <strong>carbon</strong> 的后端守护进程，以及一个显示图形并提供基本UI的前端web应用。虽然 <strong>whisper</strong> 是专门为Graphite写的，但是它也可以被单独使用。从设计上来说，它和RRDtool使用的RRD数据库十分相似，只存储时间序列数字数据。我们通常将数据库视为服务器进程，客户端应用通过sockets与之交互。但是 <strong>whisper</strong> 是一个被应用用来操作和获取存储在特殊格式文件中数据的数据库，这一点与RRDtool十分相似。最基本的 <strong>whisper</strong> 操作是 <strong>create</strong> 用于创建一个新的 <strong>whisper</strong> 文件， <strong>update</strong> 用于将新的数据点写到文件中，以及 <strong>fetch</strong> 用于获取数据点。</p><p><img src="/cdn/images/aosabook/1.png" alt="图7.1： **whisper** 文件的基本结构">　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　</p><p>像图7.1中展示的那样， <strong>whisper</strong> 文件由一个包含各种原数据的header节以及跟在其后的一个或多个archive节构成。每个archive都是一系列的连续数据点，这些数据点的格式为 <strong>(timestamp, value)</strong> 对。每当一个 <strong>update</strong> 或 <strong>fetch</strong> 操作被执行时， <strong>whisper</strong> 根据timestamp以及archive配置来确定数据在文件中被写入或读取的位置。</p><h2 id="7-2-后端：简单的存储服务"><a href="#7-2-后端：简单的存储服务" class="headerlink" title="7.2. 后端：简单的存储服务"></a>7.2. 后端：简单的存储服务</h2><p>Graphite的后端是一个名为 <strong>carbon-cache</strong> 的守护进程，简称 <strong>carbon</strong> 。它基于一个名为Twisted的高度可扩展的Python事件驱动I/O框架。Twisted使得 <strong>carbon</strong> 能够低开销的与大量客户端交互并处理大量数据。图7.2展示了 <strong>carbon</strong> ， <strong>whisper</strong> 以及web应用之间的数据流：客户端应用收集数据并将其发送给Graphite后端 <strong>carbon</strong> ，然后 <strong>carbon</strong> 通过 <strong>whisper</strong> 存储数据。这些数据则被web应用用来生成图形。</p><p><img src="/cdn/images/aosabook/2.png" alt="图7.2：数据流">　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　</p><p> <strong>carbon</strong> 主要的功能是存储客户端提供的度量的数据点。在Graphite术语中，一个度量是任何随时间变化的可测量的数量（比如一个服务器的CPU使用率以及产品的销量）。一个数据点就是一个 <strong>(timestamp, value)</strong> 对，其与某个时间点上对一个特定度量的测量值相一致。度量由他们的名字唯一确定，而它们的名字和其数据点一样由客户端应用提供。比较常见的客户端应用类型是监控代理，其功能是收集系统或应用度量并向 <strong>carbon</strong> 收集到的数据用于简易存储和可视化。Graphite中的度量有简单分层的名字，这和文件系统路径名十分相似，唯一的区别是用于分层的是点而不是斜杠或反斜杠。 <strong>carbon</strong> 接受任何合法的名字并且为每个度量创建一个 <strong>whisper</strong> 文件用于存储其数据点。 <strong>whisper</strong> 文件存储在 <strong>carbon</strong> 的数据目录下，其路径名由度量的名字映射而来，例如 <strong>servers.www01.cpuUsage</strong> 映射到 <strong>…/servers/www01/cpuUsage.wsp</strong> 。</p><p>每当一个客户端应用想要发送数据点给Graphite时，它都需要与 <strong>carbon</strong> 建立一个TCP连接，这个连接通常使用2003<sup>5</sup>端口。所有的数据发送都由客户端完成； <strong>carbon</strong> 在连接过程中不发送任何东西。客户端以简单的纯文本格式发送数据点，而这个连接可能会被保持以备后续使用。这个格式是每个数据点一行，每行包含度量名、值以及一个Unix时间戳，它们之间以空白分割。比如客户端也许会发送如下数据：</p><p>‘’servers.www01.cpuUsage 42 1286269200</p><p>products.snake-oil.salesPerMinute 123 1286269200</p><p>[one minute passes]</p><p>servers.www01.cpuUsageUser 44 1286269260</p><p>products.snake-oil.salesPerMinute 119 1286269260’’</p><p>从顶层来看， <strong>carbon</strong> 所做的所有事情就是监听这个格式的数据并通过 <strong>whisper</strong> 将其尽可能快的存储到磁盘上。稍后我们将会讨论一些在典型磁盘下用于保证可扩展性并且获取最佳表现的小技巧的细节。</p><h2 id="7-3-前端：请求式图形"><a href="#7-3-前端：请求式图形" class="headerlink" title="7.3. 前端：请求式图形"></a>7.3. 前端：请求式图形</h2><p>Graphite的web应用允许用户通过一个简单的基于URL的API来请求定制图形。绘图参数通过一个HTTP GET请求的查询字符串确定，一个PNG图形将会被返回给用户。例如如下URL:</p><p>‘’<a href="http://graphite.example.com/render?target=servers.www01.cpuUsage&amp;width=500&amp;height=300&amp;from=-24h&#39;&#39;" target="_blank" rel="noopener">http://graphite.example.com/render?target=servers.www01.cpuUsage&amp;width=500&amp;height=300&amp;from=-24h&#39;&#39;</a></p><p>为度量 <strong>servers.www01.cpuUsage</strong> 及其过去24小时的数据请求了一个500×300的图形。事实上，只有target参数是必须的；其他参数都是可选的，如果省略的话将会使用默认值。</p><p>Graphite支持很多显示选项以及数据操作函数，调用这些函数只需要通过一个简单的功能语法。比如我们可以按照以下格式为前例中的度量绘制一个有10个点的移动平均图:</p><p> <strong>target=movingAverage(servers.www01.cpuUsage,10)</strong> </p><p>考虑到复杂的表达式和计算，函数可以嵌套。</p><p>下面是另一个例子，它给出了当天的销量累计，其度量为每分钟的销量:</p><p>‘’target=integral(sumSeries(products.*.salesPerMinute))&amp;from=midnight’’</p><p> <strong>sumSeries</strong> 函数计算出匹配 <strong>products.*.salesPerMinute</strong> 的度量之和的时间序列。随后 <strong>integral</strong> 计算出累计和而不是每分钟的数量。由此不难想象应该如何构建一个网站UI来查看和操作图形。像图7.3中展示的那样，Graphite有它自己的Composer UI，这个UI能随着使用者点击各个选项通过Javascript来修改图形的URL参数。</p><p><img src="/cdn/images/aosabook/3.png" alt="图7.3：Graphite的Composer界面">　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　</p><h2 id="7-4-仪表盘"><a href="#7-4-仪表盘" class="headerlink" title="7.4. 仪表盘"></a>7.4. 仪表盘</h2><p>从一开始Graphite就作为创建基于网站的仪表盘的工具被使用。URL API使得这成为一个非常自然的使用方法。创建一个仪表盘就和创建一个满是如下标签的HTML页面一样简单：</p><p><code>&lt;img src=&quot;../http://graphite.example.com/render?parameters-for-my-awesome-graph&quot;&gt;</code></p><p>但是，不是每个人都喜欢手动处理URL，因此Graphite的Composer UI提供了一个点击式的方法来创建一个图形，通过这个方法用户只需要复制粘贴URL就可以达到目的。当Graphite和另外一个允许快婿创建网站页面的工具（如wiki）结合使用时，创建仪表盘将会简单到非技术用户也能轻松搞定。</p><h2 id="7-5-一个明显的瓶颈"><a href="#7-5-一个明显的瓶颈" class="headerlink" title="7.5. 一个明显的瓶颈"></a>7.5. 一个明显的瓶颈</h2><p>我的用户一开始创建仪表盘，Graphite很快就遇到了性能上的问题。我研究了网站服务器日志来查看是什么请求让它陷入了泥沼。结果表明问题出在绘图请求的数目上。由于一直在渲染图形，web应用遇到了CPU瓶颈。我发现Graphite收到了大量相同的请求，而这是由仪表盘造成的。</p><p>想象一下已有一个包含10张图的仪表盘，它每分钟刷新一次。每当一个用户在浏览器中打开这个仪表盘，Graphite每分钟就需要多处理10张图。这个代价很快就变得十分的高昂。<br>一个简单的解决方案是每个图形只绘制一次，而每当用户发出请求时就返回给他们这个图形的复制品。Django网站框架（Graphite基于其建造）提供了一个极佳的快速缓存机制，它可以使用多种后端比如分布式内存对象缓存系统。分布式内存对象缓存系统<sup>3</sup>本质上就是一个作为网络服务提供的哈希表。客户端应用可以像操作普通的哈希表一样获取和设置键值对。使用分布式内存对象缓存系统最主要的好处是一个高代价请求（如渲染一个图形）的结果可以被快速存储并且在处理接下来的请求的时候被取出。为了避免一直返回同一张图，该系统可以被配置为每隔一段时间清空缓存的图形。即使这个间隔只有几秒，其为Graphite减轻的负担也是巨大的，因为重复的请求太频繁了。</p><p>另一个造成大量渲染请求的情况是用户在Composer UI中改变显示选项和应用函数。用户每次改变某些东西，Graphite都必须重新绘制图形。每个请求都包含了相同的数据，因此将基本数据存储到分布式内存对象缓存系统中也是十分重要的。这使得UI能够保持对用户的响应，因为获取数据的步骤被跳过了。</p><h2 id="7-6-优化I-O"><a href="#7-6-优化I-O" class="headerlink" title="7.6. 优化I/O"></a>7.6. 优化I/O</h2><p>想象一下你有60,000个度量需要发送到你的Graphite服务器上，并且每个度量每分钟都有一个数据点。要知道每个度量在文件系统中都有自己的 <strong>whisper</strong> 文件。这意味着 <strong>carbon</strong> 每分钟需要对60,000个不同的文件进行一次写操作。只要 <strong>carbon</strong> 能够每1ms完成一次写操作，这些数据就能够处理完。这确实不难达到，但假如你每分钟有600,000个度量需要更新，或者你的度量每秒钟更新一次，或者你仅仅不能提供足够快的存储，不管是哪种情况，假定数据到来的速度超过了你的存储能够提供的写操作的速度，这个问题应该如何解决？<br>现在大多数的硬盘都有缓慢的寻找时间<sup>4</sup>，这个缓慢的寻找时间是指和写入一系列连续的数据相比，在两个不同位置进行I/O操作的延时。这就意味着我们进行越多的连续写操作，效率就越高。但是如果我们需要在成千上万的文件中经常进行写操作，并且每次写操作数据量都十分小（一个 <strong>whisper</strong> 数据点仅有12字节），那么我们的硬盘就肯定会花大量的时间在寻找上。</p><p>在写操作速率有一个相对较低顶点的前提下，唯一让数据点流通量超过这个速率的办法就是在单个写操作内写多个数据点。由于 <strong>whisper</strong> 将连续的数据点连续的存放在硬盘上，所以这是可行的。因此我为 <strong>whisper</strong> 增加了一个名为 <strong>update_many</strong> 的函数，其功能是获取一个度量的一系列数据点然后将它们压缩到一个写操作内。尽管这使得每次写操作数据量变大，但是写十个数据点（120字节）和写一个数据点（12字节）在时间上的区别是可以忽略的。在不明显影响时间的前提下，这个函数会尽可能多的获取数据点。</p><p>随后我在 <strong>carbon</strong> 中实现了一个缓冲机制。每个到来的数据点都被映射到一个基于其度量名的队列中并添加到队尾。另一个线程不停的遍历所有的队列，取出所有数据点并将它们通过 <strong>update_many</strong> 写到对应的 <strong>whisper</strong> 文件中。现在我们回到之前的例子上，假如我们有600,000个每分钟更新一次的度量，我们的存储设备仅能支持每1ms一次写操作，那么每个队列就会平均保有10个数据点。这个策略唯一消耗的资源就是内存，而这个是相对较充裕的，因为每个数据点都只有十几个字节。</p><p>这个策略动态的缓冲尽可能多的数据点以维持数据点到来的速率，保证其不超过存储设备能提供的I/O操作速率。这个方法一个明显的优点是它增加了一定的弹性以解决临时的I/O速率降低问题。如果系统需要进行其它Graphite之外的I/O工作，那么写操作的速率很有可能就会降低，这个时候的 <strong>carbon</strong> 队列就会增长。队列越大，写的越多。因为所有的数据点流通量等于写操作速率乘以每次写操作的平均大小，所以只要还有足够的内存用于存放队列， <strong>carbon</strong> 可以继续运行。 <strong>carbon</strong> 的队列机制如图7.4所示。</p><p><img src="/cdn/images/aosabook/4.png" alt="图7.4： **carbon** 的队列机制">　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　</p><h2 id="7-7-保证实时"><a href="#7-7-保证实时" class="headerlink" title="7.7. 保证实时"></a>7.7. 保证实时</h2><p>缓冲数据点是一个很棒的优化 <strong>carbon</strong> 的I/O的方式，但是很快我的用户就发现了一个相当麻烦的副作用。回到我们之前的例子，我们有600,000个每分钟更新一次的度量，并且我们的存储设备只能提供每分钟60,000次写操作。这意味着我们在任意时间都有将近10分钟的数据被保存在 <strong>carbon</strong> 的队列中。对用户来说，这就意味着他们向Graphite的web应用请求的图形会确实最近10分钟的数据:这无疑非常糟糕。</p><p>幸运的是解决方案是十分直接的。我为 <strong>carbon</strong> 添加了一个socket监听器，它为访问缓冲的数据点提供了一个查询接口，然后我修改了Graphite的web应用，使得它每次获取数据时都调用这个接口。接着web应用就把它从 <strong>carbon</strong> 中获取的数据和从磁盘中获取的数据结合起来，于是图形就是实时的了。就算在我们的例子中数据点是每分钟更新一次因此不算严格意义上的实时，但是事实上，图形中的数据点只要可以被访问到就会马上被 <strong>carbon</strong> 获取，因此它是实时的。</p><h2 id="7-8-内核、缓存以及灾难性错误"><a href="#7-8-内核、缓存以及灾难性错误" class="headerlink" title="7.8. 内核、缓存以及灾难性错误"></a>7.8. 内核、缓存以及灾难性错误</h2><p>现在不难看出，Graphite的一个关键特点是其性能取决于它的I/O延时。之前我们一直假设我们系统的I/O延时始终较低，平均每次写操作1ms，但这是一个巨大的需要一些深入分析的假设。大部分硬盘根本没有那么快的速度；即使是磁盘阵列中的磁盘，随机访问的延迟也很可能超过1ms。但是即使你在一个老旧的笔记本电脑上测试向硬盘中写1KB的数据的速度，你也会发现写操作系统调用会在远小于1ms的时间内返回，这是为什么呢？</p><p>当软件有不一致的或不符合预期的性能特性时，其原因通常是缓冲或缓存。在目前的情况下，我们两个方面都要处理。写操作系统调用严格意义上并不会把你的数据写到硬盘上，它仅仅将数据放到一个缓冲区中，内核会在之后将其中的数据写到硬盘中。这就是调用写操作返回的速度极快的原因。就算在缓冲区中的内容被写到硬盘中之后，这些数据也会被缓存以备接下来的读取。当然，缓冲和缓存都需要内存。</p><p>聪明的内核开发者认为使用当前空闲的用户空间内存是一个比永久分配内存更好的主意。事实证明这是一个非常有效的性能促进方法，而且这也解释了为什么不管你为一个系统添加了多少内存，空闲内存都会在不多的I/O操作之后几乎降到0。如果你的用户空间应用没有在使用那些内存，那么很可能就是你的内核在使用它们。这个方法不好的地方就是当用户空间应用确定需要为自己分配更多的内存时，这些空闲内存就可能被从内核中拿走。而内核除了让出内存没有别的选择，从而就会丢失那块内存中所有的缓冲数据。</p><p>那么所有的这些对Graphite意味着什么呢？我们刚刚强调了 <strong>carbon</strong> 对始终较低的I/O延时的依赖，并且我们也知道写操作系统调用能够迅速返回仅仅只因为数据只是被复制到一个缓冲中。那么当系统中没有足够的内存来让内核继续缓冲写操作数据时会发生什么呢？写操作会并发从而变得极其缓慢！这会导致 <strong>carbon</strong> 的写操作速率极大的降低，进一步导致 <strong>carbon</strong> 的队列增长，而这又需要更多的内存，使得内核陷入恶性循环中。最后，这种情况通常会导致 <strong>carbon</strong> 用光内存或者被愤怒的系统管理员杀死进程。</p><p>为了避免这种灾难，我向 <strong>carbon</strong> 中添加了几种特性，包括可配置的队列中数据点数目限制以及各种 <strong>whisper</strong> 操作的速率限制。这些特性可以避免 <strong>carbon</strong> 失控，并且使得如丢失数据点或者拒绝接受更多数据点这样不好的影响更少。但是这些设置的合适的值是系统相关的，并且需要不少的测试来调整。它们是很有用的，但是不能从根本上解决问题，这需要更多的硬件。</p><h2 id="7-9-集群"><a href="#7-9-集群" class="headerlink" title="7.9. 集群"></a>7.9. 集群</h2><p>从用户的角度来看，让多个Graphite服务器表现的像一个系统一样应该不是那么困难。Web应用的用户交互主要由两个操作构成：寻找度量和获取数据点（通常以图的形式获取）。Web应用的寻找和获取操作被隐藏在一个类库中，这个类将它们的实现从其它代码中抽象出来，这两个操作可以很轻松的通过HTTP请求处理器进行远程调用。</p><p> <strong>find</strong> 操作会在 <strong>whisper</strong> 数据的本地文件系统中寻找匹配一个用户指定模式的文件，就像 <strong>*.txt</strong> 匹配与其有相同扩展名的文件一样。 <strong>find</strong> 返回的结果是一系列 <strong>Node</strong> 对象，构成一个树状结构，每个 <strong>Node</strong> 对象都来源于 <strong>Node</strong> 的子类 <strong>Branch</strong> 或 <strong>Leaf</strong> 。路径与分支节点一致， <strong>whisper</strong> 文件与叶节点一致。这种抽象层次使得系统可以很轻松的支持包括RRD文件<sup>5</sup>在内的不同种类的基础存储以及gzip压缩的 <strong>whisper</strong> 文件。</p><p> <strong>Leaf</strong> 接口定义了一个 <strong>fetch</strong> 方法，其实现取决于叶节点的类型。如果是 <strong>whisper</strong> 文件，那么这个方法就是 <strong>whisper</strong> 库的 <strong>fetch</strong> 函数加上一层简单的封装。当添加了集群支持时， <strong>find</strong> 函数会被扩展，从而可以通过HTTP向web应用配置指定的其它Graphite服务器进行远程 <strong>find</strong> 调用。这些从HTTP调用中获取的节点数据会被封装成RemoteNode对象，这个对象与 <strong>Node</strong> ， <strong>Branch</strong> 和 <strong>Leaf</strong> 接口相一致。这使得集群对于web应用的其它代码变得透明。远程叶节点的 <strong>fetch</strong> 方法被实现为从节点的Graphite服务器获取数据点的HTTP调用。</p><p>这些调用在web应用之间的使用方式和客户端调用的使用方式一样，除了一个额外的参数用来指定该操作应该在本地执行并且不在集群中再分配。当web应用需要渲染一个图时，它会执行 <strong>find</strong> 操作来定位指定的度量并且在每个服务器上调用 <strong>fetch</strong> 来获取对应的数据点。不管数据是在本地服务器、远程服务器或者两者都有，这个流程都是有效的。如果一个服务器宕机了，远程调用很快就会超时，并且该服务器会在一段时间内被标记为停止服务，在这期间不会有远程调用指向它。从用户角度来看，无法被访问的服务器上的所有数据都会在图上缺失，除非这些数据在集群中的另一个服务器上有备份。</p><h3 id="7-9-1-集群效率的简单分析"><a href="#7-9-1-集群效率的简单分析" class="headerlink" title="7.9.1. 集群效率的简单分析"></a>7.9.1. 集群效率的简单分析</h3><p>一个绘图请求中开销最大的部分就是渲染图形。每个渲染操作都由单个服务器执行，因此添加更多的服务器可以有效的提高渲染图形的性能。但是，事实上很多请求最后都会向集群中的其它服务器执行 <strong>find</strong> 调用，这意味着我们的集群会共享大部分的前端负载而不是分散它。不过由于每个 <strong>carbon</strong> 请求都是独立执行的，因此在这一方面我们已经实现了一个有效的分散后端负载的方法。这无疑是极好的，因为大部分时间后端瓶颈会远在前端瓶颈之前达到，而且很明显前端不会因为这个方法而横向扩展。</p><p>为了使前端更有效的扩展，web应用执行的远程 <strong>find</strong> 调用的数量必须减少。同样的，最简单的解决方案还是缓存。上文中我们提到了分布式内存对象缓存系统被用于缓存数据点和绘制的图形，它同样可以用来缓存 <strong>find</strong> 请求的结果。由于度量的位置不太可能经常改变，因此它通常可以被缓存更长的时间。但是为 <strong>find</strong> 请求的结果设置较长的缓存时间的代价就是新添加的度量在用户看来可能会比较慢。</p><h3 id="7-9-2-在集群中分散度量"><a href="#7-9-2-在集群中分散度量" class="headerlink" title="7.9.2. 在集群中分散度量"></a>7.9.2. 在集群中分散度量</h3><p>Graphite的web应用在整个集群中都是几乎一样的，因此它在每个服务器上都执行完全相同的任务。但是 <strong>carbon</strong> 的角色可以在不同服务器上有所区别，它取决于你选择的要发送给每个请求的数据。通常会有很多不同的客户端发送数据给 <strong>carbon</strong> ，因此连接客户端的配置和Graphite集群布局是一件非常烦人的事情。应用度量可能需要发送到一个 <strong>carbon</strong> 服务器，而事务度量可能需要发送到多个 <strong>carbon</strong> 服务器以保证冗余性。</p><p>为了简化对这种情况的管理，Graphite添加了一个额外的名为 <strong>carbon-relay</strong> 的工具。它的工作非常简单；它像标准 <strong>carbon</strong> 守护进程（实际上叫 <strong>carbon-cache</strong> ）一样从客户端接受度量数据，但它并不存储这些数据，而是通过一个规则集对度量名进行检测，从而决定应该把这些数据发送到哪个 <strong>carbon-cache</strong> 服务器上。每条规则都由一个正则表达式和一个目标服务器列表构成。对于每个收到的数据点，规则集都会按顺序检测，第一个正则表达式和度量名匹配的规则会被使用。这样一来，客户端需要做的所有事情就是把数据发送到 <strong>carbon-relay</strong> ，而它会把这些数据都发送到正确的服务器上。</p><p>从某种意义上来说， <strong>carbon-relay</strong> 提供了复制功能，不过更精确的说这应该叫输入复制，因为它并不涉及到同步问题。如果一个服务器临时宕机，那么在这段时间内数据点就会缺失，但功能任然正常。此外，有不少管理脚本将再同步过程交给系统管理员控制。</p><h2 id="7-10-设计反思"><a href="#7-10-设计反思" class="headerlink" title="7.10. 设计反思"></a>7.10. 设计反思</h2><p>设计Graphite的经验再次证明了我的一个观点，那就是可扩展性与底层性能相关性不大，相反，它是整体设计的产物。我在整个过程中遇到了很多瓶颈，但每次我都是寻找设计上的改进而不是性能上的加速。我曾经被问到过很多次为什么我要用Python写Graphite而不是Java或者C++，而我的回答始终是我还没有遇到过另一种语言可以像Python这样提供对性能真正的需求。在[[<a href="http://aosabook.org/en/bib1.html#bib:knuth:goto|[Knu74]]]" target="_blank" rel="noopener">http://aosabook.org/en/bib1.html#bib:knuth:goto|[Knu74]]]</a>, Donald Knuth曾说过一句很有名的话“过早的最优化是万恶之源”。只要我们还坚信我们的代码可以继续以不平凡的方式进化，那么所有的最优化<sup>6</sup>从某种意义上来说都是过早的。</p><p>Graphite一个最大的优点同时也是最大的缺点就是它只有很少一部分是真正按照传统观念设计的。随着问题增加，Graphite也在一个一个的克服障碍逐渐进化。很多时候这些障碍都是可以预见的，并且有各种看起来十分合理的前瞻性的解决方案。但是避免解决你还没有遇到的问题是有用的，不管你有多可能马上就会遇到这个问题。其原因是相比于优秀策略的理论，仔细研究失败能让你学到更多。问题解决是由我们手中的经验数据和我们的知识以及直觉共同驱动的。我发现充分的质疑你的智慧可以迫使你更加全面的检视你的经验数据。</p><p>比如，当我刚开始写 <strong>whisper</strong> 我坚信它会由C语言写成以提高速度，而我的Python实现只是一个原型。如果我不是赶时间的话我很有可能会完全丢弃掉Python实现。而最后I/O瓶颈远比CPU瓶颈更早达到，因此Python较低的效率在实践中几乎无关紧要。</p><p>但是就像我说的，Graphite的进化方式也是它一个巨大的缺点。从结果来看，接口并不能很好的适应这种逐渐发展的过程。一个好的接口应该是一致的并且能通过约定来最大化可预测性。按照这种标准来看，Graphite的URL API目前是一个低于平均水平的接口。选项和功能随时间推移被添加到系统中，有时候会达成局部的一致性，但总体上缺乏整体的一致性。解决这个问题唯一的办法是通过接口的版本控制，但是这也有缺点。新的接口被设计出来之后，之前的那个仍然很难摆脱，于是便作为进化的包袱遗留下来，就像人的阑尾一样。它可能看上去足够无害，直到有一天你的代码得了阑尾炎（i.e.和旧接口相关的一个BUG）于是你必须进行手术。如果我在早期需要更改Graphite的一个部分，那么我就要花更大的精力在设计外部接口上，因为我需要提前想好而不是一点点的改进它们。</p><p>Graphite另一个造成了一些挫折的部分是不灵活的分层度量命名模型。虽然它十分简单并且在大多数情况下十分方便，但是它也导致了一些复杂的请求变得十分困难甚至无法表示。当我刚开始考虑创造Graphite时，我就十分明确我想要的是一个用于创建图<sup>7</sup>的可以人工编辑的URL API。尽管我对Graphite提供了这个功能感到十分高兴，但是由于过分简单的语法使得复杂表达式变得十分庞大，我担心这个要求让API陷入了沉重的负担中。分层使得检测度量的主关键字变得十分简单，因为一个路径从本质上来说就是树上的一个主关键字节点。其副作用就是所有的描述数据（i.e.列数据）都必须直接嵌入到路径中。一个可能的解决方案是保持分层模型并添加一个单独的元数据数据库，使得用户能通过特殊语法对度量进行更高级的选择。</p><h2 id="7-11-开源"><a href="#7-11-开源" class="headerlink" title="7.11. 开源"></a>7.11. 开源</h2><p>回顾Graphite的发展过程，它作为项目走了很远，而我也因为它走了很远，深入的程度至今仍让我感到惊讶。Graphite开始于一个只有几百行代码的小程序。渲染引擎则开始于一次实验，而这个实验仅仅只是看看我是否能写出来一个渲染引擎。 <strong>whisper</strong> 是在一个周末的课程上写出来的，仅仅是出于要在严格的上市时间前解决一个show-stopper问题的绝望。 <strong>carbon</strong> 被重写的次数已经多到我不想记了。当我在2008年被允许在开源许可下发布Graphite时，我根本没期待有多少回应。几个月后它在一片CNET的文章中被提到，而这篇文章又被Slashdot选中了，于是这个项目马上就火了起来并且一直活跃到现在。如今有几十个大中型公司使用Graphite。Graphite社区也十分活跃并且人数一直在增长。但它还远不是一个完成的项目，还有很多十分炫酷的实践性工作要做，而这使得它保持有趣并且充满潜力。</p><h2 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h2><ol><li><p><strong><a href="http://launchpad.net/graphite" target="_blank" rel="noopener">http://launchpad.net/graphite</a></strong> </p></li><li><p>序列化对象可以发送到另一个端口，比纯文本格式更加有效。这个只有在流量非常大时才需要使用。</p></li><li><p><strong><a href="http://memcached.org" target="_blank" rel="noopener">http://memcached.org</a></strong> </p></li><li><p>和传统硬盘相比，固态硬盘有极快的寻找时间。</p></li><li><p>RRD文件实际上是分支节点，因为他们包含多个数据源；一个RRD数据源是一个叶节点。</p></li><li><p>Knuth特质底层代码优化，而不是指如改进设计等宏观优化。</p></li><li><p>这要求图片开源。任何人都可以查看图片的URL来理解或修改它。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Graphite&quot;&gt;&lt;a href=&quot;#Graphite&quot; class=&quot;headerlink&quot; title=&quot;Graphite&quot;&gt;&lt;/a&gt;Graphite&lt;/h1&gt;&lt;p&gt;Graphite&lt;sup&gt;1&lt;/sup&gt;执行两个相当简单的任务：存储随时间变化的数字并绘制它
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>LLVM</title>
    <link href="http://blog.ccao.cc/2018/09/28/LLVM/"/>
    <id>http://blog.ccao.cc/2018/09/28/LLVM/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.669Z</updated>
    
    <content type="html"><![CDATA[<p>这一章节讨论了一些对 LLVM((<a href="http://llvm.org" target="_blank" rel="noopener">http://llvm.org</a> )) 有重大影响的设计决策。LLVM 是涵盖一系列紧密结合的底层工具链组件（比如汇编器、编译器、调试器等）的维护和开发的总项目，设计目标是与现有的工具兼容，特别是 Unix 系统的工具。”LLVM” 曾经是一个缩写词，但是现在仅仅是这个项目的代名词。虽然 LLVM 有一些独特的功能，并且因其优秀的工具而出名（比如 Clang 编译器((<a href="http://clang.llvm.org" target="_blank" rel="noopener">http://clang.llvm.org</a> ))，一个比 GCC 更好用的 C/C++/Objective-C 的编译器），但 LLVM 的内部架构才是它与其它编译器区分开来的主要原因。</p><p>自 2000 年 12 月项目诞生起，LLVM 便致力于提供一组接口清晰的的可复用库。当时，开源编程语言的具体实现只针对特定用途，往往是单体的可执行文件。在静态分析和代码重构时，这不利于复用静态编译器（比如 GCC）的语法分析器。虽然脚本语言经常提供将运行时和解释器嵌入更大规模的应用中的方法，但是它们的运行时也是不可拆分的、臃肿的代码，只能整体包含。当时没有办法复用这些具体实现的特定功能，同时语言具体实现工程之间也极少进行代码共享。</p><p>除了编译器本身的组合问题之外，对于一个具体实现是提供一个像 GCC、Free Pascal 和 FreeBASIC 那样传统的静态编译器，还是实现一个解释器或 JIT 形式的运行时编译器，流行编程语言具体实现社区的观点常常两极分化。很少有语言具体实现同时支持上面两种方式，就算他们真这么做了，也几乎没有共享的代码。</p><p>过去十年间，LLVM 带来了翻天覆地的变化。LLVM 现在是一系列静态或运行时编译语言实现的共通基础设施（比如，GCC 支持的语言集合、Java、.NET、Python、Ruby、Scheme、Haskell、D，以及无数不知名的语言）。它同时取代了一系列专用编译器，比如 Apple 的 OpenGL 软件栈和 Adobe 的 After Effects 产品的图像处理库的所使用的运行时专用引擎。最后 LLVM 还用于创造各式各样的新产品。最著名的恐怕要属 OpenCL 编程语言及它的运行时。</p><h2 id="11-1-经典编译器设计简介"><a href="#11-1-经典编译器设计简介" class="headerlink" title="11.1. 经典编译器设计简介"></a>11.1. 经典编译器设计简介</h2><p>三段式设计在传统静态编译器中最为流行（比如大多数 C 编译器），它的主要组件是前端、优化器和后端（<imgref three_phases="">）。前端分析源代码，检查错误并构建针对该语言的抽象语法树来表示输入的源代码。抽象语法树可以为优化而进一步转换成新的表示方式，然后让优化器和后端处理这段新代码。</imgref></p><p><img src="http://aosabook.org/cdn/images/aosabook/llvm/SimpleCompiler.png" alt="三段式编译器的主要部件"></p><p>优化器负责用各种各样的转换来提高代码的运行效率，比如消除冗余计算。这一行为或多或少独立于源语言和目标格式。之后后端（又叫代码生成器）将代码映射到目标指令集。保证代码正确性之余，后端还要生成高质量的代码，使得它们能够利用目标架构的特性。编译器后端的常见部分包括指令选择、寄存器分配和指令排序。</p><p>三段模型同样能很好地适用于解释器和 JIT 编译器。Java 虚拟机（JVM）也是这一模型的具体实现。JVM 采用 Java 字节码作为前端和优化器之间的接口。</p><h3 id="11-1-1-三段式设计的启示"><a href="#11-1-1-三段式设计的启示" class="headerlink" title="11.1.1. 三段式设计的启示"></a>11.1.1. 三段式设计的启示</h3><p>当编译器希望支持多种语言或目标架构时，经典的三段设计的价值就凸显出来了。如果编译器在优化器中使用通用代码表示，那么就能为任何语言编写前端，为任何目标编写后端，只要它们能转化到通用代码或者由通用代码生成，如 <imgref retarget=""> 所示。</imgref></p><p><img src="http://aosabook.org/cdn/images/aosabook/llvm/RetargetableCompiler.png" alt="可重定目标能力"></p><p>这个设计下，移植编译器以支持新的源语言（比如 Algol 或 BASIC）需要实现一个新的前端，但是现存的优化器和后端可以被复用。如果这些部分没有分离，实现一个新的源语言需要从零开始，于是支持 N 个目标和 M 个源语言就需要 N × M 个编译器。</p><p>相较于只支持单一源语言与目标平台，三段设计的编译器可以服务更多的程序员，这是该设计的另一个优势（直接来自其可重定目标能力）。而对一个开源项目来说，这意味着可以召集到更多潜在的贡献者。同时这也自然而然地给编译器带来了改进和增强。这正说明了为什么相比于受众面窄的编译器如 FreePASCAL，服务大量社区的开源编译器（如 GCC）更易产生更加优化的代码。但是商业编译器并不适用这个道理，因为它们的质量是与项目预算直接挂钩的。例如，尽管受众面窄，但是 Intel ICC Compiler 凭借其高质量的生成代码而声名远扬。</p><p>三段式设计的最后一个主要优势在于实现前端和优化器以及后端所需要的技能不同，将它们分离有利于简化前端人员的改进和维护工作。虽然这只是一个社会分工问题，而不是技术难题，但是它在实践中非常重要，对于想要尽可能减少贡献门槛的开源项目来说更是如此。</p><h2 id="11-2-已有的语言实现"><a href="#11-2-已有的语言实现" class="headerlink" title="11.2. 已有的语言实现"></a>11.2. 已有的语言实现</h2><p>尽管三段式设计的好处在编译教材中都有所提及，但是在实践中人们几乎没有认真地考虑过它。看看那些开源编程语言的具体实现（在 LLVM 项目开始之前的），你会发现 Perl、Python、Ruby 和 Java 的实现没有共享任何代码。后来，Glasgow Haskell Compiler (GHC) 和 FreeBasic 等项目有所进步，能支持多种不同的 CPU，但是它们的实现只针对单一的源语言。还有许多特殊用途的编译器技术用来 JIT 编译器的实现，这些编译器用于支持如图像处理、正则表达式、显卡驱动以及其它一些对运算性能有需求的细分领域。</p><p>即便如此，这个模型也有三个成功案例。第一个是 Java 和 .NET 虚拟机。这些系统提供了 JIT 编译器、运行时支持以及经过精心设计的字节码格式。这意味着只要能编译到字节码，任何语言都能享受到优化器和 JIT 以及运行时带来的好处（这样的语言有很多((<a href="http://en.wikipedia.org/wiki/List_of_JVM_languages" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/List_of_JVM_languages</a> ))。遗憾的是这些实现不能灵活地选择运行时：它们都在事实上强制即时编译、垃圾回收以及使用特定的对象模型。这导致编译不匹配这一模型的语言只能获得次优的性能，如 C 语言（具体来说，配合 LLJVM 项目的 C 语言）。</p><p>第二个成功案例也许是最不幸的，但也是最常用的复用编译器的技术：将输入源代码翻译成 C 代码（或者其他语言）然后把它交给已有的 C 编译器。这个方法能够复用优化器和代码生成器，能灵活选择运行时并加以控制，同时对前端实现者来说十分易于理解、实现和维护。不幸的是，这种方法不能实现高效的异常处理机制，调试体验糟糕，编译速度慢，并且这手段对需要尾递归优化（或其他一些 C 不支持的特性）的语言不大行得通。</p><p>三段式模型的最后一个成功实现是 GCC((现在是 “GNU Compiler Collection” 的反向缩略语。))。GCC 支持许多前段和后端，同时有一群活跃的贡献者。很长一段时间里，GCC 是一个支持多目标的 C 编译器，同时用很偏门的方法支持了其他个别语言。年复一年，GCC 缓慢地演变成一个更加干净的设计。到了 GCC 4.4，它有一个新的优化器（叫做“GIMPLE Tuples”），越来越独立于前端。另外，它的 Fortan 和 Ada 前端用上了一个整洁的抽象语法树。</p><p>尽管这三个案例很成功，但是它们还是在使用场景上有局限，因为它们是单体应用。举个例子，将 GCC 作为运行时或 JIT 编译器嵌入其他应用，或者在不整体嵌入的情况下提取复用 GCC 的部分功能是不切实际的。需要使用 GCC 的 C++ 前端做文档生成、代码索引、重构以及静态分析工具的人需要单独使用 GCC 以 xml 格式产生需要的信息，或者写补丁往 GCC 进程注入代码。</p><p>GCC 的部分功能不能作为库加以复用的原因有很多：肆意使用全局变量、不使用常量、设计糟糕的数据结构、杂乱无章的代码库，以及使用宏导致的编译后无法同时支持多个前端后端配对。然而，最难处理的问题是其内部架构，这个问题源自它的早期设计。具体来说，GCC 的层次问题和抽象泄露令人头痛：后端要遍历前端的抽象语法树来产生调试信息，前端产生后端的数据结构，并且整个编译器依赖命令行接口设置的全局数据结构。</p><h2 id="11-3-LLVM-的代码表示形式：LLVM-IR"><a href="#11-3-LLVM-的代码表示形式：LLVM-IR" class="headerlink" title="11.3. LLVM 的代码表示形式：LLVM IR"></a>11.3. LLVM 的代码表示形式：LLVM IR</h2><p>暂时忘记历史背景，我们来深入 LLVM 内部：其设计最重要的层面是 LLVM 中间表示形式 (Intermediate Representation, IR)，这是 LLVM 在编译器中表示代码的形式。LLVM IR 能够支持中等水平的分析和转换，你能在编译器的优化器中找到对应的部分。它在设计时包含了很多独特的想法，包括支持运行时优化、过程间优化、全程序分析以及激进的重构变换等等。然而，LLVM IR 最重要的层面是它自身是有明确语义的语言。这里有一个简单的 ‘’.ll’’ 文件来具体说明这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">define i32 @add1(i32 %a, i32 %b) &#123;</span><br><span class="line">entry:</span><br><span class="line">  %tmp1 = add i32 %a, %b</span><br><span class="line">  ret i32 %tmp1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">define i32 @add2(i32 %a, i32 %b) &#123;</span><br><span class="line">entry:</span><br><span class="line">  %tmp1 = icmp eq i32 %a, 0</span><br><span class="line">  br i1 %tmp1, label %done, label %recurse</span><br><span class="line"></span><br><span class="line">recurse:</span><br><span class="line">  %tmp2 = sub i32 %a, 1</span><br><span class="line">  %tmp3 = add i32 %b, 1</span><br><span class="line">  %tmp4 = call i32 @add2(i32 %tmp2, i32 %tmp3)</span><br><span class="line">  ret i32 %tmp4</span><br><span class="line"></span><br><span class="line">done:</span><br><span class="line">  ret i32 %b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段 LLVM IR 对应下面这段 C 代码，这份代码实现了两种做整数加法的方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unsigned add1(unsigned a, unsigned b) &#123;</span><br><span class="line">  return a+b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">* Perhaps not the most efficient way to add two numbers.</span><br><span class="line">unsigned add2(unsigned a, unsigned b) &#123;</span><br><span class="line">  if (a == 0) return b;</span><br><span class="line">  return add2(a-1, b+1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这个例子可以看出，LLVM IR 是一个底层的 RISC 风格的虚拟指令集。就像真实的 RISC 指令集一样，它支持简单指令如加法、减法、比较和分支的顺序执行。这些指令采用三地址形式，即它们接受一些输入并在另一个不同的寄存器产生一个输出。((这与二地址指令集和一地址机器不同，前者如 X86，它破坏性地更新输入寄存器；后者如一地址机器，它接受一个显式操作数并作用于一个累加器或者栈顶（如果是栈式机）。)) LLVM IR 支持标签并且看起来基本就是一种格式古怪的汇编语言。</p><p>不同于大多数的 RISC 指令集，LLVM 是强类型的，它有一个简单的类型系统（比如，’’i32’’ 是一个 32 位的整型，’’i32**’’ 是一个指向 32 位整型的指针），并且与机器相关的细节都被屏蔽了。例如，调用规约以 ‘’call’’ 和 ‘’ret’’ 以及显式的参数列表的形式抽象地表示。另一个重要的不同于机器码的地方是 LLVM IR 并不使用固定数量的具名寄存器，而是使用无限的临时寄存器，它们的名字都含有 % 字符。</p><p>不仅仅作为一门语言来实现，LLVM IR 事实上有三种同构的形式：上述的文本格式，一种内存数据结构，在优化过程中分析和修改，以及一种存储在磁盘上的密集的二进制格式，叫做 “bitcode”。LLVM 项目同时提供工具，将文本格式转换到二进制格式：llvm-as。它将文本格式的 ‘’.ll’’ 文件汇编成 ‘’.bc’’ 文件，’’.bc’’ 文件中包含所谓的 bitcode。llvm-dis 则将 ‘’.bc’’ 文件反汇编成 ‘’.ll’’ 文件。</p><p>编译器的中间表示形式十分有趣，因为它为优化器提供了一个完美世界：不想编译器的前端和后端，优化器并不被特定源语言或目标机器所限制。但是另一方面，中间表示形式必须同时考虑到前端和后端：它要让前端能够容易地生成，并且要有一定的可读性，使得针对真实目标的重要优化能够实施。</p><h3 id="11-3-1-编写-LLVM-IR-的优化策略"><a href="#11-3-1-编写-LLVM-IR-的优化策略" class="headerlink" title="11.3.1. 编写 LLVM IR 的优化策略"></a>11.3.1. 编写 LLVM IR 的优化策略</h3><p>观察一些具体的例子，有助于对优化的工作原理有一个直观的认识。编译器可以做很多种优化，所以很难给出一个通解。也就是说，大多数优化遵循下面三步流程：</p><ul><li>寻找要转换的模式。</li><li>确认能安全正确地对找到实体进行转化。</li><li>实施转换，更新代码。</li></ul><p>最简单的优化是数学恒等式的模式匹配，比如：对任意整数 ‘’X’’ ， ‘’X - X’’ 即 0 ， ‘’X - 0’’ 即 ‘’X’’ ， ‘’（X * 2) - X’’ 即 ‘’X’’ 。首当其冲的问题是这些在 LLVM IR 下长什么样。下面是一些例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">?    ?    ?</span><br><span class="line">%example1 = sub i32 %a, %a</span><br><span class="line">?    ?    ?</span><br><span class="line">%example2 = sub i32 %b, 0</span><br><span class="line">?    ?    ?</span><br><span class="line">%tmp = mul i32 %c, 2</span><br><span class="line">%example3 = sub i32 %tmp, %c</span><br><span class="line">?    ?    ?</span><br></pre></td></tr></table></figure><p>对于这类窥孔优化，LLVM 提供了指令化简接口，作为其他各种各样的高级变换的工具。这些细小的变换在 ‘’SimplifySubInst’’ 函数中，形式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">* X - 0 -&gt; X</span><br><span class="line">if (match(Op1, m_Zero()))</span><br><span class="line">  return Op0;</span><br><span class="line"></span><br><span class="line">* X - X -&gt; 0</span><br><span class="line">if (Op0 == Op1)</span><br><span class="line">  return Constant::getNullValue(Op0-&gt;getType());</span><br><span class="line"></span><br><span class="line">* (X*2) - X -&gt; X</span><br><span class="line">if (match(Op0, m_Mul(m_Specific(Op1), m_ConstantInt&lt;2&gt;())))</span><br><span class="line">  return Op1;</span><br><span class="line"></span><br><span class="line">…</span><br><span class="line"></span><br><span class="line">return 0;  * Nothing matched, return null to indicate no transformation.</span><br></pre></td></tr></table></figure><p>在这份代码中，Op0 和 Op1 分别绑定了整数减法指令的左右操作数（需要注意，这些恒等式对 IEEE 浮点数不一定成立）。LLVM 用 C++ 实现，C++ 并不以模式匹配能力见长（与 OCaml 这类函数式语言相比的话），但是它提供了非常泛化的模板系统，这使得我们能够实现类似（模式匹配）的东西。’’match’’ 函数和 ‘’m_’’ 开头的函数使得我们能以声明式的风格，对 LLVM IR 进行模式匹配。例如，’’m_Specific’’ 谓词只有在乘法的左操作数与 Op1 提供的情况下才会匹配到。</p><p>这三个情形都是被匹配后返回替换内容，如果没有就返回空指针。这个函数的调用者（’’SimplifyInstruction’’）是一个分派器，它根据指令的操作码，转发到对应操作码的辅助函数。它在各种各样的优化场景下被调用。下面是它的使用方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (BasicBlock::iterator I = BB-&gt;begin(), E = BB-&gt;end(); I != E; ++I)</span><br><span class="line">  if (Value *V = SimplifyInstruction(I))</span><br><span class="line">    I-&gt;replaceAllUsesWith(V);</span><br></pre></td></tr></table></figure><p>这份代码简单地遍历基本块中的所有指令，检查是否发生化简。如果发生了（因为 ‘’SimplifyInstruction’’ 返回了非空指针），它使用 ‘’replaceAllUsesWith’’ 方法，用简化的形式去更新代码中所有使用这个可化简操作的地方。</p><h2 id="11-4-LLVM-的三段式设计实现"><a href="#11-4-LLVM-的三段式设计实现" class="headerlink" title="11.4. LLVM 的三段式设计实现"></a>11.4. LLVM 的三段式设计实现</h2><p>在基于 LLVM 的编译器中，前端负责对输入代码进行语法分析，语义验证和错误诊断，然后把分析后的代码翻译成 LLVM IR （通常是构造 AST 然后将 AST 转换成 LLVM IR，但不一定）。中间代码可以经过送入一系列分析和优化流程得到改进，然后传入代码生成器，产生本地机器码，如 <imgref llvm_three_phases=""> 所示的那样。这是三段式设计的直观实现，但是这种泛泛的描述掩盖了 LLVM 架构从 LLVM IR 所衍生出来的强大功能和灵活性。</imgref></p><p><img src="http://aosabook.org/cdn/images/aosabook/llvm/LLVMCompiler1.png" alt=""></p><h3 id="11-4-1-LLVM-IR-是一个完备的代码表示"><a href="#11-4-1-LLVM-IR-是一个完备的代码表示" class="headerlink" title="11.4.1. LLVM IR 是一个完备的代码表示"></a>11.4.1. LLVM IR 是一个完备的代码表示</h3><p>特别地，LLVM IR 是指定的优化器的唯一接口。这意味着你只需要知道 LLVM IR 以及它的工作原理、期望的不变量(?)就可以为 LLVM 编写前端。因为 LLVM IR 有优秀的文本格式，让前端生成文本形式的 LLVM IR 不仅可行，更是合理的做法，之后可以使用 Unix 的管道将它送入优化器序列以及你选择的代码生成器。</p><p>这可能令人感到惊讶，但是这确实是 LLVM 的新颖之处，也是它在许多不同的应用中获得成功的的主要原因之一。即便是获得广泛成功并且相对来说架构良好的 GCC 也没有这个特点：它的 GIMPLE 中间表示形式不是完备的。举一个简单的例子，当 GCC 代码生成器要生成 DWARF 调试信息时，它会回过头去遍历源码级的语法树。GIMPLE 本身用元组形式表示代码中的操作，但是（至少到 GCC 4.5）仍然将操作数表示成对源码树的引用。</p><p>GCC 这种做法意味着前端作者需要同时了解并生成 GCC 的树形数据结构和 GIMPLE，才能编写 GCC 的前端。GCC 后端也有类似的问题，所以他们也需要了解一点 RTL(Register Transfer Level?) 后端的工作原理。最终，GCC 没有办法转储源码的所有信息，也没有办法以文本形式读写 GIMPLE（以及形成中间代码的相关数据结构）。结果就是用 GCC 来做实验相对困难，并且它的前端也因此相对地少。</p><h3 id="11-4-2-LLVM-是代码库集合"><a href="#11-4-2-LLVM-是代码库集合" class="headerlink" title="11.4.2. LLVM 是代码库集合"></a>11.4.2. LLVM 是代码库集合</h3><p>在 LLVM IR 的设计之后，下一个关于 LLVM 的重要的层面是它是一组代码库，而不是像 GCC 那样的单体的命令行编译器，或者像 JVM 或 .NET 那样封闭的虚拟机。LLVM 是基础设施，是实用编译技术的集合，可以应用于特定问题（像构建 C 编译器，或者特效管道中的优化器）。尽管这是 LLVM 最强大的特点之一，它也是最不被理解的设计要素。</p><p>作为一个例子，我们来看一下优化器的设计：它读入 LLVM IR，进行些处理，然后生成期望能执行得更快的 LLVM IR。在 LLVM 中（就像在其它编译器中那样），优化器多个不同的优化过程串联起来的管道，每个优化过程的执行依赖输入，并且会做些事情。常见的优化过程的例子有内联器（它在函数调用处直接展开函数体）、表达式重组、循环不变代码移动等等。根据优化等级，会执行不同的过程：比如在 -O0 （无优化）级，Clang 编译器部执行任何优化过程，在 -O3 级它在优化器中执行 67 个优化过程（以 LLVM 2.8 为准）。</p><p>LLVM 的优化过程是一个 C++ 的类，间接继承自 ‘’Pass’’ 类。大多数过程写在单独的 ‘’.cpp’’ 文件中，并在匿名名空间中定义 ‘’Pass’’ 的子类（这使得其完全私有化）。为了让这个过程有实用价值，外部代码要能实用它，于是要从代码文件中导出一个单独的函数（来创建过程）。为了具体化前面的内容，这里有一个略微简化的过程的例子。((更多的细节请参见  <a href="http://llvm.org/docs/WritingAnLLVMPass.html" target="_blank" rel="noopener">http://llvm.org/docs/WritingAnLLVMPass.html</a> |Writing an LLVM Pass .))</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">namespace &#123;</span><br><span class="line">  class Hello : public FunctionPass &#123;</span><br><span class="line">  public:</span><br><span class="line">    * Print out the names of functions in the LLVM IR being optimized.</span><br><span class="line">    virtual bool runOnFunction(Function &amp;F) &#123;</span><br><span class="line">      cerr &lt;&lt; &quot;Hello: &quot; &lt;&lt; F.getName() &lt;&lt; &quot;\n&quot;;</span><br><span class="line">      return false;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">FunctionPass *createHelloPass() &#123; return new Hello(); &#125;</span><br></pre></td></tr></table></figure><p>前面提到过，LLVM 优化器提供许多不同的优化过程，每一个都用相似的风格编写。这些过程被编译到一个或多个 ‘’.o’’ 文件，这些文件之后会装入若干归档库（在 Unix 系统上是 ‘’.a’’ 文件）。这些库提供各种各样的分析和转换功能，并且过程是松耦合的：它们应该独立工作，或者显式地声明它们对其它过程的依赖，如果它们需要其它一些分析来完成工作的话。当给定一系列要执行的过程时，LLVM PassManager 使用显式的依赖信息来满足这些依赖并优化过程的执行。</p><p>代码库和抽象功能很棒，但是它们不能实际地解决问题。当某人想要利用编译器技术，来构建一个新工具，比如为图像处理语言所写的 JIT 编译器时，有趣的事情才会出现。这个 JIT 编译器的实现者在脑海中有种种限制：比如，也许图像处理语言对编译时延迟高度敏感，并且处于性能考虑，一些惯用的语言特性需要被优化掉。</p><p>LLVM 优化器基于代码库的设计使得实现者不仅可以定制过程执行的顺序，还可以只选择对图像处理有意义的过程：如果所有事物都被定义成单一的庞大的函数，花时间在内联上就没有意义了；如果基本没有指针，那么别名分析和内存优化不值得去考虑。尽管我们尽了最大的努力，但是 LLVM 并不能魔幻般地解决所有的优化问题！因为过程子系统是模块化的并且 PassManager 本身不知道过程的内部情况，实现者可以自由地实现他们自己的优化过程，针对特定语言，以弥补 LLVM 优化器的不足，或者明确针对特定语言的优化时机。<imgref xyz=""> 展示了一个假想的 XYZ 图像处理系统的简单例子：</imgref></p><imgcaption xyz="">![]( <a href="http://aosabook.org/cdn/images/aosabook/llvm/PassLinkage.png" target="_blank" rel="noopener">http://aosabook.org/cdn/images/aosabook/llvm/PassLinkage.png</a>  | 图 11.4: 假想的使用 LLVM 的 XYZ 系统 }}</imgcaption><p>一旦一组优化策略被选定（并且也对代码生成器做了相似的决策），图像处理编译器会构建成一个可执行文件或动态链接库。因为对 LLVM 优化过程的引用只有简单的创建函数，它们被定义在对应的 ‘’.o’’ 文件中，并且因为优化器位于 ‘’.a’’ 归档库中，只有实际用到的优化过程会真正地链接到最终的应用，而不是链接上整个 LLVM 优化器。在上述例子中，因为有对 PassA 和 PassB 的引用，它们会被链接进来。因为 PassB 使用了 PassD 去做一些分析，PassD 也会被链接进来，因为 PassC（以及许多其它的优化）没有被使用，那么它的代码不会被链接进图像处理应用。</p><p>这便是 LLVM 的基于库的设计起作用的地方。这个直观的设计方法使得 LLVM 能提供大量的功能，一些可能只对特定用户有用，但不会强制只想实现简单功能的客户包含整个库。相反地，传统编译器的优化器由大量紧密耦合的代码构建而来，很难提取子集，导出并得以提高效率。用 LLVM 你能理解独立的优化器，而不需要知道整个系统是如何组织的。</p><p>基于库的设计同时也是为什么这么多人误解 LLVM 性质的原因。LLVM 库有许多功能，但是它们实际上并不独立工作。是由依赖库的客户端（日布 Clang 编译器）的设计者来决定如何利用好这些部分。这种审慎的分层、考察因素以及专注功能子集也是为什么 LLVM 优化器能在如此广泛的，不同目的的应用中得以使用的原因。同样地，仅仅因为 LLVM 提供了 JIT 编译功能并不意味着每一个客户端都要使用它。</p><h2 id="11-5-可重定目标的-LLVM-代码生成器的设计"><a href="#11-5-可重定目标的-LLVM-代码生成器的设计" class="headerlink" title="11.5. 可重定目标的 LLVM 代码生成器的设计"></a>11.5. 可重定目标的 LLVM 代码生成器的设计</h2><p>LLVM 代码生成器负责将 LLVM 转换成特定目标的机器码。一方面，代码生成器的职责是为任何给定的目标生成尽可能最优的机器码。理想情况下，每个代码生成器应该为目标所定制，但是另一方面，每个代码生成器需要解决非常相似的问题。例如，每个目标都需要为寄存器赋值，尽管每个目标有不同的寄存器堆，使用的（分配）算法也应该尽可能共享。</p><p>类似优化器使用的方法，LLVM 的代码生成器将代码生成问题划分为独立的过程：指令选择，寄存器分配，（指令）调度，代码布局优化，以及汇编代码生成。同时提供许多内置的过程在默认情况下执行。之后目标平台的作者便可以根据需求在使用默认过程、覆写默认过程和实现完全定制的针对性过程间进行选择。例如，因为寄存器很少，x86 后端使用寄存器压力下降调度器（register-pressure-reducing scheduler）。但是 PowerPC 的寄存器很多，所以它的后端使用延迟优化调度器（latency optimizing scheduler）。x86 后端使用定制的过程来处理 x87 浮点栈，同时 ARM 后端使用定制过程，在需要时将常量池放入函数中(?)。这一灵活性使得目标平台作者不必从头实现完整的代码生成器，就可以为其平台生成优质代码。</p><h3 id="11-5-1-LLVM-目标描述文件"><a href="#11-5-1-LLVM-目标描述文件" class="headerlink" title="11.5.1. LLVM 目标描述文件"></a>11.5.1. LLVM 目标描述文件</h3><p>mix 和 match 方法使得目标作者可以选择对架构有意义的内容并且允许跨平台复用大量的代码。这带来了另一个挑战：每个共享的组件需要能够以通用的方式导出目标相关的属性。比如，一个共享的寄存器分配器需要知道每个目标的寄存器堆以及在指令和寄存器操作数之间存在的约束。LLVM 的解决方案是使用声明式的领域专用语言（domain-specific language, DSL）（一组 ‘’.td’’ 文件）为每一个目标提供目标描述，这个 DSL 由 tblgen 工具处理。（简化的）构建 x86 目标的过程如 <imgref description=""> 所示：</imgref></p><imgcaption description="">![]( <a href="http://aosabook.org/cdn/images/aosabook/llvm/X86Target.png" target="_blank" rel="noopener">http://aosabook.org/cdn/images/aosabook/llvm/X86Target.png</a>  | 简化的 x86 目标描述 }}</imgcaption><p>‘’.td’’ 文件支持的不同子系统使得目标作者能够构建目标的不同部分。比如，x86 后端定义了一个寄存器类，包含所有的 32 位寄存器，命名为 “GR32” （在 ‘’.td’’ 文件，目标专用定义都是大写的），像下面这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def GR32 : RegisterClass&lt;[i32], 32,</span><br><span class="line">  [EAX, ECX, EDX, ESI, EDI, EBX, EBP, ESP,</span><br><span class="line">   R8D, R9D, R10D, R11D, R14D, R15D, R12D, R13D]&gt; &#123; … &#125;</span><br></pre></td></tr></table></figure><p>这个定义描述了这个类里的寄存器可以存储 32 位整型数（”i32”），期望按 32 位对齐，有专用的 16 位寄存器（定义在另一个 ‘’.td’’ 文件中）并且有一些额外信息来规定偏好的分配顺序，以及其它一些内容。有了这个定义，专用指令能够使用它作为寄存器操作数。比如，”complement a 32-bit register”（对 32 位寄存器取补）定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">let Constraints = &quot;$src = $dst&quot; in</span><br><span class="line">def NOT32r : I&lt;0xF7, MRM2r,</span><br><span class="line">               (outs GR32:$dst), (ins GR32:$src),</span><br><span class="line">               &quot;not&#123;l&#125;\t$dst&quot;,</span><br><span class="line">               [(set GR32:$dst, (not GR32:$src))]&gt;;</span><br></pre></td></tr></table></figure><p>这个定义说明 NOT32r 是一条指令（它使用 tblgen 的类 ‘’I’’），规定了编码信息（’’0xF7’’，’’MRM2r’’），它定义了一个 32 位寄存器输出 ‘’$dst’’ 并且有一个 32 位寄存器输入叫做 ‘’$src’’ （上面定义的 ‘’GR32’’ 寄存器类规定了适用于操作数的寄存器类型），规定了指令的汇编语法（使用 ‘’{}’’ 语法来处理 AT&amp;T 和 Intel 语法），规定了指令的效果并且在最后一样提供了应满足的格式。第一行的 “let” 约束告诉寄存器分配器输入和输出寄存器必须被分配到同一个物理寄存器上（<del>寄存器重命名你怕不怕</del>）。</p><p>这个定义是对这条指令的非常浓缩的描述，并且通用的 LLVM 代码可以根据其产生的信息做很多事情（通过 ‘’tblgen’’ 工具）。一个这样的定义足以让指令选择通过匹配中间代码来生成这条指令。它也告知了寄存器分配器如何处理这条指令，足以用来编码指令及将指令解码到机器码，足以用来分析和打印出指令的文本形式。这些能力使得 x86 目标平台能够从目标描述中产生独立的汇编器（”gas” GNU 汇编器的取代者）和反汇编器，同时能处理 JIT 的指令编码(?)。</p><p>在提供有用功能之外，从相同的“事实”产生多个部分的信息在另一些方面有好处。这个方法使得汇编器和反汇编器在汇编语言或二进制码上不一致的情况不可能出现。它也使得目标描述更容易测试：指令编码可以在不被包含进整个代码生成器的情况下进行单元测试。</p><p>尽管致力于尽可能多地往 ‘’.td’’ 文件中写入目标信息，并保持一个优雅的声明形式，我们仍不能知道所有信息。作为替代，我们要求目标作者为各种支撑过程编写一些 C++ 代码，并自行实现他们需要的目标专用过程（像 ‘’X86FloatingPoint.cpp’’，它处理 x87 浮点栈）。在 LLVM 持续支持新的目标的同时，增加 ‘’.td’’ 文件所能表达的目标也越来越重要。我们持续增强 ‘’.td’’ 文件的表达能力来保证这点。这样的好处是随着时间前进，为 LLVM 编写目标也越来越容易。</p><h2 id="11-6-模块化设计带来的有趣功能"><a href="#11-6-模块化设计带来的有趣功能" class="headerlink" title="11.6. 模块化设计带来的有趣功能"></a>11.6. 模块化设计带来的有趣功能</h2><p>除了设计的通用优雅，模块化使得使用 LLVM 库的客户端具有一些有趣的功能。这些功能衍生自一个事实，即 LLVM 虽然提供功能，但是允许客户端决定使用这些功能的策略</p><h3 id="11-6-1-选择每个阶段执行的时间和位置"><a href="#11-6-1-选择每个阶段执行的时间和位置" class="headerlink" title="11.6.1. 选择每个阶段执行的时间和位置"></a>11.6.1. 选择每个阶段执行的时间和位置</h3><p>之前提到过，LLVM IR 能高效地序列化到一种叫 LLVM bitcode 的二进制格式（或从其反序列化）。因为 LLVM IR 是自包含的，并且序列化是一个无损的过程，所以我们能够做一部分编译工作，将进度保存到磁盘上，然后在未来某个时刻继续工作。这个特性带来了许多有趣的功能，包括对链接和安装时刻优化的支持，它们都将代码生成延迟到编译之后。</p><p>链接时优化解决了这样一个问题：传统的编译器因为每次只能观察到一个翻译单元（比如，一个 ‘’.c’’ 文件和它依赖的所有头文件），所以不能跨文件进行优化（比如内联）。LLVM 编译器比如 Clang 通过 ‘’-flto’’ 或 ‘’-O4’’ 命令行选项来支持链接时优化。这个选项告知编译器产生 LLVM bitcode，存储在 ‘’.o’’ 文件中，而不是本地目标文件，并且把代码生成时间延迟到链接时，如 <imgref linkage=""> 所示：</imgref></p><p><img src="http://aosabook.org/cdn/images/aosabook/llvm/LTO.png" alt=""></p><p>不同的操作系统可能在细节上有差异，但是要点是链接器能识别 ‘’.o’’ 文件是 LLVM bitcode 而不是本地目标文件。当发现这点，它将所有的 bitcode 文件读入内存，把它们链接起来，然后在这个聚集上运行 LLVM 优化器。因为优化器现在能看到更多的代码，它可以跨文件地进行内联、常量传播、更激进的死码删除，以及更多的优化。尽管现代编译器也支持 LTO（链接时优化），它们中的大多数（比如 GCC、Open64、ICC 等等）通过代价昂贵的并且耗时的序列化过程来实现这个功能。在 LLVM 中，LTO 从系统的设计中自然而然地产生，并且能在不同的源语言上发挥作用（不像其它编译器），因为 IR 真正地独立于源语言。</p><p>安装时优化的思想是把代码生成延迟，甚至是在链接时之后，一直到安装时再做。如 <imgref install=""> 所示。安装时是一个非常有趣的时刻（比如软件包装、下载、上传到一个移动设备等等），因为这时你才能了解作为目标的设备的规格。以 x86 家族为例，它的芯片很多，特性不同。通过延迟指令选择、调度以及其它代码生成方面的工作，你可以为最终运行应用的特定硬件做出最优的选择。</imgref></p><p><img src="http://aosabook.org/cdn/images/aosabook/llvm/InstallTime.png" alt=""></p><h3 id="11-6-2-对优化器做单元测试"><a href="#11-6-2-对优化器做单元测试" class="headerlink" title="11.6.2. 对优化器做单元测试"></a>11.6.2. 对优化器做单元测试</h3><p>因为编译器十分复杂，并且质量至关重要，所以测试是非常关键的。比如，在修复了一个导致优化器崩溃的 bug 后，需要增加回归测试以确保它不会再发生。传统测试手段的一个例子是编写一个 ‘’.c’’ 文件贯穿编译器，并且使用测试框架验证编译器不会崩溃。这种方法的具体例子是 GCC 的测试套件。</p><p>这个方法的问题是在一个包含许多不同子系统，甚至优化器中有许多不同的过程的编译器中，在测试代码到达之前有问题的代码之前，任何部件都有机会修改输入的内容。如果前端或早期优化器发生了变化，一个测试样例很容易无法测试它本应该测试的内容。</p><p>通过配合模块化的优化器使用文本格式的 LLVM IR，LLVM 测试套件的回归测试高度专注：它们将 LLVM IR 从磁盘读入，精确地在一个优化过程中运行它，并验证期望的行为。除了崩溃之外，更加复杂的行为测试要能验证一个优化被确实执行了。这里有一个简单的测试用例，它检查常量传播在加法指令上的运作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">; RUN: opt &lt; %s -constprop -S  | FileCheck %s</span><br><span class="line">define i32 @test() &#123;</span><br><span class="line">  %A = add i32 4, 5</span><br><span class="line">  ret i32 %A</span><br><span class="line">  ; CHECK: @test()</span><br><span class="line">  ; CHECK: ret i32 9</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>‘’RUN’’ 行确定了要执行的命令：在这个例子中，即 ‘’opt’’ 和 ‘’FileCheck’’ 命令工具。’’opt’’ 程序是 LLVM 的过程管理器的简单封装，它链接了所有标准过程（并且可以动态加载包含其他过程的补丁）并将它们暴露到命令行。’’FileCheck’’ 工具验证它的标准输入是否匹配一系列 ‘’CHECK’’ 指令。在这个例子中，这个简单的测试验证 ‘’constprop’’ 过程将 4 和 5 的 ‘’add’’ 折叠成 9.</p><p>尽管这个例子看起来很不起眼，这对写 ‘’.c’’ 文件来测试是十分困难的：因为前端经常在分析时做常量折叠，所以写代码让其抵达常量折叠优化过程是困难且不可靠的。因为我们能以文本载入 LLVM IR 并传送给我们感兴趣的特定优化过程，然后把结果导出到另一个文本文件，它确实能直观地精确测试我们想测试的，包括回归测试和特性测试。</p><h3 id="11-6-3-用-BugPoint-自动减少测试用例"><a href="#11-6-3-用-BugPoint-自动减少测试用例" class="headerlink" title="11.6.3. 用 BugPoint 自动减少测试用例"></a>11.6.3. 用 BugPoint 自动减少测试用例</h3><p>当在编译器或其他 LLVM 库的客户端中发现了 bug，修复它的第一步就是构造一个复现问题的测试样例。一旦你有了这样一个测试样例，你最好将其最小化到复现问题的最小样例，并且同时细化到 LLVM 中发生问题的部分，比如出错的优化过程。尽管你最终知道如何去做这些，这个过程是乏味的，手工的，并且在编译器产生错误代码但是没有崩溃时尤其痛苦。</p><p>LLVM BugPoint 工具((<a href="http://llvm.org/docs/Bugpoint.html))使用" target="_blank" rel="noopener">http://llvm.org/docs/Bugpoint.html))使用</a> LLVM IR 序列化和模块化设计来自动化这一过程。例如，给定一个 ‘’.ll’’ 或 ‘’.bc’’ 输入文件以及导致优化器崩溃的一系列优化过程，BugPoint 把输入精简到一个小的测试用例并确定哪个优化器出错了。然后它输出精简的测试用例以及复现错误的 ‘’opt’’ 命令。BugPoint 通过使用类似 “delta debugging” 的方法来精简输入和优化过程列表以发现出错点。因为知道 LLVM IR 的结构，BugPoint 不会像标准的 “delta” 命令行工具那样浪费时间产生无效 IR 输送给优化器。</p><p>在更加复杂的编译错误的场景中，你能指定传递给可执行文件的输入、代码生成器信息和命令行，以及一个参考输出。BugPoint 会首先确定问题是由优化器还是代码生成器造成的，然后重复将测试样例划分成两部分：一部分送入“已知正常”的部分，另一部分送入“已知有问题”的部分。它通过迭代地将越来越多的代码移出已知有问题的部分来精简测试用例。</p><p>BugPoint 是一个非常简单的工具，并且通过精简测试样例在 LLVM 的发展过程中节省了无以计数的时间。其它的编译器的工具没有一款能做到同等强大，因为这依赖于一个定义良好的中间表现形式。即便如此，BugPoint 也不是完美的，并且重写一下会比较好。它可以追溯到 2002 年，并且只在某个人发现了非常难以追踪的 bug 并且现有的工具无法很好地处理时才会得到改进。它经历了长时间的发展并添加新的功能（比如 JIT 调试），但是缺少一致性设计和负责人。</p><h2 id="11-7-反思与未来展望"><a href="#11-7-反思与未来展望" class="headerlink" title="11.7. 反思与未来展望"></a>11.7. 反思与未来展望</h2><p>LLVM 的模块化一开始并不是为了达到上述的功能而设计的。它是一种自我防范机制：很明显我们不可能一开始就做好所有的事情。以模块化的过程流水线为例，它的存在是为了简化过程隔离，这样它们被更好的实现替换时能很容易的废弃掉((我经常说 LLVM 的这些子系统只有至少重写一遍才真正算是优秀的。))。</p><p>LLVM 保持灵活性的另一个主要原因（同时也是使用这些库的客户端的一个争议话题）是我们希望重新考虑之前的决策并大范围地改动 API，同时不用担心破坏向后兼容性。比如，破坏性地改动 LLVM IR 本身需要更新所有的优化过程，并对 C++ API 造成潜在的混乱。我们会在个别情况下这么干。尽管这会让客户感到痛苦，但是为了保持快速进步，这是正确的。为了减少外围用户的痛苦（同时支持绑定其他语言），我们为许多 API 提供了 C 封装（它们应该是极度稳定的），同时新版本的 LLVM 也会致力于继续支持旧的 ‘’.ll’’ 和 ‘’.bc’’ 文件。</p><p>展望未来，我们期望 LLVM 能更加模块化并且易于剪裁。以代码生成器为例，它现在还是太臃肿了：目前还不太可能根据功能来剪裁 LLVM。具体地说，如果你想用 JIT，但是不需要内联汇编、异常处理或者生成调试信息，应该有办法构建没有这些功能的代码生成器才对。我们也持续地改进优化器和代码生成器生成的代码质量，增加 IR 特性来支持新的语言和目标构件，以及在 LLVM 中为高层次的语言特定优化提供更好的支持。</p><p>LLVM 项目以多种方式持续地成长和改进。LLVM 在其他项目中得到丰富的应用，它持续在设计者所不曾料想的新场景下出现，这着实令人兴奋。新的 LLDB 调试器就是一个很好的例子：它使用 Clang 中的 C/C++/Objective-C parser 来分析表达式，使用 LLVM JIT 生成目标代码，使用 LLVM 反汇编器，此外，还使用 LLVM 目标来处理调用规约。能复用现有代码使得开发调试器的人能专注于调试器逻辑，而不是重复实现另一个（比较正确）的 C++ parser。</p><p>不管 LLVM 迄今为止多么成功，还是有许多遗留问题需要解决。同时 LLVM 成长过程中僵化的风险也是时刻存在的。尽管这个问题没有一蹴而就的答案，我希望持续暴露在新的问题领域中，愿意重新评估先前的决策并重新设计和抛弃代码能够有所帮助。毕竟我们的目标不是成就完美，而是随着时间的流逝，持续进步。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这一章节讨论了一些对 LLVM((&lt;a href=&quot;http://llvm.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://llvm.org&lt;/a&gt; )) 有重大影响的设计决策。LLVM 是涵盖一系列紧密结合的底层工具链组件（比如汇编器
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Jitsi</title>
    <link href="http://blog.ccao.cc/2018/09/28/Jitsi/"/>
    <id>http://blog.ccao.cc/2018/09/28/Jitsi/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Jitsi中文翻译"><a href="#Jitsi中文翻译" class="headerlink" title="Jitsi中文翻译"></a>Jitsi中文翻译</h1><h2 id="Chapter-10-Jitsi引言"><a href="#Chapter-10-Jitsi引言" class="headerlink" title="Chapter 10. Jitsi引言"></a>Chapter 10. Jitsi引言</h2><p>Jitsi是一个允许人们进行视频和语音通话，共享桌面和交换文件和消息的应用。更重要的是它允许人们通过大量不同的的协议，从标准化的 XMPP（可扩展消息和状态协议）和 SIP（会话初始化协议）到专有的如雅虎和 Windows Live信使 (MSN)来做这些事情。它可以在微软视窗、苹果 Mac OSX、Linux，FreeBSD上运行。它大部分是用java编写的，但也包含部分用机器码编写的代码。在本章中，我们将会看到Jitsi 的基于 OSGi 的体系结构，看看它是如何实现和管理协议的，并回顾一下，我们能从构建这个软件中学到什么。</p><h2 id="10-1-设计-Jitsi（Designing-Jitsi）"><a href="#10-1-设计-Jitsi（Designing-Jitsi）" class="headerlink" title="10.1.设计 Jitsi（Designing Jitsi）"></a>10.1.设计 Jitsi（Designing Jitsi）</h2><p>在设计Jitsi（在那时被称为SIP通信器）的时候，我们必须牢记的三个重要约束（限制<em>constraint</em>）是：多协议支持、 跨平台的操作和开发者友好性。</p><p>从一个开发者的角度来看，多协议实质上是对所有的协议都有一个通用的接口。换句话说，当一个使用者发送消息的时候，不管当前选择的协议是否事实上使用了一个叫做’’sendXmppMessage’’或者’’sendSipMsg’’的方法，我们的图形用户界面需要总是调用相同的’’sendMessage’’方法。</p><p>事实是，我们大部分的代码都是在java兼容的基础上写的（<em>written in java satisfies</em>满足因素），在很大程度上，我们的第二个限制因素是跨平台操作。尽管如此（<em>still</em>），还有java的运行环境（<em>JRE</em>）不支持或者不是按照我们喜欢的方式去做的事情，例如从你的网络摄像头获取视频。因此，我们需要在 Windows上使用 DirectShow、而在Mac OS X上使用QTKit，和在linux上使用Video for Linux 2。就像协议一样（<em>just as with protocols</em>），控制视频通话部分的代码不能被这些细节干扰（它们本身已经足够复杂了）。</p><p>最后，开发者友好意味着人们能够很容易的添加新的特性（<em>features</em>）。在今天，有成百上千万的人，通过成千上万的不同方式使用网络电话（<em>VoIP</em>）。各种各样的服务提供商和服务器销售商想出了不同的关于新特性的使用案例和创意。我们必须保证对他们来说按照他们的方式使用jitsi是很容易的。某些需要添加一些新的东西的人应该只需要去阅读和理解他们正在修改或扩展的部分的项目（的代码）。相似的，一个人做出的改变应该对任何一个其他人的工作产生尽可能少的影响（<em>impact</em>）。</p><p>综上所述（<em>概括地说</em>），我们需要一个环境，在那里面代码的不同部分之间相对独立（<em>from each other</em>）。能够简单地根据操作系统替换一些部分必须是可能的。还有一些，比如说协议，并行运行但实现相同的功能（<em>act the same</em>）；完全重写这些部分中的任意一个，而且能够在剩下的部分没有任何改变的情况下工作，必须是可能的。最后，我们想要能够简单地开关各个部分的能力和通过因特网下载插件到我们的列表的能力。</p><p>我们简单地考虑了下写我们自己的框架（<em>framework</em>），但马上就放弃了这个想法。我们非常渴望尽可能快地开始写网络电话（<em>VoIP</em>）和即时通讯（<em>IM</em>）的代码，而且花几个月时间来写一个插件框架显得不那么令人兴奋。有的人建议OSGI（<em>面向Java的动态模型系统</em>），而且看起这是最适合的了。</p><h2 id="10-2-Jitsi和OSGI框架（Jitsi-and-the-OSGi-Framework）"><a href="#10-2-Jitsi和OSGI框架（Jitsi-and-the-OSGi-Framework）" class="headerlink" title="10.2.Jitsi和OSGI框架（Jitsi and the OSGi Framework）"></a>10.2.Jitsi和OSGI框架（Jitsi and the OSGi Framework）</h2><p>人们已经写过关于OSGI的一整本书，所以我们不会去讲这个框架的一切。取而代之的，我们将只解释这个框架给了我们什么已经我们如何在Jitsi中使用它的。最为重要的是，OSGI是关于模块（<em>about modules</em>）的。在OSGI应用中，特征被分成了不同的句柄（<em>bundles</em>）。一个OSGI束不仅仅是一个普通的tar文件，例如像那些用来给java库和java应用分类的。Jitsi就是这样的句柄的合集。有一个负责连接到windows实时消息传送（<em>Live Messenger</em>），另一个做XMPP，还有另一个处理图形用户界面，等等。所有这些束一起运行在提供给的环境中，在我们这个事例中，也就是通过Apache Felix，一个开源的OSGI实现。</p><p>所有这些模块需要共同协作，图形用户界面的那个句柄需要通过协议句柄发送消息，而协议句柄反过来需要通过处理消息历史的束来保存那些消息。这就是OSGI服务存在的原因：它们代表了一个句柄的对任何其他人可见的部分。一个OSGI服务通常是一组允许使用特定功能，例如，登录、通过网络发送消息、或者恢复最近通话记录，的java接口。那些真正实现这些功能的类被叫做服务实现，他们大部分带着实现的服务接口的名字，通过在最后加一个“’’Impl’’”的后缀（例如’’ConfigurationServiceImpl’’）。OSGI框架允许开发者隐藏服务实现，因此保证它们在它们所处的句柄的外部是绝对不可见的。这样，其它的束只能通过服务接口使用它们。</p><p>大部分的束也有激活器（<em>activators</em>），激活器是定义了开始和停止方法的简单的接口。每次Flix加载或者移除一个在Jitsi里面的句柄，它便调用这些方法，从而使得这个句柄能够提前准备运行或者关闭。当调用这些方法的时候， Flix传给它们一个叫做句柄环境（<em>BundleContext</em>）的参数，句柄环境给了句柄连接OSGI环境的一个方式。这样，它们就能找到任何它们需要使用的OSGI服务或者它们自己注册一个（图10.1）。</p><p>图10.1：OSGI句柄的激活</p><p><img src="http://aosabook.org/cdn/images/aosabook/jitsi/OSGI.png" alt=""></p><p>那么让我们看一下它真正是怎么工作。想象一个不停地存储和恢复特性（<em>properties</em>）的服务，在Jitsi里面我们把它叫做配置服务（<em>ConfigurationService</em>），像下面的代码所示的那样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">package net.java.sip.communicator.service.configuration;</span><br><span class="line"></span><br><span class="line">public interface ConfigurationService</span><br><span class="line">&#123;</span><br><span class="line">  public void setProperty(String propertyName, Object property);</span><br><span class="line">  public Object getProperty(String propertyName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>一个配置服务的非常简单的实现如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">package net.java.sip.communicator.impl.configuration;</span><br><span class="line"></span><br><span class="line">import java.util.*;</span><br><span class="line">import net.java.sip.communicator.service.configuration.*;</span><br><span class="line"></span><br><span class="line">public class ConfigurationServiceImpl implements ConfigurationService</span><br><span class="line">&#123;</span><br><span class="line">  private final Properties properties = new Properties();</span><br><span class="line"></span><br><span class="line">  public Object getProperty(String name)</span><br><span class="line">  &#123;</span><br><span class="line">    return properties.get(name);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public void setProperty(String name, Object value)</span><br><span class="line">  &#123;</span><br><span class="line">    properties.setProperty(name, value.toString());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>注意在’’net.java.sip.communicator.service’’包中，这个服务是怎么定义的，与此同时，实现是在’’net.java.sip.communicator.impl’’中实现的。所有在Jitsi中的服务和实现都是被分开像这样的两个包下。OSGI允许句柄只让一些包在它们的JAR外面是可见的。所以这种隔离使得句柄能够很容易地提供它们的服务，同时隐藏它们的实现。</p><p>为了让人们能够开始使用我们的实现，我们最后需要做的事情是在句柄环境（’’BundleContext’’）中注册它并且指出它给出了配置服务的一个实现，下面演示了如何做到这一点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">package net.java.sip.communicator.impl.configuration;</span><br><span class="line"></span><br><span class="line">import org.osgi.framework.*;</span><br><span class="line">import net.java.sip.communicator.service.configuration;</span><br><span class="line"></span><br><span class="line">public class ConfigActivator implements BundleActivator</span><br><span class="line">&#123;</span><br><span class="line">  public void start(BundleContext bc) throws Exception</span><br><span class="line">  &#123;</span><br><span class="line">    bc.registerService(ConfigurationService.class.getName(), * service name</span><br><span class="line">         new ConfigurationServiceImpl(), * service implementation</span><br><span class="line">         null);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>一旦’’ConfigurationServiceImpl’’这个类在束环境（’’BundleContext’’）中注册了，其它的束能够开始使用它。这里是一个例子，展示了一些随机句柄是如何能够使用我们的配置服务的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">package net.java.sip.communicator.plugin.randombundle;</span><br><span class="line"></span><br><span class="line">import org.osgi.framework.*;</span><br><span class="line">import net.java.sip.communicator.service.configuration.*;</span><br><span class="line"></span><br><span class="line">public class RandomBundleActivator implements BundleActivator</span><br><span class="line">&#123;</span><br><span class="line">  public void start(BundleContext bc) throws Exception</span><br><span class="line">  &#123;</span><br><span class="line">    ServiceReference cRef = bc.getServiceReference(</span><br><span class="line">                              ConfigurationService.class.getName());</span><br><span class="line">    configService = (ConfigurationService) bc.getService(cRef);</span><br><span class="line"></span><br><span class="line">    * And that&apos;s all! We have a reference to the service implementation</span><br><span class="line">    * and we are ready to start saving properties:</span><br><span class="line">    configService.setProperty(&quot;propertyName&quot;, &quot;propertyValue&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>再一次注意这个在’’net.java.sip.communicator.plugin’’中的包，我们使得束能够使用在其它束中定义的服务但是既不输出也不实现它们中的任何一个。配置表（<em>Configuration forms</em>）是这样的插件的一个很好的例子：它们是Jitsi用户界面的补充以允许用户能够配置应用的某些方面。当用户改变他们的喜好的时候，配置表与配置服务（’’ConfigurationService’’）交互或者直接与负责一个特征的句柄交互。然而其它句柄没有一个需要与它们以任何方式交互（图10.2）</p><p>图10.2服务结构</p><p><img src="http://aosabook.org/cdn/images/aosabook/jitsi/PKGs.png" alt=""></p><h2 id="10-3-构建和运行一个句柄（Building-and-Running-a-Bundle）"><a href="#10-3-构建和运行一个句柄（Building-and-Running-a-Bundle）" class="headerlink" title="10.3.构建和运行一个句柄（Building and Running a Bundle）"></a>10.3.构建和运行一个句柄（Building and Running a Bundle）</h2><p>既然我们已经知道如何在一个句柄里面写代码，接下来让我们谈一下包。所有的句柄在运行的时候需要给OSGi环境指示三个不同的东西，对其他人可见的java包（例如外部包），还有他们想要从其它人那里使用的包（例如输入包），还有他们句柄激活器类的名字。句柄通过他们将要被部署进的jar文件的证明来做这件事情。</p><p>对于我们上面定义的ConfigurationService，它的证明文件可能如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Bundle-Activator: net.java.sip.communicator.impl.configuration.ConfigActivator</span><br><span class="line">Bundle-Name: Configuration Service Implementation</span><br><span class="line">Bundle-Description: A bundle that offers configuration utilities</span><br><span class="line">Bundle-Vendor: jitsi.org</span><br><span class="line">Bundle-Version: 0.0.1</span><br><span class="line">System-Bundle: yes</span><br><span class="line">Import-Package: org.osgi.framework,</span><br><span class="line">Export-Package: net.java.sip.communicator.service.configuration</span><br></pre></td></tr></table></figure><p>在创建了jar证明之后，我们可以来创建句柄本身。在Jitsi里面我们使用Apache Ant来处理所有构建相关的任务。为了给Jitsi的构造程序添加一个句柄。你需要在项目的根目录里面编辑build.xml文件。句柄JARs在build.xml文件的底部创建，伴随着一个bundle-xxx的目标。为了构建我们的配置服务，我们需要下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;target name=&quot;bundle-configuration&quot;&gt;</span><br><span class="line">  &lt;jar destfile=&quot;$&#123;bundles.dest&#125;/configuration.jar&quot; manifest=</span><br><span class="line">    &quot;$&#123;src&#125;/net/java/sip/communicator/impl/configuration/conf.manifest.mf&quot; &gt;</span><br><span class="line"></span><br><span class="line">    &lt;zipfileset dir=&quot;$&#123;dest&#125;/net/java/sip/communicator/service/configuration&quot;</span><br><span class="line">        prefix=&quot;net/java/sip/communicator/service/configuration&quot;/&gt;</span><br><span class="line">    &lt;zipfileset dir=&quot;$&#123;dest&#125;/net/java/sip/communicator/impl/configuration&quot;</span><br><span class="line">        prefix=&quot;net/java/sip/communicator/impl/configuration&quot; /&gt;</span><br><span class="line">  &lt;/jar&gt;</span><br><span class="line">&lt;/target&gt;</span><br></pre></td></tr></table></figure><p>就像你看到的那样，这个Ant目标使用我们的配置证明简单地创建了一个JAR文件并且把它加入到了来自service和impl层的配置包里面。现在我们需要做的唯一一件事情就是让Felix加载它。</p><p>我们已经提到Jitsi仅仅是一个OSGi句柄的集合。当一个使用者执行这个应用时。他们事实上通过一系列它需要加载的句柄来启动Felix。你能够在我们的lib目录里面的一个叫做felix.client.run.properties的文件里面发现那个清单。Felix根据启动等级来启动句柄：所有这些在一个特定的等级是为了保证在子等级句柄开始加载的前面完成。虽然你不能在上面的举例代码里面看到这些，我们的配置服务把属性存在文件里面，从而它需要使用我们的FileAccessService，这个东西在fileaccess.jar文件里面发出。因此我们能够确认ConfigurationService在FileAccessService后面启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">?    ?    ?</span><br><span class="line">felix.auto.start.30= \</span><br><span class="line">  reference:file:sc-bundles/fileaccess.jar</span><br><span class="line"></span><br><span class="line">felix.auto.start.40= \</span><br><span class="line">  reference:file:sc-bundles/configuration.jar \</span><br><span class="line">  reference:file:sc-bundles/jmdnslib.jar \</span><br><span class="line">  reference:file:sc-bundles/provdisc.jar \</span><br><span class="line">?    ?    ?</span><br></pre></td></tr></table></figure><p>如果你看一下felix.client.run.properties文件，你会在开始看到一系列包;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.osgi.framework.system.packages.extra= \</span><br><span class="line">  apple.awt; \</span><br><span class="line">  com.apple.cocoa.application; \</span><br><span class="line">  com.apple.cocoa.foundation; \</span><br><span class="line">  com.apple.eawt; \</span><br><span class="line">?    ?    ?</span><br></pre></td></tr></table></figure><p>这个清单告诉Felix它需要使什么包对于来自系统类路径的句柄是可见的。这就意味着在这个清单上的包能够被句柄导入且没有任何被其它句柄导出的包（例如加入到他们的Import-Package证明头文件）。这个清单大多包含了来自OS-specific JRE的部分的包，以及Jitsi开发者很少加入新的包的包；在大多数情况下，包被设置为对句柄可见的。</p><h2 id="10-4-协议提供者服务（Protocol-Provider-Service）"><a href="#10-4-协议提供者服务（Protocol-Provider-Service）" class="headerlink" title="10.4.协议提供者服务（Protocol Provider Service）"></a>10.4.协议提供者服务（Protocol Provider Service）</h2><p>ProtocolProviderService定义了在Jitsi里面所有协议实现行为的方法。它是所有其它句柄（例如用户界面）当他们需要通过Jitsi连接的网络发送和接受信息，打电话以及分享文件时使用的接口。</p><p>这些协议服务接口都能在net.java.sip.communicator.service.protocol包里面发现。它们是服务的多重实现，每个支持的协议有一个，而且所有都存在net.java.sip.communicator.impl.protocol.protocol_name里面。</p><p>让我们从sevice.protocol目录开始。最为突出的一个是这个ProtocolProviderService接口。一旦当某个人需要执行一个协议相关的任务的时候，它们就去在BundleContext里面找一个那个服务的实现。这些服务和它们的实现让Jitsi能够连接到任何支持的网络来检索连接状态和细节以及最为重要的是获取真正实现了沟通任务例如聊天和打电话的实现的类的引用。</p><h3 id="10-4-1-操作集合"><a href="#10-4-1-操作集合" class="headerlink" title="10.4.1.操作集合"></a>10.4.1.操作集合</h3><p>就像我们先前提到的那样。 ProtocolProviderService需要给各种各样的沟通协议和它们的不同点划分等级。然而这个对于所有协议共享的特点尤其简单，例如发送信息，对于只有一些协议支持的任务事情变得复杂多了。有时候这些不同来自服务本身：例如大部分SIP服务不支持服务器存储联系人列表，但这个对所有其它协议来说相对都被很好地支持了。MSN和AIM是另外的很好地例子：一方面他们没有一个提供对离线用户发送消息的能力，但是所有其它的却可以做到（这个已经被改变了）</p><p>底线是我们的ProtocolProviderService需要有一个方法处理这些不同，所以其他句柄，例如GUI，相对执行；给一个AIM联系人加一个打电话按钮是没有意义的，如果没有方法来实际上打一个电话。</p><p>对于营救的操作集合（图10.3）.不那么令人吃惊的是，他们是操作的集合，并且提供Jitsi句柄用来控制协议实现的接口。你在一个操作集合接口里面发现的方法都和一个特定的特征相关联。例如OperationSetBasicInstantMessaging包含了创建和发送实时信息以及注册允许Jitsi来检索收到的信息的方法。另一个例子是，OperationSetPresence有一些用来询问你的列表里面的联系人的状态以及为你 设置一个状态的方法。所以当GUI更新它显示的一个联系人的状态或者给一个联系人发送消息的时候。它最先能够询问相对应的提供者他们是否支持在线和发送消息，这个ProtocolProviderService为那个目的定义的方法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">public Map&lt;String, OperationSet&gt; getSupportedOperationSets();</span><br><span class="line">public &lt;T extends OperationSet&gt; T getOperationSet(Class&lt;T&gt; opsetClass);</span><br></pre></td></tr></table></figure></p><h3 id="10-4-2-账户，工厂以及提供者实例"><a href="#10-4-2-账户，工厂以及提供者实例" class="headerlink" title="10.4.2.账户，工厂以及提供者实例"></a>10.4.2.账户，工厂以及提供者实例</h3><h2 id="10-5-媒体服务（Media-Service）"><a href="#10-5-媒体服务（Media-Service）" class="headerlink" title="10.5.媒体服务（Media Service）"></a>10.5.媒体服务（Media Service）</h2><p>当通过IP与实时聊天系统打交道时，有一个需要理解的很重要的事情：像SIP和XMPP那样的协议，虽然被很多人看做是普通的网络通话协议，实际上不是那些通过因特网传送语音和视频的协议。这个任务是被实时传输协议（RTP）处理的。SIP和XMPP仅仅负责为RTP准备所有需要的东西，比如说决定RTP数据包需要发送到的地址，还有协商音频和视频被编码的格式（也就是codec），等等。它们也处理例如定位使用者、维护他们的使用（<em>presence</em>）、使电话响铃很多很多…这就是为什么像SIP和XMPP这样的协议经常被指作是信号（<em>signalling</em>）协议。</p><p>这在Jitsi的语境中是什么意思？好，首先它的意思是你在SIP和JabberJitsi包中都不会发现任何控制音频和视频流的代码。这类代码存在在我们的媒体服务（<em>MediaService</em>）里面。媒体服务和它的实现在’’net.java.sip.communicator.service.neomedia’’和’’net.java.sip.communicator.impl.neomedia’’里面。</p><p>^  <strong>为什么neomedia？</strong>  ^<br>| 在neomedia中的neo指它代替了我们最初使用但之后必须完全重写的一个相似的包。这是事实上就是我们想出一个大拇指规则的方法（<em>rules of thumb</em>）：几乎从来不值得花很多时间来设计一个百分之百预见未来（<em>future-proof</em>）的应用。很显然没有办法把所有事情都考虑到，所有你无论如何注定必须在之后做改变。另外很有可能一个煞费苦心（<em>painstaking</em>）设计的部分会给你带来那些你永远不需要的复杂性，因为你准备的情况绝对不会发生。 |</p><p>除了媒体服务本身以外，有两个尤其重要的接口：媒体设备（<em>MediaDevice</em>）和媒体流（<em>MediaStream</em>）。</p><h3 id="10-5-1-捕获、流动和回放（Capture-Streaming-and-Playback）"><a href="#10-5-1-捕获、流动和回放（Capture-Streaming-and-Playback）" class="headerlink" title="10.5.1. 捕获、流动和回放（Capture, Streaming, and Playback）"></a>10.5.1. 捕获、流动和回放（Capture, Streaming, and Playback）</h3><p>媒体设备代表了我们在一个电话期间使用的捕获和回放设备（图10.4）。你的麦克风和扬声器，你的耳机和网络摄像头都是这种媒体设备的例子，但是它们不是所有媒体设备。一个电话会议使用一个音频混合设备（<em>AudioMixer</em>）为了混合从积极地参与者那里收到的语音，与此同时在jitsi中桌面流和共享通话从你的桌面端抓取视频。在所有的实例中，媒体设备仅代表了一种单一的媒体类型。也就是说，他们只能要么是音频要么是视频，不能同时两者都是。这意味着，举例来说，如果你有一个集成了麦克风的网络摄像头，Jitsi把它们看成两个设备：一个只能抓取视频，另一个只能抓取声音。</p><p>然而，单独的设备不足够用来打一个电话或视频通话。除了播放和抓取媒体，一个设备必须同时能够通过网络发送他们。这就是媒体流的出处。一个媒体流接口是用来把一个媒体设备连接到你的对话者（<em>interlocutor</em>）。它代表了在一个通话中你交换的进来和出去的数据包。</p><p>和设备一样，一个流只可以负责一个媒体类型。这意味着以防音频/视频通话，Jitsi必须创两个分开的媒体流然后分别连接到对应的音频或者视频媒体设备。</p><p>图10.4：不同设备的媒体流</p><p><img src="http://aosabook.org/cdn/images/aosabook/jitsi/Media.png" alt=""></p><h3 id="10-5-2-多媒体数字信号解码器（Codecs）"><a href="#10-5-2-多媒体数字信号解码器（Codecs）" class="headerlink" title="10.5.2. 多媒体数字信号解码器（Codecs）"></a>10.5.2. 多媒体数字信号解码器（Codecs）</h3><p>另一个在媒体流中的重要概念是关于媒体格式的（<br>MediaFromats<br>），也被叫做codecs。默认情况下，大部分操作系统让你能够通过48KHzPCM抓取音频或者类似的东西。这就是我们经常说的“原声（<br>raw audio<br>）”而且你从WAV文件中获取的音频类型是：高质量和巨大的尺寸。 用PCM格式通过因特网尝试和传输音频是非常不切实际的。</p><p>这就是codecs存在的意义：他们让你通过一系列不同的方式提交和传输音频或者视频。一些音频codecs例如iLBC，8KHz Speex，或者G.729，有着很低的带宽需要但是声音有点模糊。另外的例如wideband Speex和G.722给呢绝佳的音频质量但是同时也需要更多的带宽。有一些codecs尝试传送高质量音频的同时保持带宽在一个合理的层次。H.264，流行的视频codec，就是一个很好地例子。不过用来交换的是会议期间需要的计算数量。如果你使用Jitsi来进行一场H.264视频通话，你将会看到一个质量很好地图像，而且你的带宽需求也相当合理，但是你的CPU在高速运转。</p><p>所有这些都是过度单纯化的想法，但是想法是codec的选择全都是关于妥协的。你或者牺牲带宽，质量，CPU强度，或者这些的组合。使用VoIP工作的人们很少需要知道更多关于codecs的东西。</p><h3 id="10-5-3-连接协议提供者（Connecting-with-the-Protocol-Providers）"><a href="#10-5-3-连接协议提供者（Connecting-with-the-Protocol-Providers）" class="headerlink" title="10.5.3. 连接协议提供者（Connecting with the Protocol Providers）"></a>10.5.3. 连接协议提供者（Connecting with the Protocol Providers）</h3><p>当前在Jitsi中支持音频/视频的协议都通过相同的方式使用我们的媒体设备。首先他们询问媒体设备关于系统中有的设备：</p><p>‘’public List<mediadevice> getDevices(MediaType mediaType, MediaUseCase useCase);’’</mediadevice></p><p>媒体类型（<em>MediaType</em>）指出了我们队音频还是视频感兴趣。媒体使用事例（<em>MediaUseCase</em>）参数目前只在视频设备中被考虑。它告诉媒体设备我们是否想要获取能够在一个通常的电话（<em>MediaUseCase.CALL</em>）中使用的设备，在这个事例中，它返回一个可用的网络摄像头的列表，或者一个桌面共享的会话管理器（<em>session</em>）（<em>MediaUseCase.DESKTOP</em>）在这个事例中它返回用户桌面的引用。</p><p>接下来的一步就是获得一个对一个特定设备可用的格式列表。我们通过<code>MediaDevice.getSupportedFormats</code>方法做这件事：</p><p>‘’public List<mediaformat> getSupportedFormats();’’\<br>一旦它有了这个列表，协议实现就把它发送给远程集团（<em>party</em>），这个集团回复它们中的一个子集来表示它支持哪些。这个交互也被叫做提供/答复（<em>Offer|Answer</em>）模型，而且它经常使用会话管理器描述协议（<em>Session Description Protocol</em>）或者它的某个形式。</mediaformat></p><p>在交换了格式和一些端口号和IP地址后，VoIP协议创建、配置和开始流媒体，粗略地说，这个初始化过程和下面的代码一起：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">/ first create a stream connector telling the media service what sockets</span><br><span class="line">* to use when transport media with RTP and flow control and statistics</span><br><span class="line">* messages with RTCP</span><br><span class="line">StreamConnector connector =  new DefaultStreamConnector(rtpSocket, rtcpSocket);</span><br><span class="line">MediaStream stream = mediaService.createMediaStream(connector, device, control);</span><br><span class="line"></span><br><span class="line">* A MediaStreamTarget indicates the address and ports where our</span><br><span class="line">* interlocutor is expecting media. Different VoIP protocols have their</span><br><span class="line">* own ways of exchanging this information</span><br><span class="line">stream.setTarget(target);</span><br><span class="line"></span><br><span class="line">* The MediaDirection parameter tells the stream whether it is going to be</span><br><span class="line">* incoming, outgoing or both</span><br><span class="line">stream.setDirection(direction);</span><br><span class="line"></span><br><span class="line">* Then we set the stream format. We use the one that came</span><br><span class="line">* first in the list returned in the session negotiation answer.</span><br><span class="line">stream.setFormat(format);</span><br><span class="line"></span><br><span class="line">* Finally, we are ready to actually start grabbing media from our</span><br><span class="line">* media device and streaming it over the Internet</span><br><span class="line">stream.start();</span><br></pre></td></tr></table></figure></p><p>现在你可以在你的网络摄像头前摇摆，抓着麦克风说“Hello world!”</p><h2 id="10-6-用户界面服务（UI-Service）"><a href="#10-6-用户界面服务（UI-Service）" class="headerlink" title="10.6.用户界面服务（UI Service）"></a>10.6.用户界面服务（UI Service）</h2><p>迄今为止，我们已经讲完了Jitsi处理协议，发送和接受消息以及打电话的部分。然而，更为重要的是，Jitsi是被真实的人以及类似的使用的应用程序，它其中一个最为重要的方面是Jitsi的用户界面。用户界面使用设备的大部分时间，其它所有在Jitsi中的句柄都暴露了。然而有些情况，事情却正好相反。</p><p>插件是第一个能想到的例子。在Jitsi中的插件经常需要能够和用户交互。这意味着它们必须在用户界面中打开、关闭、移动或者添加组件给当前的窗口和面板。这就是我们的UI服务起作用的地方。在Jitsi中它允许在主窗口上的基本的控制，并且这也是在MAC OS X中我们的图标停驻的方式，而且窗口通知区域让用户能控制应用程序。</p><p>除了和联系人列表简单互动之外，插件也可以扩展它。在Jitsi中实现了对聊天加密的支持的接口（OTR）就是个很好的例子。我们的OTR句柄在用户界面的各个部分需要注册几个图形界面的部分。他在聊天窗口加了一个挂锁按钮和在所有联系人的右键菜单里的分段（<em>sub-section</em>）。</p><p>好消息是它能够通过很少的方法调用来做成这件事。OTR句柄的OSGI激活器，’’OtrActivator’’，包含以下的代码语句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Hashtable&lt;String, String&gt; filter = new Hashtable&lt;String, String&gt;();</span><br><span class="line"></span><br><span class="line">* Register the right-click menu item.</span><br><span class="line">filter(Container.CONTAINER_ID,</span><br><span class="line">    Container.CONTAINER_CONTACT_RIGHT_BUTTON_MENU.getID());</span><br><span class="line"></span><br><span class="line">bundleContext.registerService(PluginComponent.class.getName(),</span><br><span class="line">    new OtrMetaContactMenu(Container.CONTAINER_CONTACT_RIGHT_BUTTON_MENU),</span><br><span class="line">    filter);</span><br><span class="line"></span><br><span class="line">* Register the chat window menu bar item.</span><br><span class="line">filter.put(Container.CONTAINER_ID,</span><br><span class="line">           Container.CONTAINER_CHAT_MENU_BAR.getID());</span><br><span class="line"></span><br><span class="line">bundleContext.registerService(PluginComponent.class.getName(),</span><br><span class="line">           new OtrMetaContactMenu(Container.CONTAINER_CHAT_MENU_BAR),</span><br><span class="line">           filter);</span><br></pre></td></tr></table></figure></p><p>正如你所看到的，给我们的图形用户界面添加新的组件简单地归结到了注册OSGi服务。另一方面，我们的用户界面服务实现在寻找它的插件组件接口的实现。它一旦探测到一个新的实现被注册了，他就获得对它的引用然后把它加到在OSGi服务过滤器中声明的容器中。</p><p>下面演示了在右键菜单项目中这是如何发生的，在UI句柄中，代表了右键菜单的类，’’MetaContactRightButtonMenu’’，包含了如下的代码行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">* Search for plugin components registered through the OSGI bundle context.</span><br><span class="line">ServiceReference[] serRefs = null;</span><br><span class="line"></span><br><span class="line">String osgiFilter = &quot;(&quot;</span><br><span class="line">    + Container.CONTAINER_ID</span><br><span class="line">    + &quot;=&quot;+Container.CONTAINER_CONTACT_RIGHT_BUTTON_MENU.getID()+&quot;)&quot;;</span><br><span class="line"></span><br><span class="line">serRefs = GuiActivator.bundleContext.getServiceReferences(</span><br><span class="line">        PluginComponent.class.getName(),</span><br><span class="line">        osgiFilter);</span><br><span class="line">* Go through all the plugins we found and add them to the menu.</span><br><span class="line">for (int i = 0; i &lt; serRefs.length; i ++)</span><br><span class="line">&#123;</span><br><span class="line">    PluginComponent component = (PluginComponent) GuiActivator</span><br><span class="line">        .bundleContext.getService(serRefs[i]);</span><br><span class="line"></span><br><span class="line">    component.setCurrentContact(metaContact);</span><br><span class="line"></span><br><span class="line">    if (component.getComponent() == null)</span><br><span class="line">        continue;</span><br><span class="line"></span><br><span class="line">    this.add((Component)component.getComponent());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这就是它的一切。你在Jitsi中看到的大部分窗口准确地做着相同的事情，他们浏览那些实现了有着声明了他们想要被添加为匹配容器的滤波器的插件组件接口服务的句柄环境。插件就像举着写有他们的目的地的标志牌的搭顺风车的人，把Jitsi窗口看成把他们带上的司机。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Jitsi中文翻译&quot;&gt;&lt;a href=&quot;#Jitsi中文翻译&quot; class=&quot;headerlink&quot; title=&quot;Jitsi中文翻译&quot;&gt;&lt;/a&gt;Jitsi中文翻译&lt;/h1&gt;&lt;h2 id=&quot;Chapter-10-Jitsi引言&quot;&gt;&lt;a href=&quot;#Chapter
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Mailman</title>
    <link href="http://blog.ccao.cc/2018/09/28/Mailman/"/>
    <id>http://blog.ccao.cc/2018/09/28/Mailman/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GNU-Mailman-翻译"><a href="#GNU-Mailman-翻译" class="headerlink" title="GNU Mailman 翻译"></a>GNU Mailman 翻译</h1><h3 id="Barry-Warsaw"><a href="#Barry-Warsaw" class="headerlink" title="Barry Warsaw"></a>Barry Warsaw</h3><p>源自《The Architecture of Open Source Applications》II 第十章</p><p>== 注：由于本人英语水平不高，图灵社区的翻译计划恰好又没有这篇文章，故翻译有些磕磕绊绊，若有难以读懂和理解之处，敬请谅解 ==</p><p>== 原文地址 <a href="http://aosabook.org/en/mailman.html" target="_blank" rel="noopener">http://aosabook.org/en/mailman.html</a> ==</p><p><img src="http://aosabook.org/cdn/images/aosabook/cover2.jpg" alt=""></p><p><a href="http://www.list.org/" target="_blank" rel="noopener">http://www.list.org/</a> GNU Mailman 是一款管理邮件列表的免费软件。几乎所有书写或使用免费和开源软件的人都会遇到一个邮件列表。邮件列表可以以讨论为基础或以公告为基础，在这两者间有着各种类型的变化。有时邮件列表在Usenet的新闻组上是相互连通的，或者有类似的服务如 <a href="http://gmane.org/|Gmane" target="_blank" rel="noopener">http://gmane.org/|Gmane</a> 。邮件列表通常包含一些档案，这些档案涵盖了已发布到邮件列表的所有信息的历史记录。</p><p>GNU Mailman在20世纪90年代初期出现，当时John Viega编写了第一个版本来使得球迷与初期的戴夫马休斯乐队相互联系，而乐队的成员是他在大学的朋友。在90年代中期，这个早期的版本引起了Python社区的关注，那时Python领域的中心已不再是 <a href="http://www.cwi.nl/|CWI" target="_blank" rel="noopener">http://www.cwi.nl/|CWI</a> 这个荷兰的科学研究院，而是转到了<a href="http://www.cnri.reston.va.us/|CNRI" target="_blank" rel="noopener">http://www.cnri.reston.va.us/|CNRI</a> ，在美国弗吉尼亚雷斯顿的国家研究创始公司。那时，CNRI这在使用Majordomo（一款基于Perl的邮件列表管理器）来运行各种类型的与Python相关的邮件列表。当然，这不仅会为Python世界维持大量的Perl代码。更重要的是，由于它的设计，我们发现，为了我们的目修改Majordomo（如添加最小的反垃圾邮件措施）太难了。</p><p>Ken Manheimer在许多早期的Mailman工作中提供了许多帮助，并且许多优秀的开发者在那时也为Mailman做了很大贡献。今天，Mark Sapiro维护着稳定的2.1版本分支，而Barry Warsaw，本章的作者，正全神贯注于全新的3.0版本。</p><p>许多John提出的最初的体系结构设计一直到Mailman的第三版分支仍旧存留在代码之中，并且在其稳定的版本中可见。在之后的章节中，我将介绍一些在Mailman1和2中有问题的设计决策，并且我们是如何在Mailman3中处理它们的。</p><p>在早期Mailman 1的时代，我们遇到许多问题，如信息丢失，或由bug引起的信息一遍又一遍的反复传送。这促使我们明晰了两个在Mailman走向成功的道路上非常重要的准则： <em> 没有一条信息应该丢失。 </em> 没有一条信息应该被传送多次。</p><p>在Mailman 2中我们重新设计了信息处理系统来保证这两个原则总是最重要的。这部分的系统到现在已经稳定至少十年了，并且是Mailman到现在无所不在的一个重要原因。尽管这个子系统在Mailman 3中进行了现代化处理，这个设计和实现在很大程度上保持不变。</p><h2 id="10-1-报文的解析（The-Anatomy-of-a-Message）"><a href="#10-1-报文的解析（The-Anatomy-of-a-Message）" class="headerlink" title="10.1. 报文的解析（The Anatomy of a Message）"></a>10.1. 报文的解析（The Anatomy of a Message）</h2><p>Mailman中一个核心数据结构便是邮件报文（email message），表现为一个报文对象（message object）。系统中的许多接口、函数和方法，有三个参数：邮件列表对象、报文对象和当系统中的报文被加工时用于记录和传达状态的元数据字典。</p><p><img src="http://aosabook.org/cdn/images/aosabook/mailman/mime.png" alt="Figure 10.1: A MIME &#39;&#39;multipart/mixed&#39;&#39; message containing text, images, and an audio file"></p><p>在它的表面，邮件报文是一个简单的对象。它由许多的被称为表头的由冒号分隔的键-值对组成，后面跟一个空行，将表头从报文中分离出来。这种结构的表示方法应是很容易被语法分析、生成、推理、操纵的，但事实上它很快就变得非常复杂。有无数的RFC来描述所有可能发生的变化，例如处理复杂的数据类型，如图像，音频等等。电子邮件可以包含ASCII英文，或是任何存在的语言和字符集。一封电子邮件报文的基本结构已经被其他协议一遍又一遍借鉴，如NNTP和HTTP，但每个稍有不同。我们对于Mailman 的工作已经演化成几个库来处理这种格式的变化（通常被称为“RFC822”，建立于1982年[[<a href="http://www.faqs.org/rfcs/rfc822.html|IEFT" target="_blank" rel="noopener">http://www.faqs.org/rfcs/rfc822.html|IEFT</a> 标准]]）。电子邮件库最初的开发是为了GNU Mailman从而使用了Python标准库，在此开发得以继续并且符合更多的标准，变得更加健壮。</p><p>电子邮件可以作为其他类型数据的容器，正如各种MIME标准定义的那样。一个容器报文部件（message part）可以给一张图像，一些音频，或只是任何类型的二进制或文本数据编码，这囊括了其他容器部件。在邮件阅读器中，这些被称为附件。图10.1展示了一个复杂的MIME报文的结构。有实线边框的框架作为容器部件，虚线边框的框架是被二进制数据编码的Base64， 点实线边框的框架代表普通的文本信息。</p><p>容器部件还可以任意嵌套；这些被称为混合部件（multiparts），事实上可以变得更深。但是，不管它的复杂性，任何电子邮件都可以被建模为一棵树，它有一个单独的报文对象作为根节点。在Mailman中，我们常称之为报文对象树，并参考其根报文对象来传递这可树。图10.2显示了图10.1中的混合部件报文的对象树。</p><p><img src="http://aosabook.org/cdn/images/aosabook/mailman/tree.png" alt="Figure 10.2: Message object tree of a complex MIME email message"></p><p>Mailman总是会以某种方式修改原始消息。有时，转换可以是相当良性的，如添加或删除表头。有时我们会完全改变报文对象树的结构，例如内容过滤器去除某些类型像是HTML、图片或者其他非文本部分的内容。Mailman甚至可能崩溃”multipart/alternatives”，其中报文既显示为普通的文本又显示为一些富文本类型，或添加了额外的部分，这部分包含着关于邮件列表本身的信息。</p><p>Mailman仅仅解析线上代表一封报文的字节一次，便是当它第一次进入系统之时。从那时起，它只处理报文对象树，直到准备将它发送回开放的邮件服务器。在这一点上，Mailman将这棵树变成一个字节表示。在这种方式下，Mailman https:*docs.python.org/2/library/pickle.html|pickles ）报文对象树，为了快速存储和重建文件系统。Pickles是一种能够序列化任何Python对象的Python技术，包括它的所有子对象，一个字节流，并且它完全适合优化邮件对象树的处理。Unpickling是一种使字节流返回到存在对象的反序列化技术。通过在一个文件中存储这些字节流，Python程序获得低成本的持续性。</p><h2 id="10-2-邮件列表（The-Mailing-List）"><a href="#10-2-邮件列表（The-Mailing-List）" class="headerlink" title="10.2.邮件列表（The Mailing List）"></a>10.2.邮件列表（The Mailing List）</h2><p>邮件列表显然是Mailman系统的另一个核心对象，并在Mailman中的大多数操作都是以邮件列表为中心的，如： <em> 根据用户或地址成员资格被定义为已被订阅到一个特定的邮件列表。 </em> 邮件列表中有大量的配置选项被存储在数据库中，这用来控制了从邮递权限到最终递送前如何修改报文的全部事情。 <em> 邮件列表有所有者和版主，他们有更大的权限来改变列表的某些方面，或批准、或拒绝有问题的邮递。 </em> 每一个邮件列表都应有它自己的存档。 * 用户邮递一封新的报文到一个特定的邮件列表。</p><p>如上等等。几乎在Mailman中的每一个操作都把邮件列表作为参数————那是最为基本的。邮件列表的对象已经被彻底重新设计在Mailman 3中，为了使它们更高效并且扩展了其灵活性。</p><p>John最早的一个设计决定是如何在系统内部表示一个邮件列表对象。为了这个处于最中心的数据类型，他选择了一个具有多个基类的Python类，每一个都实现了邮件列表任务的一小部分。这相互合作的基类，被称为mixin类，这是一种很聪明的组织代码的方式，以致于可以轻易添加全新的功能。通过在一个新的mixin基类上嫁接，核心邮件列表’’MailList’’类可以很容易地容纳一些新的酷炫的东西。</p><p>例如，在Mailman 2中添加一个自动回复，一个mixin类被创建来支持数据实现那个功能。当一个新的邮件列表被创建时，数据将自动初始化。mixin类还提供了方法来给自动回复功能必要的支持。这种结构甚至是更加有用的当考虑到邮递’’MailList’’对象的持久性时。</p><p>另一个John的早期设计决策是使用Python pickles来存储’’MailList’’状态持续性。</p><p>在Mailman 2中，该’’MailList’’对象的状态被存储在一个名为’’config.pck’’的文件中，这只是’’MailList’’对象的字典的pickled代表。每个Python对象都有一个属性字典称为’’__dict__‘’。所以保存邮件列表对象就是是一件简单的事（pickling它的’’__dict__‘’到一个文件中），而加载它仅需从文件中阅读pickle然后重构其’’__dict__‘’。</p><p>因此，当一个新的mixin类被加入来实现一些新的功能时，所有mixin的属性都被自动且适当地pickled和unpickled。我们不得不做的唯一额外工作便是维护架构版本号来自动升级旧的邮件列表对象每当新的属性通过mixin被加入时，这是由于旧的’’MailList’’对象的标识被pickled时将会丢失新的属性。</p><p>如它过去那般便捷，mixin架构和pickle持久性最终崩塌在自己的重量之下。现场管理员经常要寻求某种方式来通过外部访问邮件列表配置变量，而非Python系统。但是pickle协议完全是Python专用，因此其内部所有有用的数据在均被隔绝了，pickle无法使用它们。同时，由于一个邮件列表的整个状态被包含在’’config.pck’’之中，而Mailman有许多需要读写、修改邮件列表状态的过程，我们不得不实现一种基于文件的并且满足NFS安全的锁来保证数据的一致性。每次Mailman的一些部分想改变邮件列表的状态时，它必须获取锁，写出变化，然后释放锁。甚至读操作也需要申请列表的’’config.pck’’文件的重载，因为在读操作之前一些其他进程可能已经改变了它。这一系列在邮件列表上的操作将造成令人可怕的慢和低效的结果。</p><p>因为这些原因，Mailman 3将所有的数据存储在SQL数据库中。默认使用SQLite3，尽管这很容易改变，由于Mailman 3使用了叫做风暴（Storm）的对象关系映射（Object Relational Mapper），它支持广泛的数据库。PostgreSQL支持通过仅仅几行代码被加入其中，并且一个站点管理员可以通过改变一个配置变量来启用它。</p><p>另一个存在于Mailman 2中很大的一个问题，便是每个邮件列表是一个仓库。通常操作要跨越多个邮件列表，甚至是所有。例如，用户可能希望在休假时暂时停止所有的订阅。或者站点管理员可能要在他的系统上给那些邮件列表中受欢迎的邮件添加一些免责声明。即使是找出哪些单独地址被请求订阅的邮件列表unpickling系统的每个邮件列表的状态这样的简单事情，也会由于会员信息被保存在’’config.pck’’文件（而跨域多个邮件列表）。</p><p>另一个问题是，每个’’config.pck’’文件都在一个以邮件列表命名的目录下，但是Mailman最初设计时没有考虑虚拟域名。这导致了一个非常不幸的问题，在不同的领域，邮件列表可能有不同的名称。例如，如果你拥有’’example.com’’和’’example.org’’域名，你想让它们独立行动并且允许各自邮件列表不同的’’support’’，你在Mailman 2中便无法做到这一点，在没有修改代码、勉强支撑的”挂钩“、或常规的解决方法（强迫不同的列表名称在覆盖之下），而这也是大型网站如SourceForge使用的方法。</p><p>这在Mailman 3中通过改变邮件列表确定的方式而得以解决，随着将所有的数据移到一个传统的数据库中。邮件列表表格中的主键是完全限定的列表名称（fully qualified list name），或者你大概已经认出它了————邮件地址。因此<a href="mailto:&#39;&#39;support@example.com" target="_blank" rel="noopener">&#39;&#39;support@example.com</a>‘’和<a href="mailto:&#39;&#39;support@example.org" target="_blank" rel="noopener">&#39;&#39;support@example.org</a>‘’现在在邮件列表表格中是完全独立的行，并可以很容易地共存于一个Mailman系统中。</p><h2 id="10-3-Runners"><a href="#10-3-Runners" class="headerlink" title="10.3.Runners"></a>10.3.Runners</h2><p>通过一组称为runners的独立的进程，报文流过整个系统。最初设想的方式，在一个特定的目录中对所有已排好队列的报文文件进行有预见性地加工，现在有几个简单独立的runners、执行特定的任务的长期运行的进程并且被一个主要进程所管理；在这以后更是如此。当一个runner在一个目录中管理文件时，它被称为一个queue runner。</p><p>Mailman是严格单线程的，即使有重要的并行事务需要开发。例如，Mailman可以接受邮件服务器上的报文同时发送邮件给收件人，或处理反弹，或进行归档。Mailman中的并行是通过多个进程来实现的，以这些runners的形式。例如，有一个输入队列runner，其唯一的工作便是接受（或拒绝）来自上游邮件服务器的邮件。有一个输出队列runner，其唯一的工作便是与其上游邮件服务器通过SMTP通信，也是为了给最终的收件人发送邮件。有一个存档（archiver）队列runner，一个弹跳（bounce）处理队列runner，一个队列runner为了给NNTP服务器转发邮件，一个runner来写摘要，以及几个其他的runner。不管理队列的runners包含一个本地邮件转移协议服务器（[[<a href="http://tools.ietf.org/html/rfc2033|Local" target="_blank" rel="noopener">http://tools.ietf.org/html/rfc2033|Local</a> Mail Transfer Protocol]]）和一个HTTP管理服务器。</p><p>每个队列的runner负责一个单独的目录，也即它的队列。而典型的邮Mailman系统给每个队列一个单独的进程也可以执行得非常出色单，我们使用了一个巧妙的算法允许在一个单一的队列目录中并行，而不需要任何形式的合作或锁定。其中的秘密便是以我们以队列目录来命名文件。</p><p>如上所述，每一个流经系统的报文也伴随着一个元数据字典来积累状态并允许Mailman中的独立部件互相通信。Python的’’pickle’’库能够序列化和反序列化多个对象到一个单独文件中，所以我们可以pickle报文对象树和元数据字典合并在一个文件中。</p><p>有一类Mailman核心类叫做’’Switchboard’’,提供一个接口使报文对象树和元数据字典在一个特定的队列目录中对文件的入队和出队操作。每个队列目录至少有一个switchboard实例，并且每个队列runner实例恰好有一个switchboard。</p><p>Pickle文件均以’’.pck’’为后缀，尽管你也可以看到’’.bak’’、’’.tmp’’、’’.psv’’的文件在队列之中。这些是用来确保Mailman中两个神圣不可侵犯的原则：没有文件会丢失，并且没有信息会被递送超过一次。但事情通常要正常运作，这些文件可能是相当罕见的。</p><p>正如所指出的那样，Mailman支持非常繁忙的网络，它在每个队列上完全平行地运行了不只一个runner进程，在处理文件之时它们之间没有任何通信也不必有任何锁定。它通过使用SHA1哈希来给pickle文件命名，然后允许一个单独的队列runner管理哈希空间的一部分。因此，如果一个站点想要在反弹队列（bounces queue）运行两个runners，一个在哈希空间上半部分处理文件，另一个在哈希空间的下半部分处理。通过使用pickled报文对象树的内容、信息已被确定的邮件列表的名字和时间戳来计算哈希值。SHA1哈希值具有高效的随机性，因此平均上一个双流道队列目录对于其每个进程都有相等数量的任务。因为哈希空间可以静态地划分，这些进程可以在同一个队列目录中进行操作，没有任何干扰也无需必要的通信。</p><p>这个算法有一个很有趣的限制。由于分裂算法分配给每个空间一个或多个位的哈希值，每个队列目录中runners的数量必须是2的幂。这意味着可以有1个，2个，4个，或8个runner进程在每个队列之中，但不可能是5个。在实践中，这从来不是一个问题，因为几乎没有站点需要超过4个进程来处理它们的负载。</p><p>此算法的另一个副作用是在这个系统早期的设计过程中产生了问题。尽管在通常的电子邮件发送是不可预见的，通过以FIFO顺序处理队列文件来提供最佳的用户体验，所以邮件列表的回复将以粗略的时间顺序发送。不去尽最大的努力尝试将使会员们感到困惑。但使用SHA1哈希值作为文件名将去除任何时间戳，为了性能原因’’stat()’’在队列文件中调用，或unpickling内容（例如，读取元数据中的时间戳）应该被避免。</p><p>Mailman的解决方案是扩展文件命名算法使其包括一个时间戳的前缀，正如纪元中秒的数字（例如，`<timestamp>+<sha1hash>.PCK’’）。每个队列runner循环以执行’’listdir()’’开始，最后返回队列目录下的所有文件。然后对每一个文件，将文件名分开，忽略任何SHA1哈希值不匹配其负责部分的文件。runner然后将以文件名的时间戳部分为基础将剩余的文件分类。确实，多队列runner每个管理哈希空间的不同片段，这可能导致并行runners间的排序问题，但在实践中，时间戳排序足以保护最终用户感觉到最大程度的按序传送。</sha1hash></timestamp></p><p>在实践中，这已经非常好地工作了至少十年，只有偶尔的小错误修正或精心的处理（针对模糊的角落用例和故障模式）。这是Mailman中最稳定的部分之一并且在Mailman 2到Mailman 3的过度中很大部分都是直接移植毫无改动的。</p><h2 id="10-4-The-Master-Runner"><a href="#10-4-The-Master-Runner" class="headerlink" title="10.4.The Master Runner"></a>10.4.The Master Runner</h2><p>拥有这些runner进程，Mailman需要有一种简单的方法能够持续地启动和停止它们；因此主监视进程诞生了。它必须能够处理队列中的runners和不管理队列的runners。例如，在Mailman 3中，我们通过LMTP从上游邮箱服务器的输入端接受信息，这是一种类似SMTP的协议，但其操作仅可本地传送，因此它可以非常简单而不需要处理过一个不可预知的互联网上传送邮件的异常行为。LMTPrunner仅仅监听一个端口，等待其上游的邮件服务器连接并发送一个字节流。然后将这个字节流解析为一个消息对象树，创建初始元数据字典，并且在一个进程队列目录中使其入队。</p><p>Mailman也有一个runner监听另一个端口然后处理HTTP上的REST请求。这个进程不处理队列文件。</p><p>一个典型的运行时Mailman系统可能有八个或十个进程，并且它们都需要适当且方便地停止和开始。它们也可以偶尔崩溃；例如，当Mailman中的一个bug导致突如其来的异常发生。当这一切发生的时候，被传递的消息被分流到一个固定区域，此时系统的状态正处在异常依旧存在于消息元数据的时间。这确保了未捕获的异常不会导致消息的多次交付。在理论上，Mailman网站点管理员可以解决这个问题，然后对违规的消息不去分流以再次传递，在它离开的地方挑出它。分流有问题的消息后，master重启崩溃的队列runner，开始处理队列中剩余的消息。</p><p>当主监视器启动时，它在一个配置文件中查看来确定有多少并且哪些类型的子runners需要启动。对于LMTP和RESTrunners，通常有一个单独的进程。对于队列runners，如上所述，可以有2的幂的个数的并行进程。master基于配置文件’’fork()’’和’’exec()’’所有的runner进程，经过适当的命令行参数相互传递（例如，告诉子进程需要查看哪一块散列空间）。master基本上是处于一个无限循环中，直到它的一个子进程出现时退才堵塞。它跟踪了每个子进程的进程标识，以及子进程已重新启动的次数的计数。此计数防止灾难性的错误（造成一连串不可阻挡的重新启动）。有一个配置变量指定多少次重启是允许的，在那之后一个错误将被记入日志并且runner不再重新启动。</p><p>当一个子进程退出时，master查看退出代码和杀死子进程的信号。每个runner进程都安装了大量能处理以下几个语义的信号： <em> ‘’SIGTERM’’:故意停止进程。它不会重新启动。’’SIGTERM’’之行’’init’’当运行级别改变之时会杀死进程，也是Mailman本身用来停止子进程的信号。 </em> ‘’SIGINT’’ ：也常用来特意阻止子进程，它是一个信号发生在shell中使用control－C之时。runner不会重启。 <em> ‘’SIGHUP’’ ：告诉进程关闭然后重新打开日至文件，但不会持续运行。这将在轮换日至文件时使用。 </em> ‘’SIGUSR1’’ ：初始阻止子进程，但不允许master重启子进程。这在’’restart’’命令行的初始代码时使用。</p><p>master会相应这四种信号，但工作量不会超过将其转交给其子进程。所以如果你发送’’SIGTERM’’信号给master，所有的子进程都会收到’’SIGTERM’’然后退出。因为’’SIGTERM’’master知道子进程的退出,并且它也知道这是一个有意识的停滞，所以它不会重新启动runner。</p><p>为了确保在任何时间只有一个master运行，它获得了一个大约一天半的全时锁。master安装一个’’SIGALRM’’信号处理程序，来每天唤醒master一次以致于它可以重新刷新锁。由于锁的生命周期比唤醒的间隔时间长，锁应该永远不会超时或破坏当Mailman正在运行之时，除非系统崩溃或master被一个不可捕获的信号杀死了。在这些情况下，命令行界面到master进程间提供一个选项来重写一个过期的锁。</p><p>这导致master监视器的最后一位，命令行到它的接口。现实的master脚本中需要很少的命令行选项。它和队列runner脚本都是特意保持简单的。这不是Mailman 2中的特例，在此master脚本是相当复杂的并且做的太多，这使得它很困难来理解和调试。在Mailman 3中，真正的对于master进程的命令行接口是在’’bin/mailman’’脚本中，一种包含许多子命令的元脚本，在一个类似Subvision程序营造的受欢迎的风格之中。这减少了需要安装在您的shell的’’Path’’上的程序的数量。’’bin/mailman’’有子命令来启动、停止以及重启master，还有所有的子进程，并导致所有日志文件重新开放。’’start’’子命令fork()和exec()master进程，而其他只是发出相应的信号给master，然后如上所述传到子过程。这种改进后的责任分离使得每一个独立部分更容易理解。</p><h2 id="10-5-规则、环节和链（Rules，Links，and-Chains）"><a href="#10-5-规则、环节和链（Rules，Links，and-Chains）" class="headerlink" title="10.5.规则、环节和链（Rules，Links，and Chains）"></a>10.5.规则、环节和链（Rules，Links，and Chains）</h2><p>一个邮件列表的布置经过几个阶段，从第一次收到，直到它发送给列表的成员。在Mailman 2中，每个处理步骤被表示为一个handler，以及一系列的handlers都放在一个管道之中（pipeline）。所以，当一个邮件进入系统，Mailman将首先确定使用哪一个管道来处理它，然后在管道的每个处理程序handler将依次调用。一些处理程序会做一些适度的功能（例如，“这个人可以邮寄到邮件列表吗？”），其他会做修改的功能（例如，“我应该删除或添加哪一个头文件？”），其它的会复制报文到其他队列。后者的几个例子： <em> 一个已经接收并要发送的消息将被复制到归档(‘’archiver’’)队列在某个时刻，因此它的队列runner将把报文添加到存档中。 </em> 该消息的副本最终不得不在输出(‘’outgoing’’)队列中结束，以便它可以被传送到上游的邮件服务器，该服务器最终负责将其递送给列表成员。 * 一份邮件的副本必须被放进一个摘要之中，为了那些只是偶尔、定期从列表中通信的人，而不是任何时候某人发送的单独的消息。</p><p>处理器的管道架构被证明是相当强大的。它提供了一个十分简单的方法，使人们可以扩展和修改Mailman来做定制一些自定义操作。处理程序的接口是相当直接的，实现一个新的处理程序将是一件十分简单的事，确保它被添加到管道中正确的位置以完成自定义操作。</p><p>这里有一个问题，在同一管道中缓和和修改混在一起是有问题的。处理程序必须在管道中被测序，或不可预测或不希望发生的事情则可能发生。例如，如果添加了[[<a href="http://www.faqs.org/rfcs/rfc2369.html|RFC" target="_blank" rel="noopener">http://www.faqs.org/rfcs/rfc2369.html|RFC</a> 2369]]’’List-*’’表头后处handler将会跟着另一个handler出现把消息复制到摘要整理中，然后正在接收摘要的人们将得到不正确的列表邮件副本。在不同的情况下，它可能有益于缓和报文在修改它之前或修改它之后。在Mailman 3中，缓和和修改的操作已经被分割成独立的子系统，为了更好地控制先后顺序。</p><p>如前所述，LMTP runner解析输入字节流到一个消息对象树之中并且给消息创建一个生成初始元数据字典。然后将这些入队进一个或其他的队列目录之中。一些消息可能是电子邮件命令（例如，加入或离开一个邮件列表，获得自动化帮助等），这是由一个单独的队列处理。大多数邮件都是张贴到邮件列表中，这些被放入在输入队列中。输入队列runner按顺序处理每一个消息通过一个包涵了各种链接的链（chain）。有一个内置的链，供大多数的邮件列表使用，但这也是可配置的。</p><p>图10.3阐述了在Mailman 3系统的chain中的默认集合。链中的每一个环节（link）都是由一个圆角矩形所示。内置的链是一个适度的初始规则被应用到传入消息的地方，并在这个链中，每一个环节伴随一个规则。规则是简单的代码块，它获取三个特征参数：邮件列表、消息对象树和元数据字典。规则是不支持修改消息的；他们只是作出一个二进制的决定，并返回一个布尔值来回答问题，“规则是否匹配？”。规则还可以在元数据字典中记录信息。</p><p>在图中，当规则匹配时，实心箭头指示消息流，而在规则不匹配时，点线箭头指示消息流。每个规则的结果记录在元数据字典中以便日后Mailman会精确地知道（并且能够报告）哪些规则匹配和哪些错过了。虚线箭头指示转换是无条件的，不管规则是否匹配。 </p><p><img src="http://aosabook.org/cdn/images/aosabook/mailman/chains.png" alt="Figure 10.3: Simplified view of default chains with their links"></p><p>着重提醒的一点是，规则本身不根据结果来调度。在内置链中，每一个环节都与规则匹配时执行的动作相关。例如，当“循环”规则匹配（意思是，邮件列表之前看到过这个消息）时，该消息立即被传递给“丢弃”链，它将其登记后丢弃该消息。如果“循环”规则不匹配，则链中的下一个关联会处理这个消息。</p><p>在图10.3中，伴随着“新闻”、“最大规模”，和“真理”规则的环节没有二元决策。在前二个的情况下，这是因为其行动被推迟了，所以它们简单地记录结果然后继续下一个关联的处理。如果以前的规则匹配，“任何”规则之后都会匹配。这样的话，Mailman可以报告所有为什么消息不被允许邮递的原因，而不是仅仅第一个原因。为了简单，有几个这样的规则没有在这里说明。</p><p>“真理”的规则有点不同。它总是与链中的最后一个环节关联，并且它总是匹配的。在倒数第二的”任何“规则扫除所有以前的匹配信息的组合，最后一个环节就知道任何到达这里的消息被允许可以发布到邮件列表，所以它无条件地将邮件移动到“接受”链。</p><p>有几个链处理过程的细节在这里没有被描述，但该架构是非常灵活和可扩展的，所以对任何类型的消息处理都可以实现，站点可以自定义，并且扩展规则、环节和链。</p><p>当它击中“接受”链时报文会发生什么？现在适合于邮件列表中的报文，在它被邮递给最终接收者之前，被放到管道队列中修改。这个过程在下面的章节中将更详细地描述。</p><p>“hold”链将消息放在一个特殊的桶中，为了核对人审查。“缓和（moderation）”链做了一些额外的处理，以决定是否应该接受消息，把持着为了核对人的批准，放弃或拒绝。为了不让图过于凌乱，“拒绝”链，用来反弹消息给最初的发送者，并是没有说明。</p><h2 id="10-6-Handlers和Pipelines"><a href="#10-6-Handlers和Pipelines" class="headerlink" title="10.6.Handlers和Pipelines"></a>10.6.Handlers和Pipelines</h2><p>一旦一个消息以其方式通过链和规则，并且被同意发送，消息必须进一步处理，才可以交付给最终收件人。例如，一些表头可能会增加或删除，有些信息可能会得到一些额外的装饰以提供了重要的免责声明或信息，比如如何离开邮件列表。这些修改是由一个包含一系列handlers的管道执行的。在类似的链和规则下，管道和handlers是可扩展的，但对于一般情况，有大量的内置管道。Handlers有类似的接口，就如规则，接受邮件列表、消息对象和元数据字典。然而，与规则不同，handlers可以修改消息。图10.4说明了默认的管道和一组的handlers（为了简单一些handers被省略）。<br><img src="http://aosabook.org/cdn/images/aosabook/mailman/pipeline.png" alt="Figure 10.4: Pipeline queue handlers"></p><p>例如，一个发布的消息需要有一个优先级’’Precedence’’：在表头添加，告诉其他自动化软件这个消息来自邮件列表。这表头是事实标准，以防止一些闲置程序响应邮件列表。通过“add headers”handler将其添加到表头（在其他表头修改之间）。与规则不同的是，handler顺序通常不重要，而消息总是流过管道中的所有handlers。</p><p>一些handler将消息的副本发送到其他队列。如图10.4所示，有一个handler，给哪些想要收到摘要的制作消息的副本。副本也被发送到归档队列中，为了最终交付给邮件列表存档。最后，将邮件复制到发送队列中，以最终传递给邮件列表上的成员。</p><h2 id="10-7-VERP"><a href="#10-7-VERP" class="headerlink" title="10.7.VERP"></a>10.7.VERP</h2><p>VERP代表可变信封返回路径(<a href="http://cr.yp.to/proto/verp.txt|Variable" target="_blank" rel="noopener">http://cr.yp.to/proto/verp.txt|Variable</a> Envelope Return Path )，它是一个众所周知的技术，邮件列表使用它明确收件人地址。当邮件列表上的地址不再活跃时，收件人的邮件服务器将发送一个通知返还给发件人。在邮件列表的这种情况下，你希望这个反弹回到邮件列表，而不是消息的原始作者；作者关于这个反弹不能做任何事情，更糟的是，发送反弹返还到作者可能泄露关于谁订阅了邮件列表的信息。当邮件列表得到了反弹，但是，它可以做一些有用的事，如禁用的弹跳地址或从列表的成员中删除它。</p><p>通常这有两个问题。首先，尽管对这些反弹有一个标准格式（称为发送状态通知[[<a href="http://www.faqs.org/rfcs/rfc5337.html|delivery" target="_blank" rel="noopener">http://www.faqs.org/rfcs/rfc5337.html|delivery</a> status notifications]]），许多部署邮件服务器不符合它。相反，他们的反弹信息可以包含任意数量的机器难以解读的官样文章，为自动进行语法分析带来困难。事实上，Mailman使用的库，包含许多的反弹格式的试探法，所有这些都可以在Mailman存在的15年间看到。</p><p>其次，想象一个邮件列表的成员有几个转发的情况。她可能以地址<a href="mailto:&#39;&#39;anne@example.com" target="_blank" rel="noopener">&#39;&#39;anne@example.com</a>‘’被订阅，但是这可能转发到<a href="mailto:&#39;&#39;person@example.org" target="_blank" rel="noopener">&#39;&#39;person@example.org</a>‘’，这可能进一步将消息转发到<a href="mailto:&#39;&#39;me@example.net" target="_blank" rel="noopener">&#39;&#39;me@example.net</a>‘’。当’’example.net’’最终目标服务器接收邮件，它通常只发送一个反弹说<a href="mailto:&#39;&#39;me@example.net" target="_blank" rel="noopener">&#39;&#39;me@example.net</a>‘’不再有效。但是发送邮件到Mailman服务器只知道例如<a href="mailto:&#39;&#39;anne@example.com" target="_blank" rel="noopener">&#39;&#39;anne@example.com</a>‘’的成员，所以反弹标记<a href="mailto:&#39;&#39;me@example.net" target="_blank" rel="noopener">&#39;&#39;me@example.net</a>‘’将不包含订阅地址，而Mailman会忽略它。</p><p>随着VERP的到来，开发基本的SMTP协议需求来提供明确的反弹检测，通过返回这样的反弹报文给信封的发送者。这不是消息体的’’From:’’域，但实际上在SMTP对话期间’’MAIL FROM’’的值将被设定。在传送路线中这将一只保存，并且最终的接收邮件服务器是必需的，根据标准，发送反弹到这个地址。Mailman使用这个事实将原始收件人的电子邮件地址编码成’’MAIL FROM’’值。</p><p>如果服务器是<a href="mailto:&#39;&#39;mylist@example.org" target="_blank" rel="noopener">&#39;&#39;mylist@example.org</a>‘’，然后VERP编码的信封发件人发布给<a href="mailto:&#39;&#39;anne@example.com" target="_blank" rel="noopener">&#39;&#39;anne@example.com</a>‘’为了邮件列表的递送：</p><p><a href="mailto:&#39;&#39;mylist-bounce+anne=example.com@example.org" target="_blank" rel="noopener">&#39;&#39;mylist-bounce+anne=example.com@example.org</a>‘’</p><p>在这里，’’+’’是一个本地地址分隔符，这是一种被大多数现代邮件服务器支持的格式。所以当反弹回来，它会被送到 <a href="mailto:&#39;&#39;mylist-bounce@example.com" target="_blank" rel="noopener">&#39;&#39;mylist-bounce@example.com</a>‘’但是带着’’To:’’的表头仍旧设置VERP编码的收件人地址。Mailman可以解析这个’’To:’’表头来解码最初收件人例如<a href="mailto:&#39;&#39;anne@example.com" target="_blank" rel="noopener">&#39;&#39;anne@example.com</a>‘’。</p><p>然而VERP是从邮件列表中剔除坏地址的一个非常强大的工具，它有一个重要的潜在的缺点。使用VERP要求Mailman给每一个收件人确切地发送一封消息的副本。没有VERP，Mailman可以把给多个收件人发送的相同的邮件副本扎成一捆，从而减少整体的带宽和处理时间。但是VERP需要一个特定的’’MAIL FROM’’给每个收件人，而唯一的办法就是发送一个独特的消息的副本。一般来说这是一个可以接受的折衷之策，而事实上，一旦这些个性化的信息为了VERP被发送，就会有大量的Mailman也能做的有用的事。例如，它可以嵌入URL在个性化消息的页脚中，这些消息针对每一个收件人（给他们一个直接的链接从列表中退订）。你甚至可以想象各种类型的邮件合并操作，为每个单独的收件人定制邮件的主体。</p><h2 id="10-8-REST"><a href="#10-8-REST" class="headerlink" title="10.8.REST"></a>10.8.REST</h2><p>一个在Mailman 3中框架的改变指出来一个多年来的共同需求：让Mailman与外部系统更容易进行集成。当我被Canonical聘用时，一个Ubuntu项目的赞助商，在2007时我的工作最初加入邮件列表针对Launchpad，一个软件项目协作和托管平台。我知道Mailman 2可以做这件事，但有一个要求便是使用Launchpad的Web用户界面而不是Mailman的默认用户界面。由于Lauchpad邮件列表几乎总是在讨论列表之中，我们想要很小的变化以他们操作的方式。列表管理员不需要这么多可用的选项在典型的Mailman站点中，并且几乎没几个他们需要的选项来曝光在Launchpad网络用户界面。</p><p>当时，Launchpad并不是免费的软件（这在2009年改变），所以我们不得不以这样一种方式设计一个集成，Mailman 2的GPLv2代码不能侵染 Launchpad。这导致了大量体系结构的设计，那时集成设计相当棘手并且总有些许效率低下。现在因为Launchpad是一款自由软件批准在AGPLv3下，这些黑客即使当天不必做，但也不得不这样做，提供一些非常有价值的课程针对如何使一个网络用户界面极少的Mailman能够被其他的系统集成。一个核心引擎的画面显示出来，它高效可靠地实现了邮件列表操作，并且可以通过任何Web前端管理，包括一些用Zope，Django，或PHP写的程序，或是根本没有网络用户界面。</p><p>当时有大量的技术允许这一点，并且事实上，Mailman在Launchpad上的集成是基于XMLRPC的。但是XMLRPC有一些问题使其产生了一个并不理想的协议。</p><p>Mailman 3采用表述性状态传递技术（REST）模型便于外部管理员控制。REST是基于HTTP的，而Mailman的默认对象表示的是JSON。这些协议是在一个大范围的编程语言和环境中是无处不在且受到良好支持的，使其很容易集成带有第三方系统的Mailman。REST完美契合于Mailman 3，而现在它的许多功能是通过REST的API被展示的。</p><p>这是一个功能强大的范例，以致很多的应用程序应该采用：提供一个核心引擎，更好地实现其基本功能，展露给REST的API以便查询和控制它。REST的 API不但提供了集成Mailman的另一种方法，而且也正在使用命令行界面，编写Python代码来访问内部API。这种架构是非常灵活的，可以被使用和集成，以一种超越了最初的视觉系统设计的方式。</p><p>这个设计不仅允许更多更好的选择进行部署，而且甚至允许了官方的系统部件可以被独立地设计和实现。例如，新的官方Mailman 3的网络用户界面在技术上是一个分开的项目，有自己的代码库，主要是通过有经验的网页设计师驱动。这些优秀的开发人员有权作出决定，创新设计，并在没有核心引擎开发的阻碍下执行并实现。网络用户界面工作反馈了核心引擎的实现，通过请求附加功能，通过REST的API展示，但它们不必等待它，因为它们可以在其末端模拟服务器并继续试验和开发网络用户界面，同时核心引擎逐步赶上。</p><p>我们计划使用REST的API做更多的事，包括允许将通用操作和IMAP或NNTP服务器的集成编写成脚本为了替代访问存档。</p><h2 id="10-9-国际化（Internationalization）"><a href="#10-9-国际化（Internationalization）" class="headerlink" title="10.9.国际化（Internationalization）"></a>10.9.国际化（Internationalization）</h2><p>GNU的Mailman是接受国际化的第一批Python程序之一。当然，因为Mailman通常不修改邮递过的邮件消息的内容，这些消息可以是最初的作者所选择的任何语言。然而，在Mailman直接的相互作用下，或者通过Web界面或通过电子邮件发送的命令，用户会更喜欢使用自己的自然语言。</p><p>Mailman率先提出了许多用于Python领域里的国际化的技术，但它实际上比大多数应用程序更复杂。在典型的桌面环境中，当用户登录时将选择自然语言，并在整个桌面会话中保持静态。然而，Mailman是一个服务器应用程序，所以它必须能够处理多种语言，独立于其运行系统的语言。事实上，Mailman必须以某种方法确定语言语境，以便响应被返回，并将其文本语言翻译成那种语言。有时响应可能涉及多种语言；例如，如果一个反弹消息从一个日本用户转发到可以说德语，意大利语，和加泰罗尼亚语列表管理员。</p><p>此外，Mailman率先提出一些关键的Python技术来处理复杂的语言环境等。它利用一个库，管理语言的栈，随着上下文的变化可以push和pop，甚至处理一个单独的消息。它还实现了一个精心的策划来自定义其基于网站洗好的响应模板，列出所有者的喜好，然后语言选择。例如，如果一个列表所有者想要为她的一个列表定制一个响应模板，但仅针对日本用户，她将把特定的模板放置在文件系统的适当位置，并且这将覆盖更多的通用默认值。</p><h2 id="10-10已学习课程（Lessons-Learned）"><a href="#10-10已学习课程（Lessons-Learned）" class="headerlink" title="10.10已学习课程（Lessons Learned）"></a>10.10已学习课程（Lessons Learned）</h2><p>虽然这篇文章已经提供了一篇Mailman 3架构的概述和一个关于这个架构在它存在的15年间（经过了三次主要的重写）是如何演化的领悟，还有很多Mailman中的有趣的架构设计我并没有覆盖。这包括配置子系统、测试基础设施、数据库层、纲领性的形式化接口的使用、归档、邮件列表样式、电子邮件命令和命令行界面以及发送邮件服务器的集成。联系我们在[[https:*mail.python.org/mailman/listinfo/mailman-developers|mailman-developers mailing list]]如果你想了解更多。</p><p>这里有一些我们在重写受欢迎的、已确立的和稳定的开源系统片段中获得的经验教训。</p><ul><li>使用测试驱动开发（TDD）。真的没有其他的方式！Mailman 2很大程度上缺少一个自动化测试组件，虽然这是真的：不是所有的Mailman 3中的代码库都被测试组件所覆盖了，其中最重要的是，所有伴随着测试所需要的新代码，使用了’’unittests’’或’’doctests’’。做TDD是获得信心的唯一途径，那使你今天所做的在已经存在的代码中不会引入回退。是的，TDD有时需要较长的时间，但把它作为你的未来代码质量的一种投资。在这种方式中，没有一个好的测试组件意味着你只是在浪费你的时间。记住真言：未测试的代码是断码。 </li><li>使你的字节/字符串的从一开始就是整齐的。在Python 3中，做了明显的区分在Unicode文本字符串和字节数组中，其中，最初的痛苦，是编写正确的代码是一个巨大的效益。Python 2的这条线模糊不清，在Unicode和8位ASCII字符串之中有一些自动的强制转换。虽然看似是一个有用的便利，这条模糊的线带来的问题是Mailman 2错误的头号原因。事实上没有任何帮助，电子邮件分类成字符串和字节是众所周知的困难。在技术上，线上电子邮件表示为一个字节序列，但这些字节几乎都是ASCII码，也有着把消息组件作为文本操作的强烈诱惑。电子邮件自身的标准描述为人类怎样可读，非ASCII文本可以安全地进行编码，所以即使像发现’’Re:’’前缀在一个’’Subject:’’表头之中将是文本操作，而不是字节操作。Mailman的原则是尽可能简单地将所有的收入入数据从字节转换为Unicode，在内部把文本当做Unicode处理，只有在外面将其转换为字节。当你在处理字节和处理文本时，从一开始就非常清楚是极其重要的，因为在转变之后很难再改进这个基础模型。 </li><li>从一开始就国际化你的程序。你想让你的应用程序只使用在世界上说英语地方的组成区域么？想想这忽略了多少出色的使用者！建立国际化并不难，也有很多好的工具使其变得容易，其中很多都在Mailman中做了先驱者。不要担心开始的翻译，如果你的应用程序是可以访问的对于世界上丰富多彩的语言，你会拥有志愿去翻译的人来敲你的门给你帮助。 </li></ul><p>GNU的邮差是一个有健康用户基础的充满活力的项目，其中有很多贡献的机会。如果你认为你愿意帮助我们，这也是我所希望你做的，这里有你可以使用的资源！</p><ul><li>[[<a href="http://www.list.org/|Primary" target="_blank" rel="noopener">http://www.list.org/|Primary</a> web site]]</li><li>[[<a href="http://wiki.list.org/|Project" target="_blank" rel="noopener">http://wiki.list.org/|Project</a> wiki]]</li><li>[[<a href="mailto:mailman-developers@python.org" target="_blank" rel="noopener">mailman-developers@python.org</a>|Developer mailing list]]</li><li>[[<a href="http://aosabook.org/en/mailman.html|Users" target="_blank" rel="noopener">http://aosabook.org/en/mailman.html|Users</a> mailing list]]</li><li>Freenode IRC channel: ‘’#mailman’’</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;GNU-Mailman-翻译&quot;&gt;&lt;a href=&quot;#GNU-Mailman-翻译&quot; class=&quot;headerlink&quot; title=&quot;GNU Mailman 翻译&quot;&gt;&lt;/a&gt;GNU Mailman 翻译&lt;/h1&gt;&lt;h3 id=&quot;Barry-Warsaw&quot;&gt;&lt;a 
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib_2</title>
    <link href="http://blog.ccao.cc/2018/09/28/Matplotlib_2/"/>
    <id>http://blog.ccao.cc/2018/09/28/Matplotlib_2/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.670Z</updated>
    
    <content type="html"><![CDATA[<p>##matplotlib翻译##      </p><p><strong>翻译人员：马浩杰</strong></p><p>matplotlib是基于Python的绘图库，广泛用于Python科学计算界。它完整支持二维绘图以及部分支持三维绘图。该绘图库致力于能适应广泛的用户需求。它可以根据所选的用户接口工具来嵌入绘图算法。与此同时，对于使用GTK+、Qt、Tk、FLTK、wxWidgets与Cocoa的所有主要桌面操作系统，matplotlib能支持交互式绘图。在Python的交互式shell中，我们可以使用简单的、过程式的命令交互式地调用matplotlib来生成图形，与使用Mathematica、IDL或者MATLAB绘图非常相似。matplotlib也可以嵌入到无报文头的Web服务器中，以提供基于光栅（如PNG格式）与向量（如Postscript、PDF以及纸面效果很好的SVG格式）这两种格式的图形硬拷贝。</p><p>####11.1 硬件锁问题####<br>我们其中一位开发者（John Hunter）与他的研究癫痫症的同事们试图在不借助专有软件的情况下进行脑皮层电图（ECoG）分析，于是便有了最初的matplotlib。John Hunter当时所在的实验室只有一份电图分析软件的许可证，但有各式各样的工作人员，如研究生、医科学生、博士后、实习生、以及研究员，他们轮流共享该专有软件的硬件电子锁。生物医学界广泛使用MATLAB进行数据分析与可视化，所以Hunter着手使用基于MATLAB的matplotlib来代替专有软件，这样很多研究员都可以使用并且对其进行扩展。但是MATLAB天生将数据当作浮点数的数组来处理。然而在实际情况中，癫痫手术患者的医疗记录具有多种数据形式（CT、MRI、ECoG与EEG等），并且存储在不同的服务器上。MATLAB作为数据管理系统勉强能应付这样的复杂性。由于感到MATLAB不适合于这项任务，Hunter开始编写一个新的建立在用户接口工具GTK+（当时是Linux下的主流桌面视窗系统）之上的Python应用程序。</p><p>所以matplotlib这一GTK+应用程序最初便被开发成EEG/ECoG可视化工具。这样的用例决定了它最初的软件架构。matplotlib最初的设计也服务于另一个目的：代替命令驱动的交互式图形生成（这一点MATLAB做得很好）工具。MATLAB的设计方法使得加载数据文件与绘图这样的任务非常简单，而要使用完全面向对象的API则会在语法上过于繁琐。所以matplotlib也提供状态化的脚本编程接口来快速、简单地生成与MATLAB类似的图形。因为matplotlib是Python库，所以用户可以使用Python中各种丰富的数据结构，如列表、辞典与集合等等。</p><p><img src="http://www.aosabook.org/cdn/images/aosabook/matplotlib/ecog.png" alt=""></p><p>图11.1：最初的matplotlib程序——ECoG查看器</p><p>####11.2 matplotlib软件架构概述####<br>顶层的matplotlib对象名为Figure，它包含与管理某个图形的所有元素。matplotlib必须完成的一个核心架构性任务是实现Figure的绘制与操作框架，并且做到该框架与Figure到用户视窗接口或硬拷贝渲染行为是分离的。这使得我们可以为Figure添加越来越复杂的特性与逻辑，同时保持“后端”或输出设备的相对简化。matplotlib不仅封装了用于向多种设备渲染的绘图接口，还封装了基本事件处理以及多数流行的用户界面工具的视窗功能。因此，用户可以创建相当丰富的交互式图形算法与用户界面工具（用到可能存在的鼠标与键盘），而又不必修改matplotlib已经支持的6种界面工具。</p><p>要实现这些，matplotlib的架构被逻辑性地分为三层。这三层逻辑可以视为一个栈。每层逻辑知道如何与其下的一层逻辑进行通信，但在下层逻辑看来，上层是透明的。这三层从底向上分别为：后端、美工与脚本。</p><p>####11.2.1 后端####</p><p>matplotlib逻辑栈最底层是后端，它具体实现了下面的抽象接口类：</p><ul><li>FigureCanvas对绘图表面（如“绘图纸”）的概念进行封装。</li><li>Renderer执行绘图动作（如“画笔”）。</li><li>Event处理键盘与鼠标事件这样的用户输入。</li></ul><p>对于如Qt这样的用户界面工具，FigureCanvas中包含的具体实现可以完成三个任务：将自身嵌入到原生的Qt视窗（QtGui.QMainWindow）中，能将matplotlib的Renderer命令转换到canvas上（QtGui.QPainter），以及将原生Qt事件转换到matplotlib的Event框架下（后者产生回调信号让上行监听者进行处理）。抽象基类定义在matplotlib.backend_bases中，且所有派生类都定义在如matplotlib.backends.backend_qt4agg这样的专用模块中。对于专门生成硬拷贝输出（如PDF、PNG、SVG或PS）的纯图像后端而言，FigureCanvas的实现可能只是简单地建立一个类似文件的对象，其中定义默认的文件头、字体与宏函数，以及Renderer创建的个别对象（如直线、文本与矩形等）。</p><p>Renderer的任务是提供底层的绘图接口，即在画布上绘图的动作。上文已经提到，最初的matplotlib程序是一个基于GTK+的ECoG查看器，而且很多早期设计灵感都源自当时已有的GDK/GTK+的API。最初Renderer的API源自GDK的Drawable接口，后者实现了draw_point、draw_line、draw_rectangle、draw_image、draw_polygon以及draw_glyphs这样的基本方法。我们完成的每个不同后端——最早有PostScript与GD——都实现了GDK的Drawable，并将其转换为独立于后端的原生绘图命令。如上所述，这毫无必要地增加了后端的实现复杂度，原因是单独实现Drawable造成函数泛滥。此后，Renderer已经被极大的简化，将matplotlib移植到新的用户界面或文件格式已经是非常简单的过程。</p><p>一个对matplotlib有利的设计决定是支持使用C++模板库Anti-Grain Geometry（缩写为agg[She06]）的基于像素点的核心渲染器。这是一个高性能库，可以进行2D反锯齿渲染，生成的图像非常漂亮。matplotlib支持将agg后端渲染的像素缓存插入到每种支持的用户界面中，所以在不同的UI与操作系统下都能得到精确像素点的图形。因为matplotlib生成的PNG输出也使用agg渲染器，所以硬拷贝与屏幕显示完全相同，也就是说在不同的UI与操作系统下，PNG的输出所见即所得。</p><p>matplotlib的Event框架将key-press-event或mouse-motion-event这样的潜在UI事件映射到KeyEvent或MouseEvent类。用户可以连接到这些事件进行函数回调，以及图形与数据的交互，如要pick一个或一组数据点，或对图形或其元素的某方面性质进行操作。下面的示例代码演示了当用户键入‘t’时，对Axes窗口中的线段进行显示开关。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">def on_press(event):</span><br><span class="line">    if event.inaxes is None: return</span><br><span class="line">    for line in event.inaxes.lines:</span><br><span class="line">        if event.key==&apos;t&apos;:</span><br><span class="line">            visible = line.get_visible()</span><br><span class="line">            line.set_visible(not visible)</span><br><span class="line">    event.inaxes.figure.canvas.draw()</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(1)</span><br><span class="line"></span><br><span class="line">fig.canvas.mpl_connect(&apos;key_press_event&apos;, on_press)</span><br><span class="line"></span><br><span class="line">ax.plot(np.random.rand(2, 20))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>对底层UI事件框架的抽象使得matplotlib的开发者与最终用户都可以编写UI事件处理代码，而且“一次编写，随处运行”。譬如，在所有用户界面下都可以对matplotlib图像进行交互式平移与放缩，这种交互式操作就是在matplotlib的事件框架下实现的。</p><h4 id="11-2-2-Artis层"><a href="#11-2-2-Artis层" class="headerlink" title="11.2.2 Artis层"></a>11.2.2 Artis层</h4><p>Artist层次结构处于matplotlib的中间层，负责很大一部分繁重的计算任务。延续之前将后端的FigureCanvas看作画纸的比喻，Artis对象知道如何用Renderer（画笔）在画布上画出墨迹。matplotlib中的Figure就是一个Artist对象实例。标题、直线、刻度标记以及图像等等都对应某个Artist实例（如图11.3）。Artist的基类是matplotlib.artist.Artist，其中包含所有Artist的共享属性，包括从美工坐标系统到画布坐标系统的变换（后面将详细介绍）、可见性、定义用户可绘制区域的剪切板、标签，以及处理“选中”这样的用户交互动作的接口，即在美工层检测鼠标点击事件。</p><p><img src="http://www.aosabook.org/cdn/images/aosabook/matplotlib/artists_figure.png" alt=""><br>图11.2：matplotlib生成的图形</p><p><img src="http://www.aosabook.org/cdn/images/aosabook/matplotlib/artists_tree.png" alt=""><br>图11.3：用于绘制图11.2的Artist实例的层次结构</p><p>Artist层于后端之间的耦合性存在于draw方法中。譬如，下面假想的SomeArtist类是Artist的子类，它要实现的关键方法是draw，用来传递给后端的渲染器。Artist不知道渲染器要向哪种后端进行绘制（PDF、SVG与GTK+绘图区等），但知道Renderer的API，并且会调用适当的方法（draw_text或draw_path）。因为Renderer能访问画布，并且知道如何绘制，所以draw方法将Artist的抽象表示转换为像素缓存中的颜色、SVG文件中的轨迹或者其他具体表示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class SomeArtist(Artist):</span><br><span class="line">    &apos;An example Artist that implements the draw method&apos;</span><br><span class="line"></span><br><span class="line">    def draw(self, renderer):</span><br><span class="line">        &quot;&quot;&quot;Call the appropriate renderer methods to paint self onto canvas&quot;&quot;&quot;</span><br><span class="line">        if not self.get_visible():  return</span><br><span class="line"></span><br><span class="line">        # create some objects and use renderer to draw self here</span><br><span class="line">        renderer.draw_path(graphics_context, path, transform)</span><br></pre></td></tr></table></figure><p>该层次结构中有两种类型的Artist。基本Artist表示我们在图形中能看到的一类对象，如Line2D、Rectangle、Circle与Text。复合Artist是Artist的集合，如Axis、Tick、Axes与Figure。每个复合Artsit可能包含其他复合Artist与基本Artist。譬如，Figure包含一个或多个Axes，并且Figure的背景是基本的Rectangle。</p><p>最重要的复合Artist是Axes，其中定义了大多数matplot的绘图方法。Axes不仅仅包含大多数构成绘图背景（如标记、轴线、网格线、色块等）的图形元素，还包括了大量生成基本Artist并添加到Axes实例中的帮助函数。譬如，表11.1列出了一些Axes函数，这些函数进行对象的绘制，并将它们存储在Axes实例中。</p><p>表11.1：Axes的方法样例及其创建的Artist实例<br>我们有一个专门用来处理文档字符串的模块matplotlib.docstring.</p><table><thead><tr><th>方法</th><th>创建对象</th><th>存储位置</th></tr></thead><tbody><tr><td>Axes.imshow</td><td>一到多个matplotlib.image.AxesImage</td><td>Axes.images</td></tr><tr><td>Axes.hist</td><td>大量matplotlib.patch.Rectangle</td><td>Axes.patches</td></tr><tr><td>Axes.plot</td><td>一到多个matplotlib.lines.Line2D</td><td>xes.lines</td></tr></tbody></table><p>下面这个简单的Python脚本解释了以上架构。它定义了后端，将Figure链接至该后端，然后使用数组库numpy创建10,000个正太分布的随机数，最后绘制出它们的柱状图。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># Import the FigureCanvas from the backend of your choice</span><br><span class="line">#  and attach the Figure artist to it.</span><br><span class="line">from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas</span><br><span class="line">from matplotlib.figure import Figure</span><br><span class="line">fig = Figure()</span><br><span class="line">canvas = FigureCanvas(fig)</span><br><span class="line"></span><br><span class="line"># Import the numpy library to generate the random numbers.</span><br><span class="line">import numpy as np</span><br><span class="line">x = np.random.randn(10000)</span><br><span class="line"></span><br><span class="line"># Now use a figure method to create an Axes artist; the Axes artist is</span><br><span class="line">#  added automatically to the figure container fig.axes.</span><br><span class="line"># Here &quot;111&quot; is from the MATLAB convention: create a grid with 1 row and 1</span><br><span class="line">#  column, and use the first cell in that grid for the location of the new</span><br><span class="line">#  Axes.</span><br><span class="line">ax = fig.add_subplot(111)</span><br><span class="line"></span><br><span class="line"># Call the Axes method hist to generate the histogram; hist creates a</span><br><span class="line">#  sequence of Rectangle artists for each histogram bar and adds them</span><br><span class="line">#  to the Axes container.  Here &quot;100&quot; means create 100 bins.</span><br><span class="line">ax.hist(x, 100)</span><br><span class="line"></span><br><span class="line"># Decorate the figure with a title and save it.</span><br><span class="line">ax.set_title(&apos;Normal distribution with $\mu=0, \sigma=1$&apos;)</span><br><span class="line">fig.savefig(&apos;matplotlib_histogram.png&apos;)</span><br></pre></td></tr></table></figure><p>####11.2.3 脚本层（pyplot)####</p><p>使用以上API的脚本效果很好，尤其是对于程序员而言，并且在编写Web应用服务器、UI应用程序或者是与其他开发人员共享的脚本时，这通常是比较合适的编程范式。对于日常用途，尤其对于非专业程序员而要完成一些交互式的研究工作的实验科学家而言，以上API的语法可能有些难以掌握。大多数用于数据分析与可视化的专用语言都会提供轻量级的脚本接口来简化一些常见任务。matplotlib在其matplotlib.pyplot接口中便实现了这一点。以上代码改用pyplot之后如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.random.randn(10000)</span><br><span class="line">plt.hist(x, 100)</span><br><span class="line">plt.title(r&apos;Normal distribution with $\mu=0, \sigma=1$&apos;)</span><br><span class="line">plt.savefig(&apos;matplotlib_histogram.png&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://www.aosabook.org/cdn/images/aosabook/matplotlib/histogram_demo.png" alt=""><br>图11.4：用pyplot绘制的柱状图</p><p>pyplot是一个状态化接口，大部分工作是处理样本文件的图形与坐标的生成，以及与所选后端的连接。它还维护了模块级的内部数据结构。这些数据结构表示了直接接收绘图命令的当前图形与坐标</p><p>下面仔细分析示例脚本中比较重要的几行，观察其内部状态的管理方式。</p><ul><li>import matplotlib.pyplot as plt：当pyplot模块被加载时，它分析本地配置文件。配置文件除了完成一些其他工作外，主要声明了默认的后端。可能是类似QtAgg的用户接口后端，于是上面的脚本将导入GUI框架并启动嵌入了图形的Qt窗口；或者可以是一个类似Agg的纯图像后端，这样脚本会生成硬拷贝输出然后退出。</li><li>plt.hist(x, 100)：这是脚本中第一个绘图命令。pyplot会检测其内部数据结构已查看是否存在当前Figure实例。如果存在，则提取当前Axes，并将绘图行为导向Axes.hist的API调用。在该脚本中不存在Figure实例，所以会生成一个FIgure与Axes，并将它们设为当前值，然后将绘图行为导向Axes.hist. plt.title(r’Normal distribution with $\mu=0, \sigma=1$’):就像前面一样,pyplot收件检查是否存在Figure和Axes实例.如果存在就直接调用已存在的Axes实例的Axes.set_title.plt.show()方法:这将强制Figure去渲染图像,并且如果用户在配置文件中指定了默认GUI后端,那么就执行GUI主循环并且把所有创造的fugure添加到屏幕中去.</li></ul><p>pyplot常用的划线函数matplotlib.pyplot.plot的精简版本在下面代码框中展出,用来阐述pyplot是如何将matplotlib函数包装起来的.其他所有pyplot脚本接口函数都是相似的设计.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@autogen_docstring(Axes.plot)</span><br><span class="line">def plot(*args, **kwargs):</span><br><span class="line">    ax = gca()</span><br><span class="line"></span><br><span class="line">    ret = ax.plot(*args, **kwargs)</span><br><span class="line">    draw_if_interactive()</span><br><span class="line"></span><br><span class="line">    return ret</span><br></pre></td></tr></table></figure></p><p>Python修饰符#autogen_docstring(Axes.plot)从相应的API方法中提取出文档字符串,并将适当形式的版本新题添加到pyplot.plot方法中;我们用一个专门用来处理文档字符串的模块matplotlib.docstring.<em>参数和**被在文件签名的特殊约定在Python中指所有参数和关键字参数被传递到方法.这允许我们把他们向前传递到相应的API.ax = gca()语句调用状态机来获取当前的?实例(每个python解释器只能有一个”当前轴”),并且会在必要的时候创建figure和axes.res = ax.plot(</em>args, ** kwargs)向前传递函数调用和参数给相应的axes方法,并且保存返回值用作以后返回.因此pyplot接口是对核心ArtistAPI的相当轻薄的包装,主要是尽可能避免为了通过暴漏API函数而导致的代码重复,以实现用最少的样板代码在脚本接口中调用签名和文档字符串.</p><h4 id="1-3后端重构"><a href="#1-3后端重构" class="headerlink" title="1.3后端重构"></a>1.3后端重构</h4><p>输出后端定义了许多画图API,包括<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">draw_arc, draw_image, draw_line_collection, draw_line, draw_lines, draw_point,</span><br><span class="line">draw_quad_mesh, draw_polygon_collection, draw_polygon, draw_rectangle,</span><br><span class="line">draw_regpoly_collection</span><br></pre></td></tr></table></figure></p><p>不幸的是，有太多的方法意味着设计一个后端需要花费很长的时间，并且随着新特性的加入，更新已经存在的后端也需要话费很多的精力，因为每个后端都是由精通某一特定的文件格式的开发者实现．<br>到了matplotlib 0.98,后端由开发者重构为只包含最少的必要功能，新的后端包含下面的一些API</p><ul><li><b>draw_path</b>:绘制多边形复合，此接口取代了许多的老办法：draw_arc，draw_line，draw_lines和draw_rectangle.</li><li><b>draw_image</b>绘制光栅图像</li><li><b>draw_text</b>按照给定的字体绘制文本</li><li><b>get_text_width_height_descent</b>给定一个文本字符串，返回它的尺寸<br>大部分情况下实现其它新的后端只需要实现这些方法就足够了(我们还可以更进一步，并使用draw_path，消除了draw_text方法需要绘制文本，但我们还没有得到解决，使这一简化。当然，后端仍可以自由地实现自己的draw_text方法输出“真实”的文字).这使得获得一个新的后端更容易。然而，在一些情况下，后端可能需要覆盖，以创造更高效的行为。例如，绘制标记（用来表示一个线图顶点的小符号）时，只在文件中塑性一次标记的空间效率更好，然后重复它作为一个“邮票”无处不在使用它。在这种情况下，后端可以实现draw_markers方法。如果它的实施，后端写出标记形状一次，然后写出短得多的命令，重用这个标记在若干位置。如果它没有实现，就会只是简单地调用多次draw_path来绘制标记。<br>可选的后端API方法有:</li><li>draw_markers: 绘制标记</li><li>draw_path_collection: 绘制路径</li><li>draw_quad_mesh: 绘制四边形网络</li></ul><h4 id="11-4Transforms"><a href="#11-4Transforms" class="headerlink" title="11.4Transforms"></a>11.4Transforms</h4><p>matplotlib花费很多时间将一个坐标系变换到另一个。这些坐标系包括：</p><ul><li>data: 原始数据值</li><li>axes: 由特定轴矩阵限定的空间</li><li>figure: 包含整个数字空间</li><li><p>display: 在输出中使用的物理坐标</p><p>每个Artist都有一个知道如何从一个坐标系转变到另一个的转换节点．这些节点构成一个有向图．沿着有向图的边走到根，可以将原始数据值转换为最终在文件中的输出坐标．这使得点击一个元素来获取它的数值坐标变得可能．这张图表达了节点之间的依赖关系，当一个父节点的转换改变以后，例如当artist的限制改变时，与该轴的任何转换是无效的，因为他们将需要重新绘制。有关在图中的其他轴变换，当然也可单独使用左，防止不必要recomputations和有助于更好地交互性能。<br>变换节点可以是简单仿射变换和非仿射变换。仿射变换是保持距离的直线和比例，包括旋转，平移，缩放和倾斜变换的一系列变换。二维仿射变换使用的3×3仿射变换矩阵表示。转化点（x’，y’）是原始点（x，y）进行通过下面矩阵变换得到的:<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/matrix.png" alt=""></p></li></ul><p>二维坐标可以很容易地通过变换矩阵相乘来进行变换。仿射变换也有，他们可以利用矩阵乘法可以相互组合的有用的属性。这意味着，要执行一系列仿射变换，该变换矩阵可首先相乘一次，所得矩阵可以用于转化坐标。matplotlib的转型框架自动组成（冻结）仿射变换变换坐标，以减少计算量前矩阵在一起.拥有快速仿射变换是很重要的，因为它使得交互式平移和在GUI窗口更有效的放大。<br>在matplotlib非仿射变换使用Python函数定义的，所以他们是真正的随心所欲。在matplotlib核心，非仿射变换用于对数缩放，极坐标图和地理的预测（图11.5）。这些非仿射变换在转换图中可以和仿射变换自由混合。matplotlib将自动简化仿射部和仅回落到用于非仿射部的任意函数。<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/nonaffine_transforms.png" alt=""><br>从这些简单的作品，matplotlib可以做一些非常先进的东西。混合变换是使用一个x轴变换和一个y轴变换的特殊变换节点。当然，这是唯一可能的，如果给定的变换为“可分离”，意思是在x和y坐标是独立的，但在变换本身可以是仿射或非仿射。这是用来，例如，绘制对数曲线，其中任一个或两个x和y轴的可具有对数刻度。具有混合的变换节点允许可扩展到以任意的方式组合。变换图允许的另一件事是轴的共享。这使得当进行平移和缩放”link”一条线的极限到另一条成为可能，在这种情况下，相同的变换节点简单地两个轴，这甚至可能在两个不同的数字之间共享。图11.6显示了一个例子变换图的一些工作，这些先进的功能。axes1具有对数X轴;axes1和axes2共享相同的Y轴。<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/transform_tree.png" alt=""></p><h4 id="11-5-The-Polyline-Pipeline"><a href="#11-5-The-Polyline-Pipeline" class="headerlink" title="11.5. The Polyline Pipeline"></a>11.5. The Polyline Pipeline</h4><p>当标绘线图，也有一些用于把原始数据绘制为屏幕上的线的步骤。在matplotlib的早期版本中，所有这些步骤都纠结在一起。此后，它们被重构，实现为一个“路径转换”流水线中的不连续步骤。这使得每个后端可以选择流水线的某一部分来执行，因为流水线的一些部分只在某些情况下是有用的.</p><ul><li>变换：从数据坐标转换为坐标图坐标。如果这是一个纯粹的仿射变换，如上所述，这是作为一个矩阵乘法一样简单。如果这涉及任意变换，变换函数被调用的坐标转换成数字空间。</li><li>处理数据丢失:该数据阵列可能有部分在数据丢失或无效。用户可以通过这些值设定为NaN时，或使用numpy的掩蔽阵列任表明这一点。矢量输出格式，如PDF和渲染库，如此Agg，不经常有绘制一个折线时丢失数据的概念，因此，管道的这一步必须用MOVETO命令，告知在丢失的数据段跳跃渲染拿起笔，开始在一个新的点上重新绘制。</li><li>剪裁:图中的边界之外的点可以通过包括许多看不见的点增加文件大小。更重要的是，非常大或非常小的坐标值可以在输出文件的渲染，这会导致完全混乱的输出导致溢出错误。管道剪辑的这一步骤，因为它进入和退出图中的边缘，以防止这两个问题的折线。</li><li>贴紧：完美垂直线和水平线可以看模糊由于抗混叠时它们的中心未对准到一个像素的中心（参见图11.7）。流水线的捕捉步骤首先确定整个折线是否是由水平和垂直段（例如一个轴对齐的矩形），且如果是这样，轮每个所得顶点到最接近的像素中心。这个步骤仅用于光栅后端，因为矢量后端应继续精确的数据点。在屏幕上查看时的矢量文件格式，如Adobe Acrobat一些渲染器，执行像素贴紧。<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/pixel_snapping.png" alt=""><br>Figure 11.7: A close-up view of the effect of pixel snapping. On the left, without pixel snapping; on the right, with pixel snapping.</li><li>简化：当绘制真的密集的地块，很多就行了点，实际上可能不是可见的。这是尤其如此表示嘈杂的波形图的。包括在剧情这些点增加文件大小，甚至可能打在允许的文件格式点的数量限制。因此，准确的落在他们的两个相邻点之间的线路上的任何点都拆除（见图11.8）。确定取决于基于什么是可见的由用户指定的一个给定的分辨率的阈值。<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/path_simplification.png" alt=""><br>Figure 11.8: The figure on the right is a close-up of the figure on the left. The circled vertex is automatically removed by the path simplification algorithm, since it lies exactly on the line between its neighboring vertices, and therefore is redundant.</li></ul><h4 id="11-6-Math-Text"><a href="#11-6-Math-Text" class="headerlink" title="11.6. Math Text"></a>11.6. Math Text</h4><p>由于matplotlib的用户往往是科学家，能够直接把格式丰富的数学表达式放上图是非常有用的。也许对于数学表达式使用最广泛的语法是高德纳的TeX的排版系统。这是把输入表示为下面这样的纯文本语言：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sqrt&#123;\frac&#123;\delta x&#125;&#123;\delta y&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>格式输出表达式中的字符和线条的位置。<br>matplotlib提供两种方法来渲染数学公式，首先，usetex,在主机上使用Tex的完全拷贝来渲染数学公式，Tex直接输出DVI(device independent)中定义的数学表达式的字符和线．matplotlib然后分析DVI文件并将其转换为一组绘制命令，然后其输出后端之一直接渲染到图上。这种方法处理晦涩的数学语法。但是，它需要用户有充分的工作和安装的TeX。因此，matplotlib还包括其自身的内部数学渲染引擎，称为mathtext。<br>mathtext是TeX的数学渲染引擎的直接端口，粘到使用pyparsing [McG07]解析框架编写一个更简单的解析器。这个端口是基于TeX发行的源代码[Knu86]的拷贝。简单解析器构建一颗由盒子和胶（在TeX的命名法）构成的语法书，即随后由布局引擎布局树。虽然其中包括完整的TeX数学渲染引擎，大组第三方TeX和LaTeX的数学库是没有的。在这样的库功能需要被移植的基础上，其中对常用的和非学科特有的功能排在第一位。这使得一个不错的，轻量级的方式来呈现最多的数学表达式。</p><h4 id="11-7-Regression-Testing"><a href="#11-7-Regression-Testing" class="headerlink" title="11.7. Regression Testing"></a>11.7. Regression Testing</h4><p>从历史上看，matplotlib一直没有大量的低级别的单元测试。有时，如果出现一个严重的错误，就把一个用来重现它的脚本添加到源代码树中。缺乏自动化测试带来了所有的常见问题，尤其是之前工作的特征回归。（我们也许并不需要向你介绍自动化测试是一件好事。）当然，有这么多的代码和这么多的配置选项和可更换件（如后端），这是值得商榷的低一级单位单独测试将永远是不够的;而不是我们已经遵循的信念，这是最具成本效益的测试对于在一起工作的实体。<br>为此，作为一个第一次努力，编写一个脚本，用于生成一些行使matplotlib各种功能的plot，特别是那些有很难得到正确。这使得测试变得更容易一些，以检测当一个新的变化引起的意外破损，但仍然需要手动验证生成image的正确性。因为这需要大量的手工劳动的，不是很经常做。<br>作为第二步，这个步骤是自动的。当前matplotlib测试脚本生成多个重复的，但不是需要人工干预，这些地块被自动与基线相比的图像。所有的测试都是nose测试框架，这使得它非常容易产生哪些测试失败的报告内运行。<br>复杂的问题是，图像比较不能精确。<br>在FreeType字体渲染库版本的细微变化可以使文本的输出在不同的机器略有不同。这些差异是不够的，被认为是“错误的”，但足以甩开任何确切位对位比较。取而代之的是，测试框架计算两个图像的直方图，并计算它们的差的根均方。如果该差大于给定的阈值，则图像被认为过于不同，并比较测试失败。如果测试失败，差分图像生成该节目在哪里发生了变化曲线（见图11.9）。那么开发人员可以决定是否失败是由于故意的变化和更新基线图像匹配新的形象，还是决定形象，其实是不正确的，跟踪并解决引起变化的bug。<br><img src="http://aosabook.org/cdn/images/aosabook/matplotlib/regression.png" alt=""></p><p>Figure 11.9: A regression test image comparison. From left to right: a) The expected image, b) the result of broken legend placement, c) the difference between the two images.<br>由于不同的后端可以促进不同的bug，测试框架将对每个小部分测试多个后端：PNG，PDF和SVG。对于矢量格式，我们不直接比较向量信息，因为有多种方式来表示什么时候光栅化具有相同的最终结果。矢量后端应该随意改变其产出的具体情况，以提高效率，而不会导致所有的测试失败。因此，对于矢量后端，测试框架第一渲染使用外部工具（Ghostscript的对PDF和Inkscape中对SVG）文件到一个光栅，然后使用这些栅格进行比较。<br>使用这种方法，我们能够更容易地引导从头合理有效的测试框架，比我们去了就写了许多低级别的单元测试。不过，它并不完美;测试的代码覆盖率还不是很完整，这需要很长的时间来运行所有测试。（大约在2.33 GHz英特尔酷睿2 E6550 15分钟。）因此，一些回归仍旧落空的裂缝，但总体而言，因为测试框架，设置了版本的质量有了很大的改善。</p><h4 id="11-8-Lessons-Learned"><a href="#11-8-Lessons-Learned" class="headerlink" title="11.8. Lessons Learned"></a>11.8. Lessons Learned</h4><p>一个从matplotlib发展的重要教训是，正如勒·柯布西耶说：“好建筑师善于借鉴”.matplotlib的早期作家在很大程度上是科学家，自学成才的程序员试图完成他们的工作，没有经过正式培训的计算机科学家。因此，我们没有得到第一次尝试内部设计权。实现面向用户的脚本层与MATLAB API大体兼容的决定中受益的项目在三个显著方式：它提供了一个经过时间考验的界面来创建和自定义图形，这一个简单的过渡，从的大基地matplotlib做MATLAB用户，以及最重要的是为我们matplotlib的背景架构，它释放的开发商重构内部的面向对象的API几次几乎不影响大多数用户，因为脚本接口不变。虽然我们有API的用户（相对于脚本的用户）从一开始，他们大多是电力用户或开发能适应API的变化。该脚本的用户，在另一方面，可以一次写代码和几乎假定它是所有后续版本稳定。</p><p>对于内部绘图API，我们也从GDK借代，我们没有花足够的精力来确定这是否是绘图API的权利，而不得不付出相当大的努力后来经过多次后端是围绕这一API编写围绕一个简单的扩展功能和更灵活的绘图API。我们会一直通过采用PDF图纸规范[Ent11b]，这本身就是从几十年的经验的Adobe曾与它的PostScript规范发展良好的服务;这便给了我们大部分外的开箱即用的PDF本身的石英核芯显卡架构的兼容性，以及Enthought启用Kiva的绘图工具包[Ent11a]。<br>Python的一个诅咒的是，它是这样一个简单而传神的语言，开发人员经常发现它更容易重新发明和重新实现存在于工作以外包代码包等整合功能。matplotlib可能受益于早期发展从花费更多的精力在集成现有模块和API，如Enthought的基瓦并启用它解决了很多类似的问题，而不是重塑功能的工具包。与现有的功能整合是一个双边缘剑的，因为它可以使构建和释放更复杂，并减少在内部开发灵活性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##matplotlib翻译##      &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;翻译人员：马浩杰&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;matplotlib是基于Python的绘图库，广泛用于Python科学计算界。它完整支持二维绘图以及部分支持三维绘图。该绘图库致力于能适应广泛的用
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>MediaWiki</title>
    <link href="http://blog.ccao.cc/2018/09/28/MediaWiki/"/>
    <id>http://blog.ccao.cc/2018/09/28/MediaWiki/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.670Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MediaWiki"><a href="#MediaWiki" class="headerlink" title="MediaWiki"></a>MediaWiki</h1><p>从一开始，MediaWiki就是专门为维基百科服务的软件。开发者一直致力于使其能更方便的被第三方用户使用，但在其发展过程中，是维基百科的影响力和偏好塑造了MediaWiki的体系结构。</p><p>维基百科是世界上排名前十的网站之一，目前，它每月有4亿的绝对造访人次，并且每秒有超过10万次的点击。维基百科并不是通过做广告来获得资金，它完全由非营利组织————维基媒体基金会支持，而维基媒体基金会主要依靠捐赠作为资金来源。这意味着MediaWiki不能只是运行一个世界前十的网站，而且必须在极其有限的预算下完成。为了达到这些要求，MediaWiki在性能，缓存和优化方面有着严重偏向。维基百科无法启用的昂贵功能可以通过配置的改变来恢复或废除，在功能和性能间有着一个无休止的平衡。</p><p>维基百科对MediWiki架构的影响不只局限于功能方面。与一般的内容管理系统不同，MediaWiki从一开始就有一个特别的目标：支持一个可以在开放平台上自由地创建和管理可重用知识的社区。这意味着，MediaWiki并不包含像“发布工作流程或访问控制列表”这样许多公司内容管理系统共有的特征，而是给许多处理垃圾邮件和恶意破坏的工具。</p><p>所以，从一开始，维基百科参与者的不断发展的社区的需求和行动就在影响着MediWiki，当然，反之亦然。MediaWiki的架构已经多次应社区的需求而改变，比如维基共享资源的建立，或者是标记修改的特征。开发者对主要架构的更改都是因为维基百科对于MediaWiki的需求。</p><p>MediaWiki从一开始就是开源软件，因此有了一个坚实的外部用户基础。第三方复用者们知道，只要维基百科这样知名度高的网站使用MediaWiki，这个软件就会始终坚持并不断发展。MediaWiki以前一直专注于为维基百科的网站服务，不过现在开发者也倾注了许多努力在使它更通用，更符合第三方用户的需求。例如，当安装的所有事情都要通过命令行来完成，并且软件包含了关于维基包含的硬编码路径时，MediaWiki正制作一个完善的网络安装来使安装过程不再那么痛苦。</p><p>不过，MediaWiki仍然是为维基百科服务的软件，这从它的发展历史和架构就可以看出。</p><p>这一章的安排如下：</p><pre><code>* 历史回顾：给出一个对MediaWiki历史简短的回顾，或者再说说它的史前史和创作的环境。* MediaWiki的代码库和实践：解释了选择PHP的原因，安全保护代码的重要和实现，以及如何处理一般配置* 数据库和文本储存：讨论了分布式数据储存系统，以及它的结构是如何发展来适应数据的增长* 请求、缓存和交付：通过MediaWiki的组件来追寻一个网站请求的执行，本节包含了对不同的缓存层和资产交付系统的描述* 语言：详述了普遍的国际化和定位系统的重要性和实施过程* 用户：介绍用户在软件中的表示，及用户权限是如何工作的* 内容：详述了内容是如何结构化，格式化及被处理成最终的HTML。还有一部分专注于MediaWiki如何处理媒体文件* MediaWiki的定制和延伸：说明了JavaScript, CSS，扩展和皮肤是如何用于定制一个维基，以及他们如何修改它的外观和行为。还有一段介绍了这个软件可用计算机处理的web接口</code></pre><h2 id="12-1-历史概述"><a href="#12-1-历史概述" class="headerlink" title="12.1 历史概述"></a>12.1 历史概述</h2><h3 id="阶段1：UseModWiki"><a href="#阶段1：UseModWiki" class="headerlink" title="阶段1：UseModWiki"></a>阶段1：UseModWiki</h3><p>维基百科在2001年一月推出。在那时，它主要是个为了提高Nupedia内容产量的尝试，而Nupedia是一个Jimmy Wales创建的内容开放，由同行评议的百科全书。正因为它是一个尝试，维基百科一开始以UseModWiki为引擎，UseModWiki是一个由Perl语言编写的GPL维基引擎，采用了骆驼拼词法并且存储所有的页面在单独的文本文件，不包含改动的历史记录。</p><p>人们很快发现，骆驼拼词法并不适合给百科全书的文章命名。在2001年一月下旬，UseModWiki的开发者和维基百科的参与者Clifford Adams给UseModWiki添加了一个新的特征：自由链接，即：链接页面用一种特殊的语法能力（双括号），而不是自动用骆驼拼词法链接。几周后，维基百科更新到新版本的UseModWiki，能够支持自由链接。</p><p>尽管这个初始阶段与MediaWiki本身无关，但它提供的一些环境和表现，使得维基百科在MediaWiki建立之前就开始加强软件中的这部分功能。UseModWiki也影响了MediaWiki的部分功能，比如：它的标记语言。这个 <a href="https://nostalgia.wikipedia.org/wiki/HomePage" target="_blank" rel="noopener">https://nostalgia.wikipedia.org/wiki/HomePage</a> |怀旧版的维基百科 包含了对于2001年十二月的维基百科数据库的完整拷贝，那时维基百科还在用UseModWiki。</p><h3 id="阶段2：PHP脚本"><a href="#阶段2：PHP脚本" class="headerlink" title="阶段2：PHP脚本"></a>阶段2：PHP脚本</h3><p>在2001年，维基百科还不是世界前十的网站。这只是一个在网络的阴暗角落的不起眼的项目，对于大多数搜索引擎是未知的，并只放在一个服务器上。不过，那时性能就已经是一个问题，因为UseModWiki将它的内容存储到一个平面文件数据库。那个时候，维基百科的人很担心自己被纽约时报、 Slashdot和Wired的文章淹没。</p><p>所以在2001年夏季，维基百科的参与者Magnus Manske(在那时还是个大学生)开始在他的空闲时间去完成一个维基百科的专用引擎。他打算使用的数据库驱动的应用程序提高维基百科的性能，并且开发一些一般的维基引擎无法实现的维基百科的特定功能。用PHP语言写并且支持MySQL，这个新的引擎可以被简单地称为”PHP脚本”、”PHP维基”、”维基百科软件”或”二期”。</p><p>PHP脚本在2001年八月被提供，于九月在SourceForge上共享，测试工作一直到2001年年末完成。随着通信量的增加，维基百科一直遭受着性能问题，英文维基百科最终在2002年一月将UseModeWiki换成了PHP脚本。同样在2001年建立的其他语言的版本则是慢慢地优化，尽管其中有些直到2004年还在使用UseModWiki。</p><p>PHP软件采用的是MySQL数据库，并且为之后的MediaWiki奠定了坚实的基础。它所提供的许多关键的功能直到今天还在使用，比如：组织内容的命名空间(包括讨论页)、皮肤和特殊的页面(包括维修报告、一个工作列表和用户的监视列表)。</p><h3 id="阶段3：MediaWiki"><a href="#阶段3：MediaWiki" class="headerlink" title="阶段3：MediaWiki"></a>阶段3：MediaWiki</h3><p>尽管PHP脚本和数据库后端带来了很大的进步，但是增长的通信量、昂贵的功能和有限的硬件等仍然给维基百科带来了性能问题。在2002年，Lee Daniel Crocker重写了代码，将新的软件称为”三期”。因为网站经常遇到问题，Lee认为已经没有时间坐下来好好地设计和开发一个解决方案了，所以他只是对现有架构进行了重组以实现更好的性能，还攻击了所有的代码，并且增加了分析功能来跟踪慢函数。</p><p>三期软件保持着相同的基本接口，外观和表现尽可能设计的类似于阶段二，也加入了一些新的功能，比如：一个新的文件上传系统、内容变话的并排区分和Interwiki链接(一种链接到互联网上其他Wiki网站的简单方法)。</p><p>其他功能于2002年后被添加，比如：新的维护特殊页面，和”双击以编辑”选项。而性能问题很快又暴露了。例如，在2002年十一月，管理员就不得不停用了”访问量”和”站点”统计功能，这些造成了每一次访问有两次数据库的读写。他们也偶尔会将网站切换到只读模式来保证给读者的服务，并且因为表锁定问题，会在访问的高峰期禁用昂贵的维护页面。</p><p>在2003年初，他软件开发者们讨论了在这些性能问题变得无法控制之前，他们是应该完全重新设计一个软件，还是继续调整和完善已有的代码。最终他们还是选择了后者，主要是因为大部分开发者对于已有的代码还是比较满意的，并且有足够的信心，可以通过进一步的改进来使引擎跟上网站的发展。</p><p>在2003年六月，管理员添加了第二个服务器，第一个数据库服务器和网站服务器分开了(新的机器同样也是非英语网站的Web服务器)。这两家服务器之间的负载平衡将在今年晚一年中设定。管理员也启用了新的页面缓存系统，即用文件系统进行缓存渲染，为匿名用户提供准备输出页面。</p><p>2003年六月时，Jimmy Wales也创建了非盈利的维基媒体基金会来支持维基百科，并且管理其基础设施和日常运作。在七月，”维基百科软件”被正式命名为”MediaWiki”，这是根据维基媒体基金会的名字”WikiMedia”而来。当时这被认为是一个巧妙的双关语，混淆了用户和开发者。</p><p>还有些新的功能与七月被添加，如：自动生成目录和编辑页面部分的能力，这些直到今天都还在使用。”MediaWiki”于2003年八月发不了第一个版本，这表明了一个稳定的软件架构有着漫长的发展史。</p><h2 id="12-2-MediaWiki的代码库和实践"><a href="#12-2-MediaWiki的代码库和实践" class="headerlink" title="12.2 MediaWiki的代码库和实践"></a>12.2 MediaWiki的代码库和实践</h2><h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p>PHP于2001年被选作为维基百科”二期”软件框架的语言。在那之后，维基百科开始有机地成长，并且还在不断发展。MediaWiki的大多数开发者都是志愿者，都是与空闲的时间进行开发工作，很少有人是从一开始就参与了软件的开发。在现在来看，软件的一些决策似乎是错的，并且还有不少遗漏。不过我们不应该去指责那些创始人，指责他们没有完成一些目前来看是至关重要的东西，因为最初的代码是如此之少，并且用来发展的时间又如此之短。</p><p>例如，MediaWiki用的是无前缀的类名，那么当PHP核心和PECL(PHP扩展模块)开发者添加新类时就可能引起冲突。MediaWiki的’’Namespace’’类必须更名为’’MWNamespace’’来与PHP 5.3兼容。坚持给所以类加前缀(例如’’MW’’)可以使类更容易嵌套进MediaWiki里的其他程序中。</p><p>使用PHP对于程序性能来说并不是最好的选择，其他的一些动态语言有着更大的优势。比如用Java的话性能会更好，并且可以简化后端维护任务的执行。不过在另一方面，PHP更受欢迎，使用PHP有利于招收开发者。</p><p>即使MediaWiki中还遗留着许多很”丑”的代码，不过这些年已经有了许多主要的改进，并且在其发展过程中许多新的元素被引入到MediaWiki里。他们包括’’Parser’’、’’SpecialPage’’和’’Database’’类，’’Image ‘’类和’’FileRepo ‘’类层次结构，资源加载器，还有’’Action’’层次结构。MediaWiki一开始没有这些东西，但是这些支持的都是一开始便存在的功能。开发者们主要致力于功能的发展，而架构则是保留了下来，只是后来因为不完善的架构有着明显的成本增加。</p><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>因为MediaWiki是像维基百科这样高知名度网站的平台，核心开发者和代码评审员执行了严格的安全规则(见 <a href="https://www.mediawiki.org/wiki/Security_for_developers" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/Security_for_developers</a> |安全开发详细指南 )。为了更容易的编写安全代码，MediaWiki给开发者提供HTML输出和数据库查询的包装来处理泄漏问题。为了审查用户的输入，开发者用采用了’’WebRequest ‘’类，它可以分析由URL和传输表传输的数据，移除”魔术引号”和斜线条，标识非法字符并且规范Unicode序列。跨站请求的伪造是通过使用令牌来避免，而跨站脚本攻击是通过验证输入和逃避输出来防止，这些经常是使用了PHP的’’htmlspecialchars()’’函数。MediaWiki也通过给XHTML清除提供(和使用)’’Sanitizer ‘’类和数据库函数类防止SQL注入攻击。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>MediaWiki提供了数百的配置设置，作为PHP中的全局变量。默认值设置在’’DefaultSettings.php’’ 中，并且系统管理员可以通过修改文件’’LocalSettings.php’’来更改它们。</p><p>MediaWiki以前过分依赖于全局变量，包括配置和上下文处理。过多的全局变量给PHP的’’register_globals’’函数(这个函数MediaWiki在1.2版本之后就不再使用)带来了严重影响。这个系统也限制了配置的潜在抽象，使其更难优化启动过程。此外，配置的命名空间与用于注册和对象上下文的变量共享，导致潜在的冲突。从用户角度来看，配置的全局变量使MediaWiki更难以配置和维护。MediaWiki的开发一直是一个将环境从全局变量移入对象的过程。将环境存入对象中可以使这些对象被更灵活地运用。</p><h2 id="12-3-数据库和文本储存"><a href="#12-3-数据库和文本储存" class="headerlink" title="12.3 数据库和文本储存"></a>12.3 数据库和文本储存</h2><p>从二期软件开始，MediaWiki就开始使用关系数据库作为后台。MediaWiki默认的(支持性最好的)数据库管理系统是MySQL，MySQL同时也被所有维基媒体基金会的网站使用，也有其他的数据库管理系统(比如PostgreSQL、Oracle和SQLite)由社区支持来实现。系统管理员可以在安装MediaWiki时选择一个数据库，并且MediaWiki提供了一个数据库的抽象和一个查询的抽象层来为开发者简化数据库接口。</p><p><img src="/cdn/images/aosabook/64.png" alt=""></p><p>Figure 12.1: 数据库设计</p><p>目前的设计啊包含了许多的表。许多适合维基百科的内容有关(例如：’’page’’、 ‘’revision’’、 ‘’category’’和’’ recentchanges’’)。其他的表则包含了关于用户(‘’user’’、 ‘’ user_groups’’)、媒体文件(‘’image’’、 ‘’ filearchive’’)、缓存(‘’objectcache’’、 ‘’ l10n_cache’’、 ‘’querycache’’)和内部工具(‘’job’’用于工作队列)等的数据，正如图12.2所示(完整的数据库布局文档可以在维基百科上找到)。因为用SQL查询大量的数据是非常昂贵的，尤其在维基百科上，所以MediaWiki广泛地使用了索引和汇总表。没有索引的查询是非常困难的。</p><p>这些年，数据库的模式有了许多的变换，其中最著名的则是MediaWiki1.5版里的文本存储的解耦和修订追踪。</p><p><img src="/cdn/images/aosabook/65.png" alt=""></p><p>Figure 12.2: Main content tables in MediaWiki 1.4 and 1.5</p><p>在1.4架构中，内容被存储在两个重要的表里，’’cur ‘’(包含当前版本页面的文本和元数据)和’’old’’(包含之前的版本)，被删除的页面保存在’’archive’’中。当页面做出了修改，当前版本的被复制到’’old’’表中，而新的修改被保存在’’cur ‘’中。当一个页面被重命名，’’old’’表中所有旧版元数据中的页面标题必须被更新，这是个耗时很长的操作。当一个页面被删时，那么在删除前，它在’’cur ‘’表和’’old’’表中的所有记录都必须复制到’’archive’’表中；这意味着要移动所有版本的文本，这会非常耗时。</p><p>在1.5版架构中，元数据和文本被分隔开：’’cur ‘’和’’old’’表被’’page ‘’(页面元数据)、’’revision’’(所有版本的元数据，无论旧版还是新版)和’’text ‘’(所有版本的文本，旧、新或被删除的)替代。现在，当出现了修改，元数据不需要再被复制到别的表上，插入新的记录并且更新’’page_latest ‘’的指针就足够了。还要，元数据不再包含页面<br>标题，只有它的ID；这样的话，当页面被改名时就不需要去修改所以版本数据。</p><p>‘’revision’’表存储着每次修改的元数据，但不包含文本；相反，它们是有一个文本的ID指向包含了完整文本的’’text ‘’表。当一个页面被删除时，页面所有版本的文本仍然保留，并且不需要被移动到别的表去。’’text ‘’表是由ID到文本块的映射组成，’’flags ‘’域则表示这个文本块是否被压缩(为了节约空间)以及这个文本块是否只是一个指向外部文本存储的指针。维基百科的网站使用一个MySQL的外部存储集来存储诸多版本的数据块。第一个版本的数据是完整存储的，之后的版本则只记录与之前版本的不同，然后在将数据压缩。因为各版本都是按页面分组的，它们都是很相似的，所以差别相对较小并且压缩的效果也很好。维基百科的压缩比在百分之98左右。</p><p>在硬件方面，MediaWiki已经内置了对负载平衡的支持，这最早在2004年的MediaWiki1.2(那时维基百科有了第二台服务器，是当时的一件大事)中被添加。负载平衡器(MediaWiki<br>的PHP代码决定连接到哪个服务器)现在是维基百科基础设施的一个重要组成部分，这也解释了它在代码的一些算法中的影响。在MediaWiki的配置中，有一个主数据库服务器和任意数量的从数据库服务器，系统管理员可以给每个服务器指定权值。负载均衡器会将所有的写操作分给主服务器，然后根据权值分配读操作。它也保持对每个从服务器反应延迟的监控。如果从服务器的响应延迟超过了30秒，它不会再接受这个服务器的中断请求。如果所有的从服务器的延迟都超过了30秒，MediaWiki会自动将自己置为只读模式。</p><p>MediaWiki的”时间表保护器”可以确保响应延迟不会使用户看到声称动作还没有完成的页面：例如，如果一个用户重命名页面，另一个用户仍可以看到旧的名字，但是改名的那个人一直看到的都是新名字，因为那是他改的名字。这是通过当用户的读请求导致了写请求时，在用户的会话中存储主服务器的位置来完成的。下次用户进行读请求时，负载均衡器会从话中读取位置，然后选择一个已经获取响应位置的从服务器来为这个请求服务。如果没有可用的，那么它会一直等待。它可能会有其他的用户，虽然动作还没有发生，但是时间表使每个用户的请求保持一致。</p><h2 id="12-4-请求、缓存和交付"><a href="#12-4-请求、缓存和交付" class="headerlink" title="12.4 请求、缓存和交付"></a>12.4 请求、缓存和交付</h2><h3 id="网页请求的执行流程"><a href="#网页请求的执行流程" class="headerlink" title="网页请求的执行流程"></a>网页请求的执行流程</h3><p>‘’index.php’’是MediaWiki的主要入口点，并且处理大部分应用服务器加工的请求(即：请求不是由缓存基础设施来服务；参见下文)。从’’index.php’’开始执行的代码依次进行下列操作，进行安全检查、从’’includes/DefaultSettings.php’’加载默认配置、通过’’includes/DefaultSettings.php’’推断配置，然后进行’’LocalSettings.php’’中网站配置。接下来，实例化一个’’MediaWiki’’对象(‘’$mediawiki’’)并且根据请求的标题及动作参数创建一个’’Title’’对象(‘’$wgTitle’’)。</p><p>‘’index.php’’可以接收URL请求中的许多行动参数；默认的动作是’’view’’，可以定期查看文章内容。例如，请求<a href="https://en.wikipedia.org/w/index.php?title=Apple&amp;action=view" target="_blank" rel="noopener">https://en.wikipedia.org/w/index.php?title=Apple&amp;action=view</a> 显示了英文维基百科中“苹果”这篇文章的内容(网页请求通常有URL重写来修饰，比如<a href="https://en.wikipedia.org/wiki/Apple" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Apple</a> )。其他的一些常见的行为，包括’’edit’’(打开一个文章来编辑)、’’submit’’(预览并保存一份文章)、’’history’’(展示一篇文章的历史)和’’watch’’(在用户的浏览列表添加一篇文章)。管理的行为包<br>括’’delete’’(删除一篇文章)和’’protect’’(阻止对文章的修改)。</p><p>‘’MediaWiki::performRequest()’’被调用来处理大部分URL请求。它可以检查标题的好坏、阅读的限制、本地维基内部链接的重定向，和重定向循环，并且确定该请求是通过一个正常的页面还是一个特殊的页面。</p><p>正常页面的请求都交给’’initializearticle() MediaWiki：：’’来给页面创建一个’’Article’’对象(‘’$wgArticle’’)，之后交给’’MediaWiki::performAction()’’来进行标准行动。一旦动作完成了，’’MediaWiki::finalCleanup()’’进行提交数据库事务、输出HTML和通过作业队列进行延期的更新等操作，以完成请求。’’MediaWiki::restInPeace()’’提交延迟的更新并适当地结束任务。</p><p>如果请求的页面是一个特殊页面(即不是一个普通的维基内容页面，而是一种特殊的与软件相关的网页，比如’’Statistics’’)，’’SpecialPageFactory::executePath’’代替’’initializeArticle()’’被调用，之后相应的PHP脚本开始执行。特殊页面可以做许多神奇的事情，并且每一个都有特定的目的，而这些通常都独立于它的标题和内容。特殊页面还包含各种类型的报告(最近的变化、日志、未分类的页面)，和维基管理工具(用户模块、用户权限更改)等。他们的执行工作流程取决于他们的功能。</p><p>许多函数包含调试代码，这样可以使它按工作流程调试。调试时可以分别通过调用’’wfProfileIn’’和’’wfProfileOut’’函数来启动和停止调试一个函数，这两个函数以被调试的函数的名字为参数。在维基百科网站，调试是按请求的百分比来实行，这样可以保持性能。MediaWiki发送UDP包给产生调试数据的中央服务器。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>由于MediaWiki在维基百科网站上起到一个中心的作用，所以它主要在性能方面有加强，不过，它也是一个更大的操作生态系统的一部分，而这个系统已经影响到了它的架构。维基百科的缓存基础设施(层次结构)在MediaWiki上强加了限制；对于这个问题，开发者们并没有尝试去对维基百科的缓存基础设施进行更广泛的优化，而是去使MediaWiki更加灵活，这样它可以不影响性能和缓存的需求地在基础设施上运行。例如，在默认情况下，MediaWiki将用户的IP显示在界面的右上角来作为一个提醒，这样当他们没有登录时，软件就会知道。’’$wgShowIPinHeader’’配置变量允许系统管理员禁用此项功能，因此页面内容可以独立于用户；所有的匿名用户访问的网页都是同样的版本。</p><p>缓存的第一层(用于维基百科网站)包含反向缓存代理服务器(Squids)，它可以在大部分请求到MediaWiki应用服务器前进行拦截和服务。Squids含有整个渲染页面的静态版本，帮助不登陆网站的用户进行简单的读取。MediaWiki一开始就支持Squids和Varnish，并完善了该缓存层，比如：当网页改变时，通知他们从缓存层上清理网页。</p><p>当MediaWiki根据多个对象渲染和组合页面时，缓存的第二层开始运用，这些对象可以存在缓存上来减少之后的调用。这些对象包括网页的界面(补充工具栏，菜单，用户界面文本)和用维基语法对内容的解析。内存对象的缓存自1.1版本的MediaWiki就有了，并且对于避免很长的重新分析和复杂的界面很重要。</p><p>登录会话的数据也可以被存储在缓存中，它使得会话可以透明地在众多前端web服务器上负载均衡地执行(维基很大程度上依赖于负载均衡，通过使用LVS和PyBal)。<br>自从1.16版本后，MediaWiki为本地化的用户界面文本使用一个专用的对象缓存；这是在注意到，存储在缓存集群上的对象中有一大部分是部分为用户语言的界面信息，之后添加的。该系统是基于快速获取个人信息从常数数据库（CDB），例如，键值对文件。在经典案例中，CDBS大大减少了内存开销和启动时间；他们也用于维基内部链接的缓存。</p><p>最后一个缓存层是PHP操作码缓存，通常能够加快PHP应用程序。编译是一个漫长的过程；为了避免每次都要将PHP脚本编译为操作码，一个PHP加速器可以用来存储编译码和执行直接编译。MediaWiki使用了许多加速器，比如：APC、PHP加速器和eAccelerator。</p><p>因为维基百科的偏向，MediaWiki在它的完整性、多层次和分布式缓存基础设施方面进行了优化。尽管如此，它一开始也有对于较小网站的可选的设置。例如，它提供了一个可选的简单的文件缓存系统，来存储完全渲染页面的输出，就像Squid那样。另外，MediaWiki的抽象类缓存层使它能在许多地方存储缓存对象，包括：文件系统、数据库和操作码缓存器。</p><h3 id="资源加载器"><a href="#资源加载器" class="headerlink" title="资源加载器"></a>资源加载器</h3><p>与许多的Web应用程序一样，MediaWiki的接口在这些年来变得更有互动性和反应力，这些都是通过JavaScript的使用。在可用性方面的努力是从2008年开始，同时还有对媒体处理的改进(例如：在线编辑视频文件)，这些都是专注于对前端性能的改进。</p><p>为了优化JavaScript和CSS内容的交付，资源加载器模块在JS和CSS的交付方面有所优化。这个工作自2009年开始，2011年完成，并且自版本1.17后成为了MediaWiki的核心功能。资源加载器会加载所需的JS和CSS的内容，从而在某些特征不用时，减少加载和解析的时间，就像使用旧的浏览器。它还可以缩减代码、通过给资源分组来减少请求，还有嵌入图像作为数据的标识符(想了解资源加载器的更多内容，请查看官方文档)。</p><h2 id="12-5-语言"><a href="#12-5-语言" class="headerlink" title="12.5 语言"></a>12.5 语言</h2><h3 id="语境和理论"><a href="#语境和理论" class="headerlink" title="语境和理论"></a>语境和理论</h3><p>有效的贡献和传播免费自由的知识的一个核心部分是提供尽可能多的语言。维基百科有超过280种语言，并且百科全书中的英文文章只占了不到百分之二十。由于维基百科和它的姊妹网站有这么多语言存在，重要的不只是给读者提供母语的内容，而是提供本地化的接口、有效的输入和转换工具，这样就有更多的参与者可以贡献内容了。</p><p>为此，本地化与国际化是MediaWiki的核心组成部分。国际化的系统是普遍的，影响了软件的许多部分；它也使最灵活和功能丰富的一个(这里有一个对于国际化和本土化的MediaWiki的 <a href="https://www.mediawiki.org/wiki/Localisation" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/Localisation</a> |详尽指南 )。翻译便利通常是为了开发的便利，但这被认为是一个可以接受的成本。</p><p>MediaWiki是目前定位在超过350种语言，包括非拉丁和从右到左（RTL）的语言，这些都有不同程度的完成。界面和内容可以存在不同的语言，有混合性。</p><h3 id="内容语言"><a href="#内容语言" class="headerlink" title="内容语言"></a>内容语言</h3><p>MediaWiki最初使用的每种语言的编码，这导致很多问题，比如：国外的脚本不可以被使用在网页标题。于是，UTF-8被采用了。随着MediaWiki1.5中主要数据库设计的改变，对UTF-8之外的字符集的支持于2005年废止了，内容必须是UTF-8编码。</p><p>编者键盘上没有的字符可以通过MediaWiki的编辑工具自定义地插入，接口信息会出现在编辑窗口下面；JavaScript版本的会自动插入被点击的字符。WikiEditor是MediaWiki的延<br>伸，发展为可用性工作的一部分，将特殊的字符放入工具栏。Narayam是另一个延伸，提供额外的输入方法和对非ASCII编码的映射这一关键功能。</p><h3 id="接口语言"><a href="#接口语言" class="headerlink" title="接口语言"></a>接口语言</h3><p>自从三期软件刚建立开始，接口信息就被存储在PHP关键值对数组。每条信息都是由唯一的钥匙(key)确定的，不过有着许多不同的值(value)。钥匙是由开发者决定的，他们被鼓<br>励使用前缀扩展，比如：对于UploadWizard扩展的钥匙会以’’mwe-upwiz-‘’开头，这里的’’mwe’’表示MediaWiki的扩展。</p><p>MediaWiki信息可以嵌入软件提供的参数，这往往会影响消息的语法。为了支持几乎任何语言，MediaWiki的定位系统进行了改进，并且随着时间不断复杂化，来容纳语言的特点和例外，这经常被认为是说英语的人做出的怪事。</p><p>例如，形容词在英语中是不变的单词，但是像法语这类语言就要求形容词与名词保持一致。如果用户在他们的首选项中指定了他们的性别，那么’’<img src="GENDER:}}&#39;&#39;就会被用在接口信息以适当的定位他们。其他的开关包括&#39;&#39;![](PLURAL:}}&#39;&#39;(简单的复数和语言，像有着双数和几个数字的阿拉伯语" alt="">和’’<img src="GRAMMAR:}}&#39;&#39;(为像芬兰这样语法造成的改变或变化的语言提供转换功能" alt="">。</p><h3 id="定位信息"><a href="#定位信息" class="headerlink" title="定位信息"></a>定位信息</h3><p>本地化界面信息页面存储在’’MessagesXx.php’’文件，其中Xx语言的ISO-639编码(例如：’’MessagesFr.php’’表示法国)；默认的信息都是英文的，并且存储在’’MessagesEn.php’’。MediaWiki的扩展使用了类似的系统，或者将所有本地信息放入了`<extension-name>.i18n.php’’文件。随着转换，消息文件还包括语言相关的信息，如日期格式。</extension-name></p><p>起作用的转换过去是通过给’’MessagesXx.php’’文件提供PHP补丁来完成的。在2003十二月，MediaWiki 1.1引入了的“数据库信息”，是含有接口消息的MediaWiki命名空间上的维基页面的一个子集。页面’’MediaWiki:<message-key><code>的内容是一个关键信息的文本，并且优先于它在PHP文件上的值。本地化版本的信息存储在&#39;&#39;MediaWiki:&lt;Message-key&gt;/&lt;language-code&gt;</code>，比如：’’MediaWiki:Rollbacklink/de’’。</message-key></p><p>此功能允许用户转换(和定制)本地维基的接口信息，但这个过程不会更新国际化的文件。在2006年，Niklas Laxstr?m创建了一个特别的，被黑客严重攻击过的MediaWiki网站(现在托管在<a href="http://translatewiki.net" target="_blank" rel="noopener">http://translatewiki.net</a> )，在这译者可以仅仅通过编辑一个维基页面来更改所以语言的接口信息。之后’’MessagesXx.php’’文件再MediaWiki的代码仓库进行更新，在那里他们可以在那里他们可以自动读取任何维基，并利用LocalisationUpdate扩展更新。在维基网站，数据库的信息现在只用于用户化，并没有任何更多的定位。MediaWiki扩展<br>和相关程序，如机器人，也定位在translatewiki.net。</p><p>为了帮助翻译人员理解接口信息的语境和意义，给每一个信息都提供记录是MediaWiki的一个不错的实践。这些记录是被存储在特殊的消息文件中，用的是’’qqq’’语言的代码，这种语言并不是任何一种真实存在的语言。之后每条消息的翻译记录会在translatewiki.net.上的翻译界面显示。另一个有用的工具是’’qqx’’语言，每当使用’’&amp;uselang’’参数显示一个维基界面时(例如：<a href="https://en.wikipedia.org/wiki/Special:RecentChanges?uselang=qqx" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Special:RecentChanges?uselang=qqx</a> )，MediaWiki会将信息的key而不是value显示在界面上，这对于识别信息是否被修改过很有用。</p><p>注册用户可以在他们的首选项中设置自己的界面语言，以覆盖该网站的默认界面语言。MediaWiki也支持回退语言：如果信息无法以所选择的语言显示，它将在尽可能接近的语言显示，而不一定是英语。例如，布列塔尼回退的语言是法语。</p><h2 id="12-6-用户"><a href="#12-6-用户" class="headerlink" title="12.6 用户"></a>12.6 用户</h2><p>用户在代码中使用的用户类的实例表示，它封装了用户所有的特定的设置（用户ID、名称、权限，密码，电子邮件地址等等）。客户类使用访问器来访问这些字段，他们的工作主要是确定用户是否登录、请求的选项是否与cookies符合，以及是否需要数据查询操作。一般页面的大部分设置都记录在cookie中，以减少对数据库的使用。</p><p>MediaWiki提供了一个非常细致的权限系统，每一个可能的操作都要用户权限。例如，进行”回滚”操作(即：快速回滚最后编辑页面的用户的编辑)时，用户需要回滚权限，包括在MediaWiki的’’sysop’’的用户集中。但它也可以被添加到其他用户组，或有一个专门的用户组提供本许可(英文维基百科，就有这样的’’Rollbackers’’组)。用户权限的定制是通过修改’’LocalSettings.php’’中的’’$wgGroupPermissions’’数组，例如：’’$wgGroupPermissions[‘user’][‘movefile’] = true;’’允许所有注册用户重命名文件。一个用户可以属于几个组，并继承与他们每个人相关的最高权利。</p><p>然而，MediaWiki的用户权限系统是根据维基百科的想法设计的；一个网站的内容是对所有人开放，而且对于用户只有一定的行动限制。MediaWiki缺少一个统一的、普适的权限的概念；它不提供传统的CMS功能，比如：按主题或内容类型来限制阅读和确定写权限。MediaWiki的一些扩展在一定程度上提供了这样的功能。</p><h2 id="12-7-内容"><a href="#12-7-内容" class="headerlink" title="12.7 内容"></a>12.7 内容</h2><h3 id="内容结构"><a href="#内容结构" class="headerlink" title="内容结构"></a>内容结构</h3><p>命名空间的概念被使用在维基百科的UseModWiki时代，讨论页的标题是“&lt;项目名称&gt; /Talk”。命名空间一开始就被正式引入了Magnus Manske的第一个“PHP脚本”。这些年来虽然有了许多改动，但仍使用同样的函数来区分不同种类的内容。他们由一个网页标题分离出来的前缀加一个冒号组成(例如：’’Talk:’’、’’File:’’、’’Template:’’)；主内容的命名空间没有前缀。维基百科用户很快就采纳了他们，他们为社区提供了不同的空间来发展。命名空间已被证明是MediaWiki的重要特征，作为他们创建一个Wiki社区、促进社区发展，并且建立元层次的讨论、、门户网站、用户配置文件，等等的必要前提。</p><p>MediaWiki主要内容的命名空间的默认配置是平的(没有子页面)，因为这就是维基百科的运行方式，启用子页面是无意义的。不过他们会在其他命名空间上启用(例如：在’’User’’上人们可以做打草稿等工作)并且陈列一些琐碎的内容。</p><p>命名空间通过类型的不同对内容进行区分；在同一个命名空间中，页面可以按标题类别进行分组，伪分层组织方案在是MediaWiki1.3被引入。</p><h3 id="内容处理：MediaWiki标记语言和语法分析器"><a href="#内容处理：MediaWiki标记语言和语法分析器" class="headerlink" title="内容处理：MediaWiki标记语言和语法分析器"></a>内容处理：MediaWiki标记语言和语法分析器</h3><p>用户生成的页面并不是以HTML存储在MediaWiki上，而是用一种MediaWiki的特殊标记语言，这种语言有时被称作” wikitext”。 它允许用户去更改格式（如粗体，斜体使用引号），添加链接（用方括号），包括模板，插入上下文相关的内容（如日期或签名），并使其他特殊的事情达到一个令人难以置信的数量。（ <a href="https://www.mediawiki.org/wiki/Markup_spec" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/Markup_spec</a> |详尽文档 ）。</p><p>要显示一个页面，相关内容需要被分析，组装所有外部或动态的部分，并转换为适当的HTML。解析器是MediaWiki的重要组成部分，这使得它很难被改变或改善。由于全球数以亿计的Wiki页面需要解析器按它固有的方式持续输出HTML，所以它必须保持非常稳定。</p><p>MediaWiki一开始并没有使用标记语言，它是随着” UseModWiki”开始使用的，之后演变和进化成了一种需求。在缺少正常的规则的情况下，MediaWiki的标记语言已经成为了一个复杂而特殊的语言，基本上之和解析器兼容，它不能被表示为一个正式的语法。当前解析器的规范被戏称为“任何解析器从wikitext吐出来的，都要用几百个测试用例去检验”。</p><p>有许多人尝试去完成其他的解析器，但至今没有成功。在2004年，Jens Frank写了一个分解器来解析wikitext，并且被维基百科采用了，但仅使用了三天就不得不被禁用，原因是在PHP数组的内存分配上性能很差。从那时起，大多数的分析是通过一大堆的正则表达式，和许多的辅助函数完成的。wiki标记，和解析器需要支持的所有特殊情况，也都变得更为复杂，使得未来的尝试更加困难。</p><p>一个显著的改进是Tim Starling的预处理器重写在MediaWiki 1.12，其主要目的是通过复杂的模板提高页面上的分析性能。预处理器将wikitext转换为一个XML DOM树来表现文档(模板调用，解析器的功能，标签挂钩，章节标题，和一些其他的结构)的部分内容，但是可以跳过”枯枝”，比如在扩展模板中，没有事例跟随的’’#switch’’还有未使用过的默认参数，解析器接着遍历DOM结构并将其内容转换为HTML。</p><p>最近已经有一些对可视化编辑器的改善，使分析过程有所改进(或是使它更快)，所以对于解析器上MediaWiki标记和最终HTML代码之间中间层的改进已重新开始。(参见下文的”未来”)。</p><h3 id="特殊词和模板"><a href="#特殊词和模板" class="headerlink" title="特殊词和模板"></a>特殊词和模板</h3><p>MediaWiki提供了”特殊词”来修改网页的一般行为或者将动态内容包含进去。他们由开关’’<strong>NOTOC</strong>‘’(隐藏内容的自动表)或’’<strong>NOINDEX</strong>‘’(告诉搜索引擎不索引页面)，变量’’<img src="CURRENTTIME}}&#39;&#39;或&#39;&#39;![](SITENAME}}&#39;&#39;，和分析函数的参数&#39;&#39;![](lc:&lt;string&gt;}}&#39;&#39;(以小写字母输出`&lt;string&gt;`" alt="">，结构体’’![](GENDER:}}’’，’’![](PLURAL:}}’’及’’![](GRAMMAR:}}’’组成，被用于本地化的用户界面，是解析器的功能。</p><p>最常见的包括MediaWiki其他页面内容的方式是使用模板的。模板常被用来包括在不同的页面上的相同的内容，例如，维基百科文章中的导航面板或维护横幅；这种创建部分页面布局并在成千上万的文章重用他们，还可以正常地维护好他们的能力，对像维基百科这样的网站有着巨大的作用。</p><p>然而，用户也以一个完全不同的目的使用（和滥用）模板。MediaWiki 1.3使得模板带参数来改变输出；添加默认参数的能力（于MediaWiki 1.6被引入）以PHP实现了函数式程序设计语言的建设，这最终成为性能方面最昂贵的特征之一。</p><p>Tim Starling之后开发了额外的解析器函数（ParserFunctions扩展）来作为应对用户疯狂使用模板的情况的临时措施。这套功能包括逻辑结构’’#if’’和’’#switch’’，和其他功能如’’#expr’’（评价的数学表达式）和’’#time’’（时间格式）。</p><p>很快，维基百科用户开始创建更复杂的模板，使用新的功能，这大大降低了使用许多模板的页面上的解析性能。新的处理器被引入MediaWiki 1.12（一个主要的结构变化）来部分解决这个问题。近日，MediaWiki的开发者们已经讨论了是否使用实际的脚本语言，或许是Lua，来提高性能。</p><h3 id="媒体文件"><a href="#媒体文件" class="headerlink" title="媒体文件"></a>媒体文件</h3><p>用户通过’’Special:Upload’’页面来上传文件，管理员可以通过额外的名单来配置允许被上传的文件类型。文件一旦上传，便存储在文件系统上的一个文件夹内，并列在一个专用的缩略的目录中。</p><p>因为维基的教育使命，MediaWiki支持可能在其他Web应用程序或CMS上罕见的文件类型，如SVG矢量图像和多页的PDF文件和DjVus。它们呈现为PNG文件，并可显示缩略图和内联，同样也可以作为其他更常见的图像文件，如GIF，JPG和PNG图片。</p><p>当一个文件被上传，它会产生一个包含上传者信息的’’File:’’页面，这是自由文本，通常包括版权信息（作者、许可证）和件的内容的描述或分类文（名称、位置、日期、类别等）。而私人维基可能根本不在乎这个信息，在媒体库像维基共享资源中，组织收集和保证共享这些文件的合法性才是关键。这些元数据被认为应该被存储在一个可查询的结构像一个数据库表，事实上也是如此。这将大大方便搜索，并且也可由第三方使用，比如，通过API使用。</p><p>大部分维基百科的网站仍允许本地文件上传到每个维基，但社区在试着将得到许可，免费的媒体文件存储到维基百科的免费媒体库(Wikimedia Commons)中。任何维基百科的网站可以像播放本地媒体文件一样播放媒体库中的文件。这种惯例可以避免每个使用文件的网站都要传一份文件。</p><p>MediaWiki从一开始就支持国外媒体库，即：通过API和’’ForeignAPIRepo’’系统访问在别的维基上的媒体文件的能力，而且有了成果。.16以后的版本，任何页面的网站可以很容易地通过’’InstantCommons’’特征使用维基共享资源。使用外来存储库时，缩略图存储在本地以节省带宽。然而，这是不可能从另一个维基上传文件到外国媒体库。</p><h2 id="12-8-MediaWiki的定制和延伸"><a href="#12-8-MediaWiki的定制和延伸" class="headerlink" title="12.8 MediaWiki的定制和延伸"></a>12.8 MediaWiki的定制和延伸</h2><h3 id="等级"><a href="#等级" class="headerlink" title="等级"></a>等级</h3><p>MediaWiki的架构提供了不同的方式来定制和扩展软件。这可以通过不同级别的权限做到：</p><ul><li><p>系统管理员可以安装扩展和皮肤，并配置维基独立的辅助程序（例如，图像缩略图和TeX渲染）和全局设置（详见”配置”）。</p></li><li><p>维基站长（有时也被称为“管理员”）可以编辑用于所有维基网站的小配件，JavaScript和CSS的设置。</p></li></ul><ul><li>每个注册的用户都可以通过自己选择参数或制作mod来定制自己的设置和界面。</li></ul><p>如果机器的API被启用，外部程序就可以通过它与 MediaWiki沟通，主要可以使用户能够访问任何功能和数据。</p><h3 id="JavaScript和CSS"><a href="#JavaScript和CSS" class="headerlink" title="JavaScript和CSS"></a>JavaScript和CSS</h3><p>MediaWiki可以通过自定义的维基页面阅读并使用适用于所有网页和皮肤的JavaScript和CSS：这些页面在’’MediaWiki:’’的命名空间，因此只能由站长编辑；例如，’’MediaWiki:Common.js’’中的JavaScript的模组适用于所有皮肤，’’MediaWiki: Common.css’’中的CSS模组也适用于所有皮肤，但’’MediaWiki: Vector.css’’只适用于用户的载体皮肤。</p><p>用户可以通过用户页面的子页面来做同样类型的修改，不过只适用于他们自己的界面(例如：JavaScript的’’User:<username>/common.js’’适用于所有皮肤，CSS的’’User:<username>/common.css’’适用于所有皮肤，CSS的模组’’User:<username>/vector.css’’只适用于载体皮肤)。</username></username></username></p><p>如果安装扩展的小部件，站长也可以编辑小部件，例如：JavaScript代码片段，用户可以自己选择提供的功能的开关。以后会尽可能让这些小部件通过维基来传播，这样可以避免重复。</p><p>这套工具产生了巨大的影响，大大提高了MediaWiki的软件开发的民主化。个人用户有权为自己添加功能；高权限用户可以非正式地，或通过全局配置的管理员控制系统来与他人分享。这个框架更适用于小的、独立的模组，并且通过一个较低的门槛而不是代码复杂的模组来进入扩展和hook。</p><h3 id="扩展和皮肤"><a href="#扩展和皮肤" class="headerlink" title="扩展和皮肤"></a>扩展和皮肤</h3><p>当JavaScript和CSS的模组不够时，页面提供了一个hook系统，来让第三方开发者运行自定义的PHP代码，来代替用于特殊事件的MediaWiki代码。(MediaWiki hooks参见<a href="https://www.mediawiki.org/wiki/Manual:Hooks" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/Manual:Hooks</a> )。MediaWiki的延伸通过hook来添加到代码里。</p><p>在MediaWiki开始使用hook之前，添加定制的PHP代码意味着修改核心代码，这是既不容易，也不推荐的。第一个hook由Evan Prodromou提出并于2004添加；这些年来已经有许多新的hook因为需要被添加。使用hook甚至可以扩展MediaWiki标记的作用。</p><p>扩展系统还并不完善，扩展的注册是在运行的代码的基础上实现的，而不是缓存的数据，这限制了代码的抽象和优化，并降低了性能。但总的来说，扩展的框架现在是一个相当灵活的基础设施，可以使专用代码更加模块化，在扩展时保持核心软件，并使第三方用户创建自定义功能上更容易定制。</p><p>相反的是，在不重新构建基础的情况下，给MediaWiki写一个新皮肤是非常困难的。在MediaWiki中，皮肤都是延伸自’’Skin’’类的PHP类，他们通过收集需要的数据来实现HTML。已经有很长寿命的“MonoBook“皮肤很难被定制，因为它包含很多浏览器特定的、支持旧的浏览器CSS ，编辑模板和CSS需要根据所有浏览器和平台的变化来进行很多后续的变化。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>除了’’index.php’’，其他主要的进入MediaWiki的点就是’’api.php’’了，这是用来访问它的机器可读的网页查询API（应用编程接口）。</p><p>维基百科用户最初创建的“机器人”，是通过抓取屏幕中的HTML内容来工作的。这个方法很不可靠，出了许多问题。为了改善这种情况，开发商推出的一种只读接口（位于’’query.php’’），然后进化成一个完整的读写机API，这个API提供了直接的、高层次的对包含在MediaWiki数据库数据的访问( <a href="https://www.mediawiki.org/wiki/API:Main_page" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/API:Main_page</a> |详尽文档 )。</p><p>客户端程序可以使用该API进行登录，获取数据，并进行更改。这个API支持简单的基于网络的JavaScript客户端和最终用户程序。几乎所有可以通过Web界面来完成的事情，基本上都可以通过这个接口来完成。客户几乎所有可以通过Web界面来完成的事情，基本上都可以通过这个接口来完成。客户端库是通过多种语言实现API的，包括Python和.NET。</p><h2 id="12-9未来"><a href="#12-9未来" class="headerlink" title="12.9未来"></a>12.9未来</h2><p>当初那个由PHP开发者于夏天单独完成的工程，已经成为了MediaWiki这个成熟的、稳定的维基引擎，甚至仅通过很小的基础设施就能支撑维基百科这个全球前十的网站。这个框架的实现，是通过一个优秀的开发团队，不断地进行性能优化和架构修改来完成的。</p><p>随着网络技术的发展，和维基百科的增长，MediaWiki的架构需要不断的改进和并添加新的功能。例如，不断发展的可视化编辑工程，促使了解析器的发展，以及维基标记语言、DOM、HTML之间的转换。</p><p>MediaWiki是一种用于不同目的的工具。例如，对于维基媒体项目，它被用来完成创建和管理一个百科全书(维基百科)，支持一个庞大的媒体库(维基共享资源)，将扫描转换为文本等工作。在其他情况下，MediaWiki是作为一个集团的CMS，或作为一个数据存储库，有时会与语义框架结合。这些一开始并不在计划内的用途，可能会促使软件框架不断地进行内部调整。因此，MediaWiki框架是非常活跃的，就想它所支持的有许多用户的巨大的社区。</p><h2 id="12-10扩展阅读"><a href="#12-10扩展阅读" class="headerlink" title="12.10扩展阅读"></a>12.10扩展阅读</h2><ul><li>1、 <a href="https://www.mediawiki.org/wiki/MediaWiki" target="_blank" rel="noopener">https://www.mediawiki.org/wiki/MediaWiki</a> |MediaWiki的文档和支持 </li><li>2、 <a href="https://phabricator.wikimedia.org/diffusion/" target="_blank" rel="noopener">https://phabricator.wikimedia.org/diffusion/</a> |自动生成的页面文件 </li><li>3、MySQL用户大会上，维基百科的Domas Mituzas的发言， <a href="https://dom.as/talks/" target="_blank" rel="noopener">https://dom.as/talks/</a> |site internals, configuration, code examples and management issues <h2 id="12-11鸣谢"><a href="#12-11鸣谢" class="headerlink" title="12.11鸣谢"></a>12.11鸣谢</h2>本章是协作创作。Guillaume Paumier通过组织MediaWiki的用户和代码开发者所给材料，完成了本章大部分内容。Sumana Harihareswara协调了界面和输入采集阶段。特别感谢Antoine Musso, Brion Vibber, Chad Horohoe, Tim Starling, Roan Kattouw, Sam Reed, Siebrand Mazeland, Erik M?ller, Magnus Manske, Rob Lanphier, Amir Aharoni, Federico Leva, Graham Pearce等人提供材料和审核内容。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MediaWiki&quot;&gt;&lt;a href=&quot;#MediaWiki&quot; class=&quot;headerlink&quot; title=&quot;MediaWiki&quot;&gt;&lt;/a&gt;MediaWiki&lt;/h1&gt;&lt;p&gt;从一开始，MediaWiki就是专门为维基百科服务的软件。开发者一直致力于使其能更方
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Moodle</title>
    <link href="http://blog.ccao.cc/2018/09/28/Moodle/"/>
    <id>http://blog.ccao.cc/2018/09/28/Moodle/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.671Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Moodle</strong>作者：Tim Hunt<br>译者：朱凯文</p><p>Moodle是一个用于教育系统设计的web应用程序。<br>这一篇翻译将详细的讲解Moodle是怎么运作的，尤其是从以下这几个方面：</p><ul><li><p>用插件来分割应用方法</p></li><li><p>权限系统***-掌握着每个用户所拥有的权限</p></li><li><p>输出的方式以及多样化的主题皮肤，使得界面可以得到本地化</p></li><li><p>数据库抽象层</p></li></ul><p>Moodle 为老师和学生提供了一个线上教学的环境。一个Moodle站点被划分为不同的课程。<br>每一个课程都有与之相对应的角色参与进来比如老师和学生。每一门课程都是由一系列的资源和活动组成。资源可能是一个PDF文件，一个Moodle内网的地址，或者是一些散步在网络中的资源链接。而活动可能是一个讨论，一次考试，或者是一个wiki。当用户在使用Moodle的时候这些资源和活动就可以按照某种方式被组织起来，比如说，他们可以按照逻辑上相关，或者是日程上的特定周目被分配到一起。</p><p>Moodle 平台可以作为一个独立的应用程序，如果你想在网络上授课，你可以尝试下载Moodle 到你的服务器，安装并创建课程，然后学生就可以来注册并选课了。Moodle也可以作为一个系统运行，如果你是一个庞大的机构，您可能需要尝试完成以下的架构：</p><p>一个管理夸系统的用户账号身份认证服务（例如使用LDAP）<br>一个学生信息系统。它其实就是一个庞大的数据库，里面记载着所有的学生信息，包括他们当前正在进行的课程，以及需要完成的课程，还有他们的笔记，这份笔记可以是他们都一门所完成课程的高度总结。当然，这个信息系统也可以提供其他的管理功能，比如跟踪一个学生是否上缴了学费。<br>一个文档库（比如使用Alfresco）。它用来储存文件，以及跟踪用户合作维护文件时的工作流。<br>一个电子档案袋。学生可以在这里存放他们自己的资料比如实验，简历等文件，或者是用来证明档案所有者以及满足了一门实践课的选修条件。<br>一个报告或分析工具。以产生高权限的信息，分析报告您所在的机构正在发生什么。</p><p>相比其他为单一教育单位设计的系统，Moodle更专注于为所有参与到教学中的人提供一个在线平台。<br>Moodle仅仅为非主要功能提供了最基本的实现，所以它可以单独的作为一个应用，或者与其他系统进行集成。Moodle 扮演的角色被正式的称为虚拟教学环境（VLE），或者是教学/课程管理系统（LMS，CMS，甚至是LCMS）。</p><p>Moodle是一个用pfp编写的开源免费软件。它可以在绝大多数的Web服务器和平台上运行。它需要一个数据库，目前支持MySQL，PostgreSql，Ms SQL Server以及Oracle。</p><p><strong> Moodle运作方式综述 </strong></p><p>安装Moodle的三个部分</p><p>1 代码，通常在一个类似/var/www/moodle 或者 ~/htdocs/moodle 的目录里。Web服务器应该对这个目录不具有修改权限。<br>2 数据库，由上面提到过的几种RDMS管理。实际上，Moodle 给所有的表名增加了一个前缀。所以如果需要的话，它可以和其他应用共用一个数据库。<br>3 Moodledata 目录， 这个目录用于存储用户上传的文件以及系统生成的文件，同样Web服务器需要对这个目录拥有修改可写的权限。处于安全考虑，这个目录应该设置于Web根目录之外。<br>以上三部分可以完全部署在一台服务器上。或者，采用负载均衡设置，在每台Web服务器上都部署代码，但是仅仅共用一个数据库和一个moodledata目录。<br>当Moodle安装完毕后，上述的三部分的配置信息将被存储在Moodle根目录下的config.php文件中。</p><p>调度请求<br>Moodle是一个Web应用，需要用户通过浏览器去使用它。从Moodle自己的角度来看，这就意味着它要响应HTTP请求。Moodle在一开始设计时URL的设计就是一个重要的考量，包括URL如何被调度到不同的脚本上。<br>Moodle这里采用标准的PHP方法。当你在浏览一个课程的主页时，URL可能像…/course/view.php?id=123，这里123就是这门课在数据库中的唯一标识。浏览一个论坛并参与讨论时，URL可能是…/mod/forum/discuss.php?id=456789。也就是说，这些特定的脚本，course/view.php或者mod/forum/discuss.php 会来处理这些请求。</p><p>这对于开发者就很容易明白Moodle是怎么处理这类的请求了，你只需要看看URL，然后就可以去阅读那份php文件的代码了。但是这从用户的角度来看却是十分丑陋的，因为这些URL永久不变。比方说一个课程改了名字，或者某个管理员把一个讨论转移到另一个板块中，这些URL都不会变。<br>可以采取的另一种方法是设定唯一的入口…/index.php/[唯一的确定信息]。这个单独的index.php脚本会通过某种方式进行调度。这个方法调价了一个大多数软件开发者都喜欢用的间接层。但其实，没有这个间接层也并不会影响到Moodle的使用。</p><p>插件<br>和许多其他成功的开源项目一样，Moodle是由一个系统内核协同许多各种功能的插件构建起来的。这是一个很好的注意，因为它可以使用户按照他们自己的喜好来增强Moodle的功能。这就是一个开源系统很重要的优势：你可以根据自己的特定需求来更改它。但是，就算拥有很好的版本控制系统，在系统升级时仍然可能会因为代码的高可定制性从而导致很多的问题。<br>Moodle的插件通过定义好的API与内核交互，它使得人们在定制病分享自己的Moodle时更加容易，并且在Moodle系统内核升级时也不会受到影响。<br>一个插件化的系统有多种不同的构建方法。Moodle具有一个相对庞大的内核，并且所有的插件都是强类型的。所谓的庞大的内核，指的是内核里已经提供了大量的功能。这其实违反了那类由一个小型的插件启动器引导，其余部分都是插件的架构设计。<br>所谓强类型的插件，是指根据你想实现的具体功能，你可能需要写完全不同的插件，实现不同的API。比如，一个新建活动模块插件会与一个新建认证插件截然不同。根据最后统计，我们现在一共有35种不同的插件。这违背了那类，所有插件都要通过使用最基本的API，通过注册它们感兴趣的项目和事件与内核进行交互的架构设计。<br>Moodle曾经有尝试把更多的功能移到插件中以减小内核，然而这并没有取得很明显的效果，因为当前Moodle有一个不断去扩展内核的趋势。还有一个趋势是尽可能的将不同种类的插件进行规范化。这样在许多公共功能上，比如安装和升级，所有的插件都可以按照统一的方式运行。</p><p>Moodle的每一个插件其实就是一个包含许多文件的目录。每一个插件都有一个类型和名字，这两个构成了这个插件的”Frankenstyle”组件名称。插件类型和名字决定了这个插件目录的路径。插件类型给定一个前缀，目录名称就是这个插件的名字。<br>这里有一些例子。</p><table><thead><tr><th>插件类型</th><th>插件名称</th><th>Frankenstyle</th><th>目录</th></tr></thead><tbody><tr><td>mod(Activity moudule)</td><td>forum</td><td>mod_forum</td><td>mod/forum</td></tr><tr><td>mod(Activity moudule)</td><td>quiz</td><td>mod_quiz</td><td>mod/quiz</td></tr><tr><td>block(Side-block)</td><td>navigation</td><td>block_navigation</td><td>blocks/navigation</td></tr><tr><td>qtype(Question type)</td><td>shortanswer</td><td>qtype_shortanswer</td><td>question/type/shortanswer</td></tr><tr><td>quiz(Quiz report)</td><td>statistics</td><td>quiz_statistics</td><td>mod/quiz/report/statistics</td></tr></tbody></table><p>最后一个例子表明每一个活动模块被允许声明为一个插件的子插件。只有活动模块才能做到这点。这出于两点原因，首先如果所有的插件都可以声明为子插件类型，这可能会带来严重的性能问题，其次，活动模块是Moodle中最重要的教育活动，也是插件中最重要的类型，所以它们应该具有特殊的权限。</p><p>插件示例：<br>我们接下来将以一个具体的插件实例来解释Moodle架构中的大量细节。作为一种传统，我们选择实现一个现实”Hello world”的插件。</p><p>这个插件实际上并不适合任何一种Moodle标准插件。它只是一个简单的脚本，和其他任何东西都没有联系，所以我选择把它制作成一个’local’类型的插件。这是一个catch-all的插件类型，这种插件类型专门处理一些杂乱的功能，所以在这里非常的合适。不给我的插件命名为greet，所以它的Frankenstyle的名字是local_greet，路径为local/greet。</p><p>每一个插件都必须包含一个叫做version.php 的文件，这个文件定义了关于这个插件本身的元数据。Moodle的插件安装系统会使用它来对插件进行安装和升级。例如local/greet/version.php包含代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$plugin-&gt;component = &apos;local_greet&apos;;</span><br><span class="line"></span><br><span class="line">$plugin-&gt;version   = 2011102900;</span><br><span class="line"></span><br><span class="line">$plugin-&gt;requires  = 2011102700;</span><br><span class="line"></span><br><span class="line">$plugin-&gt;maturity  = MATURITY_STABLE;</span><br></pre></td></tr></table></figure><p>由于可以从路径上明显的看出插件的名字，所以乍看之下代码里面包含组件的名称会略显多余。但事实上安装包需要通过组件名称来验证插件是否安装在正确的位子上。而你们可以给相同插件的不同版本标上对应的版本号。通常来说可以用版本的完成性比如ALPHA，BETA，RC等代号，或者是STABLE这样的标签，或者是Requires字段，Requires字段可以用来表示与Moodle兼容的最低版本号。必要的话，你也可以记录下这个插件依赖的其他插件。</p><p>以下是这个简单插件的主要脚本（存储在local/greet/index.php）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">require_once(dirname(__FILE__). &apos;/../../config/php&apos;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">require_login();</span><br><span class="line"></span><br><span class="line">$context = context_system::instance();</span><br><span class="line"></span><br><span class="line">require_capability(&apos;local/greet:begreeted&apos;,$context);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$name = optional_param(&apos;name&apos;,&apos;,PARAM_TEXT);</span><br><span class="line"></span><br><span class="line">if(!$name)&#123;</span><br><span class="line"></span><br><span class="line">$name = fullname($USER);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">add_to_log(SITEID,&apos;local_greet&apos;,&apos;begreeted&apos;,</span><br><span class="line"></span><br><span class="line">&apos;local/greet/index.php?name=&apos;.urlencode($name));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$PAGE-&gt;set_context($context);</span><br><span class="line"></span><br><span class="line">$PAGE-&gt;set_url(new moodle_url(&apos;/lacal/greet/index.php&apos;), array(&apos;name&apos;=&gt; $name));</span><br><span class="line"></span><br><span class="line">$PAGE-&gt;set_title(get_string(&apos;welcome&apos;,&apos;local_greet&apos;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo $OUTPUT-&gt;header();</span><br><span class="line"></span><br><span class="line">echo $OUTPUT-&gt;box(get_string(&apos;greet&apos;,&apos;local_greet&apos;,format_string($name)));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo $OUTPUT-&gt;footer();</span><br></pre></td></tr></table></figure></p><p>Line 1: 引导Moodle<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">require_once(dirname(__FILE__). &apos;/../../config/php&apos;);</span><br></pre></td></tr></table></figure></p><p>这单独的一行是大多数插件都要首先完成的。之前提到过，config.php包含着Moodle如何连接数据库以及找到metadata目录的细节。引导功能在require_once(‘lib/setup.php’)结束，然而引导功能完成了：<br>1加载了左右Moodle标准库<br>2开始处理会话<br>3连接数据库<br>4初始化一系列全局变量。（一会儿你就明白了）</p><p>Line 2： 检查用户是否登录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">require_login();</span><br></pre></td></tr></table></figure></p><p>这行是的Moodle利用管理员配置过的任何认证插件来判断当前访问用户是否已经登录。如果尚未登录，则用户将被重新引导到用户登录界面。并且这个函数是不能撤回的。<br>一个与Moodle整合性更好的插件会在这里传递更多的参数，比如这个页面属于哪个课程或者哪个活动。然后调用的require_login仍然会检查当前用户是否参加了这门课程或者活动。如果该用户允许访问，则他就可以访问这门课程或者是观看这个活动；如果没有权限，那么适当的错误性息将被显示出来。</p><p>13.2 Moodle中的角色和权限系统<br>接下来的两行代码将显示出如何检查用户是否有做某件事的权限。正如你所见，从开发者的角度来说，这些API都十分的简单。但是，实际上在这下面是一个非常复杂的接入系统。这会给管理员很大的伸缩性来控制每个人的权限。<br>Line 3： 获得上下文</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$context = context_system::instance();</span><br></pre></td></tr></table></figure><p>在Moodle中用一个人可能在不同的地方拥有不同的权限。比如一个用户可能在某个课程上做一名老师，也可能在另一门课程中是一位学生。这些地方被称为上下文，上下文在Moodle 中构筑了一个特别像文件系统中目录结构那样的多层结构。而在这个结构的最上层是系统上下文，由于我们展示的代码不能很好的融入Moodle，它使用的是最上层的上下文。<br>系统中的上下文中，有许多的上下文信息被构造出来，他们负责维护那些为了阻止课程而被创建的不同分类。这些上下文可以是嵌套的，比如在一个分类里包含其他更多的分类。分类上下文同时也包含着课程上下文。最后，每一个课程中的活动也会拥有自己的Moodle上下文。</p><p>Line 4： 检查用户是否有权执行这个脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">require_capability(&apos;local/greetbegreeted&apos;,$context);</span><br></pre></td></tr></table></figure><p>在我们获得了上下文后，就可以检查权限了。某个用户能否执行某个功能的信息被称作能力（Capability）。基于能力的检车可以提供比简单的require_login检查更加细致的访问检查。在我们这个简单的插件中，只有一个能力：local/greet:begreeted。<br>这个价差通过require_capability 函数来完成，不过这需要这个能力的名字以及当前的上下文，就像其他require…函数一样，如果用户没有这个能力，则不会正常返回，而是现实一个错误。在其他地方，非致命的has_capability函数，当可用的时候返回true，比如要不要再另一个网页上添加对于当前这个脚本的一个链接。<br>那么管理员是如何配置什么用户拥有什么权限呢？这里显示的has_capability函数如何通过计算得到（至少理论上是这样的）：<br>1 从当前上下文开始； </p><p>2 获得这个用户在当前上下文中所扮演的所有角色； </p><p>3 计算出当前上下文中，每一个角色所拥有的权限； </p><p>4 将这些权限整合起来获得一个最终的结果。</p><p>定义能力<br>在下面一个例子中，一个插件可以根据它要提供的独特功能来定义新的能力。在每一个Moodle插件中都有一个子目录，叫db。这个目录包含了所有安装和升级这个插件所需的信息，期中有一个access.php文件来定义能力。下面就是我们插件的access.php，它位于Local/greet/db/access.php</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">$capabilities = array(&apos;local/greet:begreeted&apos; -&gt;array(</span><br><span class="line"></span><br><span class="line">&apos;captype&apos; -&gt; &apos;read&apos;,</span><br><span class="line"></span><br><span class="line">&apos;contextlevel&apos; -&gt;CONTEXT_SYSTEM,</span><br><span class="line"></span><br><span class="line">&apos;archetypes&apos; -&gt; arrat(&apos;guest&apos;-&gt;CAP_ALLOW, &apos;user&apos; -&gt; CAP_ALLOW)</span><br><span class="line"></span><br><span class="line">));</span><br></pre></td></tr></table></figure><p>这里定义了对于每个能力的元信息，这些元信息会在在狗仔权限管理用户界面的时候被用到。它规定了对于常见角色的默认权限。</p><p>角色<br>Moodle 权限系统的下一部分就是角色了。一个角色其实就是一个权限集合的名字。当你登录到Moodle 后，你在系统上下文中就拥有一个Authenticated user 的角色。由于系统上下文储存在上下文结构的根节点，所以这个角色会被应用到所有的地方。<br>在一个特定的课程中，你可能是一个学生，那么这个角色就会在这个课程上下文中储存自己的信息，并在你访问该课程模块以及其子模块的上下文中都有效。然而在另一门课程中，你可能有一个不同的身份。例如，Grandgrind 先生可以是“Facts，Facts，Facts”这门课的教师，但是他却是职业发展课程“Facts Aren‘t Everything” 中的一名学生。 最后，一个用户或许会在特定的论坛（模块上下文）中被指派成为一个主持人（Moderator）的角色。</p><p>权限<br>每一个角色对每一种能力都规定了一个权限。例如教师的角色很有可能被允许拥有moodle/course:manage，?但是学生角色就不会。但是教师和学生都会被允许有用mod/forum:startdiscussion。<br>角色通常是拥有全局性的，但是他们在每一个上下文中仍然可以被重新定义。比如说，某个wiki可以通过修改上下文中对于学生的mod/wiki:edit能力成禁止，来把学生的角色变成只读。<br>一般来说，有四种权限：</p><ul><li>未设置/继承（默认）</li><li>允许</li><li>预防</li><li>禁止<br>在给定的上下文中，一个角色对每一个能力都有着四种权限之一。预防和禁止的一个重要区别是，禁止在预防的基础上海确保子上下文不能覆盖这个权限。</li></ul><p>权限整合<br>最后，一个用户在这个上下文中根据所有角色所获得的权限会被整合起来。</p><ul><li>如果任何角色对于一个能力给出的权限是禁止，那么返回false。</li><li>否则，如果任何角色对于这个能力给出的权限是允许，那么返回true。</li><li>再否则，返回false</li></ul><p>一个使用禁止权限的用例如下：<br>假设有一个用户在许多论坛中持续乱发帖，我们想让这个家伙立刻闭嘴。那么我们可以建立一个叫做捣蛋鬼的角色，这个角色对于类似mod/forum:post这样的能力全部设置为禁止。我们可以把这个捣蛋鬼的角色在系统上下文中分配给那个乱发帖子的用户。这样我们就能保证这个用户在所有论坛里面都不能发帖了。（然后可以跟这个学生好好谈谈，得到一个满意的答复，然后再把这个角色指派删除掉，这样他又能发帖了）<br>总而言之，Moodle的权限系统给了管理员很大的伸缩性。他们可以定义任何他们喜欢的角色，为这个角色的每一个能力指定不同的权限；他们可以在子上下文中改变角色的定义；<br>并且，他们还可以在不同的上下文中对用户赋予不同的角色。</p><p>回到样例脚本<br>脚本的下一个部分解释了一些繁杂的任务；<br>Line 5：从请求中获得数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">￥name = optional_param(&apos;name&apos;,&quot;,PARSM_TEXT);</span><br></pre></td></tr></table></figure></p><p>每一个网络应用程序都会做的事情就是，在不产生sql注入和跨站脚本攻击的前提下，把数据从请求中获取出来（通过GET或者POST变量），Moodle提供了两种方法来完成这件事。<br>上面那行代码就是一个简单的方法。它通过一个参数名（name），一个缺省值，以及一个期望类型来获取一个单独的值。期望类型是用来清理掉所有带有非法字符的输入。我们定义了许多类型，诸如PARAM_INT，PARAM_ALPHANUM，PARAM_EMAIL等等。<br>这里你也可以用类似 requires_param 这样的函数。这些require…函数如果发现期望的参数没有找到时会停止执行并显示一个错误信息。</p><p>另一个Moodle从请求中获得数据的机制是来自一个非常成熟的库。它给PEAR的HTML QuickForm库套了一个包。（对于非PHP程序员来说，PEAR在PHP中相当于CPAN）。所以者貌似看起来是一个不错的选择，但是已经没有人在维护它了。或许在将来，我们会使用一种新的库，就如很多人希望的一样，因为QuickForm的很多使人诟病的设计。但是，目前来说，QuickForm就已经足够了。表单可以被定义为一个字段的集合（例如 text box, select drop-down, date-selector） 每个字段可能有不同用于前端或后端验证的字段（包括 PARAM_…类型）</p><p>Line 6： 全局变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(!$name)&#123;</span><br><span class="line">$name = fullname($USER);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个函数显示了Moodle所提供的第一个全局变量。￥USER保存了关于执行当前脚本的用户信息。而其他全局变量包括：</p><ul><li><p>￥CFG： 保存常用的用户设置</p></li><li><p>￥DB： 跟数据库的连接</p></li><li><p>￥SESSION： 封装了PHP的session</p></li><li><p>￥COURSE： 当前请求所对应的课程。</p></li></ul><p>当然不止这些，有一些其他的我们会在下面提到。</p><p>你可能会对全局变量感到慌张。然而，请注意，PHP每次只处理一个请求。所以，这些变量并没有想象中的全局。事实上，PHP的全局变量可以被看做是线程安全的注册表模式，这就是Moodle怎么去使用它们的。 让最常用的对象始终可见是非常方便的，因为你不需要把它们作为参数传入到每一个函数和方法中去。这个方法很少被滥用。</p><p>事情没想象的简单<br>这行代码同时也揭示了一点：任何事情都不是那么简单。显示一个用户名远比轻易地把￥USER-&gt;firstname，~，￥USER-&gt;lastname拼接起来复杂的多。学校或许有规定只允许显示名字的其中一部分，况且许多不同的文化对于名字显示的顺序也有不同的习惯。所以，根据这些规则，才会有针对它的不同配置和一个用来组装全名的函数。<br>当然在时间上也会有同样的问题，不同的用户可能会处在不同的时区上。Moodle把所有的时间都储存为Unix时间戳，这种时间戳是一个整数，所以所有的数据库都支持。然后再调用userdate这个函数在特定的时区还有设置下，显示出时间。</p><p>Line 7：日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add_to_log(SITEID, &apos;local_greet&apos;, &apos;begreeted&apos;,</span><br><span class="line"></span><br><span class="line">        &apos;local/greet/index.php?name=&apos; . urlencode($name));    * 7</span><br></pre></td></tr></table></figure><p>Moodle中所有重要的操作都会被记录在日志中，而这个日志会被写到数据库的一个表中，这是一种折中的方式，这让复杂的分析变得容易，并且Moodle 在可以提供比较详细的报告。但是对于一个大规模、高访问量的网站来说这却是一个性能的问题。记录日志的表格可能会变得非常巨大，这使得数据库的备份会变的非常困难，且对于日志的查询也会变得非常慢。在日志的表中还存在着写入竞争。这些问题可以通过不同的方式得以缓解。比如批量写，存档或者删除旧的记录，把他们从主数据库中移除。</p><p><strong>13.4 页面生成</strong><br>页面生成主要是通过两个全局对象来处理</p><p>Line 8 ：$PAGE 全局变量</p><p>$PAGE 保存着要被输出的页面信息。这个信息在所有产生HTML的代码中都可以轻易获得。在这个脚本中，必须明确的指明当前的上下文是什么。（在某些情况，require_login函数可能会自动的帮你设置好）这个页面的URL也必须被明确。这或许看起来没什么必要，但或许你可能会使用不同的URL 来获取同一页面。如果你喜欢的话，你可以把传递给set_url的URL规范成一个永久链接。页面的标题也要被被设置。这样HTML的head元素就被构建出来了。</p><p>Line 9 ： MOODLE URL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$PAGE-&gt;set_url(new moodle_url(&apos;/local/greet/index.php&apos;),</span><br><span class="line"></span><br><span class="line">        array(&apos;name&apos; =&gt; $name));                              * 9</span><br></pre></td></tr></table></figure><p>顺便说一句，上面用过的add_to_log 并没有使用这个辅助类。确实，日志API 不能够接受moodle_url 对象。这种不一致性是一个像Moodle 一样老的code-base的典型特征。</p><p>Line 10 : 国际化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$PAGE-&gt;set_title(get_string(&apos;welcome&apos;, &apos;local_greet&apos;));        10</span><br></pre></td></tr></table></figure><p>Moodle 使用自己的系统使它来支持多语言。或许现在有许多的PHP国际化库，但是在2002年我刚实现这个任务的时候，并没有任何库可以实现该任务。这个系统是围绕着get_string 函数构成的。字符串被一个键和插件的Frankenstyle名字唯一确定。就像你在第十二行看到的，完全可以把值插入到字符串中。（多值在PHP中通过数组和对象来处理）。</p><p>字符串会在一个语言文件中被查找，这些语言文件其实就是一个PHP数组。这是我们插件的语言文件local/greet/lang/en/local_greet.php：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line"></span><br><span class="line">$string[&apos;greet:begreeted&apos;] = &apos;Be greeted by the hello world example&apos;;</span><br><span class="line"></span><br><span class="line">$string[&apos;welcome&apos;] = &apos;Welcome&apos;;</span><br><span class="line"></span><br><span class="line">$string[&apos;greet&apos;] = &apos;Hello, &#123;$a&#125;!&apos;;</span><br><span class="line"></span><br><span class="line">$string[&apos;pluginname&apos;] = &apos;Hello world example&apos;;</span><br></pre></td></tr></table></figure></p><p>注意到，除了两个我们脚本中用到的字符串，这里还给某个能力了一个名字，还有这个插件显示在用户界面上的名字。<br>不同语言由两个字母的国家码唯一确定（这里是en）。语言包或衍生于其他语言包。比如说fr_ca（加拿大法语）语言包声明了fr（法语）作为它的母语，所以它只需要定义不同于法语的部分。因为Moodle诞生于澳大利亚，而en以为着是英式英语，所以导致en_us（美式英语）从他衍生过来。</p><p>同样，这个看似简单的get_stringAPI 把巨大的复杂性从插件开发者面前隐藏起来，包括计算出当前的语言（这可能由用户的偏好，或者特定课程的设置来决定）以及搜索语言包以及所有母语言包来找到这个字符串。</p><p>语言包制作以及协同翻译在【<a href="http://lang.moodle.org" target="_blank" rel="noopener">http://lang.moodle.org</a> 】上管理，Moodle用它们只做了一个可定制插件（Local_amos）。它使用Git和数据库作为存储语言文件的后端。并保留了所有历史版本。</p><p>Line 11： 开始输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $OUTPUT-&gt;header();                                       /11</span><br></pre></td></tr></table></figure><p>这又是一个看似平淡无奇的一行，然而它所做的工作可比看起来的多得多。这里最关键的一点在于，在任何的输出之前，页面所采用的主题（皮肤）必须被计算出来。这取决于页面上下文以及用户偏好的组合。然而， $PAGE-&gt;context 只在第8行被设置，所以$OUTPUT 全局变量不能再脚本一开始就初始化。为了解决这个问题，我们使用了一些PHP的小技巧，根据 $PAGE的信息，在第一次调用输出方法的时候才构造合适的 $OUTPUT。<br>另一件需要考虑的事情是，Moodle中的每一个界面都有可能包含块（blocks）。这些块是一部分可以额外配置的内容，通常被显示在主要内容的左侧或右侧。（它们也是插件的一种）同时，具体块在哪里被显示出来是通过一种弹性的方式（管理员可控制的），由页面的上下文和其他页面的标识来决定的。所以，输出的另一个准备工作就是调用 $PAGE-&gt;blocks-&gt;load_block()。<br>当所有必要的信息都被准备好了以后，主题插件（控制页面的整体外观）被调用以产生页面的整体布局，包括任何标准需要的头部和页脚。这个调用同时也在负责在HTML中对应的位置填入块中的内容。在布局的中间，或有一个div，这个页面特定的内容会显示在这里。当HTML的布局产生之后，在主要内容的div上一切两半。在第一半完成后，其他的部分被存储起来，由$OUTPUT-&gt;footer()返回。</p><p>Line 12： 输出页面Body<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $OUTPUT-&gt;box(get_string(&apos;greet&apos;, &apos;local_greet&apos;,</span><br><span class="line">        format_string($name)));                               / 12</span><br></pre></td></tr></table></figure></p><p>这一行输出了整个页面的主体。这里仅仅把我们的问候显示在了这一行输出了整个页面的主体。这里仅仅把我们的问候显示在一个盒子里。这一句问候，同样，是一个本地化过的字符串，因为这时我们已经用了一个值替换掉了占位符。内核渲染器$OUTPUT 提供了许多像box 这样方便的方法，以高级术语来描述我们所需要的输出。不同的主题可以控制什么样的HTML 元素真正地被用来构建这个盒子。<br>首先输出的内容是通过format_string 函数处理过的用户的信息（$name ）。这是XSS<br>（Cross-Site Scripting，跨站脚本攻击）保护的另一部分。另外这也使文本过滤器产生作<br>用。使用过滤器的一个例子就是LaTex 过滤器，它把像$$x + 1$$这样的输入转换成一个公<br>式的图片。我会简单的提到，但是不会进行详细的解释，实际上，这里有三个不同的函数（s，<br>format_string 和format_text）进行字符串处理。具体使用哪个取决于输出内容的具体类型。</p><p>Line 13: 结束输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $OUTPUT-&gt;footer();                                       / 13</span><br></pre></td></tr></table></figure><p>最后，页脚被输出。这个例子并没有显示出来，但是Moodle 会记录所有这个页面需要的JS 文件，然后把它们都添加到页脚上。这是一个经典的好实现。这样用户就可以先看到页面， 而不必等待所有的JS 加载完成。一个开发者可以像$PAGE-&gt;requires-&gt;js(‘/local/greet/cooleffect.js’)这样用API 添加JS 。</p><p>这个脚本应该混杂逻辑和显示吗？<br>很显然，吧进行输出的代码直接写在index.php里，及时这是一个高级的抽象，也会限制主体对于输出更改的灵活性。这是另一个Moodle老旧code-base 的现象。全局变量$OUTPUT 在2010年的时候才被引入。当时是把它设计成拯救旧代码的垫脚石。在这之前，所有处理输出和控制器的代码都写在了同一个文件中。而它成功的分离了这两类代码。这也解释了那个十分丑陋的渲染方法—— 先把整个页面布局产生出来，再劈成两半，才使得脚本任何自己的输出能够正确地显示在页首和页脚之间。自从把视图代码从脚本中分离出来，放到一个Moodle 叫做渲染器的东西中后，主题就可以<br>完全（或者部分）重写一个给定脚本的视图了。<br>一个很小的重构就可以把所有在index.php 中处理输出的代码抽出，转移到一个渲染器里面。<br>那么在index.php 的最后（11到13行）就变为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$output = $PAGE-&gt;get_renderer(&apos;local_greet&apos;);</span><br><span class="line">echo $output-&gt;greeting_page($name);</span><br></pre></td></tr></table></figure><p>然后，我们就有了一个新文件local/greet/renderer.php:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">class local_greet_renderer extends plugin_renderer_base &#123;</span><br><span class="line">    public function greeting_page($name) &#123;</span><br><span class="line">        $output = &apos;&apos;;</span><br><span class="line">        $output .= $this-&gt;header();</span><br><span class="line">        $output .= $this-&gt;box(get_string(&apos;greet&apos;, &apos;local_greet&apos;, $name));</span><br><span class="line">        $output .= $this-&gt;footer();</span><br><span class="line">        return $output;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果一个主题想完全改变这个输出，它可以定义一个这个渲染器的子类，并且覆盖掉greeting_page 这个方法。$PAGE-&gt;get_renderer()根据当前的主题来选择合适的渲染器类进行初始化。所以输出（视图）代码完全地被从index.php 的控制器代码中分离出来，这个插件也从典型的Moodle 遗留代码被重构成干净的MVC 结构。</p><p>13.5 数据库的抽象</p><p>我们所用做示范的”Hello World”脚本太简单了以至于它根本不需要进行数据库的访问。然而有一些Moodle的库确实有调用数据库的需求。现在，我将简单的介绍一下Moodle的数据库层。</p><p>在过去，Moodle的数据库抽象层基于ADOdb库，但这给我们带来了种种麻烦。并且这个库的代码中多出来了额外的一层，对我们的性能产生了严重的影响。所以，在Moodle2.0中，我们将之转换到我们自己的数据抽象层，它只不过把PHP的数据库封装起来罢了。</p><p>moodle_database类</p><p>整个库的核心是moodle_database类。它定义了$DB 全局变量提供的用于连接数据库的接口。一个典型的用法是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$course = $DB-&gt;get_record(&apos;course&apos;, array(&apos;id&apos; =&gt; $courseid));</span><br></pre></td></tr></table></figure></p><p>它翻译成SQL语句就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM mdl_course WHERE id = $courseid;</span><br></pre></td></tr></table></figure></p><p>这将返回一个公开属性的PHP对象，所以你可以简单地像$course-&gt;id, $course-&gt;fullname等等来获取相应的属性。<br>这样简单的方法可以处理最基本的查询、更改和插入。有些时候，做一些更加复杂的SQL查询是很必要的，比如生成报告。在这样的情况下，有许多方法来执行任意的SQL 语句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$courseswithactivitycounts = $DB-&gt;get_records_sql(</span><br><span class="line">   &apos;SELECT c.id, &apos; . $DB-&gt;sql_concat(&apos;shortname&apos;, &quot;&apos; &apos;&quot;, &apos;fullname&apos;) . &apos; AS coursename,</span><br><span class="line">        COUNT(1) AS activitycount</span><br><span class="line">   FROM &#123;course&#125; c</span><br><span class="line">   JOIN &#123;course_modules&#125; cm ON cm.course = c.id</span><br><span class="line">   WHERE c.category = :categoryid</span><br><span class="line">   GROUP BY c.id, c.shortname, c.fullname ORDER BY c.shortname, c.fullname&apos;,</span><br><span class="line">   array(&apos;categoryid&apos; =&gt; $category));</span><br></pre></td></tr></table></figure></p><p>这里有几点需要注意：</p><ul><li>表名需要被{}包起来，这样库函数才能找到它们，并且加上前缀。</li><li>库函数使用占位符来将值填入SQL 语句中。在某些场合，我们使用了底层数据库驱动的功能。在其他情况下，这些值必须通过转译，然后利用字符串操作将其插入到SQL语句中。库函数支持两种填充方法，一种使用命名占位符（就像上面那样），还有一种使用?作为占位符的匿名方式。</li><li>为了让查询在我们所有支持的数据库中都得以实现，只有标准SQL 中的一个安全子集被筛选出来以供使用。比如，你能看到我使用了关键字AS 来对列名作别名处理，但是从来没有对表名的别名。这两个用法规则都十分的重要。</li><li>即使是这样，仍然有一些情况，没有任何一个标准SQL 的子集可以在所有我们需要支持的数据库上都能运作。比如说，每一种数据库都用完全不同的方式来处理字符串拼接。在这些时候，我们提供一些兼容功能来产生正确的SQL 语句。</li></ul><p>定义数据库结构</p><p>另一个数据库系统之间差异很大的地方就是，创建表的SQL 语法。为了克服这个问题，每一个Moodle 插件（包括Moodle 内核）都在一个XML 文件中定义了需要的数据库表。Moodle 安装系统会解析install.xml 文件，并且利用它们包含的信息来创建所需的表和索引。有一个Moodle 内建的叫做XMLDB 的工具，它可以用来帮助开发者创建和编辑这些安装文件。<br>如果在两个不同的Moodle 发布版（或者是一个插件）中数据库结构需要更改，那么开发者就需要负责编写代码（使用一个额外提供DDL 方法的数据库对象）来更新这些数据库结构，同时必须保持所有的用户数据。所以，Moodle 总是在版本升级的时候总是进行自我更新，简化了管理员的维护成本。<br>另一个有争议的地方是，鉴于Moodle 最开始使用的是MySQL 3这个版本的事实，Moodle数据库没有使用外键。这就有可能使得许多容易产生BUG 的行为很难被检测到，但是现代数据库却很容易检测到它们。困难在于，我们的用户不用外键使用Moodle 站点已经很多年了，所以现在几乎肯定有数据不一致性存在。如果现在要添加这些键，不进行一次非常困难的清理工作是不可能的。尽管如此，自从XMLDB 系统加入到Moodle 1.7（在2006年！）以来，这些install.xml 文件已经规定了外键可以存在的定义。我们始终希望，总有一天，通过必要的工作，可以允许我们在安装过程中创建这些键。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Moodle&lt;/strong&gt;作者：Tim Hunt&lt;br&gt;译者：朱凯文&lt;/p&gt;
&lt;p&gt;Moodle是一个用于教育系统设计的web应用程序。&lt;br&gt;这一篇翻译将详细的讲解Moodle是怎么运作的，尤其是从以下这几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;用插
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Nginx</title>
    <link href="http://blog.ccao.cc/2018/09/28/Nginx/"/>
    <id>http://blog.ccao.cc/2018/09/28/Nginx/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.671Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NginX"><a href="#NginX" class="headerlink" title="NginX"></a>NginX</h1><p>nginx（读作”engine x”）是俄罗斯软件工程师Igor Sysoev开发的免费开源web服务器软件。nginx在2004年发布后，就一直专注于高性能，高并发和低内存消耗问题。在基本的web服务器功能的基础上，nginx还具有一些额外的特性，比如负载均衡，缓存，访问控制，带宽控制，以及高效整合各种应用的能力，这些特性使nginx成为构架现代网站架构一个不错的选择。目前，nginx是互联网上第二流行的开源web服务器软件。</p><h2 id="14-1-为什么高并发重要"><a href="#14-1-为什么高并发重要" class="headerlink" title="14.1.为什么高并发重要"></a>14.1.为什么高并发重要</h2><p>现在互联网是如此的广泛和普及以至于我们很难想象十年前没有网络的时候是什么样子的，它已经从用NCSA后来用Apache的web服务器提供的可点击的文本HTML已然进化成超过20亿人在线的通信媒介。随着永久在线的个人电脑，移动终端以及平板电脑的增多，互联网在快速变化，经济系统也变得数字有线化。在线服务日益精化并且明显的偏向于提供实时可用信息和娱乐，而且运行在线服务的安全需求也有了显著变化。现在的网站比从前更为复杂，需要在工程上做的更具有健壮性和可伸缩性。</p><p>并发总是网站架构最大的挑战之一。由于web服务的兴起，并发的数量级在不断增长。热门网站为几十万甚至几百万的同时在线用户提供服务也不稀罕。十年前，并发的主要原因是由于客户端接入速度慢–用户使用ADSL或者拨号商务。现在，并发是由移动终端和新应用架构所的合并所带来的，这些应用通常基于持久连接来为客户端提供新闻，微博，通知等服务。另一个重要的因素就是现代浏览器行为变了，它们浏览网站的时候会同时打开4到6个连接来加快页面加载速度。</p><p>为了说明客户端接入速度慢的问题，我们可以想象一个Apache网站要产生小于100KB的响应–包含文本或图片的网页。产生或者恢复这个页面可能仅仅只需要1秒钟，但是如果带宽只有80kbps（10KB/s），需要花10秒才能把这个页面发送到客户端。基本上，web服务器相对快速的推送100KB数据，然后需要等待10秒发送数据之后才能关闭连接。那么现在如果有1000个同时连接的客户端请求相同的页面，那么如果为每个客户端分配1MB内存，就需要1000MB内存来为这1000个客户端提供这个页面。实际上，一个典型的基于Apache的web服务器通常为每个连接分配1MB内存，而移动通信的有效速度也通常是几十kbps。虽然借助于增加操作系统内核socket缓冲区大小，可以优化发送数据给慢客户端的场景，但是这并不是一个常规的解决方案，并且会带来无法预料的副作用。</p><p>随着持久连接的需要，处理并发行的问题更加明显，因为为了避免新建HTTP连接所带来的延时，客户端需要保持连接，那么web服务器就需要为每个连接上的客户端分配一定数量的内存。</p><p>所以，为了处理持续增长的用户所带来的负载和高水平的并发性要求（并且能够持续处理），网站需要建立在高效的构建上面。然而在与其所对应的另一面，例如硬件（CPU、内存、硬盘）、网络容量、应用和数据存储结构就变得尤为重要，毕竟客户端连接还是在web服务器软件上处理和接受的。因而，随着同时在线数和每秒请求数的增长，web服务器性能也应该能够非线性扩展。</p><h3 id="Apache就不适用吗？"><a href="#Apache就不适用吗？" class="headerlink" title="Apache就不适用吗？"></a>Apache就不适用吗？</h3><p>Apache，一个产生于二十世纪九十年代的web服务器，在现代的互联网市场上仍占据极大地份额。起初，它的架构符合当时的硬件和操作系统，当然也符合当时的互联网的状况，那时一个网站通常是运行着一个Apache实例的独立物理服务器。到了二十一世纪初，通过对独立的物理服务器模型进行复制来满足日益增长的web服务需求，显然是不能了。虽然Apache为未来的发展打下了坚实的基础，但是它已经被架构成对每一个新的连接请求就把自身复制一份，而这种架构并不适用于网站的非线性扩展。最终Apache成为了一个通用的web服务器，聚焦于多特性、多种第三方扩展、对任何种类的web应用开发的普遍适用性。然而，由于每次连接所消耗的CPU和内存不断增加，把大量的功能集中在单个软件上而不降价，这种做法已经不具有可扩展性了。</p><p>因此，当服务器硬件、操作系统和网络资源不再是网站增长的主要限制因素时，网站开发者们开始满世界的寻找高效搭建web服务器的方法。大概十年前，Daniel Kegel，一个卓越的软件工程师，宣布说：“是时候让web服务器同时处理10000个客户端了。”并且他还预言了现在称为云服务的技术。Kegel的C10K问题很明显激励着一大批人去尝试解决这个问题，他们试图通过优化web服务器软件来支持大规模客户端连接的并发处理，而结果nginx是其中最好的一个。</p><p>（注：C10K问题的详细介绍：<a href="http://www.kegel.com/c10k.html）" target="_blank" rel="noopener">http://www.kegel.com/c10k.html）</a></p><p>为了解决C10K问题，也就是10000个并发连接问题，nginx基于一个不同的架构，一个在处理并发连接和每秒请求的非线性扩展性上更合适的架构。nginx是事件驱动的，所以它没有按照Apache那样对每一个网页请求都创建一个新的进程或线程。最后的结果就是，即使负载增加了，cpu和内存的使用仍然保持可控。现在nginx可以在一个普通硬件构建的服务器上同时处理10000个并发请求</p><p>当第一版nginx发布的时候，它是为了部署在Apache旁边以便nginx处理像Html、CSS、JS和图片等静态的内容来为基于Apache应用搭建的服务器分担并发的和潜在的进程。后来随着nginx的演化，它通过支持FastCGI,uswgi和SCGI协议增加了应用程序的集成，以及对分布式内存对象缓存系统如memcached的支持。其他的很有用的功能比如带有缓存和负载均衡的反向代理也被加了进来。这些新加进来的功能把nginx塑造成了一个工具的整合包，这些工具可以高效的搭建一个可扩展的网络基础设施。</p><p>在2012年2月，Apache的2.4.x版本发布了。虽然最新发布的Apache版本增加了新的并发处理核心模块和新的代理模块来优化可扩展性和性能，但要说性能、并发能力和资源利用率是否能赶上或超过纯事件驱动模型的web服务器还为时尚早。Apache新版本具有了更好的性能值得高兴，因为对于nginx+Apache的web网站架构，新的Apache虽然不能解决全部问题，但是够缓解后端潜在的瓶颈。</p><h3 id="使用nginx还有更多优点吗？"><a href="#使用nginx还有更多优点吗？" class="headerlink" title="使用nginx还有更多优点吗？"></a>使用nginx还有更多优点吗？</h3><p>高效的处理高并发性一直是部署nginx的最关键的好处。但是除此以外部署nginx还有很多很有意思的优势。</p><p>最近几年，web架构一直在拥抱去耦的理念并且从web服务器中分离出它们的应用设施。虽然现在仅仅是将原先基于LAMP(Linux, Apache, MySQL, PHP, Python or Perl)所构建的网站，变为基于LEMP（E表示Engine x）的。但是，越来越多的实践是将web服务器推入基础设施的边缘，并且用不同的方法整合这些相同或更新的应用和数据库工具集。</p><p>nginx很适合做这样的事情，因为它提供了关键性的特性和功能，可以很方便地把并发性、延时处理、SSL、缓存和压缩、连接和请求限制甚至是HTTP媒体流从应用层剥离下来，转移到一个更加高效的边缘的服务器层上。同时nginx还允许直接集成memcached/Redis或者是NoSQL的其他解决方案，以在处理大量并发用户的时候提升性能。</p><p>随着现代开发包和程序设计语言的普及，越来越多的公司开始改变他们应用开发和部署的方式。nginx已经成为这些正在改变的范式当中最重要的组件之一，而且它已经帮助许多公司在预算内快速开发出他们的web应用。</p><p>nginx的开发始于2002年，在2004年基于2-clause BSD协议发布。自此以后，nginx的用户数量不断增加，他们贡献想法和创意，提交错误报告、建议和观察报告，为整个nginx社区提供了极大的帮助。</p><p>nginx的基本代码是完全由C语言从头编写的，现在它已经移植到了许多架构和操作系统中，包括Linux, FreeBSD, Solaris, Mac OS X, AIX和Microsoft Windows。Nginx有自己的函数库，并且除了zlib、PCRE和OpenSSL之外，标准模块只使用系统C库函数。而且如果不需要的话或者为了避免潜在的证书上的矛盾，我们还可以有选择的去掉一些模块。</p><p>下面是关于Windows版nginx的一些话。当在Windows环境下运行nginx，Windows版的nginx更像是一个概念验证的版本而不是全部功能移植的版本。这是因为在现阶段nginx与Windows的内核架构有限制所导致的。我们目前已知的Windows版本的nginx存在以下问题：并发连接数低、效率下降、没有缓存和宽带管理。未来Windows版本的nginx会更加贴近于主流版本。</p><h2 id="14-2-nginx架构总览"><a href="#14-2-nginx架构总览" class="headerlink" title="14.2.nginx架构总览"></a>14.2.nginx架构总览</h2><p>传统的基于进程/线程模型来解决并发连接的问题通过对每一个连接都创造一个单独的进程或线程来处理，从而陷入了网络或者是I/O操作的阻塞。根据应用的不同，就内存和CPU的消耗而言，这种方式是毫无效率的。产生一个单独的进程或线程需要准备一个新的运行时环境，包括分配栈区和堆区的内存和产生一个新的执行上下文。创建这些事情还需要额外的CPU时间，并且由于CPU在线程可执行上下文之间大连切换，最终导致效率低下。所有这些并发症在像Apache一样的旧web服务器架构上凸显出来。这是一个在提供丰富的通用应用功能和优化服务器资源使用之间的权衡。</p><p>从一开始的时候，nginx就意在成为一个专门的软件，在允许网站可以动态增长的同时，提高服务器性能和资源的密集高效的使用效率，所以它使用了不同的模型。这个模型的灵感来源于日益发展的在不同操作系统上的事件驱动的开发技术，并最终形成了一个模块化、事件驱动的、异步的、单线程的、非阻塞的架构，这就是nginx代码的基础。</p><p>nginx大量使用多路传输和事件通知机制，并且致力于为不同的进程分配不同的任务。连接请求是由有限的单线程进程组成的高效的回环处理的，这些进程被称作’’worker’’.每个’’worker’’每秒可以处理成千上万的并发请求和连接。</p><h3 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h3><p>nginx’’worker’’的代码包含核心和功能模块。nginx的核心负责维持一个紧致的事件处理循环并且在请求处理的每个阶段执行恰当的代码模块。模块组成了大部分的展示和应用层的功能。模块会从网络和存储设备上读取和写入信息、转换内容、做输出过滤、SSI（server-side include）处理或者在启用代理的时候给上游服务器发送请求。</p><p>nginx模块化的架构通常允许开发者在不修改nginx核心的情况下扩展web服务器功能。nginx的模块有以下这些略有不同的形态，叫做核心模块、事件模块、阶段处理器、协议、变量处理器、过滤器、上游和负载均衡器等。目前，nginx不支持动态的加载模块，例如（可以这样理解），模块代码和核心代码是一起编译的。然而，支持动态加载模块和ABI已经计划在将来的某个版本开发。关于不同模块角色的详细信息可以参见14.4节。</p><p>（注：在最近发布的nginx1.10.0中已经开始加入动态模块加载）</p><p>在处理各种各样的跟接受、处理、管理网络连接和内容检索的操作时，nginx使用事件通知机制和大量Linux、Solaris和BSD系统上的增强硬件IO性能的技术，比如’’kqueue’’、’’epoll’’还有’’event ports’’.目的在于尽可能的为操作系统提供提示，这些提示是为了及时地获得网络进出流量，磁盘操作，套接字读取和写入，超时等事件的异步反馈。nginx极大的优化了基于Unix的操作系统多路传输和高级IO操作的方法。</p><p>图14.1展示了nginx的高层架构</p><p><img src="http://www.aosabook.org/cdn/images/aosabook/nginx/architecture.png" alt=""></p><h3 id="‘’Worker’’模型"><a href="#‘’Worker’’模型" class="headerlink" title="‘’Worker’’模型"></a>‘’Worker’’模型</h3><p>之前提到过，nginx不会为每个连接产生一个进程或线程。反之，每个’’worker’’为处理成千上万个连接，会监听一个共享的套接字来接受请求并在内部执行一个高效的循环。在nginx的’’worker’’中不存在仲裁器和分发器，这项工作由操作系统内核完成。在启动之初，nginx会创建并初始化一系列的监听套接字，之后’’worker’’进程不断地通过这些套接字接受、读取HTTP请求和输出响应。</p><p>nginx’’worker’’中最复杂的部分就是事件处理循环。它包括了全面的内部调用，并且极其依赖异步任务处理思想。异步操作通过模块化、事件通知、大量回调函数以及微调定时器等实现。总的来说，关键原则就是尽可能的非阻塞。nginx’’worker’’进程被阻塞的唯一情况就是磁盘存储性能不足。</p><p>因为nginx没有为每个连接产生进程或线程，所以内存的使用在大多数情况下是节约且高效的。同时nginx也节省CPU时间，因为对于进程或线程来说并不存在持续不断的创建-销毁状态。nginx要做的就是检查网络和存储的状态、初始化新的连接、把它们加入事件循环、在完成之前做异步处理，到那时，连接请求已经解除分配并且从时间循环中移除了。兼具精心设计的系统调用和诸如内存池等支持接口的精确实现，nginx在极端负载的情况下通常能做到中低CPU使用率。</p><p>因为nginx派生多个’’worker’’进程来处理连接，所以在多核CPU中有很好的扩展性。通常来说，一个单独的’’worker’’占有一个CPU可以充分利用多核架构，而且可以避免线程抖动和锁。那么在一个’’worker’’进程中就不存在资源匮乏的问题，资源控制机制也是隔离的。这个模型也允许了物理存储设备之间的扩展，提高磁盘利用率并避免磁盘IO上的阻塞。其结果就是，通过将工作负载分配到多个worker进程上，服务器资源可以得到高效的利用。</p><p>在某些磁盘使用和CPU负载模式下，nginx’’worker’’进程的数量需要做适当的调整。这里都是些基本规则，系统管理员应该根据工作负载多尝试几种配置。</p><p>下面是一些通常的推荐规则：</p><ul><li><p>如果负载模式是CPU密集型，例如处理大量TCP/IP协议，使用SSL，或者压缩数据等，nginx worker进程应该和CPU核心数相匹配</p></li><li><p>如果是磁盘密集型，例如从存储中提供多种内容服务，或者是大量的代理服务，worker的进程数应该是1.5到2倍的CPU核心数</p></li></ul><p>一些工程师根据独立存储单元的数量来选择’’worker’’进程的数量，虽然这种方式的效率依赖于磁盘存储的类型和配置。</p><p>nginx的开发者在未来版本中要解决的主要问题就是怎么样避免磁盘IO上的阻塞。在目前的版本中，如果没有足够的存储性能为一个’’worker’’进程的磁盘操作提供服务，那么’’worker’’进程依然会阻塞在磁盘读写上。现在有很多的机制和配置文件命令可以缓解这样的磁盘IO阻塞的情形。最显著的像sendfile和AIO的结合使用通常可以减少很多磁盘性能的消耗。所以nginx的安装应该基于数据集、可用内存数和底层存储架构来规划。</p><p>现有的’’worker’’模型存在的另一个问题是对嵌入式脚本支持有限。举个例子，在现在nginx的布局中，只支持perl语言作为嵌入脚本。原因解释起来很简单：一个嵌入脚本可能在任何的操作中阻塞或者异常退出。这两种行为都会立即导致’’worker’’进程被挂起，同时影响到成千上万的链接。更多的使nginx嵌入脚本更简单、更可靠、更适用于广泛应用的工作已经在计划中。</p><h3 id="nginx进程角色"><a href="#nginx进程角色" class="headerlink" title="nginx进程角色"></a>nginx进程角色</h3><p>nginx在内存中运行着许多进程，其中包括一个单一的主进程和许多’’worker’’进程。同时还有一些特殊用途的进程，例如缓存加载和缓存管理进程。在nginx的1.x版本中，所有的进程都是单线程的，所有的进程主要都通过内存共享的机制进行进程间通信，主进程运行在root权限下，缓存加载器、缓存管理器以及其他进程运行在非特权用户下。</p><p>主进程负责下列任务：</p><pre><code>* 读取和校验配置文件* 创建、绑定、关闭套接字* 启动、终止和维护配置数目的&apos;&apos;worker&apos;&apos;进程* 在不中断服务的情况在重新配置* 控制不停止的程序升级（启动新的程序并在必要时回滚）* 重新打开日志文件* 编译嵌入的Perl脚本</code></pre><p>‘’worker’’进程接收、处理和加工来自客户端的连接，提供反向代理和过滤功能并且做其他nginx所能做的所有事情。对于监控nginx实例的行为，系统管理员应该保持关注worker进程，因为它们才是每天web服务器操作的实际执行着。</p><p>缓存加载程序负责检查磁盘缓存项并使得缓存元数据存在于nginx的内存数据库中。本质上，缓存加载进程使用特定分配的目录结构来管理已经存储在磁盘上的文件，为nginx实例做准备，它会遍历目录，检查缓存内容元数据，更新共享内存的相关条目然后在一切工作都准备好之后退出。</p><p>缓存管理进程主要负责缓存的过期和失效。在进行nginx的正常操作时它常驻内存，遇到异常时由主进程负责重启。</p><h3 id="nginx缓存简介"><a href="#nginx缓存简介" class="headerlink" title="nginx缓存简介"></a>nginx缓存简介</h3><p>nginx的缓存在文件系统中是以分层数据存储形式实现的。缓存键都是可以配置的，而且不同的特殊请求的参数可以用来控制缓存中的内容。缓存键和缓存元数据存储在缓存加载器、缓存管理器和’’worker’’进程都有权限访问的共享内存段中。目前在缓存中还不可以存储文件，除了用操作系统的虚拟文件系统机制进行优化。每个缓存响应存储在文件系统的不同文件中，其分层方式（分层级别和命名细节）可以通过nginx配置命令来控制。当一个响应要写入缓存目录结构中时，那个文件的文件名和路径名可以从代理URL的MD5中分离获得。</p><p>下面是把内容放入缓存的处理过程：当nginx从上游服务器读取到一个响应时，内容会先被写到一个缓存目录结构之外的临时文件中；当nginx完成处理请求的过程后，会把临时文件重命名并转移到缓存目录下。如果用于代理的临时文件位于另一个文件系统上，那么这个临时文件会被复制一份，所以我们建议临时文件目录和缓存目录在同一个文件系统中。当我们要清理缓存目录时，比较安全的做法是删除缓存目录下的文件。nginx有很多的第三方扩展来使它可以远程控制缓存内容，在主版本中集成这种功能的工作也在计划当中。</p><h2 id="14-3-NginX配置"><a href="#14-3-NginX配置" class="headerlink" title="14.3.NginX配置"></a>14.3.NginX配置</h2><p>nginx配置系统的灵感来源于Igor Sysoev使用Apache的经验。他的主要观点是：一个可扩展的配置系统对一个web服务器来说至关重要。当我们要维护大量复杂的虚拟服务器、目录、位置和数据集的配置文件时，我们就会遇到一些主要的扩展性问题。在一个规模相当大的网站的建立过程中，如果没有在应用层进行恰当的配置，那么配置就是工程师们的噩梦。</p><p>结果是，nginx的配置系统就是为简化每日操作所设计，并且为web服务器将来的扩展提供了简单的方法。</p><p>nginx的配置信息一般保存在位于’’/usr/local/etc/nginx’’或者是’’/etc/nginx’’的文本文件中。主配置文件通常叫做’’nginx.conf’’。为了使配置保持整洁，部分配置可以放到一些分开的文件当中，这些文件可以自动的包括在主配置文件中。然而值得注意的是，目前nginx并不支持Apache风格的分布式配置（例如：’’.htaccess’’文件）。所有的有关nginx的web服务器配置都应该位于一个集中的配置文件集中。</p><p>配置文件最初是由主进程读取和校验。’’worker’’进程可以使用一份编译好的只读的配置文件，因为它们都是由主进程产生的。配置信息结构会通过常见的虚拟内存管理机制自动共享。</p><p>nginx的配置有很多的上下文，有：’’main’’、’’http’’、’’server’’、’’upstream’’、’’location’’（还有’’mail’’用于邮件代理）这些命令模块。这些上下文从不重叠，比如，从来没有把’’location’’块放到主模块的命令中的。除此以外，为了避免不必要的歧义nginx也没有像“全局服务器配置”这样的东西。nginx的配置是整洁并富有逻辑性的，允许用户去维护一个包含成千上万条指令的复杂的配置文件。在一次私人访谈中，Sysoev说：“我从来都不喜欢Apache全局服务器配置中位置、目录还有其他模块这样的特性，这也就是nginx从未实现过它们的原因。”</p><p>配置语法、格式和定义遵循一个所谓的C风格协定。这种特别的配置文件的方法已经用于各种开源和商业软件。根据设计，C风格的配置非常符合嵌套描述，又因为富有逻辑性并易于编写、阅读和维护受广大工程师喜爱。此外，C风格的nginx配置还易于自动化。</p><p>尽管nginx中的一些指令与Apache配置中的一些指令很相似，但是搭建一个nginx实例是一个相当不同的体验。例如，虽然nginx支持重写规则，但是它需要一个管理员手动的调整遗留的Apache重写配置以使其符合nginx重写风格。当然重写引擎的实现也不一样。</p><p>通常来说，nginx提供了对一些原始机制的支持，这对一个精简服务器的配置来说非常有用。在这里我们简短的谈一谈变量和’’try_files’’指令，这非常有意义，因为它们差不多是nginx独有的。Nginx开发了变量用于提供附加的更强大的机制来控制运行时的web服务器配置。变量为快速求值做了优化并且在内部就被预编译为索引。求值是要立即计算的，例如，变量的值通常在一个请求的生命周期中只计算一次。变量可以用在不同的配置指令中，为描述条件请求的处理行为提供了额外的灵活性。</p><p>‘’try_files’’起初是想以一个更恰当的方式逐渐替代表示条件的’’if’’配置语句，并且它被设计有快速且高效的try/match来应对URI与内容之间的映射。总的来说，’’try_files’’指令非常有效并且极其高效和有用。所以我们非常推荐读者完整地阅读 <a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files" target="_blank" rel="noopener">http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files</a> |try_files指令 ，并且任何能用的时候使用它。</p><h2 id="14-4-nginx内部构件"><a href="#14-4-nginx内部构件" class="headerlink" title="14.4.nginx内部构件"></a>14.4.nginx内部构件</h2><p>正如之前所提到的，nginx的基本代码由一个核心和大量模块组成。nginx的核心负责提供web服务器、web和反向代理邮件功能的基础；实现底层网络协议，构建必要的运行时环境，并且保证不同模块之间的无缝衔接。然而，大量协议上的、应用上的特性都是模块实现的，而跟核心没关系。</p><p>从内部讲，nginx通过模块流水线或模块链来处理连接。换句话说，每一个操作都有对应的模块来做相关工作，例如：压缩，修改内容，执行SSI，通过FastCGI或uwsgi协议同后端应用服务器通信，以及同memcached通信等。</p><p>有一些模块处于核心与实际“功能”模块之间，它们是’’http’’和’’mail’’.这两个模块在核心和底层构件之间提供了一个额外的抽象层。在这些模块中实现了HTTP、SMTP、IMAP等各自应用层事件序列的处理。这些上层模块和nginx核心搭配起来一起负责以正确的次序调用各自的功能模块。尽管目前HTTP协议是作为’’http’’模块的一部分实现的，我们仍然有计划在将来根据支持像SPDY这样的其他协议的需求把它分离成一个功能模块（参见 <a href="http://www.chromium.org/spdy/spdy-whitepaper" target="_blank" rel="noopener">http://www.chromium.org/spdy/spdy-whitepaper</a> |SPDY: An experimental protocol for a faster web ）。</p><p>功能模块可以分为事件模块、阶段处理器、输出过滤器、变量过滤器、协议、上游和负载均衡器。大部分的这些模块补足了nginxHTTP的功能，虽然事件模块和协议也用在’’mail’’模块中。事件模块提供了一种特别的与操作系统相关的事件通知机制像’’kqueue’’和’’epoll’’.nginx所使用的事件模块依赖于操作系统的能力和构建配置。协议模块允许nginx通过HTTPS,TLS/SSL,SMTP,POP3和IMAP协议进行通信。</p><p>一个典型的HTTP请求处理周期如下：</p><ul><li>客户端发送HTTP请求。</li><li>nginx核心找出与请求匹配的配置好的位置，并根据这个位置选择合适的阶段处理器。</li><li>如果配置中要求了，负载均衡器就会挑选一个上游服务器做反向代理。</li><li>阶段处理器开始工作并把每一个输出缓冲区送向第一个过滤器。</li><li>第一个过滤器把输出传递给第二个过滤器。</li><li>第二个过滤器把输出传递给第三个过滤器（以此类推）。</li><li>最终响应会发送至客户端。</li></ul><p>nginx模块的调用是极其可制定化的。它通过使用指针指向可执行的函数来完成一系列的回调行为。然而，这样的副作用是它给想开发自己模块的程序员带来了很大的负担，因为他们必须精确定义出它们的模块什么时候以及怎么运行。我们正在改进nginx的API和开发者文档以减轻这部分的负担。</p><p>关于在哪里可以添加模块，可以参考如下例子：</p><ul><li>配置文件读取和处理之前</li><li>每个location和server的指令出现的时候</li><li>主配置初始化的时候</li><li>服务器（例如主机/端口）初始化的时候</li><li>服务器配置与主配置合并的时候</li><li>位置配置初始化或与它的上级服务器配置合并的时候</li><li>主进程启动或退出的时候</li><li>一个新的worker进程启动或退出的时候</li><li>处理一个请求的时候</li><li>过滤响应头和响应体的时候</li><li>挑选、初始化和重新初始化上游服务器的时候</li><li>处理一个来自上游服务器的响应的时候</li><li>与一个上游服务器完成一次交互的时候</li></ul><p>在一个’’worker’’内部，一个事件处理回环由一串行为序列产生，从而生成响应，过程如下：</p><ul><li>开始’’ngx_worker_process_cycle()’’</li><li>通过具体操作系统的机制来处理事件（比如’’kqueue’’或’’epoll’’）</li><li>接收事件并派发相应的行为</li><li>处理/代理请求头和请求体（译者注：原文“proxy”含义不明并且包含语法错误）</li><li>生成响应内容（响应头、响应体）并以流的形式发送给客户端</li><li>完成请求处理</li><li>重新初始化定时器和事件</li></ul><p>事件处理回环本身（步骤5和6）保证了响应的增量生成并且以流的形式发送给客户端</p><p>下面是处理HTTP请求的更多细节：</p><ul><li>初始化请求处理</li><li>处理头部</li><li>处理内容</li><li>调用相关的处理器</li><li>执行所有的处理阶段</li></ul><p>这些细节谈论到了处理阶段这个概念。当nginx处理一个HTTP请求时，它会让请求经过很多个处理阶段，在每个阶段都会有相应的处理器来调用。通常来说，阶段处理器处理一个请求并产生相应的输出。阶段处理器与配置文件中定义的位置绑定。</p><p>阶段处理器通常做四件事：获取位置配置，生成恰当的响应，发送响应头，发送响应体。一个处理器只有一个参数：描述请求的具体的结构。一个请求结构体包含着许多与客户端请求有关的信息，比如请求方式、URI、头部。</p><p>当HTTP请求的头部被读取的时候，nginx会查找相关的虚拟服务器配置。如果虚拟服务器被找到，那么请求将会经历六个阶段：</p><ul><li>服务器重写阶段</li><li>定位阶段</li><li>位置重写阶段（这个阶段可以把请求退回上一阶段）</li><li>访问控制阶段</li><li>try-files阶段</li><li>日志阶段</li></ul><p>为了在与请求对应的响应中写入必要的内容，nginx把请求传递给一个合适的内容处理器。依据准确的位置配置信息，nginx可能会先尝试所谓的无条件处理器，如：’’perl’’,’’proxy_pass’’,’’flv’’,’’mp4’’等。如果请求无法与上述的任何一个处理器匹配，那么它就会被下面的某一个处理器挑选并处理，这个挑选过程有明确的顺序：’’random index’’,’’index’’,’’autoindex’’,’’gzip_static’’,’’static’’.</p><p>我们可以在nginx的文档中找到index模块的细节信息，但是这些模块只能处理结尾是斜杠的请求。如果是一个像’’mp4’’和’’autoindex’’这样专门的模块都无法匹配上的请求，那么这个请求的内容就会被认为是磁盘上的一个文件或目录（也就是说是静态的），并由’’static’’内容处理器处理。对于一个目录，它总是会自动的把URI的结尾重写成一个斜杠（然后发起一个HTTP重定向）。</p><p>内容过滤器的内容之后会传递给过滤器。过滤器与位置也有联系，一个位置信息可以配置多个过滤器。过滤器加工处理器产生的输出，其执行顺序在编译时刻决定。对于nginx本来就有的可以直接使用的过滤器，其执行顺序早就确定了，对于第三方的过滤器，其执行顺序可以在编译阶段配置。在当前nginx的实现中，过滤器只能做输出数据的修改，目前还没有机制支持过滤器对输入内容进行修改。这个功能将会在nginx未来版本中实现。</p><p>过滤器遵循一个特定的设计模式。一个过滤器被调用，开始工作后会调用下一个过滤器，直到过滤器链的最后一个过滤器被调用为止。在这之后，nginx结束响应处理。过滤器不用等到前一个过滤器结束，一旦上一个过滤器的输入已经可用（功能上很像Unix的管道）链上的下一个过滤器就开始工作。因而，在从上游服务器接收到所有的响应之前，所生成的输出响应已经被发送给客户端。</p><p>过滤器分为header过滤器和body过滤器（译者注：在这里把header和body可以翻译为响应头和响应体，但是会影响句子流畅性），nginx会把响应的header和body分别发送给相关的过滤器。</p><p>header的过滤过程包含以下三个步骤：</p><ul><li>决定是否对这个相应进行操作</li><li>对这个相应进行操作</li><li>调用下一个过滤器</li></ul><p>body过滤器转换生成的内容，body过滤器的例子有：</p><ul><li>SSI</li><li>XSLT过滤器</li><li>图片过滤器（例如调整图片大小）</li><li>字符集修正</li><li>‘’gzip’’压缩</li><li>块编码</li></ul><p>在经过过滤器链之后，响应会被传递到writer，有一些额外的特殊目的的过滤器与writer有关，叫做’’copy’’过滤器和’’postpone’’过滤器。’’copy’’过滤器负责将相关的响应内容填充到内存缓冲区，这些响应内容有可能存储在反向代理的临时目录。’’postpone’’过滤器负责子请求处理。</p><p>子请求处理是请求/响应处理流程中的一个非常重要的机制，它也是nginx最强大的一个方面之一。通过子请求处理机制，nginx可以返回不同的URL的响应，这些URL不是原来客户端所请求的URL.一些网站框架把它叫做内部重定向。然而，nginx能做的更多，它不仅能让过滤器处理多个子请求并把多个子请求合并成一个响应输出，还能让子请求嵌套和分级。一个子请求可以产生自己的子-子请求，子-子请求还可以产生子-子-子请求。子请求可以映射到磁盘文件、其他的处理器或者是上游服务器。子请求是在原有的响应数据的基础上插入额外的数据的最有用的方法。例如，SSI模块使用一个过滤器来解析返回文档的内容，然后用指定URL的内容替换’’include’’指令。或者另一个例子，可以用它来做一个过滤器，这个过滤器可以把整个文档的内容作为一个过滤器来进行取回，然后在这个URL后面添加新的文档。</p><p>上游和负载均衡器也值得我们简短描述一下。上游是用来实现反向代理处理器（’’proxy_pass’’处理器）这样的内容处理器。上游模块大多数情况下是来准备把请求发送给上游服务器（或“后端”），然后从上游服务器接收响应。这个过程不用调用输出过滤器。准确的说上游模块做的是设置好上游服务器读写时所需要的回调函数。回调函数实现了如下功能：</p><ul><li>创建一个请求缓冲区（或缓冲链）并发送给上游服务器</li><li>重新初始化或重新设置与上游服务器的连接（刚好发生在重新发起请求之前）</li><li>处理上游响应的前几个bit并保存从上游服务器接收的负载的指针</li><li>放弃请求（当客户端过早关闭连接时）</li><li>在nginx结束从上游服务器读取信息时结束请求</li><li>修整响应体（例如去除尾部标号）</li></ul><p>负载均衡器模块可以附加在’’proxy_pass’’处理器上，在有多个合适的上游服务器时选择合适的上游服务器。负载均衡器注册了一个配置文件指令，提供了额外的上游服务器初始化功能（通过DNS解析上游服务器名字等）,初始化连接结构，决定请求的转发地址，并且更新状态信息。目前nginx支持两种标准的上游服务器负载均衡规则：轮询和ip哈希。</p><p>上游和负载均衡处理机制包括一些算法，这些算法主要是监测上游服务器的异常并把请求重新路由到可用的上游服务器上，虽然现在还有很多计划中的工作来加强这个功能。总的来说，有关负载均衡器的一些工作已经在计划中，在nginx的下几个版本中，上游服务器健康检查和将负载分发到不同的上游服务器的机制将会得到很大的提升。</p><p>在nginx中还有一些有意思的模块，它们在配置文件中提供了一些额外的变量来使用。尽管nginx的变量是在不同模块中创造和更新的，还是有两个nginx的模块是完全用于变量的：’’map’’和’’geo’’.’’geo’’模块是用来使根据IP地址跟踪客户端更加容易。这个模块可以根据客户端IP地址创建任意数量的变量。另一个模块，’’map’’，允许通过其它变量来创造变量，本质上是提供了灵活的将主机名向运行时的其他变量映射的能力。这类模块可以叫做变量处理器。</p><p>单个nginx’’worker’’进程中实现的内存分配机制，从某种意义上来说，也是受Apache启发。高层次的nginx内存管理的描述可以看一下内容：对于每一次连接，nginx会自动的分配、链接、使用必要的内存来储存和处理请求和响应的header和body，然后在连接释放时释放。这里有很重要的一点需要提醒，就是nginx会尽可能的避免在内存中复制数据，并且传递数据的方式是传递指针，而不是调用’’memcpy’’方法。</p><p>进一步说，当模块生成一个响应时，这个响应的内容会放入一个缓冲区，这个缓冲区会加入一条缓冲区链。这个缓冲区链同样适用于子请求处理。nginx中的缓冲区链是相当复杂的，因为根据处理模块类型的不同有非常多的处理场景。例如，在实现body过滤器模块时，要想实现精确的缓冲区管理是非常困难的。这种模块在一个缓冲区（缓冲区链上的）上只能进行一次操作，并且它必须决定是重写输入缓冲区，还是用新分配的缓冲区替换原来的缓冲区，还是在当前的缓冲区之前或之后插入一个缓冲区。更复杂的情况，有时一个模块会接收到多个缓冲区导致它现在必须要操作的缓冲区链是不完整的。然而在现阶段，nginx只提供了一个底层的API来处理缓冲区链的问题，所以在实际开发一个第三方模块之前，开发者们必须要掌握这晦涩难懂的一部分。</p><p>以上提到的内容有一点需要注意，就是内存缓冲区是为连接的整个生命周期分配的，所以对于长时间的连接就需要保留额外的内存。与此同时，对于一个空闲的keepalive（就是保持活跃状态的）连接，nginx只消耗550自己的内存。一个在未来nginx版本中可以优化的地方就是重用和共享长时间连接的内存缓冲区。</p><p>管理内存分配的任务是由nginx内存分配池完成的。共享内存区域主要是用来接受互斥量、缓存元数据、SSL会话缓存、以及和带宽策略管理（限速）相关的信息。nginx实现了一个slab分配器进行共享内存的分配。为了允许并发安全的使用共享内存，nginx还提供了一些锁机制（互斥量与信号量），同时为了管理复杂的数据结构，nginx还提供了红黑树的实现。红黑树用于在内存中保存缓存元数据，查找非正则的位置定义，以及其他一些任务。</p><p>不幸的是，上述的所有内容都没有写进一个一致的、简单的指南之中，使得nginx的第三方扩展开发变得异常困难。尽管有一些nginx内部的好文档，例如Evan Miller写的一些，但是这些文档还需要一些逆向工程的工作，所以对于很多人来说，nginx模块的实现还是跟变魔术一样。</p><p>尽管nginx第三方模块的开发有一定的困难，nginx社区最近还是涌现大量有用的第三方模块。比如，将Lua解释器嵌入nginx的模块，负载均衡的额外模块，完整的WebDAV的支持，高级缓存控制，还有在本章作者所鼓励的、将来所支持的工作。</p><h2 id="14-5-经验总结"><a href="#14-5-经验总结" class="headerlink" title="14.5.经验总结"></a>14.5.经验总结</h2><p>在Igor Sysoev开始写nginx的时候，大部分构建互联网的软件都已经存在，这些软件的架构通常都遵循着传统的服务器、网络硬件、操作系统和旧的互联网架构。但是这并没有阻止Igor考虑在web服务器领域做进一步的工作。所以我们第一条经验显而易见，那就是：所有的事物总会有它的提升空间。</p><p>带着使web软件更好的想法，Igor花了很长的时间开发原始的代码结构，并学习在各种操作系统上优化代码的不同方法。十年之后，他正在开发nginx2.0版本的原型，这是考虑到nginx的第一代已经经历了十年的活跃开发。显而易见，一个新架构的原型、原始代码结构对未来软件产品是多么的至关重要。</p><p>另一点值得提到的就是我们应该聚焦开发。nginx的Windows版本就是一个很好的例子，它告诉我们避免稀释一些开发工作的价值，这些开发工作既不属于开发者的核心竞争力又不是他们的目标应用。同样努力加强nginx重写引擎对现存遗留配置的后向兼容能力，也是值得的。</p><p>最后但是一样值得提及的，就是尽管nginx开发者的社区并不是非常大，nginx的第三方模块和扩展还是nginx广受欢迎的一个很重要的因素。nginx用户社区和它的开发者们都非常感激Evan Miller,Piotr Sikora,Valery Kholodkov,Zhang Yichun(agentzh)以及其他优秀软件工程师所做的工作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NginX&quot;&gt;&lt;a href=&quot;#NginX&quot; class=&quot;headerlink&quot; title=&quot;NginX&quot;&gt;&lt;/a&gt;NginX&lt;/h1&gt;&lt;p&gt;nginx（读作”engine x”）是俄罗斯软件工程师Igor Sysoev开发的免费开源web服务器软件。ngi
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Pypy</title>
    <link href="http://blog.ccao.cc/2018/09/28/Pypy/"/>
    <id>http://blog.ccao.cc/2018/09/28/Pypy/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.672Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PyPy"><a href="#PyPy" class="headerlink" title="PyPy"></a>PyPy</h1><p>PyPy 是一个 Python 的实现，同时也是一个动态语言实现框架。</p><p>本章假定读者熟悉如字节码和常量叠算等有关解释器和编译器的基本概念。</p><h2 id="19-1-一点历史"><a href="#19-1-一点历史" class="headerlink" title="19.1. 一点历史"></a>19.1. 一点历史</h2><p>Python 是一个高层次动态编程语言。它是由荷兰程序员 Guido van Rossum 在20世纪80年代末发明的。Guido 最初的实现是一个用 C 语言编写的传统的字节解释器，人称 CPython。现在有许多其他的 Python 实现。其中最引人注目的有用 Java 编写的并允许 Java 代码接口的 Jython，用 C# 编写并允许和微软 .NET 框架接口的IronPython，以及本章的主题 PyPy。 CPython 仍然是使用最广泛的实现，也是当前唯一支持下一代 Python 3 语言的实现((译者注：翻译时 PyPy 已经支持 Python 3 了))。本章将谈谈让 PyPy 与其他 Python 实现乃至其他任何动态语言实现都有所不同的一些设计决策。</p><h2 id="19-2-PyPy-概览"><a href="#19-2-PyPy-概览" class="headerlink" title="19.2. PyPy 概览"></a>19.2. PyPy 概览</h2><p>除了微不足道的少量 C 代码，PyPy 完全是用 Python 写成的。PyPy 代码树包含两个主要部分：Python 解释器和 RPython 翻译工具链。 Python 解释器是面向程序员的运行库，人们使用 PyPy 作为 Python 实现时会进行调用。它实际上是用 Python 的一个子集 Restricted Python（通常缩写为 RPython）写成的。用 RPython 编写 Python 解释器的目的是让解释器可以输出给 PyPy 的另一个重要组成部分——RPython 翻译工具链。 RPython 翻译器会把 RPython 代码转换为一个选定的低级语言，最常用的是 C。这使得PyPy成为一个自我托管的实现，也就是说它是用它自己实现的语言写成的。我们在本章后文中还会看到，RPython 翻译也让 PyPy 成为一个普适的动态语言实现框架。</p><p>PyPy 强大的抽象使之成为最灵活的 Python 实现。从不同的垃圾回收到各种翻译优化参数，它有近200个不同的配置选项。</p><h2 id="19-3-Python-解释器"><a href="#19-3-Python-解释器" class="headerlink" title="19.3. Python 解释器"></a>19.3. Python 解释器</h2><p>由于 RPython 是 Python 的真子集，PyPy Python 解释器可以不经翻译地在另一个 Python 实现上运行。当然，这会非常慢，但这样我们就可以快速测试解释器的变化。这也让我们可以使用普通的 Python 调试工具来调试解释器。 PyPy 解释器的大多数测试可以同时运行在无翻译和有翻译的解释器上。这让开发时的快速测试成为可能，并保证了有翻译和无翻译的解释器的行为一致。</p><p>在大多数情况下，PyPy Python 解释器的细节和 CPython 非常类似，PyPy 和 CPython 在解释时使用的字节码和数据结构几乎完全一样。两者之间的主要区别在于 PyPy 有一种很聪明的抽象，称为//对象空间//（简称objspaces）。objspace 封装了代表和操作 Python 数据类型的所有知识。例如，对两个 Python 对象执行二元操作或获取对象的一个属性，都完全由 objspace 处理。这让解释器无需知道 Python 对象的任何实现细节。字节码解释器把 Python 对象看成是黑盒子，并在需要操作它们时调用 objspace 方法。例如，下面是 ‘’BINARY_ADD’’ 机器码的一个粗糙的实现，在两个对象用 + 运算符结合的时候会调用它。请注意解释器如何不去检查运算符；所有处理都立即被委托给 objspace。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def BINARY_ADD(space, frame):</span><br><span class="line">    object1 = frame.pop() # pop left operand off stack</span><br><span class="line">    object2 = frame.pop() # pop right operand off stack</span><br><span class="line">    result = space.add(object1, object2) # perform operation</span><br><span class="line">    frame.push(result) # record result on stack</span><br></pre></td></tr></table></figure><p>objspace 的抽象有许多优势。新的数据类型实现可以在不修改解释器的情况下进行交换。并且因为 objspace 是对对象进行操作的唯一途径，objspace 可以拦截、代理或者记录对对象的操作。通过使用 objspace 强大的抽象，PyPy实验了形实转换程序和污染。通过形实转换程序，结果被懒惰地，但同时又完全透明地按照需求被计算出来了。污染则是指任何对对象的操作都将触发异常（在向不被信任的代码中传递敏感数据时很有用）。然而，对于 objspace 的最为重要的应用将会在 [[pypy_wiki_1#19.3. RPython 翻译器|19.4 节]]中进行讨论。</p><p>在平常的 PyPy 解释器中使用到的 objspace 被称之为标准 objspace(简称为std objspace）。除了 objspace 系统中提供的抽象之外，标准 objspace 还提供了另一个层次的间接方法；一种数据类型可能有多种实现方式。然后，对数据类型的操作会采用多方法发送。这使得对一个给定的数据能采用最为高效的表示形式。例如，Python的 long 型（表面上是大整数数据类型）在足够小的时候可以被表示为一个标准机器字长的整数，只有在必要的时候才会使用内存和计算代价更高的任意精度 long 型实现，甚至可可以使用标记指针来实现 Python 的整形数。容器类型同样可以被特化针对特定数据类型。例如，PyPy 中有针对字符串键值的字典类型（Python 的哈希表数据类型）实现。同样的数据类型可以被不同的实现方式所表示，这对于应用级代码是完全透明的；一个为字符串类型特化的字典和普通的字典是相同的，当有非字符串类型的键值放入时将会进行退化。</p><p>PyPy 对解释器层（interp-level）与应用层（app-level）的代码进行区分。编写大部分解释器所采用的解释器层代码必须是 RPython 并且被翻译过。这层代码直接作用于 objspace 和封装的 Python 对象。应用层代码一般通过 PyPy 字节码解释器运行。与 C 和 Java 相比，PyPy 的开发者们认为在翻译器的一些部分使用纯应用层代码是最方便的，这和解释器层的 RPython 代码一样简单。因此，PyPy 支持在解释器中内嵌应用层代码。例如，用于将对象写到标准输出的 Python ‘’print’’ 语句的功能就是通过应用层 Python 实现的。内置模块同样也可以同时用两种层次的代码写成。</p><h2 id="19-4-RPython-翻译器"><a href="#19-4-RPython-翻译器" class="headerlink" title="19.4. RPython 翻译器"></a>19.4. RPython 翻译器</h2><p>RPython 翻译器是一个由几个向下阶段组成的工具链，用于将 RPython 重写至目标语言，例如 C 语言。图 19.1 描述了较高层的翻译。翻译器自身使用（不严格的）Python 编写的，并在链接到 PyPy 的 Python 解释器，具体原因将会在稍后解释。</p><p><img src="http://aosabook.org/cdn/images/aosabook/pypy/translation_steps.png" alt="图 19.1: 翻译步骤"></p><p>翻译器所做的第一件事是将 RPython 程序加载到其进程（这一过程通过一般 Python 模块加载支持完成）。RPython 在一般动态的 Python 之上添加了一组限制。例如，函数不能在运行时创建，一个变量没有存放不匹配类型的可能性，比如一个整型数和一个对象实例。但是当程序被翻译器初次载入后，其将会运行在一个一般的 Python 解释器上，并且能够使用 Python 所有的动态特性。PyPy 的 Python 解释器是一个庞大的 RPython 程序，其大量使用这一特性用于元编程。举例来说，它为了标准的 objspace 多方法分派生成代码。唯一的要求是，程序在翻译器开始下一阶段翻译之前是合法的 RPython 代码。</p><p>翻译器通过一个名为<em>抽象解释</em>的过程为 RPython 程序构建流图。抽象解释重用了 PyPy 的 Python 解释器通过一个名为<em>流 objspace</em> 特殊的 objspace 来解释 RPython 程序。回忆一下，Python 解释器把程序中的对象看成是黑盒，通过调用 objspace 来执行所有的操作。流 objspace 与标准的 Python 对象集不同，只有两个对象：变量和常量。变量表示翻译时仍然不知道的值，而常量则表示已知的不变的值。流 objspace 有一个用于常量叠算的组件：如果需要对全是常量的参数执行操作，它将对其进行静态评估。在 RPython 中，不可变的、必须是常量的东西范围比标准 Python 中更广。例如，在 Python 中显然可变的模块在流 objspace 中是常量，并且必须被 objspace 常量叠算，因为它们在 RPython 中不存在。在 Python 解释器解释 RPython 函数字节码时，流 objspace 记录会记录它所执行的操作。它谨慎地记录条件控制流的所有分支。函数抽象翻译的最终结果是一个由连接的块组成的流图，每个块包含一个或多个操作。</p><p>下面是一个流图生成过程的示例，这是一个简单的阶乘函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n):</span><br><span class="line">    if n == 1:</span><br><span class="line">        return 1</span><br><span class="line">    return n * factorial(n - 1)</span><br></pre></td></tr></table></figure></p><p>上面函数的流图如下所示：</p><p><img src="http://aosabook.org/cdn/images/aosabook/pypy/flowgraph.png" alt="图19.2: 阶乘的流图"></p><p>这个阶乘函数被分成了若干块，每块都包含了流空间记录的操作。每块都有输入参数和一个对变量和常量的操作表。第一个块在结尾处有一个选择，它将决定控制流接下来将进入哪一个块。退出选择一般基于一些变量的值或在块最后的操作处是否有异常出现。控制流沿着块之间线移动。</p><p>在流 objspace 生成的流图是静态单分配形式的，或者 SSA， 一种在编译器中常见的中间表示形式。SSA 的关键特性是每一个变量只会被分配一次。这一特性简化了很多编译器转化和优化的实现。</p><p>在一个函数图被生成之后，注释阶段就会开始。注释器为每一个操作的参数和结果分配一个类型。例如，前面提到的阶乘函数的接收和返回类型都被分配为整型数。</p><p>下一个阶段叫做 RTyping。RTyping 使用从注释器获得的类型信息把流图中的每一个高层次操作扩展成低层次的操作。这是目标后端所关心的翻译的第一部分。后端为 RTyper 选择一套类型系统来特化代码。目前 RTyper 拥有两套类型系统：为像 C 语言这样的后端准备的低层次类型系统，和一个有类的高层次类型系统。高层 Python 的操作和类型被转化到这个类型系统的层次。例如，含有被注释为整型数操作数的 ‘’add’’ 操作在低层次类型系统下会生成一个的 ‘’int_add’’ 操作。像哈希表查找这样更复杂的操作会生成函数调用。</p><p>在 RTyping 之后，将会进行低层次的流图的优化。它们大多是传统的编译处理，如常量折叠、存储下沉、删除无用代码等等。</p><p>Python 代码含有尤其频繁地动态存储分配。RPython 作为 Python 的衍生物继承了这种集中分配的形式。但是，在很多情况下，分配对函数来说是暂时的、局部的。//分配消除//是针对这类问题的优化。分配消除通过尽可能地把先前动态分配的对象“扁平化”为组件标量来消除这些分配。</p><p>为了了解分配消除是怎么工作的，下面是一个用迂回的方式计算平面上两点之间欧式距离的函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def distance(x1, y1, x2, y2):</span><br><span class="line">    p1 = (x1, y1)</span><br><span class="line">    p2 = (x2, y2)</span><br><span class="line">    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])</span><br></pre></td></tr></table></figure><p>在 RTpye 初始化之后，函数题包含了以下操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">v60 = malloc((GcStruct tuple2))</span><br><span class="line">v61 = setfield(v60, (&apos;item0&apos;), x1_1)</span><br><span class="line">v62 = setfield(v60, (&apos;item1&apos;), y1_1)</span><br><span class="line">v63 = malloc((GcStruct tuple2))</span><br><span class="line">v64 = setfield(v63, (&apos;item0&apos;), x2_1)</span><br><span class="line">v65 = setfield(v63, (&apos;item1&apos;), y2_1)</span><br><span class="line">v66 = getfield(v60, (&apos;item0&apos;))</span><br><span class="line">v67 = getfield(v63, (&apos;item0&apos;))</span><br><span class="line">v68 = int_sub(v66, v67)</span><br><span class="line">v69 = getfield(v60, (&apos;item1&apos;))</span><br><span class="line">v70 = getfield(v63, (&apos;item1&apos;))</span><br><span class="line">v71 = int_sub(v69, v70)</span><br><span class="line">v72 = cast_int_to_float(v68)</span><br><span class="line">v73 = cast_int_to_float(v71)</span><br><span class="line">v74 = direct_call(math_hypot, v72, v73)</span><br></pre></td></tr></table></figure><p>这段代码在很多方面还欠缺优化。两个从未离开函数的元组被分配内存了。此外，还有不必要的元组域的间接访问。</p><p>运行分配消除生成了下面简洁的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v53 = int_sub(x1_0, x2_0)</span><br><span class="line">v56 = int_sub(y1_0, y2_0)</span><br><span class="line">v57 = cast_int_to_float(v53)</span><br><span class="line">v58 = cast_int_to_float(v56)</span><br><span class="line">v59 = direct_call(math_hypot, v57, v58)</span><br></pre></td></tr></table></figure><p>元组的内存分配被彻底移除了，间接访问被扁平化了。后面，我们将介绍另一个和分配消除相似的技术在 PyPy JIT 的 Python 应用层被应用（19.5 节）。</p><p>PyPy 也会进行函数内联。像低层次语言一样，内联能提高 RPython 的性能。令人惊奇的是，这同样可以缩小最后生成的二进制文件的大小。这是因为内联后可以进行更多的常量叠算和分配消除，这总体上简化了代码。</p><p>优化后的程序和低层次流图会传递到后端生成源代码。在生成 C 代码之前，C 的后端必须进行一些额外的转化。其中之一是异常转化，异常处理将会被重写成手动栈展开。另一个则是栈深度检查的插入。这一操作使得如果运行时递归太深，会抛出一个异常。程序调用图会计算循环找到需要栈深度检查的地方。</p><p>还有一个 C 后段会执行的转化是添加垃圾回收（GC）。RPython 和 Python 一样是有自动垃圾回收的语言，但是 C 语言没有，所以垃圾回收需要被添加进去。为了达成这一目标，一个垃圾回收转换器将程序的流图转换为垃圾回收程序。PyPy 的垃圾回收转换器为翻译如何抽象一般细节做了一个很好的示范。在 CPython 中，其使用了引用计数，解释器的 C 代码必须小心翼翼地跟踪它正在处理的 Python 对象的引用。这不仅使整个代码库中的垃圾回收方案变得复杂，还容易产生微妙的人为错误。PyPy 的 垃圾回收转换器解决了这两个问题，它允许不同的垃圾回收方案进行无缝地切换。我们可以简单地调整一个翻译的配置选项来评估一个垃圾回收实现（PyPy 有很多实现）。除了转换器 bug，垃圾回收转换器同样不会出现引用错误或当一个对象不再被使用时没有通知垃圾回收器的情况。垃圾回收抽象的威力使得垃圾回收的实现实际上通过翻译器不可能很复杂。举个例子，一些 PyPy 的垃圾回收实现需要一个//写隔离//。写隔离是指一个每次垃圾回收管理的对象被放置在另一个垃圾回收管理的数组或结构中时都会进行的检查。插入写隔离的过程如果手工完成会费力而且充满错误，但是用垃圾回收转换器自动完成就很轻松。</p><p>C 后端最终会生成 C 源代码。通过低层次流图生成的 C 代码是一个有着很多 ‘’goto’’ 和晦涩命名的变量的丑陋混乱的代码。使用 C 语言的一个优势是 C 的编译器可以做大部分复杂的静态转化工作，这些工作对于最终的二进制循环优化和寄存器分配是必须的。</p><h2 id="19-5-PyPy-JIT"><a href="#19-5-PyPy-JIT" class="headerlink" title="19.5. PyPy JIT"></a>19.5. PyPy JIT</h2><p>Python 和大多数动态语言一样，都牺牲了部分效率使其更为灵活。PyPy 的结构尤其灵活与抽象，这使得其很难进行非常快速的解释。强大的 objspace 和标准 objspace 的多方法抽象都是有代价的。因此，PyPy 解释器比 CPython 慢四倍。为了补偿这一缺陷并且挽救 Python 被称作缓慢的语言的声誉，PyPy 拥有一个即时的编译器（JIT）。JIT 在程序运行时将经常使用的代码编译成汇编语言。</p><p>PyPy JIT 利用了 19.4 节提到的 PyPy 独特的翻译架构的优势。PyPy 实际上并没有<em>针对 Python </em>的 JIT；它有一个 JIT 生成器。JIT 的实现就和翻译时其他的选择一样简单。一个需要 JIT 生成的解释器只需两个特殊的函数：<em>JIT 提示</em>。</p><p>PyPy 的 JIT 是一个<em>跟踪型的 JIT</em>。这表示它会检测“热的”（经常运行的）循环以此编译成汇编优化。当 JIT 决定要编译一个循环的时候，它会记录循环中一趟的操作，这一过程被称作<em>跟踪</em>。这些操作会被依次汇编成机器码。</p><p>如同前文提到的那样，JIT 生成器要生成一个 JIT 只需要解释器的两个提示：’’merge_point’’ 和 ‘’can_enter_jit’’。’’can_enter_jit’’ 告诉 JIT 在解释器中循环从哪里开始。在 Python 解释器中，这是 ‘’JUMP_ABSOLUTE’’ 字节码结束的地方。（’’JUMP_ABSOLUTE’’ 使得解释器跳到应用层循环的开头。）’’merge_point’’ 告诉 JIT 从哪里回到解释器是安全的。在 Python 解释器中，这是分配循环的字节码开始的地方。</p><p>JIT 生成器在翻译的 RTyping 阶段之后运行。回忆一下，这时程序的流图是有由几乎准备好生成目标代码的低层次操作构成的。JIT 生成器会定位解释器中上面提到的提示，并在运行时将它们替换为对 JIT 的调用。JIT 生成器接下来会编写每个解释器需要 JIT 化的函数的流图的序列化表示。这些序列化的流图被称为实时编译码（jitcodes）。现在整个解释器都通过低层次的 RPython 操作来描述了。实时编译码被保存在了最终的二进制文件中，在运行时会被调用。</p><p>在运行时，JIT 会为程序中运行的每个循环维护一个计数器。当一个循环的计数超过了设置的阈值时，JIT 就会被调用然后开始跟踪。跟踪中的关键对象被称作<em>元解释器（meta-interpreter）</em>。元解释器执行翻译过程中生成的实时编译码。它实际在解释主解释器，这就是它名字的由来。在它跟踪循环的时候，它会生成它正在执行的操作的列表，并用 JIT 的中间表示（IR）把他们记录下来。这个列表被称为循环的<em>跟踪表</em>。当元解释器接收到了对 JIT 化的函数（就是实时编译码存在的来源）的调用时，元解释器会进入这个函数并将它的操作记录到原始跟踪表中。因此，跟踪有扁平化函数调用栈的效果；跟踪中唯一的调用是对 JIT 所不知道的解释器函数的调用。</p><p>元解释器被强制用于特化循环迭代内容的跟踪表。举个例子，当元解释器遇见一个实时编译码编写的条件语句时，它当然要基于程序的状态选择一条路径。当它基于运行时的信息作出选择时，元解释器会记录一个被称为<em>防护（guard）</em>的 IR 操作。在条件分支中，条件变量上会有一个 ‘’guard_true’’ 或者 ‘’guard_false’’ 操作。大多数算数操作同样有防护，他们的作用是为了确保操作不会造成溢出。简要的说，防护在进行跟踪的时候将元解释器正在做的假设转化为代码。当汇编代码生成后，防护会确保汇编代码不会在一个未知的上下文环境中运行。当元解释器到达和开始跟踪时一样的 ‘’can_enter_jit’’ 操作时，跟踪就会结束。循环的 IR 现在就可以被传递给优化器了。</p><p>JIT 的优化器可以进行一些传统的编译器优化和许多为动态语言设计的优化，后者最重要的包括 <em>虚拟对象</em> 和 <em>可虚拟化对象</em>。</p><p>虚拟对象指的是已知的不会离开跟踪的对象，这意味着他们不会被作为参数被传递到外部的非 JIT 的函数调用。结构体和定长数组都可以是虚拟对象。虚拟对象不需要被分配内存，他们的数据可以被直接储存在寄存器或栈上。（这很像在翻译后端优化那一节中描述的静态内存分配消除阶段。）虚拟对象优化了 Python 解释器间接表示和内存分配带来的效率低下。例如，通过变成虚拟对象，被封装的 Python 整型数对象被拆分成简单的单字大小的整型数，这样就可以被直接存放在机器的寄存器中。</p><p>可虚拟化对象的行为与虚拟对象类似，但是必须在跟踪表之外（这意味着这些行为要被传递到非 JIT 的函数中）。在 Python 解释器中，框架对象保存变量的值和指令指针，它会被标记为可虚拟化的，使栈操作和栈上的其他操作可以被优化。尽管虚拟对象和可虚拟化对象很相似，然而它们在实现上却完全不同。可虚拟化对象在跟踪过程中由元解释器处理，而虚拟对象则是在跟踪优化的时候处理的，之所以会有这样的区别是因为可虚拟化对象可能会离开跟踪表，因此需要一些特殊的操作。具体来说，元解释器需要确保可能会使用到可虚拟化对象的非 JIT 函数实际上不会去尝试获取它的域。因为在 JIT 代码中，可虚拟化对象的域实际是储存在栈和寄存器中的，因此真正的可虚拟化对象相对 JIT 代码中的当前值而言可能会过期。在 JIT 生成过程中，访问了一个可虚拟化对象的代码会被重写以检查 JIT 汇编是不是在运行。如果正在运行，JIT 就会被要求从汇编的数据中更新域。此外在从外部调用回到 JIT 代码中时，程序的执行会回到解释器。</p><p>在优化之后，跟踪表已经准备好被汇编了。因为 JIT IR 已经很底层了，汇编代码的生成并不是很困难。大部分 IR 操作对应于一小部分 x86 汇编操作。寄存器的分配是一个简单的线性算法。此时，使用一个更为复杂的寄存器分配算法在后端所花费的大量时间和生成代码性能的微弱提升相比是不值得。汇编代码生成中最体现技巧的事垃圾回收集成和防护恢复。垃圾回收需要注意生成的 JIT 代码的栈的根。这通过垃圾回收中对动态根定位的特殊支持实现。</p><p>当一个防护失败时，编译出的汇编就不再合法，控制必须回到字节码解释器。这个回退事 JIT 视线中最困难的部分之一，因为需要从防护失败时的寄存器和栈状态中重建解释器的状态。对于每一个防护而言，汇编器会生成一个重建解释器状态所需要的所有变量的位置的详细描述。在防护失败时，运行跳转到一个解码这一描述的函数，并把恢复的变量传递到更高的层级用以重建。失败的防护可能是在一个复杂的操作码执行的中间，因此解释器不能只是从下一个操作码开始。PyPy 使用了<em>黑洞解释器</em>来解决这一问题。黑洞解释器从防护失效的点开始运行实时编译码直到下一个汇合点到达。在那里，真正的解释器恢复运行。黑洞解释器之所以叫这个名字是因为不像元解释器，它不会记录任何它所执行的操作。图 19.3 描述了防护失败的过程。</p><p><img src="http://aosabook.org/cdn/images/aosabook/pypy/guard_fails.png" alt="图19.3: 在防护失败时回退到解释器"></p><p>就像上面所描述的一样，JIT 在经常变化条件的循环中并没有什么作用，因为防护失败会阻止汇编代码运行特别多的循环。每个防护都有一个失败计数器，当它的值超过一个特定的阈值之后，JIT 将从防护失败的点开始跟踪而不是回退到解释器。这一新的子跟踪表被称为<em>桥</em>。当跟踪到达循环结束位置时，桥就会被优化和编译，原来的循环在防护处会被打上补丁，使其跳转到新的桥而不是失败代码。通过这种方式，通过这种方式动态条件的循环实现了 JIT 化。</p><p>PyPy JIT 中所使用的技术到底有多成功呢？在这篇文章写下时，PyPy 在综合测试下几何平均运行时间比 CPython 快五倍。通过 JIT，应用层 Python 可能比解释器层的代码还要快。PyPy 开发者最近发现了一个奇特的问题，他们为了性能需要在应用层 Python 写解释层的循环。</p><p>更重要的是，JIT 并不是为了 Python 自己设计的，它可以应用在任何使用 PyPy 框架的解释器上。而且也可以不是一个语言解释器。例如，JIT 被用作 Python 的正则表达式引擎。NumPy 是一个非常强大的 Python 数组模块，常被用于数字计算和科学研究。PyPy 有一个实验性的 NumPy 重实现，利用 PyPy JIT 的能力来加速数组操作。虽然目前 NumPy 的实现才刚刚起步，但其表现让人期待接下来的发展。</p><h2 id="19-6-设计缺陷"><a href="#19-6-设计缺陷" class="headerlink" title="19.6. 设计缺陷"></a>19.6. 设计缺陷</h2><p>虽然战胜了 C 语言，但用 RPython 写程序是一个令人沮丧的经历。它的隐含类型让人开始的时候很难适应。有些 Python 语言的特性不被支持还有一些特性会被严格限制。RPython 并不是所有的地方都被正式的决定了，翻译器所接受的对象可能会经常改变，因为 RPython 要适应 PyPy 的需求。这一章节的作者经常会为了写一个程序困在翻译器中一个半小时，只因为一个隐晦的错误。</p><p>RPython 翻译器是一个全程序分析器，这带来了很多实际问题。翻译代码中任何小修改都需要重新翻译整个解释器。这在一个现代高速的系统上大概要跑 40 分钟。这对于测试修改是如何影响 JIT 这一工作来说尤其恼人，因为测试性能需要一个翻译好的解释器。在翻译阶段整个程序要准备好意味着含有 RPython<br> 的模块不能从核心解释器中剥离出来，单独构建载入。</p><p>PyPy 的抽象层次并不总是像理论上那样明晰。技术上 JIT 生成器仅需要上面提到的两个提示就能就应该能为语言生成一个极好的 JIT，但实际上有些代码上生成的比其他代码上生成的好。为了让 Python 解释器更加 “JIT 友好”已经做了很多的工作，包括更多的 JIT 提示和为 JIT 优化的新数据结构。</p><p>PyPy 的多层结构令追踪 bug 成为了一个艰辛的过程。Python 解释器的 bug 可能会直接存在于解释器代码或埋藏在 RPython 语义和翻译工具链的某处。尤其是当一个 bug 无法在一个没有翻译的解释器上重现时，调试会很艰难。这需要在近乎不可读的生成的 C 代码上运行 GDB。</p><p>即便是一个被严格限制的 Python 的子集，将其翻译到像 C 那样更低层次的语言也不是一件简单的事。19.4 节描述的向下传递实际上并不是独立的。函数在翻译过程中会被注释并转化为 RType，注释需要标明一些低层次的类型。因此 RPython 翻译器是一个相互依赖的错综复杂的网。翻译器可能会在几个地方执行清理工作，但这一工作即不简单也不有趣。</p><h2 id="19-7-过程记录"><a href="#19-7-过程记录" class="headerlink" title="19.7.  过程记录"></a>19.7.  过程记录</h2><p>为了和其自身的复杂性作斗争，PyPy 采取了一些所谓的“敏捷开发”的方法。到目前为止其中最为重要的就是测试驱动开发。所有的新特性和 bug 修复都需要测试来确保它们的正确性。PyPy Python 解释器同样可以在 CPython 的回归测试套件下运行。PyPy 的测试驱动 py.test 已经被剥离了出来，现在在其他很多的项目中都有应用。PyPy 也有一个持续集成系统，它会运行测试套件并在很多不同的平台上翻译解释器。每天针对所有平台的二进制文件都会被生成并进行基准套件测试。所有的这些测试都是为了确保无论这个复杂的结构作出了什么改变，各个组件都能正常运行。</p><p>PyPy 项目中有强烈的实验文化。开发者被鼓励创建 Mercurial 仓库的分支。这样就可以在不影响主分支稳定的情况下尝试新的想法。分支并不总是成功的，有些被废弃了。要说的话，PyPy 的开发者都是顽强的。最为著名的是目前所使用的 PyPy JIT 实际是将 JIT 添加进 PyPy 的//第五次//尝试。</p><p>PyPy 项目以其可视化工具为傲，在 19.4 节中描述的流图是一个例子。PyPy 也有工具用来展示垃圾回收随时间变化的调用，检查正则表达式的匹配树。特别有趣的是 jitviewer，一个用来可视化地剥离 JIT 化函数的层次的程序，从 Python 字节码到 JIT IR 再到汇编。（图 19.4 中展示了 jitviewer。）可视化工具帮助开发者理解 PyPy 的层次是如何交互的。</p><p><img src="http://aosabook.org/cdn/images/aosabook/pypy/jitviewer.png" alt="图19.4: 展示 Python 字节码和对应 JIT IR 操作的 jitviewer"></p><h2 id="19-8-总结"><a href="#19-8-总结" class="headerlink" title="19.8. 总结"></a>19.8. 总结</h2><p>Python 解释器将 Python 对象视作黑箱，它的行为由 objspace 来处理。每个 objspace 都可以为 Python 对象提供特殊的延伸行为。这种利用 objspace 的方法也使得抽象的解释技术可以用来进行翻译工作。    </p><p>RPython 翻译器的抽象让语言解释免于一些细节问题，例如垃圾回收和异常处理。同时，它通过使用不同的后端，使得在许多不同的平台上运行 PyPy 成为可能。 </p><p>这种翻译结构很重要的一个应用就是 JIT 生成器。JIT 生成器的普适性让它可以被添加新的语言或者副语言(sub-language)，例如正则表达式。得益于JIT 生成器，PyPy成为了最快的 Python 实现。      </p><p>尽管 PyPy 的大多数的开发都集中在 Python 解释器，PyPy 可以应用于任何动态语言的实现。这些年以来，像 JavaScript, Prolog, Scheme, IO 的局部解释器都是用 PyPy 写的。</p><h2 id="19-9-学到的知识"><a href="#19-9-学到的知识" class="headerlink" title="19.9. 学到的知识"></a>19.9. 学到的知识</h2><p>最后是一些从 PyPy 项目中学到的知识：</p><p>反复重构通常是一个必要的过程。例如，最初构想时翻译器的 C 后段应该能够直接处理高层次的流图！反复几次之后才有了现在的多阶段翻译过程。</p><p>从 PyPy 中学到最重要的一点就是抽象的力量。在 PyPy 中，抽象屏蔽了实现相关的考量。例如，RPython 的自动垃圾回收允许开发者开发解释器的时候不用担心内存管理。同时，抽象会带来一些脑力的损耗。在翻译链上工作会使得翻译的不同层次一起涌入开发者的闹钟。抽象同样会掩盖 bug 所在的层次，抽象泄漏也是常见的问题，抽象泄漏指替换可互换的低层次组件打断了高层次代码。使用测试确保系统的所有部分正常运行是很重要的，这样一个系统的一个改变就不会影响另一个系统。更确切地说，因为抽象使用了很多间接的方式，所以程序的运行会变慢。</p><p>(R)Python 作为一个实现语言的灵活性使得测试新的 Python 语言特性（甚至是新的语言）变得容易。得益于其独特的架构，PyPy 将在 Python 和其他动态语言未来的实现上扮演重要角色。</p><h2 id="翻译信息"><a href="#翻译信息" class="headerlink" title="翻译信息"></a>翻译信息</h2><p>感谢劳佳的1-3节的翻译，<a href="http://www.ituring.com.cn/article/3894" target="_blank" rel="noopener">http://www.ituring.com.cn/article/3894</a> 。本篇在其基础之上对其进行了修改并完成了整章的翻译。另外感谢 Zhichen Liu 对本人翻译的协助。</p><p>译者水平有限，欢迎大家提出修改意见，本人邮箱<a href="mailto:liujiyuan126@yeah.net" target="_blank" rel="noopener">liujiyuan126@yeah.net</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PyPy&quot;&gt;&lt;a href=&quot;#PyPy&quot; class=&quot;headerlink&quot; title=&quot;PyPy&quot;&gt;&lt;/a&gt;PyPy&lt;/h1&gt;&lt;p&gt;PyPy 是一个 Python 的实现，同时也是一个动态语言实现框架。&lt;/p&gt;
&lt;p&gt;本章假定读者熟悉如字节码和常量叠算等有
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Pypy_2</title>
    <link href="http://blog.ccao.cc/2018/09/28/Pypy_2/"/>
    <id>http://blog.ccao.cc/2018/09/28/Pypy_2/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PyPy"><a href="#PyPy" class="headerlink" title="PyPy"></a>PyPy</h1><p>PyPy是一个对于python的实现，和一个关于动态语言实现的框架。</p><p>这一章假设读者对一些基本的编译器和解释器的知识很熟悉，比如字节码和常量合并。</p><h2 id="19-1-一点点历史"><a href="#19-1-一点点历史" class="headerlink" title="19.1 一点点历史"></a>19.1 一点点历史</h2><p>Python是一门高级语言，也是一门动态的程序设计语言，它是在上世纪80年代被荷兰的程序员Guido van Rossum发明出来的。Guido最初实现的版本是一个用C语言写成的经典的关于字节码的解释器，一般被广泛地称之为CPython。现在有许多其它的Python解释器，在其中最出名的是Jpython，IronPython和PyPy。Jpython是用Java语言编写的，并且允许使用java的接口，ironPython是用C#语言编写，并且使用微软的.NET架构的接口，PyPy则是这一章的主题。然而，CPython仍然是使用广泛的解释器，并且现在是唯一支持Python 3（下一代Python）的解释器。这一章将详细阐述Pypy的设计思想以及它与其它的Python解释器和其它动态语言的解释器所不一样的部分。</p><h2 id="19-2-PyPy综述"><a href="#19-2-PyPy综述" class="headerlink" title="19.2 PyPy综述"></a>19.2 PyPy综述</h2><p>除了数量极少可以忽略不计的C存根代码以外，PyPy完全是用Python语言编写的。PyPy的源代码树包含两个部分：Python解释器和RPython翻译工具链。Python解释器是面向程序员的运行库，人们使用PyPy来调用Python实现。它其实是由Python的一个子集——限制Python（缩写为RPython）写成的。使用RPython来编写Python解释器的目的是为了让解释器能够将结果输出到PyPy的第二个重要部分，即RPython翻译工具链。RPython翻译器接收到RPython代码，并将它们翻译成给定的低级别语言（比如C语言）。这就使得PyPy成为一个自足执行的实现，意味着它是使用它需要执行的源语言来写的。就像我们即将在这一章中看到的那样，RPython翻译器同样使得PyPy成为了一个通用的动态语言实现的框架。</p><p>PyPy强大的抽象功能使它成为了最灵活的Python解释器。它具有将近200种配置选项，从选择不同的垃圾回收机制，到改变不同的翻译优化的参数。</p><h2 id="19-3-Python解释器"><a href="#19-3-Python解释器" class="headerlink" title="19.3 Python解释器"></a>19.3 Python解释器</h2><p>由于RPython是Python的一个真子集，因此PyPy Python解释器可以不经翻译就在另一个Python实现器上执行。当然，这样运行起来非常慢，但是我们可以快速检测到解释器的变化。因此，使用普通的Python调试工具同样可以用来调试这个Python解释器。大部分关于PyPy解释器的检测都可以同时运行在未经翻译的和经过翻译的解释器上，从而允许了开发过程中的快速检测，并且保证了未经翻译和经过翻译的解释器产生的结果是一样的。</p><p>大部分情况下，PyPy Python解释器的实现细节与CPython Python解释器十分相似；在解释过程中，PyPy和CPython使用了几乎相同的字节码和数据结构。两者最主要的区别在于PyPy使用了一个更加聪明的抽象机制，叫做对象空间（简写为objspaces）。一个objspace封装了所有代表和操作Python数据类型所需要的知识。例如，对两个Python对象进行位运算或者获取对象的一个属性可以直接用objspaces进行处理。这样解放了Python解释器，它不必知道Python对象的全部实现细节。字节码解释器把Python对象看做是黑盒，当需要操作它们的时候，会调用objspace的方法来处理。例如，这里是一个’’BINARY_ADD’’操作码的粗糙实现方式，当两个对象通过“+”操作符连接的时候会调用。请注意解释器是如何不去检查操作符，所有的处理都立刻被委托给objspace。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def BINARY_ADD(space, frame):</span><br><span class="line">    object1 = frame.pop() # pop left operand off stack</span><br><span class="line">    object2 = frame.pop() # pop right operand off stack</span><br><span class="line">    result = space.add(object1, object2) # perform operation</span><br><span class="line">    frame.push(result) # record result on stack</span><br></pre></td></tr></table></figure></p><p>这种objspace抽象有多到数不清的好处。它允许新的数据类型在不修改解释器的情况下进行交换。而且，由于对对象进行操作的唯一方式是通过objspace，所以objspace可以对对象的操作进行拦截、代理或者记录。通过使用objspace强大的抽象功能，PyPy实验了形实转换和污点。在形实转换中，结果可能是“懒惰的”，但是已经按照需要被完全计算出来了。在“污点”中，任何在对象上面的操作都将会触发异常（这一点在从不被信任的代码上传递带有敏感信息的数据时很有用）。然而，对于objspaces的最为重要的应用，将会在19.4节中进行讨论。</p><p>在平常的PyPy解释器中使用到的objspace被称之为标准objspace(简称为std objspace）。除了objspace系统中提供的抽象之外，标准objspace还提供了另一个层次的间接方法（indirection）；一种数据类型可能有多种实现方式。然后，在数据类型上的操作是采用多方法进行调度，这也允许了对一个给定的数据采用最为高效的表示形式。举个例子来说，Python的长型（表面上看是一个BIGINT数据类型），在它足够小的时候可以被表示为一个标准机器字长的整数，甚至可以用标记指针来实现Python的可用整数。容器类型同样可以被专门化为某一特定的数据类型。例如，Python中的字典类型（Python的哈希表数据类型）就可以为字符串键（string keys）进行专门实现。同样的数据类型可以被不同的实现方式所表示，这个事实对于应用级的代码来说是透明的；一个为string类型进行了专门化的字典和普通的字典是相同的，当有非字符串类型的元素放入时它将退化为正常的字典。</p><p>PyPy将解释器级别（interp-level)的代码和应用级(app-level)的代码进行区分。解释器级（interp-level）的代码，包含了解释器中的大部分代码，必定在RPython中并且已经被翻译过。它对objspace直接进行处理，并且封装Python的对象。应用级（app-level）代码通常是通过PyPy字节码解释器来运行的。就和解释器级（interp-level） RPython代码一样简单的是，相比于C或者Java，PyPy开发者发现在解释器的某些部分中使用纯应用级代码是最简单的。所以，PyPy支持对嵌入式的应用程序级代码的解释。例如，Python中的’’print’’功能（用来把对象写到标准输出），是在应用级的Python被实现的。内建模块同样可以一部分是解释器级代码，一部分是应用级代码。</p><h2 id="19-4-RPython翻译器"><a href="#19-4-RPython翻译器" class="headerlink" title="19.4 RPython翻译器"></a>19.4 RPython翻译器</h2><p>RPython翻译器是由几个对语言层次进行降低的阶段构成的工具链。这些降低阶段负责将RPython重写成一个目标语言，最典型的是C语言。高层次阶段的翻译过程在图19.1中呈现。翻译器本身由（不受限制的）Python编写，并且与PyPy Python解释器紧密相连。</p><p><img src="/cdn/images/aosabook/38.png" alt="图19.1 翻译步骤"></p><p>翻译器做的第一件事，就是把RPython程序装载到它自己的进程中。（这是通过普通Python模块的装载支持来完成的。）RPython在标准的、动态的Python基础上加了一系列的限制。举个例子，函数不能在运行时被创建，并且一个变量不能存储与它不兼容的类型，比如一个整型数和一个对象实例。但是，当一个程序被翻译器首先装载过之后，它就是在一个普通的Python解释器上运行，并且可以使用Python的所有动态特性。作为一个巨大的RPython程序，PyPy Python解释器大量使用这种特性用于元编程。例如，它为objspace的多方法分派来生成代码。唯一的要求是，在翻译器开始下一个阶段的翻译时，这个程序是一个有效的RPython程序。</p><p>翻译器通过一种叫做“抽象解释”(abstract interpretation)的过程生成了RPython程序的流图。抽象解释重用了PyPy Python解释器，通过一个叫做流objspace的特殊objspace来解释RPython程序。回想我们之前说的，Python解释器把程序中的对象看成是黑盒，通过调用objspace来执行所有的操作。流objspace，它不是Python对象的某一个标准的子集，它只含有两个对象：变量和常量。变量表示的是在翻译过程中所不知道的数值，所以常量表示的就是翻译过程中已经被知道的并且不会被改变的数值。流objspace有着对于常量折叠的最基本的操作：如果它要去执行一个所有参数都是常量的操作，它将对其进行静态评估。在RPython中，一成不变的和必须被定义为常量的东西比标准Python多。例如，模块，这在Python中被着重强调为可变，在流objspace中是常量，因为它在RPython中不存在，并且必须要被流objspace进行常量折叠。因为Python解释器对RPython有关函数和功能的字节码进行了解释，流objspace记录下了它需要执行的操作。它负责记录条件控制流结构的所有分支。对于一个函数（function）进行抽象解释的最终结果是一个包含有很多互相连接的块的流图，每一个块包含一个或者多个操作。</p><p>一个流图生成的典型例子就是顺序执行。考虑如下的一个简单的阶乘函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n):</span><br><span class="line">    if n == 1:</span><br><span class="line">        return 1</span><br><span class="line">    return n * factorial(n - 1)</span><br></pre></td></tr></table></figure></p><p>这个函数的流图如下图所示：<br><img src="/cdn/images/aosabook/39.png" alt="图19.2： 阶乘的流图"></p><p>阶乘函数被分割成了不同的块，每一块中都包含着流空间所记录下来的操作。每一个块都含有输入参数和对于变量和常量的一系列操作。在第一块的末尾含有一个退出的选择转换，这决定了在第一个块运行过之后会跳转到哪一个块控制流中。退出转换器可以基于某个变量的值，或者是否在这个块的最后一个操作中出现异常。控制流按照块与块之间的连接线来运行。</p><p>流动objspace中产生的流图是静止单分配形式，或者SSA，一个在编译中常用的中间表示。SSA的关键特征就是所有的变量都只能被分配一次。此属性简化了许多编译器的转换和优化的实现。</p><p>在函数图产生之后，注释阶段就开始了。注释器为每一个操作的参数和结果指派一个类型。例如，上文中提到的递归函数需要接收和返回的类型都是整型数。</p><p>下一个阶段叫做RTyping。RTyping使用从注释器那里获得的类型信息来把流图中的高层次操作扩展成低层次的操作。这是目标后端所关心的翻译中的第一部分。后端为RTyper选择一套类型系统，并根据此对代码进行专门化。目前RTyper拥有两套类型系统：为像C语言这样的后端准备的低层次类型系统，和一个高层次的、含有类结构的类型系统。例如，一个含有被注释为整型数的操作数的’’add’’操作会生成一个具有低级别类型系统的’’int_add’’操作。像哈希表查找这样更复杂的操作会生成函数调用。</p><p>在RTyping之后，在低级别的流图上将会执行一些优化。它们大多是传统的编译处理，如常量折叠、存储下沉(store sinking)、删除死代码等等。</p><p>Python代码非常典型地含有频繁地动态存储分配。RPython，Python的衍生物，继承了这种分配并且使它更加集中(intensive pattern)。然而，在很多例子中，分配对函数来说是暂时的、局部的。去除分配(Malloc removal)是对解决这些问题的优化。去除分配是通过在可能的情况下把先前动态分配的对象“扁平化”成组件的标量来删除这些分配。</p><p>想要知道去除分配是怎么工作的，考虑如下的用一种迂回的方式来计算平面两点之间欧氏距离的函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def distance(x1, y1, x2, y2):</span><br><span class="line">    p1 = (x1, y1)</span><br><span class="line">    p2 = (x2, y2)</span><br><span class="line">    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])</span><br></pre></td></tr></table></figure></p><p>当它首先被RType之后，函数的主体部分含有如下的操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">v60 = malloc((GcStruct tuple2))</span><br><span class="line">v61 = setfield(v60, (&apos;item0&apos;), x1_1)</span><br><span class="line">v62 = setfield(v60, (&apos;item1&apos;), y1_1)</span><br><span class="line">v63 = malloc((GcStruct tuple2))</span><br><span class="line">v64 = setfield(v63, (&apos;item0&apos;), x2_1)</span><br><span class="line">v65 = setfield(v63, (&apos;item1&apos;), y2_1)</span><br><span class="line">v66 = getfield(v60, (&apos;item0&apos;))</span><br><span class="line">v67 = getfield(v63, (&apos;item0&apos;))</span><br><span class="line">v68 = int_sub(v66, v67)</span><br><span class="line">v69 = getfield(v60, (&apos;item1&apos;))</span><br><span class="line">v70 = getfield(v63, (&apos;item1&apos;))</span><br><span class="line">v71 = int_sub(v69, v70)</span><br><span class="line">v72 = cast_int_to_float(v68)</span><br><span class="line">v73 = cast_int_to_float(v71)</span><br><span class="line">v74 = direct_call(math_hypot, v72, v73)</span><br></pre></td></tr></table></figure></p><p>在某些方面这个代码还不是最优的。从来没有逃脱出这个函数(escape the function)的两个元组也被分配了空间。此外，还有对元组字段的不必要的间接访问。</p><p>运行去除分配产生如下简洁的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v53 = int_sub(x1_0, x2_0)</span><br><span class="line">v56 = int_sub(y1_0, y2_0)</span><br><span class="line">v57 = cast_int_to_float(v53)</span><br><span class="line">v58 = cast_int_to_float(v56)</span><br><span class="line">v59 = direct_call(math_hypot, v57, v58)</span><br></pre></td></tr></table></figure></p><p>对元组的分配已经被完全去除，间接访问也已经变平(flatten out)。稍后，我们将会看到在PyPy JIT中一个类似于去除分配的技术是如何运用到应用级Python中的（19.5节）。</p><p>PyPy同样进行对函数的内联操作。就像在低层次语言中一样，内联改善了RPython的性能。更令人惊讶的是，它同样减少了最终二进制代码的长度。这是因为它允许了更多可以用来减少代码长度的常量折叠和去除分配的实现。</p><p>现在在优化的，低层流量图程序，被传递到后端以产生源。在产生C代码之前，C语言后端还需要做一些额外的改变。其中的一个是异常转换，使用手动堆栈展开重写了异常处理过程。另一个是栈深度的嵌入式检查。如果递归的深度过于深，在运行时会抛出一个异常。在程序的调用图中，栈深度检查所需要检查的部分在计算周期中被发现。</p><p>C语言后端做出的另一个改变是加入了垃圾收集机制（GC）。RPython和Python一样，都是一个进行垃圾收集的语言，但是C语言不是，因此需要加入垃圾收集机制。为了实现这个机制，垃圾收集转化器把程序中的流图转变成一个垃圾收集程序。PyPy的垃圾收集转化器提供了一个极好的示范，关于翻译时如何抽象那些平凡的细节。在CPython中，使用的是引用计数，因此解释器C代码必须小心地对它所操纵的Python对象进行追踪。这不仅要对整个代码库的垃圾回收计划进行硬编码，还更容易产生一些人为错误。PyPy的GC转化器把两个问题同时解决了。它允许不同的垃圾回收机制，并且可以进行无缝进出交换。仅仅通过在翻译时调整一个配置选项来评价一个垃圾收集器的实现，这是微不足道的（PyPy的垃圾收集器的实现方式有多种）。GC转化器也没有出现模变换错误或者引用错误，以及当一个对象不再使用的时候忘记通知GC这样的错误。GC的抽象能力允许GC实现那些解释器硬编码所几乎不可能实现的内容。例如，几种PyPy的GC实现需要写屏障。写屏障是一种检查，每次当一个被GC管理的对象被插入一个被GC管理的数组或者结构体中时，写屏障都会被执行。插入写屏障的过程是费力且充满错误的，但是如果使用GC转化器来完成的话，这些费力和错误都将是微不足道的。</p><p>C语言后端可以最终产生C代码。从低级别流图生成的C代码，是一个包含了很多个’’goto’’和隐晦命名变量的非常丑陋的“烂摊子”。不过，写C语言代码的一个好处就是C语言编译器可以做很多非常复杂的数据转换的工作，这些工作需要对最终的二进制串进行优化，并且对寄存器进行分配。</p><h2 id="19-5-PyPy-JIT"><a href="#19-5-PyPy-JIT" class="headerlink" title="19.5 PyPy JIT"></a>19.5 PyPy JIT</h2><p>如同大部分的动态语言一样，Python也牺牲了部分效率来保证高灵活度。PyPy的架构在灵活性和抽象方面尤其复杂，因此很难进行非常快速的翻译。强大的objspace以及标准objspace中的多种方法抽象的产生都是需要代价的。因此，一个PyPy解释器的翻译速度比CPython慢4倍。不仅要对这一缺陷进行补救，还要挽救Python作为一门“缓慢语言”的声誉，PyPy拥有一个即时编译器（通常被写作JIT）。在程序运行时，JIT将经常使用的代码翻译成汇编语言。</p><p>PyPy JIT使用了19.4节中描述的Python独特的翻译结构。PyPy实际上并没有<em>针对Python的</em>JIT，它拥有的是JIT生成器。JIT的实现就和翻译其它的部分一样简单。一个需要JIT生成的翻译只需要两个特殊的函数调用，<em>JIT和暗示</em>。</p><p>PyPy的JIT是一个<em>追踪JIT</em>。这意味着它发现“热”（频繁运行）的循环，并且通过转化成汇编代码来优化它们。当JIT决定对一个循环进行编译，它记录下一趟循环中的操作，这一过程叫做<em>追踪</em>。这些操作最后都会被编译成机器代码。</p><p>就像上文中提到的那样,JIT生成器生成一个JIT的时候只需要来自翻译器的两个提示:’’merge_point’’和’’can_enter_JIT’’.’’can_enter_JIT’’告知了在翻译器中一个循环是从哪里开始的.在python翻译器中,这是在’’JUMP_ABSOLUTE’’字节码的最后开始的(‘’JUMP_ABSOLUTE’’使翻译器跳转到应用级循环的开头）。’’merge_point’’告知JIT它在哪里返回到翻译器是安全的。这是python解释器中分配循环字节码开始的地方。</p><p>JIT生成器在RTyping翻译阶段之后调用。回想一下，在这时程序的流图由几乎准备好生成目标代码的低层次操作构成。JIT生成器对上文中提到的翻译器中的提示进行定位，并且将它们替换为在运行时对JIT的调用。然后JIT生成器写入每一个解释器中需要JIT化的函数流图的序列化表示。这些序列化的流图叫做实时编译码(jitcodes)。现在，整个解释器都是通过低层次的Rpython来进行描述。实时编译码在被存储在最终等等二进制文件中，以便于运行时刻的使用。</p><p>在运行时刻，JIT为程序中每一个执行的循环维护一个计数器。当一个循环计数器超过可配置的阈值时，JIT被调用，跟踪开始。跟踪中的关键部分叫做<em>元解释器(meta-interpreter)</em>。元解释器对翻译中产生的实时编译码进行解析。因此，它是对主解释程序进行解释，故因此而得名。当它跟踪循环时，它创建了一个正在执行操作的序列，并且将它们保存在JIT中间表示(IR)中。这个序列叫做循环的跟踪表。当中间表示调用了一个JIT化的函数（即时编译码存在的地方之一），元解释器进入这个函数并将它的操作记录到原始跟踪表中。因此，追踪将函数调用栈扁平化了。跟踪中唯一的调用就是对JIT所不了解的解释器函数的调用。</p><p>元解释器被强制为对它所跟踪的循环迭代内容进行特定化的跟踪表。例如，当元解释器遇到了一个实时编译码编译的条件语句时，它必须根据程序的状态选择其中的一条路径。当它根据运行时信息做出选择的时候，元解释器记录一个叫做<em>防护(guard)</em>的IR操作。在条件选择语句的情况下，条件变量上会有’’guard_true’’和’’guard_false’’操作。大多数的算术运算符都拥有防护来保证操作不会溢出。从本质上说，防护在跟踪的时候将元解释器正在进行的假设转化为代码。当汇编代码被生成时，防护将对汇编代码进行保护，来防止它被一个没有被它进行特定化的内容运行。当元解释器到达了与它开始跟踪时的’’can_enter_git’’操作相同的操作时，跟踪就停止了。循环IR可以被传递给优化器。</p><p>JIT优化器可以实现一些经典的编译器优化和许多专门为动态语言设计的优化。在经典编译器优化中最重要的是<em>虚拟对象</em>和<em>可虚拟化对象</em>。</p><p>虚拟对象是一些不会从追踪中逃脱出的对象，这意味着它们不会作为参数传递给外部的、没有被JIT化的函数调用。结构体和定长数组可以作为虚拟对象。虚拟对象不需要分配空间，它们的数据可以被直接保存在寄存器和栈中。（这很像在翻译后端优化中所提到的静态分配去除阶段。）虚拟对象的优化除去了python解释器中间接表示和内存分配所带来的效率低下问题。例如，通过变为虚拟对象，封装好的python整型对象被解封为基本的字类型的整型数，并且能被直接保存在机器的寄存器中。</p><p>可虚拟化对象和虚拟对象很相似，但是可以从追踪中逃脱（可以被传输给没有JIT化的函数）。在python解释器中，包含了变量值和指令指针的框架对象被标记为可虚拟化对象。这使得栈操作和栈上的其它操作可以被优化。尽管虚拟对象和可虚拟化对象时相似的，它们在实现方面没有任何的共同点。可虚拟化对象是在元解释器的追踪中被处理，而虚拟对象是在追踪优化中被处理。这是因为需要对可虚拟化对象进行特殊的处理，由于它们可能会逃脱出追踪。特别地说，元解释器需要确认那些可能会使用可虚拟化对象的、没有被JIT化的函数实际上不会去尝试获取它的域。这是因为在JIT代码中，可虚拟化对象的域被存储在栈和寄存器中，所以真正的可虚拟化对象相对于它在JIT代码中的当前值而言可能会过时。在JIT生成过程中，那些获取和使用可虚拟化对象的代码被重写，从而检查出JIT汇编代码是否在运行。如果在运行，JIT会从汇编语言的数据中更新这些域。此外，从外部的调用回到JIT代码中时，程序的执行会回到解释器。</p><p>在优化之后，跟踪表已经做好了汇编的准备。因为JIT IR已经很底层了，汇编代码的生成并不是很困难。大部分的IR操作仅仅和一小部分x86汇编操作相对应，并且寄存器的分配是一个简单的线性算法。在此时，将时间花费在使用更复杂的寄存器分配代码从而产生一个稍微好一点的代码上并不是一个合理的选择。在汇编代码生成中最为棘手的部分就是垃圾回收集成和防护恢复。垃圾回收需要注意生成的JIT代码的栈根，这通过垃圾回收中对动态根定位的特殊支持来实现。</p><p>当防护失败时，编译出的汇编代码就不再是合法的了，控制必须回退到字节码解释器。这个回退过程是JIT实现中最为困难的部分之一，因为在防护失败时解释器的状态必须由寄存器和栈的状态来重新构造。对于每一个防护，汇编生成器会生成一个包含所有重建解释器时所需要的状态的详细位置信息。当防护失败时，程序跳转到解码这个信息的函数，并将恢复信息传递给更高层次以便进行重建。防护失败可能是在一个复杂的操作符执行的中间，因此解释器没法立刻开始下一个操作码的执行。PyPy使用了<em>黑洞解释器</em>来解决这个问题。黑洞解释器从防护失败点开始执行JIT代码，直到达到了下一个归并点。在那里，真正的解释器将恢复运行。和元解释器不同，黑洞解释器不对任何它执行的操作进行记录，故因此而得名。图19.3描述了防护失败的过程。</p><p><img src="/cdn/images/aosabook/40.png" alt="图19.3 防护失败时回退到解释器"></p><p>就像上文描述的那样，JIT在经常变化的循环中并没有什么用，因为防护失败会阻止汇编代码运行非常多次的迭代过程。每个防护都有一个失败计数器，当它的值超过某个阈值时，JIT就开始对防护失败点进行追踪，而不是回退到解释器中。这个新的子追踪过程被叫做<em>桥梁</em>。当追踪到达循环结束的位置时，桥就会被优化和编译，原来的循环会在防护处跳转到新的桥而不是失败代码。通过这种方式，动态条件循环实现了JIT化。</p><p>PyPy中使用的JIT技术究竟有多成功呢？在这篇文章写作的时候，PyPy在综合条件下的测试速度比CPython快5倍。通过JIT，应用级Python可能比解释器级的代码还要快。PyPy的开发者最近遇到了一个奇特的问题，为了性能他们需要在应用层Python写解释器层的代码。</p><p>更重要的是，JIT不是专门为Python设计的，这意味着它可以在任何使用PyPy框架的解释器中被使用，甚至可以不是一个语言解释器。例如，Python的正则表达式引擎中也使用了JIT。NumPy是Python中一个非常强大的数组模块，经常被用于数字计算和科学研究。PyPy有一个实验室级的NumPy重新实现，它利用了PyPy JIT的能力来对数组操作进行加速。尽管NumPy的实现还在起步阶段，但是它的表现让人期待。</p><h2 id="19-6-设计缺陷"><a href="#19-6-设计缺陷" class="headerlink" title="19.6 设计缺陷"></a>19.6 设计缺陷</h2><p>尽管它战胜了C语言，但是使用RPython写代码是是一种令人十分沮丧的经历。它的隐含类型在开始时让人难以适应，并且它不是支持所有的Python语言的特性，有些特性被严格限制。RPython不是在每一处都被严格定义，并且由于RPython要适应PyPy的需求，翻译器所接受的内容可能天天都在改变。这一章的作者写程序时往往会在翻译上折腾半个小时，只是因为某一个隐含的错误。</p><p>RPython的翻译器实际上是一个全程序分析器，这带来了很多实际问题。任何在翻译代码中的小修改都会造成整个解释器的重新翻译，这在现在的快速的、现代的程序中至少要花上40分钟。当测试各种改变是如何影响JIT时，这个延迟更加恼人，因为性能测试需要一个翻译好的解释器。在翻译阶段整个程序都需要准备好意味着含有RPython的模块不能从核心解释器中分离出来单独进行构建和加载。</p><p>PyPy中的抽象层次不总是和理论上所说的那样清晰。虽然在技术上JIT生成器应该为每一个只提供上文中所述的两种暗示的语言构造出一个性能良好的JIT，事实却是在某些代码上它的表现要比在另一些代码上好。为了让Python解释器变得“JIT友好”已经做了大量的工作，比如包括了更多的JIT暗示，并且为JIT优化了新的数据结构。</p><p>PyPy的多层结构会将错误追踪变为一个实验室级的过程。Python解释器的错误可能会直接存在于Python解释器的程序中，或者埋藏在RPython的语义和翻译链的某处。尤其是一个错误无法在没有翻译的解释器上重现的时候，调试过程会很艰难。这需要在生成的近乎于不可读的C代码上运行GDB。</p><p>将Python的一个限制子集翻译成一个像C语言一样的更低层次的语言也不是一件容易的事情。19.4节中描述的向低层次的传递并不是真的独立存在。函数在翻译过程中会被注释并转化为Rtype，并且注释中含有低层次类型的信息，因此RPython翻译器是交叉依赖、错综复杂的。翻译器可以在几个地方进行清理工作，但是这个工作并不是简单有趣的。</p><h2 id="19-7-过程记录"><a href="#19-7-过程记录" class="headerlink" title="19.7 过程记录"></a>19.7 过程记录</h2><p>在降低其自身复杂性方面（见19.6节），PyPy使用了几种“敏捷”开发方法，在其中最重要的是测试驱动开发。所有的新功能和错误修复都需要测试来证明它们的正确性。PyPy Python解释器同样可以在CPython的回归测试套件中运行。PyPy的测试驱动py.test已经被剥离出来并且在很多其它的项目中被应用。PyPy也有一个持续集成系统，它可以运行测试套件，并且在多个平台上翻译解释器。针对所有平台的二进制文件每天都被生成并进行基准套件运行。所有的测试确保了无论复杂架构中出现什么变化，这些部件都会运行。</p><p>PyPy的项目中有着强烈的实验文化。它鼓励开发者创建Mercurial仓库分支，这样就能在不影响主分支的情况下实验自己的想法。这些分支不总是成功的，有些可能会被丢弃。如果要说的话，PyPy的开发者都是顽强的。最著名的例子就是，现在的PyPy JIT是把JIT加到PyPy上的<em>第五次</em>尝试！</p><p>PyPy项目同样以它的可视化工具为傲。在19.4节中描述的流图就是一个例子。PyPy同样有工具来显示随着时间的推移垃圾收集器的调用情况，并查看正则表达式的解析树。最特别的是jitviewer，一个用来可视化地JIT函数层次的程序，从python字节码到JIT IR再到汇编。可视化工具帮助开发者了解PyPy的各层是如何与其它层进行交互的。</p><p><img src="/cdn/images/aosabook/41.png" alt="图19.4: 展示 Python 字节码和对应 JIT IR 操作的 jitviewer"></p><h2 id="19-8-总结"><a href="#19-8-总结" class="headerlink" title="19.8 总结"></a>19.8 总结</h2><p>python解释器把python对象看做黑盒，并把所有行为处理交给objspace。每一个objspace都可以为python对象提供特殊的眼神行为。使用objspace方法的技术也使抽象的解释技术可以用来进行翻译工作。</p><p>Rpython翻译器允许像垃圾收集和异常处理这样的细节从语言翻译器中抽象出来。它同时也使得使用不同的后端在不同的运行平台上运行PyPy成为现实。</p><p>最重要的翻译架构的使用之一就是JIT生成器。JIT生成器的普适性允许JIT添加新的语言或者子语言，如正则表达式。因为有JIT生成器，PyPy是目前最快的python实现。</p><p>虽然大部分的PyPy开发工作都是关于python解释器的，但是PyPy可以被使用在任何动态语言的实现上。这几年以来，javascript、prolog和IO的部分解释器都是用PyPy写的。</p><h2 id="19-9-学到的经验"><a href="#19-9-学到的经验" class="headerlink" title="19.9 学到的经验"></a>19.9 学到的经验</h2><p>最后，从PyPy项目中学到了如下的知识：</p><p>反复重构往往是一个必要的过程。例如，最初的设想时翻译器的C语言后端可以直接处理高层次的流图。现在的多阶段翻译过程是在反复了几次之后才最终产生的。</p><p>PyPy中最重要的就是抽象的力量。在PyPy中，抽象屏蔽了相关实现细节。例如，Rpython的自动垃圾收集器允许开发者开发解释器时不需要关心内存管理。同时，抽象带来了脑力上的损耗。翻译链的工作意味着翻译的不同层次全部涌入翻译者的脑中。同时，错误的层次被抽象掩盖会更加难以确定；抽象泄漏，在其中交换来本来应该是高层次代码中断时内部交换的代码，是一个长期存在的问题。使用测试来确保系统的所有部分都正常运行是很重要的，这样一个系统中的改变就不会对另一个系统造成破坏。更确切地说，抽象汇因为创建了过多的重定位而拖慢程序的速度。</p><p>作为一个实现语言，（R）python的灵活性使得在python的新语言特性（甚至于一个新的语言）上进行实验变得容易。因为它独特的架构，PyPy将来会在python和动态语言的事项上扮演更重要的作用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PyPy&quot;&gt;&lt;a href=&quot;#PyPy&quot; class=&quot;headerlink&quot; title=&quot;PyPy&quot;&gt;&lt;/a&gt;PyPy&lt;/h1&gt;&lt;p&gt;PyPy是一个对于python的实现，和一个关于动态语言实现的框架。&lt;/p&gt;
&lt;p&gt;这一章假设读者对一些基本的编译器和解释器
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib</title>
    <link href="http://blog.ccao.cc/2018/09/28/Matplotlib/"/>
    <id>http://blog.ccao.cc/2018/09/28/Matplotlib/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p>matplotlib是一个基于Python的绘图库，完全支持二维图表绘制，对三维图表支持有限。它被广泛用于Python科学计算，该绘图库希望适应广泛的用户需求。matplotlib能支持交互式绘图，它可以根据你所选的用户接口工具来嵌入绘图库，目前它支持包括GTK+、Qt、Tk、FLTK、wxWidgets与Cocoa等所有主流桌面操作系统上的工具包。在Python的交互式shell中，我们可以使用简单的、过程式的命令，交互式地调用matplotlib来生成图形，与使用Mathematica、IDL或者MATLAB绘图非常相似。matplotlib也可以嵌入到无报文头的Web服务器中，以提供基于光栅（如PNG格式）与矢量（如Postscript、PDF以及纸面效果很好的SVG 格式）这两种格式的图形硬拷贝。</p><p>##1.硬件锁问题 ##<br>我们其中一位开发者（John Hunter）与他的研究癫痫症的同事们试图在不借助专有软件的情况下进行脑皮层电图（ECoG）分析，于是便有了最初的matplotlib。John Hunter当时所在的实验室只有一份电图分析软件的许可证，但有各式各样的工作人员，如研究生、医科学生、博士后、实习生、以及研究员，他们轮流共享该专有软件保护器（加密狗）。生物医学界广泛使用MATLAB进行数据分析与可视化，所以Hunter着手使用基于MATLAB的matplotlib来代替专有软件，这样很多研究员都可以使用并且对其进行扩展。但是MATLAB天生将数据当作浮点数的数组来处理。然而在实际情况中，癫痫手术患者的医疗记录具有多种数据形式（CT、MRI、ECoG 与EEG 等），并且存储在不同的服务器上。MATLAB作为数据管理系统勉强能应付这样的复杂性。Hunter感到MATLAB不适合于这项任务，便开始编写一个基于GTK+工具包（一种图形用户界面（GUI）工具包，当时是linux系统下编写视窗系统的主流工具包）的全新的python应用程序。</p><p>所以matplotlib这一GTK+应用程序最初便被开发成EEG/ECoG可视化工具。这样的使用方式决定了它最初的软件架构。matplotlib最初的设计也服务于另一个目的：代替命令驱动的交互式图形生成（这一点 MATLAB做得很好）工具。MATLAB的设计方法使得加载数据文件与绘图这样的任务非常简单，而要使用完全面向对象的API则会在语法上过于繁琐。所以 matplotlib也提供状态化的脚本编程接口来快速、简单地生成与 MATLAB类似的图形 。因为 matplotlib是Python库，所以用户可以使用 Python中各种丰富的数据结构，如列表、辞典与集合等等。<br><img src="/cdn/images/aosabook/46.png" alt=""></p><p>图1.1 最初版本的matplot：一个ECoG查看器</p><h2 id="2-matplotlib软件架构概述"><a href="#2-matplotlib软件架构概述" class="headerlink" title="2. matplotlib软件架构概述"></a>2. matplotlib软件架构概述</h2><p>顶层的matplotlib对象名为Figure，它包含并且管理某个图形的所有元素。matplotlib必须解决的一个核心架构性任务是实现Figure的绘制与操作，并且做到该框架与Figure渲染到窗口或者硬拷贝（可以简单理解为打印输出）的动作是分离的。这使得我们可以为Figure添加越来越复杂的特性与逻辑，同时保持“后端”或输出设备的相对简化。matplotlib不仅封装了用于向多种设备渲染的绘图接口，还封装了基本事件处理以及多数流行的用户界面工具的视窗功能。因此，用户可以创建相当丰富的交互式图形算法与用户界面工具（用到可能存在的鼠标与键盘），而又不必修改matplotlib已经支持的6种界面工具。</p><p>要实现这些，matplotlib的架构被逻辑性地分为三层，这三层逻辑可以视为一个栈。每一层知道如何与它的下一层进行通信，但在下层其实不会感知到上层的存在。这三层从底向上分别为：后端、美工与脚本。</p><h3 id="2-1-后端"><a href="#2-1-后端" class="headerlink" title="2.1 后端"></a>2.1 后端</h3><p>matplotlib逻辑栈最底层是后端，它提供了如下这些抽象接口的具体实现：</p><ul><li>FigureCanvas 对绘图表面（如“绘图纸”）的概念进行封装。</li><li>Renderer 执行绘图动作（如“画笔”）。</li><li>Event 处理键盘与鼠标事件这样的用户输入。</li></ul><p>对于如Qt这样的用户界面工具，FigureCanvas中包含的具体实现可以完成三个任务：将自身嵌入到原生的Qt窗口（QtGui.QMainWindow），将 matplotlib的Renderer命令转换到canvas上（QtGui.QPainter），以及将原生Qt事件转换到matplotlib的Event框架下（ 后者产生回调信号让上行监听者进行处理）。抽象基类定义在matplotlib.backend_bases 中 ， 且 所 有 派 生 类 都 定 义 在 如 matplotlib.backends.backend_qt4agg这样的专用模块中。对于专门生成硬拷贝输出（如 PDF、PNG、SVG 或 PS）的纯图像后端而言，FigureCanvas的实现可能只是简单地建立一个类似文件的对象，其中定义默认的文件头、字体与宏函数，以及 Renderer 创建的独立对象（如直线、文本与矩形等）。</p><p>Renderer的任务是提供底层的绘图接口来将“墨水”加到“画布”上。正如前文提到的，最初的matplotlib程序是一个基于GTK+的ECoG查看器，而且很多早期设计灵感都源自当时已有的GDK/GTK+的API。最初Renderer的API源自GDK的Drawable接口，后者实现了draw_point、draw_line、draw_rectangle、draw_image、draw_polygon以及draw_glyphs这样的基本方法。我们实现的每个不同后端——最早有PostScript与GD——都实现了GDK的Drawable接口，并将其转换为独立于后端的原生绘图命令。如上所述，这毫无必要地增加了后端的实现复杂度，原因是单独实现Drawable造成函数泛滥。此后，这个API已经被极大的简化，将matplotlib移植到新的用户界面或文件格式已经是非常简单的过程。</p><p>一个对matplotlib有利的设计决定是支持使用C++模板库Anti-Grain Geometry（缩写为agg[She06]）的基于像素点的核心渲染器。这是一个高性能库，可以进行2D反锯齿渲染，生成的图像非常漂亮。matplotlib支持将agg 后端渲染的像素缓存插入到每种支持的用户界面中，所以在不同的UI 与操作系统下都能得到精确像素点的图形。因为matplotlib生成的PNG输出也使用agg渲染器，所以硬拷贝与屏幕显示完全相同，也就是说在不同的UI与操作系统下，PNG的输出所见即所得。</p><p>matplotlib的Event框架将key-press-event或mouse-motion-event这样的底层UI事件映射到KeyEvent或MouseEvent类。用户可以连接到这些事件进行函数回调，以及图形与数据的交互，如要pick一个或一组数据点，或对图形或其元素的某方面性质进行操作。下面的示例代码演示了当用户键入‘t’时，对Axes窗口中的线段进行显示开关。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">def on_press(event):</span><br><span class="line">    if event.inaxes is None: return</span><br><span class="line">    for line in event.inaxes.lines:</span><br><span class="line">        if event.key==&apos;t&apos;:</span><br><span class="line">            visible = line.get_visible()</span><br><span class="line">            line.set_visible(not visible)</span><br><span class="line">    event.inaxes.figure.canvas.draw()</span><br><span class="line">fig, ax = plt.subplots(1)</span><br><span class="line">fig.canvas.mpl_connect(&apos;key_press_event&apos;, on_press)</span><br><span class="line">ax.plot(np.random.rand(2, 20))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>对底层UI 事件框架的抽象使得matplotlib 的开发者与最终用户都可以编写UI 事件处理代码，而且“一次编写，随处运行”。譬如，在所有用户界面下都可以对matplotlib 图像进行交互式平移与放缩，这种交互式操作就是在matplotlib 的事件框架下实现的。</p><h3 id="2-2-Artis层"><a href="#2-2-Artis层" class="headerlink" title="2.2 Artis层"></a>2.2 Artis层</h3><p>Artist层次结构处于 matplotlib的中间层，负责很大一部分繁重的计算任务。延续之前将后端的 FigureCanvas 看作画纸的比喻，Artis 对象知道如何用Renderer（画笔）在画布上画出墨迹。matplotlib中的 Figure就是一个Artist 对象实例。标题、直线、刻度标记以 及 图 像 等 等 都 对 应 某个Artist 实 例（ 如 图 11.3 ）。Artist 的 基 类 是matplotlib.artist.Artist，其中包含所有 Artist的共享属性，包括从美工坐标系统到画布坐标系统的变换（后面将详细介绍）、可见性、定义用户可绘制区域的剪切板、标签，以及处理“选中”这样的用户交互动作的接口，即在美工层检测鼠标点击事件。 </p><p><img src="/cdn/images/aosabook/47.png" alt=""></p><p>图2.1：matplotlib 生成的图形</p><p><img src="/cdn/images/aosabook/48.png" alt=""></p><p>图2.2：用于绘制图11.2的Artist 实例的层次结构</p><p>Artist层于后端之间的耦合性存在于 draw 方法中。譬如，下面假想的SomeArtist 类是Artist的子类，它要实现的关键方法是 draw，用来传递给后端的渲染器。Artist不知道渲染器要向哪种后端进行绘制（PDF、SVG 与GTK+绘图区等），但知道 Renderer的 API，并且会调用适当的方法（draw_text 或 draw_path）。因为 Renderer 能访问画布，并且知道如何绘制，所以 draw方法将 Artist的抽象表示转换为像素缓存中的颜色、SVG 文件中的轨迹或者其他具体表示。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class SomeArtist(Artist):</span><br><span class="line">&apos;An example Artist that implements the draw method&apos;</span><br><span class="line"></span><br><span class="line">def draw(self,render):</span><br><span class="line">    &quot;&quot;&quot;Call the appropriate renderer methods to paint self onto canvas&quot;&quot;&quot;</span><br><span class="line">    if not self.get_visible(); return</span><br><span class="line"></span><br><span class="line">    #create some objects and use renderer to draw self here</span><br><span class="line">    renderer.draw_path(graphics_context,path,transform)</span><br></pre></td></tr></table></figure></p><p>该层次结构中有两种类型的 Artist。基本 Artist 表示我们在图形中能看到的一类对象，如Line2D、Rectangle、Circle 与Text。复合 Artist 是Artist 的集合，如Axis、Tick、与 Figure。每个复合Artsit 可能包含其他复合 Artist 与基本Artist。譬如，Figure包含个或多个Axes，并且Figure的背景是基本的 最重要的复合 Artist 是 Axes，其中定义了大多数 matplot的绘图方法。Axes不仅仅大多数构成绘图背景（如标记、轴线、网格线、色块等）的图形元素，还包括了大量生成本 Artist并添加到Axes 实例中的帮助函数。譬如，表11.1列出了一些Axes函数，这些 函数进行对象的绘制，并将它们存储在Axes实例中。 </p><p>表2.1：Axes的方法样例及其创建的Artist 实例</p><table><thead><tr><th>方法</th><th>创建对象</th><th>存储位置</th></tr></thead><tbody><tr><td>Axes.imshow</td><td>一到多个matplotlib.image.AxesImage</td><td>Axes.images</td></tr><tr><td>Axes.hist</td><td>大量matplotlib.patch.Rectangle</td><td>Axes.patches</td></tr><tr><td>Axes.plot</td><td>一到多个matplotlib.lines.Line2D</td><td>Axes.lines</td></tr></tbody></table><p>下面这个简单的 Python脚本解释了以上架构。它定义了后端，将 Figure链接至该后端，然后使用数组库numpy 创建10,000个正太分布的随机数，最后绘制出它们的柱状图。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># Import the FigureCanvas from the backend of your choice</span><br><span class="line">#  and attach the Figure artist to it.</span><br><span class="line">from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas</span><br><span class="line">from matplotlib.figure import Figure</span><br><span class="line">fig = Figure()</span><br><span class="line">canvas = FigureCanvas(fig)</span><br><span class="line"></span><br><span class="line"># Import the numpy library to generate the random numbers.</span><br><span class="line">import numpy as np</span><br><span class="line">x = np.random.randn(10000)</span><br><span class="line"></span><br><span class="line"># Now use a figure method to create an Axes artist; the Axes artist is</span><br><span class="line">#  added automatically to the figure container fig.axes.</span><br><span class="line"># Here &quot;111&quot; is from the MATLAB convention: create a grid with 1 row and 1</span><br><span class="line">#  column, and use the first cell in that grid for the location of the new</span><br><span class="line">#  Axes.</span><br><span class="line">ax = fig.add_subplot(111)</span><br><span class="line"></span><br><span class="line"># Call the Axes method hist to generate the histogram; hist creates a</span><br><span class="line">#  sequence of Rectangle artists for each histogram bar and adds them</span><br><span class="line">#  to the Axes container.  Here &quot;100&quot; means create 100 bins.</span><br><span class="line">ax.hist(x, 100)</span><br><span class="line"></span><br><span class="line"># Decorate the figure with a title and save it.</span><br><span class="line">ax.set_title(&apos;Normal distribution with $\mu=0, \sigma=1$&apos;)</span><br><span class="line">fig.savefig(&apos;matplotlib_histogram.png&apos;)</span><br></pre></td></tr></table></figure><h3 id="2-3-脚本层-pyplot"><a href="#2-3-脚本层-pyplot" class="headerlink" title="2.3 脚本层(pyplot)"></a>2.3 脚本层(pyplot)</h3><p>使用以上 API 的脚本效果很好，尤其是对于程序员而言，并且在编写 Web 应用服务器、UI 应用程序或者是与其他开发人员共享的脚本时，这通常是比较合适的编程范式。对于日常用途，尤其对于非专业程序员而要完成一些交互式的研究工作的实验科学家而言，以上API 的语法可能有些难以掌握。大多数用于数据分析与可视化的专用语言都会提供轻量级的脚本接口来简化一些常见任务。matplotlib 在其matplotlib.pyplot接口中便实现了这一点。以上代码改用pyplot之后如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.random.randn(10000)</span><br><span class="line">plt.hist(x, 100)</span><br><span class="line">plt.title(r&apos;Normal distribution with $\mu=0, \sigma=1$&apos;)</span><br><span class="line">plt.savefig(&apos;matplotlib_histogram.png&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/cdn/images/aosabook/49.png" alt=""></p><p>图 2.3 用pyplot绘制的柱状图</p><p>pyplot是一个状态化接口，大部分工作是处理样本文件的图形与坐标的生成，以及与所选后端的连接。它还维护了模块级的内部数据结构。这些数据结构表示了直接接收绘图命令的当前图形与坐标。</p><p>下面仔细分析示例脚本中比较重要的几行，观察其内部状态的管理方式。</p><ul><li>import matplotlib.pyplot as plt：当pyplot模块被装载时，它会解析一个在本地本的配置文件中的用户声明的默认后端偏好设置。这有可能是一个像QtAgg一样的用户交互后端后台，在这种情况下，前面的脚本将导入的GUI框架，并启动嵌入了plot的Qt窗口，或者它可能是一个像AGG一样的纯图片后端，在这种情况下，该脚本将产生硬拷贝输出并退出。</li><li>plt.hist(x, 100)：这是这个脚本的第一条绘图命令，pyplot会检查它自己内部的数据结构，来确定是不是已经有了一个当前的图表实例。如果有，那么它会提取当前的Axes并且直接调用Axes.hist的API。如果没有的话，它就会创建一个图表和Axes，并将这两者设置为当前的，并且直接绘制Axes.hist。</li><li>plt.title(r’Normal distribution with $\mu=0, \sigma=1$’)：像上面一样，pyplot会检查是不是已经有了一个当前的图表和Axes对象。如果有，它就不会创建新的实例，并且直接调用已有Axes实例的Axes.set_title方法。</li><li>plt.show()：这个命令会让Figure渲染，如果用户已经在配置文件中声明了一个默认的GUI后端，pyplot会启动这个GUI的主循环并输出所有的图表。</li></ul><p>下面我们以一个经常用来画线的函数matplotlib.pyplot.plot的简化版本为例，来解释一下一个pyplot函数是如何被封装在matplotlib的面向对象内核中的。其他所有的pyplot脚本交互函数都遵循相同的设计。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@autogen_docstring(Axes.plot)</span><br><span class="line">def plot(*args, **kwargs):</span><br><span class="line">    ax = gca()</span><br><span class="line"></span><br><span class="line">    ret = ax.plot(*args, **kwargs)</span><br><span class="line">    draw_if_interactive()</span><br><span class="line"></span><br><span class="line">    return ret</span><br></pre></td></tr></table></figure><p>@autogen_docstring(Axes.plot)这个python装饰器会提取对应API的文档字符串，并附加一个被正确格式化的版本到pyplot.plot方法上。我们有一个专用的模块matplotlib.docstring来处理这个docstring魔法。在这个文档字符串签名中的<em>args和**kwargs是Python中的特别约定，用来表示所有的参数和关键词参数将通过这两者传入这个方法。这使得我们可以按照这些参数来找到对应的API方法。ax=gca()调用状态机来获取当前的Axes对象(每一个Python解释器只能有一个当前的Axes对象)，并且如果有必要的话会创建Figure和Axes对象。ret = ax.plot(</em>args, **kwargs)这句调用了合适的Axes方法并且存储了将要返回的返回值。因此pyplot接口是一个Artist API内核相当轻的封装，Artist内核通过暴露API方法，尽可能减少代码重复，在这个脚本接口中的调用签名和装饰字符串是最小化的模板代码。</p><p>##3.后端重构##<br>随着时间推移，输出后端的绘图API添加了大量的方法，包括：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">draw_arc</span><br><span class="line">draw_image </span><br><span class="line">draw_line_collection </span><br><span class="line">draw_line </span><br><span class="line">draw_lines </span><br><span class="line">draw_point</span><br><span class="line">draw_quad_mesh</span><br><span class="line">draw_polygon_collection</span><br><span class="line">draw_polygon </span><br><span class="line">draw_rectangle</span><br><span class="line">draw_regpoly_collection</span><br></pre></td></tr></table></figure></p><p>不幸的是，越来越多的后端方法意味着写一个新的后端将会花费大量的时间，并且当新特性被加到内核后，更新已有的后端也是一项相当可观的工作。由于每一个后端都由一个精通某种输出格式的独立开发者所开发，有时候会需要很长的时间才能把一个新特性加到后端，从而导致用户会比较困惑新特性可以从哪里调用。</p><ul><li>draw_path:绘制复合多边形，由直线和贝塞尔段组成，这个接口替换了许多旧的方法：draw_arc, draw_line, draw_lines, 和draw_rectangle。</li><li>draw_image:绘制光栅图片。</li><li>draw_text：根据给定的字体绘制文本。</li><li>get_text_width_height_descent：输入一个字符串，返回它的长宽。</li></ul><p>只是用以上这些必要的绘图方法来构建一个新的后端是可以做到的。（我们甚至可以进一步，移除draw_text方法，用draw_path方法来绘制文本，但是我们并没有足够的时间来完成这样的简化。当然，后端仍然可以自由调用它自己的draw_text方法来输出真正的文本。）这对于新开发一个后端以及更简单地运行非常有帮助。但是，在某些情况下，后端可能会想要重写内核的这些行为，来获取更高效地输出。比如，当绘制一些标记时（小的符号，用来指示线图的顶点），采取只写一次标记的形状到文件，并且在所有用到它的地方都作为一个stamp，的方法更加节省空间。在那种情况下，后端可以继承一个draw_markers方法。如果这个方法被继承，后端就只会输出这个标记的形状一次，并且在许多地方输出许多更为简短的命令来重复使用它。如果没有被继承，内核就会简单地多次调用draw_path，多次绘制这个标记。</p><p>完整的可选后端API如下：</p><ul><li>draw_markers: 绘制一系列的标价。</li><li>draw_path_collection: 绘制一个路径的集合。</li><li>draw_quad_mesh: 绘制一个四边形网格。</li></ul><p>##4.变换##<br>matplotlib花了很多时间用来将坐标系从一个系统中变换到另一个系统中。这个坐标系统包括：</p><ul><li>data: the original raw data values</li><li>axes: the space defined by a particular axes rectangle</li><li>figure: the space containing the entire figure</li><li>display: the physical coordinates used in the output (e.g. points in PostScript, pixels in PNG)</li></ul><p>每一个Artist都拥有一个变换节点，这个节点知道如何从一个坐标系变换到另一个坐标系。这些变换节点的连接方式是有向图，每个节点都独立于它的父节点。通过有向图中通向根节点的边，数据空间的坐标可以一直变换直到最终。同时，大多数变换都是可逆的。这使得点击图标中的单个元素，获取其数据空间中的坐标成为可能。这个变换图在变换节点之间建立这样的依赖关系：当一个父节点变换了，比如当一个Axes对象的限制发生了改变，任何与这个Axes对象相关的变换就都无效了，因此他们需要被重新绘制。而这个图表中，和其他Axes对象相关的变换，当然，可能会被独立开，以避免不必要的重复计算，从而获得更好地交互表现。</p><p>变换节点可能不光是简单的仿射变换，也可能是非仿射变换。仿射变换属于保持直线和距离的比率的哪一类变换，包括旋转，平移，缩放和斜切等。二维的仿射变换用3×3的变换矩阵来表示。变换后的点(x’, y’)由矩阵乘以原来的点 (x, y) 得到：</p><p><img src="/cdn/images/aosabook/50.png" alt=""></p><p>二维坐标可以很容易的使用简单的变换矩阵来完成变换。仿射变换通过矩阵乘法可以将有用的属性组合起来。这意味着要执行一系列的放射变换，可以先将这些变换乘起来，然后这个结果变换矩阵可以用来变换坐标。matplotlib的变换框架为了减少计算量，在变换坐标之前就自动组合了仿射变换。快速的放射变换是相当重要的，因为它能够使GUI界面中的平移和缩放变换更加高效。</p><p>而matplotlib中的非仿射变换使用Python的函数来定义，因此他们实在是有些任意。在matplotlib的内核中，非仿射变换用来做对数缩放，极坐标和地理预测(如图 4.1)。这些非仿射变换可以自由地和仿射变换组合。matplotlib会自动地简化仿射变换的部分，并且为了执行非仿射的部分，它回退到任意函数。</p><p><img src="/cdn/images/aosabook/51.png" alt=""></p><p>图4.1 相同的数据三种不同的呈现方式：对数，极坐标，兰伯特投影</p><p>基于这些简单的模块，matplotlib可以做一些相当高级的东西。混合变换是一种使用了X和Y两个坐标变换的特殊变换。这仅在给定的变换是分离的（也就是X和Y坐标是独立的，但是它们自身可能既是仿射的又是非仿射的）情况下才有可能。举个例子，这被用于绘制X和Y轴都是对数标尺的对数图像。混合变换节点让组合变换可以以任意方式组合。变换图同时还允许共享坐标轴。可以将一个图连接到另一个图，并且保证当其中一个缩放或者平移的时候，另外一个也做出相应的更新来适应其对应的图。在这种情况下，相同的变换节点被简单地由两个坐标轴共享，甚至可能出现在两个完全不同的图表上。图4.2展示了这样的一个例子。其中axes1有一个对数x轴，axes1和axes2共享一个y axes。</p><p><img src="/cdn/images/aosabook/52.png" alt=""></p><p>图4.2 变换图示例</p><p>##5.折线管道##<br>当绘制折线图的时候，从原始数据到屏幕输出，中间有许多步骤要执行。在matplotlib的早期版本，这些步骤是纠缠在一起的。此后，他们被重构，从而使它们在一个路径转换的管道中分离开来。这就使得每个后端可以选择执行管道的某一个部分，因为有一些只在某些上下文中才会有用。</p><ul><li>Transformation：坐标由数据表示转换到图像表示。如果这是一个纯粹的仿射变换（见前面的定义），那么这就和矩阵乘法一样简单。如果涉及到任意变换，变换函数就会被调用，将坐标转换到图像空间。</li><li>Handle missing data:数据数组中可能会有缺失或者失效的部分。用户可以用NaN来申明这些部分，或者用numpy来隐藏这些数组。矢量输出格式，比如PDF和渲染库（比如Agg）,在绘制折线的时候，就从来没有缺失数据这一概念，因此绘图管道的这一步就必须用MOVETO命令跳过缺失的数据段，并告诉渲染器从一个新的点开始重新绘制。</li><li>Clipping：图像边界之外的点会增加文件的大小。更重要的是，非常大或者非常小的坐标值会在渲染的时候导致溢出错误，从而生成一堆乱码输出。管道的多边形裁剪这一步是为了避免这两个问题。</li><li>Snapping：完美垂直和水平的直线，当它们的中心没有对齐到像素中心时，可能会因为抗锯齿而看起来有点模糊（如图 5.1）。管道的snapping这一步首先会决定整个折线是不是有垂直或水平段（比如一个坐标对齐的长方形），如果是这样的话，将这个长方形的每个顶点近似到它各自最近的像素中心点。这一步仅用于光栅输出的后端，因为矢量后端应该继续使用准确的数据点。一些支持矢量文件格式的渲染器，比如Adobe Acrobat，在呈现到屏幕的时候才会做snapping操作。</li></ul><p><img src="/cdn/images/aosabook/53.png" alt=""></p><p>图 5.1 像素对齐的细节效果。左边：无像素对齐，右边有像素对齐。</p><ul><li>Simplification：当绘制非常稠密的图表时，线上的很多顶点实际上并不会显示出来。这在表示噪声波的图表上特别明显。将这些点添加在图表上会增加文件大小，甚至会达到该文件格式所允许的顶点数上限。因此，任何位于相邻两点的连线上的点都将被移除（如图5.2）。这个判定基于用户设置的解析度。</li></ul><p><img src="/cdn/images/aosabook/54.png" alt=""></p><p>图 5.2 右图是左边的某个细节部分。右图中圈起来的那个点由于位于相邻两个点的连线上，因此是多余的，所以被路径简化算法自动移除了。</p><p>##6.数学公式##<br>由于许多matplotlib的用户是科学工作者，在图表上直接添加丰富的格式化的数学表达式是非常有用的。可能最被广泛使用的数学表达式语法是Donald Knuth的TeX排版系统。它将像这样的纯文本输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sqrt&#123;\frac&#123;\delta x&#125;&#123;\delta y&#125;&#125;</span><br></pre></td></tr></table></figure><p>转换为格式化的数学表达式。</p><p>matplotlib提供了两种方法来渲染数学表达式。第一种就是使用tex语法，在用户机器上使用完整的TeX系统来渲染数学表达式。TeX在它自己的原生DVI（设备独立）格式中输出字符和线的位置。matplotlib然后解析DVI文件并将其转换成一系列的绘图命令，其中某一个输出后端就直接渲染到图表上。这种方法解决了许多模糊的数学语法。不过，它要求用户有一个完整可运行的TeX，因此，matplotlib也有它自己的内部数学渲染引擎，名叫mathtext。</p><p>mathtext是一个直接的TeX数学渲染引擎接口，整合了一个相当简单的用pyparsing解析框架写的解析器。这个接口基于TeX的公开版源码。这个简单的解析器建立一个盒子树和连接器（在TeX的命名空间），然后由布局引擎布局。尽管完整的TeX数学渲染引擎被整合进来了，但是一大批的第三方TeX和LaTeX数学库却没有。这个整合的原则是基于用到才会被整合进来，像一些使用频率非常高的，不具备学科单独特性的接口会被整合。这使得mathtext成为一个漂亮轻巧的,能够渲染大多数数学表达式的方式。</p><p>##7.回归测试##<br>从历史上来看，matplotlib并没有大量的低级单元测试。偶然的，如果一系列bug被报告了，会有一个脚本将它复制到对应的在源码树中的目录。缺少自动化测试导致了所有这些常见的问题，最重要的是回退到以前能工作的特性。（我们可能不需要安利你自动化测试是一个好东西）。当然，有这么多的代码，这么多的配置选项和可互换的模块（比如很多的后端），有争议的是，独立的低级别的单元测试可能是远远不够的。相反，我们认为测试一起测试所有的模块才是最具有性价比的。</p><p>为此，作为第一次的努力，我们写了一个可以生成许多图表的，用于测试matplotlib各个特性的脚本，尤其针对那些不容易正确的部分。<br>这使得检测新变化导致的无意间的破损变得更加容易，但是图表的正确性还是需要手动去检查。因为这需要许多手工操作，所有我们不经常做这样的检测。</p><p>到了第二阶段，这些普遍的方法都已经自动化了。目前的matplotlib测试脚本生成许多的图表，但是已经不需要手工干预了，那些图表会自动和基准图像比较。所有这些测试都在nose测试框架内运行，并且使得生成哪些测试失败的报告变得非常容易。</p><p>使问题复杂化的是，图像的对比是不准确的。在FreeType字体渲染库版本的微妙变化可以使文本稍有不同，在不同的机器上输出。这些差异不足以被认为是“错误的”，但也足以把任何确切的位比较。相反，测试框架计算两个图像的直方图，并计算其差异的根均方。如果这种差异大于给定的阈值，则图像被视为太大，而比较测试失败。当测试失败了，展示两张图片不同的差异图像就会生成（如图 7.1）。开发人员可以决定是否是由于故意改变和更新的基线图像匹配的新的图像，或决定的图像是在事实上不正确和跟踪和修复的错误造成的变化。</p><p><img src="/cdn/images/aosabook/55.png" alt=""></p><p>图 7.1 回归测试图比较。从左到右：a)期望的图像,b)测试结果，c)两张图的差异</p><p>由于不同的后端可以提供不同的bug，测试框架，测试多个后端的每个情节：PNG、PDF和SVG。对于矢量格式，我们不比较矢量信息直接，因为有多种表达方式有相同的结果时，光栅化。矢量的后台可以自由改变其输出的细节来提高效率而不引起所有失败的测试。因此，矢量的后端，测试框架首先将文件光栅使用外部工具（Ghostscript的PDF和Inkscape SVG）然后使用栅格数据的比较。</p><p>使用这种方法，我们能够引导一个合理有效的测试框架，从零开始，更容易比我们已经走上写下许多低级别的单元测试。然而，它不是完美的，测试的代码覆盖率不是很完整，它需要很长的时间来运行所有的测试。（在2.33 GHz英特尔核心2 e6550。约15分钟）因此，一些回归仍然通过裂缝下降，但总体质量的发布以来的测试框架的实施大大提高了。</p><p>##8.学到的东西##<br>一位来自matplotlib发展的重要教训是，正如柯布西耶说：“好的建筑师借”。Matplotlib早期作者主要科学家，自学的程序员试图做他们的工作，没有受过正式训练的计算机科学家。因此，我们没有得到内部设计上的第一次尝试。决定实施一个面向用户的脚本层在很大程度上兼容Matlab API受益项目三个重要方面：它的时间测试接口来创建和自定义图形提供了一个简单的过渡从MATLAB用户基数大，matplotlib，最重要的是我们在matplotlib建筑释放开发者重构内部的面向对象的API几次与大多数用户的影响最小，因为脚本接口不变。虽然我们已经从一开始就已经拥有了一个接口的用户（相对于脚本用户），其中大多数是用户或开发人员能够适应原料药的变化。另一方面，脚本用户可以编写一次代码，相当多的假设它是稳定的，为所有后续版本。</p><p>对于内部绘图API，同时我们也借GDK，我们没有花足够的努力确定这是否是正确的绘图API，不得不花费相当大的力气随后经过许多后台写这个API在更简单和更灵活的绘图API的功能扩展。我们会一直采用PDF图纸规范[ ent11b ]很好的服务，这本身就是从几十年的发展经验与Adobe PostScript规范；它会给我们多出的PDF里面的兼容性，石英核心图形框架，和enthought使Kiva绘图。</p><p>一个Python的诅咒，这是一个很容易和富于表现力的语言，开发商往往更容易重新发明和重新实现的功能存在于其他包比工作整合其他包的代码。matplotlib可以得益于早期的发展从花费更多的努力在现有的模块集成和API如enthought的Kiva和使工具包解决很多类似的问题，而不是重塑功能。然而，与现有的功能集成，一把双刃剑，因为它可以使建立和释放更复杂，减少内部发展的灵活性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Matplotlib&quot;&gt;&lt;a href=&quot;#Matplotlib&quot; class=&quot;headerlink&quot; title=&quot;Matplotlib&quot;&gt;&lt;/a&gt;Matplotlib&lt;/h1&gt;&lt;p&gt;matplotlib是一个基于Python的绘图库，完全支持二维图表绘制，对
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>SQLAlchemy</title>
    <link href="http://blog.ccao.cc/2018/09/28/SQLAlchemy/"/>
    <id>http://blog.ccao.cc/2018/09/28/SQLAlchemy/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.673Z</updated>
    
    <content type="html"><![CDATA[<p>SQLAlchemy诞生于2005年，是一个Python语言的数据库工具包和对象关系映射(ORM)系统。在一开始，SQLAlchemy是一个提供使用Python数据库API（DBAPI）处理关系数据库的端到端系统。它的核心特性包括顺畅地处理复杂的SQL查询和对象映射和“工作单元”(unit of work)模式的实现。这些特性使得SQLAlchemy能够提供高度自动化的数据库系统，因此SQLAlchemy在很早期的几个版本里就受到了大量的关注。</p><p>SQLAlchemy从一个小的、实现粗糙的概念开始，通过一系列的修订迅速进步。在用户技术不断增长的同时，内部架构和外部API也在迭代更新。在2009年1月0.5版本面世时，SQLAlchemy已经在大范围的生产部署后稳定了下来，到了0.6版本（2010年4月）和0.7版本（2011年5月），架构和API的改进使得生产最高效和最稳定的库成为可能。在写作本文时，SQLAlchemy已经在多个领域中被大量组织所采用。在很多人眼中，它已经成为Python关系数据库处理事实上的标准。</p><h2 id="20-1-数据库抽象面临的挑战"><a href="#20-1-数据库抽象面临的挑战" class="headerlink" title="20.1 数据库抽象面临的挑战"></a>20.1 数据库抽象面临的挑战</h2><p>术语“数据库抽象”通常用来表示一个隐藏了数据存储和查询的细节的系统。人们有时候会把这个术语极端化，认为不仅关系数据库的细节应当被系统隐藏，甚至连关系结构本身都应当隐藏，用户不需要关心底层的存储结构是否是关系型的。</p><p>对ORM最常见的评论文章认为这种系统的主要目标就是如上所述——把关系数据库“藏起来”，接管构建数据库和与数据库交互的任务，降格为底层实现细节。这种方式的核心在于剥夺开发人员对关系结构进行设计和查询的能力，转交由不透明的库来处理。</p><p>经常和关系数据库打交道的人都知道，这种方式是完全不切实际的。关系结构和SQL查询的功能性很强，组成了软件设计的核心。如何设计、组织、操纵这些结构不仅取决于要查询哪些数据，还取决于数据的结构。如果隐藏了数据的结构，在一开始使用关系型数据库就没有意义了。</p><p>既要寻求屏蔽关系数据库底层细节的方法，又面对着关系数据库需要详尽的说明的事实。这种矛盾通常被称为“对象-关系阻抗失配”(object-relational impedance mismatch)问题。SQLAlchemy采用了一种比较新颖的方法来解决这个问题。</p><h4 id="SQLAlchemy-解决数据库抽象的方法"><a href="#SQLAlchemy-解决数据库抽象的方法" class="headerlink" title="SQLAlchemy 解决数据库抽象的方法"></a>SQLAlchemy 解决数据库抽象的方法</h4><p>SQLAlchemy认为开发人员必须考虑数据的关系结构。一个预先定义并隐藏数据模式(schema)和查询方法的系统只是在忽视关系型数据库的意义，导致传统的阻抗失配问题。</p><p>但与此同时，这些决定的实现可以在，也应该在尽可能高的层次模式上执行。建立对象模型和数据库模式间的关联、并在SQL查询中保持这种关联是一个重复性很高的工作。使用工具自动化执行这些任务，可以使应用开发更加简洁、高效。创建自动化工具的时间，远远少于手工实现这些操作的时间。</p><p>SQLAlchemy称自己是一个工具包，强调开发人员的角色应是关系结构及其与应用程序间联系的设计者和构建者，而不是被动地接受一个第三方库所做的决定。SQLAlchemy采取“不完全抽象”理念，暴露关系概念，鼓励开发者在应用程序和关系数据库之间裁剪出一个自定义的、但又是完全自动化的交互层。SQLAlchemy的创新之处在于，它在不牺牲开发者对于关系数据库的控制的同时，实现了高度的自动化。</p><h2 id="20-2-核心层与ORM层"><a href="#20-2-核心层与ORM层" class="headerlink" title="20.2 核心层与ORM层"></a>20.2 核心层与ORM层</h2><p>SQLAlchemy工具包的中心目标是在数据库交互的每一层都开放丰富的API，将任务划分为核心层和ORM层。核心层包括Python数据库API(DBAPI)的交互，生成数据库能够识别的SQL语句，以及模式(schema)管理。这些功能都通过公开的API来展现。ORM层，或者叫对象-关系映射层，则是构建在核心层上的一个特定的库。SQLAlchemy提供的ORM层只是可以构建在核心层上的众多对象抽象层的其中一个，很多开发者和组织是直接在核心层上构建自己的应用。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/layers.png" alt="图20.1: SQLAlchemy层次图"></p><p>核心层和ORM层的分离一直是SQLAlchemy最典型的特征，这个特征既有优点也有缺点。核心层的显式存在导致：（一）ORM需要将映射到数据库的类属性关联到一个叫’’Table’’的结构上，而不是直接关联到数据库中表述的字符串属性名。（二）ORM需要使用一个叫’’select’’的结构来产生SELECT查询，而不是直接将对象属性拼接成一个字符串的语句。（三）ORM需要从’’ResultProxy’’接受结果行（’’ResultProxy’’自动将’’select’’映射到每个结果行），而不是直接操纵数据库游标(cursor)将数据转化成用户定义的对象。</p><p>在一个很简单的以ORM为中心的应用中，核心层的元素可能是不可见的。然而，由于核心层是仔细地集成到ORM层，能够支持两个层次间流畅的转化的，一个复杂得多的ORM中心的应用，在形势所迫时，可以“下潜”一两个抽象层次，更具体、更细致地处理数据库。随着SQLAlchemy日渐成熟，ORM层提供了越来越多的全面周到的模式，核心层的API在常规使用中已经很少明显出现了。然而，核心层可操控也是SQLAlchemy早期成功的因素之一，因为这让早期的用户在ORM还不成熟的时候，可以做到很多看似不可能的事情。</p><p>核心层/ORM层的缺点是，一个指令必须经过更多的步骤。对于Python传统的C实现，单独的函数调用是额外开销的主要来源，导致了运行时速度缓慢。对此，传统的改善方法是通过重排和内联缩短调用链，并且将性能需求高的模块用C代码代替。SQLAlchemy多年来一直在用这两种方法来提升性能。然而，随着Python的PyPy解释器逐渐被接受，由于PyPy通过JIT的内联和编译减少了长调用链的影响，SQLAlchemy遗留的性能问题或许已经可以忽略，不需要使用C代码来代替。</p><h2 id="20-3-改良DBAPI"><a href="#20-3-改良DBAPI" class="headerlink" title="20.3 改良DBAPI"></a>20.3 改良DBAPI</h2><p>SQLAlchemy的底层是一个通过DBAPI和数据库进行交互的系统。DBAPI本身不是一个实际的库，只是一个规范。因此，DBAPI有不同的实现，有的是针对特定的目标数据库，比如MySQL或PostgreSQL，有的是针对特定的非DBAPI数据库适配器，如ODBC和JDBC。</p><p>DBAPI为SQLAlchemy提出了两点挑战。一点挑战是为DBAPI的基本使用模式提供一个易用且功能全面的界面（译注：facade，即对外提供简化过的接口），另一点挑战是应对极其多变的DBAPI具体实现和数据库引擎。</p><h4 id="方言系统"><a href="#方言系统" class="headerlink" title="方言系统"></a>方言系统</h4><p>DBAPI描述的接口极其简单。它的核心组件就是DBAPI自己，连接（connection）对象，和游标（cursor）对象——“游标”在数据库中指一个语句（statement）和它相关的结果的上下文。它们相互配合，连接数据库并提取数据的一个简单的例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">connection = dbapi.connect(user=&quot;user&quot;, pw=&quot;pw&quot;, host=&quot;host&quot;)</span><br><span class="line">cursor = connection.cursor()</span><br><span class="line">cursor.execute(&quot;select * from user_table where name=?&quot;, (&quot;jack&quot;,))</span><br><span class="line">print &quot;Columns in result:&quot;, [desc[0] for desc in cursor.description]</span><br><span class="line">for row in cursor.fetchall():</span><br><span class="line">    print &quot;Row:&quot;, row</span><br><span class="line">cursor.close()</span><br><span class="line">connection.close()</span><br></pre></td></tr></table></figure><p>SQLAlchemy在传统的DBAPI会话之上进行了封装。一开始调用’’create_engine’’，将连接和配置信息装配好，并返回一个’’Engine’’类的对象，通过这个对象访问不直接对外开放的DBAPI。</p><p>对于简单的语句执行，’’Engine’’提供了一个叫“隐式执行”（implicit execution）的接口。获取和关闭DBAPI连接的工作过程都被隐藏了起来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">engine = create_engine(&quot;postgresql:*user:pw&amp;#64;host/dbname&quot;)</span><br><span class="line">result = engine.execute(&quot;select * from table&quot;)</span><br><span class="line">print result.fetchall()</span><br></pre></td></tr></table></figure><p>从0.2版起，SQLAlchemy加入了Connection对象，提供显式维护DBAPI连接的功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conn = engine.connect()</span><br><span class="line">result = conn.execute(&quot;select * from table&quot;)</span><br><span class="line">print result.fetchall()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><p>‘’Engine’’、’’Connection’’两个类的’’execute’’方法返回的结果是一个’’ResultProxy’’，它提供了一个与DBAPI的游标类似但功能更丰富的接口。’’Engine’’，’’Connection’’和’’ResultProxy’’分别对应于DBAPI模块、一个具体的DBAPI连接对象，和一个具体的DBAPI游标对象。</p><p>在底层，’’Engine’’引用了一个叫’’Dialect’’的对象。’’Dialect’’是一个有众多实现的抽象类，它的每一个实现都对应于一个具体的DBAPI和数据库。一个为’’Engine’’而创建的’’Connection’’会咨询’’Dialect’’作出选择，对于不同的目标DBAPI和数据库，’’Connection’’的行为都不一样。</p><p>‘’Connection’’创建时会从一个连接池获取并维护一个DBAPI的连接，这个连接池叫’’Pool’’，也和’’Engine’’相关联。’’Pool’’负责创建新的DBAPI连接，通常在内存中维护DBAPI连接池，供频繁的重复使用。</p><p>在一个语句执行的过程中，’’Connection’’会创建一个额外的’’ExecutionContext’’对象。这个对象从开始执行的时刻，一直存在到’’ResultProxy’’消亡为止。</p><p>图20.2说明了所有这些对象之间的关系，以及它们与DBAPI组件间的关系。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/engine.png" alt="图20.2： Engine, Connection, ResultProxy API"></p><h4 id="处理DBAPI多变性"><a href="#处理DBAPI多变性" class="headerlink" title="处理DBAPI多变性"></a>处理DBAPI多变性</h4><p>为了管理DBAPI多变的行为，首先我们需要考虑问题的领域。DBAPI的规约（目前是第二版）定义为一组很大程度上允许行为多变且留有许多未定义领域的API。于是，实际使用的DBAPI在多个领域都显示出很大程度的多变性，包括是否接受Python Unicode字符串，是否能够在INSERT语句执行后获取自动生成的主键，是否能说明参数的取值范围。这些DBAPI同样还有很多面对不同类型时的特殊行为，包括处理二进制、高精度数值、日期、布尔、Unicode等类型。</p><p>SQLAlchemy通过允许’’Dialect’’和’’ExecutionContext’’的多级子类多样性来解决这个问题。图20.3展示了当使用psycopg2时’’Dialect’’和’’ExecutionContext’’间的关系。’’PGDialect’’类提供了特定于PostgreSQL数据库的行为，包括ARRAY数据类型和schema catalog；’’PGDialect_psycopg2’’类提供了特定于psycopg2 DBAPI的行为，包括Unicode处理和服务器端游标行为。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/dialect-simple.png" alt="图20.3： 简单的Dialect/ExecutionContext继承体系"></p><p>在处理支持多个数据库的DBAPI时，会出现上述模式的一个变体。这样的例子包括pyodbc（处理经由ODBC的任意数据库后端）和zxjdbc（一个处理JDBC的Jython驱动）。上述关系通过使用一个混入类(mixin class)得到扩展。混入类来自’’sqlalchemy.connectors’’包，提供了不同后端共有的DBAPI行为。图20.4展示了’’sqlalchemy.connectors.pyodbc’’中由不同的pyodbc方言（如MySQL方言和Microsoft SQL Server方言）共有的功能。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/common-dbapi.png" alt="图20.4：dialect继承体系中的DBAPI行为"></p><p>‘’Dialect’’和’’ExecutionContext’’对象提供了定义与数据库和DBAPI的每一项交互的方法，包括连接的参数应该如何格式化，包括如何处理语句执行时的古怪行为。’’Dialect’’还生成了SQL编译构件（用于为目标数据库正确生成SQL）和类型对象（用于定义Python数据与目标DBAPI和数据库间如何互相转化）。</p><h2 id="20-4-模式定义"><a href="#20-4-模式定义" class="headerlink" title="20.4 模式定义"></a>20.4 模式定义</h2><p>在数据库连接和交互建立好之后，下一步就是要提供创建和操纵SQL语句的方法了。为了实现这一点，首先需要定义我们将如何表示数据库中的表和字段(column)——也即所谓的的“模式”(schema)。表和字段表示了数据的组织方式，大部分的SQL语句是由和它们相关的的表达式和命令组成的。</p><p>一个ORM或是数据访问层需要在程序级提供对SQL语言的访问，此方法的基础是描述表和字段的编程系统。SQLAlchemy在这里通过提供’’Table’’和’’Column’’构件，独立于用户的模型类定义描述数据库结构，将核心层和ORM层分离。将模式定义与ORM分离的原理在于，关系模式可以用关系数据库的术语（如果必要，还包括平台特定的细节）无歧义地设计，而无需对象-关系概念——这完全是两码事。独立于ORM组件也意味着模式描述系统对任何其他可能构建在核心层上的对象-关系系统都很重要。</p><p>‘’Table’’和’’Column’’模型包含在一个叫做<em>metadata</em>（元数据）的概念内，用一个叫’’MetaData’’的集合对象代表’’Table’’对象的集合。这个结构主要源于Martin Fowler在<em>Patterns of Enterprise Application Architecture</em>一书中描述的“元数据映射”(MetaData Mapping)。图20.5展示了’’sqlalchemy.schema’’包中的一些关键元素。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/basic-schema.png" alt="图20.5： sqlalchemy.schema基本对象"></p><p>‘’Table’’表示了目标schema中一个实际的表的名字等属性，它所含的’’Column’’对象集合代表了每个表中字段的名字和类型信息。’’Table’’中还含有一系列完整的描述constraint, index, sequence的对象，其中一些对引擎和SQL构建系统的行为影响很大。特别的，’’ForeignKeyConstraint’’在决定两个表如何进行连接上非常关键。</p><p>‘’Table’’和’’Column’’相比schema包中的的其他类的独特之处在于他们是双重继承的，从’’sqlalchemy.schema’’和’’sqlalchemy.sql.expression’’包中同时继承。它们不仅是作为schema级的模块，也是SQL表达式语言的语法单元。这个关系在图20.6中展示。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/table-column-crossover.png" alt="图20.6： Table和Column的双重身份"></p><p>从图20.6中我们可以看出，’’Table’’继承自SQL的’’FromClause’’，即“你能select的对象”；’’Column’’继承自SQL的’’ColumnElement’’，即“你能在SQL表达式中使用的东西”。</p><h2 id="20-5-SQL表达式"><a href="#20-5-SQL表达式" class="headerlink" title="20.5 SQL表达式"></a>20.5 SQL表达式</h2><p>在SQLAlchemy诞生之初，如何生成SQL并不明确。一个文本语言是最可能的选择，因为这是一个普遍的方法，Hibernate’s HQL等知名的对象-关系工具都以此作为核心。然而，在Python中有一个更好的方法：使用Python的对象和表达式生成表达式树结构，甚至是重载Python的操作符使其表现出SQL语句的行为。</p><p>SQLAlchemy的表达式语言使用的Python对象和操作符主要受到lan Bicking的SQLObject中包含的SQLBuilder库的启发，虽然它也许不是第一个这么做的工具。在这种方式中，Python对象代表了一个SQL表达式的词法单元。这些对象的方法和重载的操作符就生成了源于它们的词法结构。最常见的对象是”Column”对象——SQLObject用一个映射到ORM上的类代表”Column”，放置在可以通过’’.q’’属性访问的命名空间里；SQLAlchemy则将属性命名为’’.c’’。这个’’.c’’属性一直保留到现在，在核心层的selectable元素，如表示table和select语句的元素上使用。</p><h4 id="表达式树"><a href="#表达式树" class="headerlink" title="表达式树"></a>表达式树</h4><p>SQLAlchemy中的SQL表达式很像在分析SQL语句中产生的结构——一个分析树。唯一的不同在于开发者是直接构造出一个分析树，而不是从一个字符串中分析得到。分析树上节点的核心类型叫做’’ClauseElement’’，图20.7描述了’’ClauseElement’’和其他一些关键的类之间的关系。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/expression-hierarchy.png" alt="图20.7： 基本的表达式继承体系"></p><p>通过使用构造函数，方法，重载的表达式，语句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT id FROM user WHERE name = ?</span><br></pre></td></tr></table></figure></p><p>的结构可以这样在Python中构造出来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sqlalchemy.sql import table, column, select</span><br><span class="line">user = table(&apos;user&apos;, column(&apos;id&apos;), column(&apos;name&apos;))</span><br><span class="line">stmt = select([user.c.id]).where(user.c.name==&apos;ed&apos;)</span><br></pre></td></tr></table></figure><p>上面代码中’’select’’的结构如图20.8所示。注意到’’_BindParam’’中包含一个’’’ed’’’值，这会使SQL语句中产生一个用问号表示的bound parameter marker.</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/example-expression.png" alt="图20.8：表达式树示例"></p><p>从树的图形上我们可以看出，一个简单的自顶向下遍历就可以快速产生出一条SQL语句。我们在后面语句编译的部分还会详细探究。</p><h4 id="Python操作符"><a href="#Python操作符" class="headerlink" title="Python操作符"></a>Python操作符</h4><p>在SQLAlchemy中，一个像这样的表达式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">column(&apos;a&apos;) == 2</span><br></pre></td></tr></table></figure><p>得到的既不是’’True’’也不是’’False’’，而是一个SQL表达式结构。做到这一点的核心在于使用Python特殊操作符函数（如’’__eq__‘’, ‘’__ne__‘’, ‘’__le__‘’, ‘’__lt__‘’, ‘’__add__‘’, ‘’__mul__‘’）实现的操作符重载。面向字段的表达式节点通过使用混入类’’ColumnOperators’’提供重载的操作符。使用操作符重载后，表达式’’column(‘a’) == 2’’等价于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sqlalchemy.sql.expression import _BinaryExpression</span><br><span class="line">from sqlalchemy.sql import column, bindparam</span><br><span class="line">from sqlalchemy.operators import eq</span><br><span class="line"></span><br><span class="line">_BinaryExpression(</span><br><span class="line">    left=column(&apos;a&apos;),</span><br><span class="line">    right=bindparam(&apos;a&apos;, value=2, unique=True),</span><br><span class="line">    operator=eq</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>‘’eq’’实际上是一个源于Python内置的’’operator’’的一个函数。将操作符表示为一个对象（如’’operator.eq’’）而不是一个字符串（如’’=’’）使字符串表示可以在语句编译时，针对具体的数据库方言指定。</p><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p>与SQL表达式树产生出字符串的SQL相关的中心类是’’Compiled’’类。这个类有’’SQLCompiler’’和’’DDLCompiler’’两个主要的子类。’’SQLCompiler’’为SELECT，INSERT，UPDATE，DELETE语句处理SQL渲染工作，这些语句统称为DQL（数据查询语言）和DML（数据操纵语言）。而’’DDLCompiler’’是处理CREATE和DROP语句的，这些语句统称为DDL（数据定义语言）。从’’TypeCompiler’’开始还有另一支类继承体系，关注类型的字符串表示。每个数据库方言提供自己的子类，继承自三个compiler type，来定义SQL语言特定于目标数据库的方面。图20.9提供了这个类继承体系关于PostgreSQL方言的概览。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/compiler-hierarchy.png" alt="图20.9： 编译器继承体系，包括特定于PostgreSQL的实现"></p><p>‘’Compiled’’的子类提供了一系列的<em>visit</em>方法，每一个<em>visit</em>方法都被’’ClauseElement’’的一个特殊子类所引用。通过对（语法树上的）’’ClauseElement’’节点进行遍历，递归地连接每个visit函数的字符串输出，就构建出了一个语句。在这个过程中，’’Compiled’’对象维护关于匿名标识符名、bound parameter名，以及嵌套子查询的状态。这些都是为了产生出一个字符串形式的SQL语句，和带有默认值的bound parameter集合。图20.10展示了visit函数产生出字符串单元的过程。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/statement-compilation.png" alt="图20.10： 一个语句编译过程中的调用树"></p><p>一个完整的’’Compiled’’结构包括完整的SQL字符串和绑定值的集合。’’ExecutionContext’’将他们强制转换为DBAPI的’’execute’’方法所期望的格式，包括如下方面的考虑：Unicode语句对象的处理，存储绑定值使用的集合类型，以及绑定值自己如何强制转换为适合DBAPI和目标数据库的表示的规范。</p><h2 id="20-6-ORM的类映射"><a href="#20-6-ORM的类映射" class="headerlink" title="20.6 ORM的类映射"></a>20.6 ORM的类映射</h2><p>我们现在将注意力转移到ORM上来。第一个目标是使用我们定义的表元信息(table metadata)系统，允许从用户定义的类到数据库表中的字段集合的映射。第二个目标是基于数据库中表间的关系，允许定义用户定义的类之间的关系。</p><p>SQLAlchemy将这个叫做“映射”(mapping)，这个名字来自Fowler的<em>Patterns of Enterprise Architecture</em>一书描述的著名的数据映射器模式(Data Mapper Pattern)。总体来看，SQLAlchemy的ORM很大程度上从Fowler详细描述的实践中借鉴而来。它还受到了著名的Java关系映射器Hibernate和lan Bicking的SQLObject的很大影响。</p><h4 id="Classical-vs-Declarative"><a href="#Classical-vs-Declarative" class="headerlink" title="Classical vs. Declarative"></a>Classical vs. Declarative</h4><p>我们使用术语<em>传统映射(classical mapping)</em>来指代SQLAlchemy将对象-关系数据映射应用到已存在的用户类的系统。这种映射形式取’’Table’’对象和用户定义的类，将两个独立定义的实体用一个叫’’mapper’’的函数结合在一起。一定’’mapper’’应用在一个用户定义的类上，这个类就新获得了与表中字段对应的属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class User(object):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">mapper(User, user_table)</span><br><span class="line"></span><br><span class="line"># now User has an &quot;.id&quot; attribute</span><br><span class="line">User.id</span><br></pre></td></tr></table></figure><p>‘’mapper’’还能给类加上其他的属性，包括对应于其他对象引用的属性，也包括对应于任意SQL表达式引用的属性。给一个类添加任意属性的过程在Python中叫做“猴子补丁”(monkeypatching)。然而，由于我们并不是任意地添加属性，而是用数据驱动的方式添加，这个行为用术语<em>class instrumentation</em>来表达更为准确。</p><p>SQLAlchemy近来的用法主要关注声明式（Declarative）扩展。声明式扩展是一个配置系统，看起来像是许多其他对象-关系工具使用的常见的类似活动记录的类声明系统。在这个系统中，最终用户显式在类定义中定义属性，每个属性代表类上一个需要被映射的属性。在大多数情况下，’’Table’’类和’’mapper’’函数都不会显式提及，只有类、’’Column’’对象、其他ORM相关的属性出现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class User(Base):</span><br><span class="line">    __tablename__ = &apos;user&apos;</span><br><span class="line">    id = Column(Integer, primary_key=True)</span><br></pre></td></tr></table></figure><p>在上面的例子中，看起来是通过’’id = Column()’’直接实现了class instrumentation，但实际上并不是这样。声明式扩展使用一个Python元类（一种在一个类新定义时执行一系列操作的简便方法）来从已定义的类生成一个新的’’Table’’对象，并将这个对象和原来的类一起传给’’mapper’’函数，’’mapper’’函数用完全相同的方式实现功能，将它自己的属性附加到类上（在这个例子中，是’’id’’属性），取代原先的属性值。在元类的初始化完成时（即执行流离开’’User’’类描述的区块时），被’’id’’标记的’’Column’’对象已经移动到了一个新的’’Table’’中，并且’’User.id’’已经被一个特定于映射的新属性所取代。</p><p>SQLAlchemy看似应该有一个描述简单的声明式配置形式。然而，为了支持传统映射继续稳固化的工作，对声明式的支持被推迟了。在早期有一个叫ActiveMapper的临时扩展（后来成为了Elixir项目）支持声明式映射。它在一个高层的声明系统中重新定义了映射构件。声明式映射的目标是反转Elixir重度抽象方法的方向。它建立了一个系统，几乎原样保留了SQLAlchemy的传统映射概念，只是重新组织了它们的使用方式，使之更加简洁，并相比传统映射更适应类级扩展。</p><p>无论使用传统映射还是声明式映射，映射到的类都表现出新的特性，能够根据自己的属性表达SQL构件。SQLAlchemy原先继承了SQLObject的行为，使用一个特殊的属性来获取SQL字段表达式，在SQLAlchemy中这个属性叫做’’.c’’，如下面的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = session.query(User).filter(User.c.username == &apos;ed&apos;).all()</span><br></pre></td></tr></table></figure><p>然而，在版本0.4中，SQLAlchemy将这个功能移到映射到的属性自身：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = session.query(User).filter(User.username == &apos;ed&apos;).all()</span><br></pre></td></tr></table></figure><p>这个属性访问上的变化被证明是一个巨大的进步，因为它允许在类上出现类似字段（而不是字段）的对象获得额外的特定于类的能力，这些能力并不直接源于底层的’’Table’’对象。它还允许不同类型的类属性的集成使用，比如指向直接表中字段的属性，指向从字段生出的SQL表达式的属性，还有指向相关类的属性。最终，它实现了映射类和映射类的实例的对称性，因为同样的属性在不同的类中会有不同的行为。类上的属性返回SQL表达式，而实例上的属性返回实际的数据。</p><h4 id="映射剖析"><a href="#映射剖析" class="headerlink" title="映射剖析"></a>映射剖析</h4><p>添加到’’User’’类中的’’id’’属性是Python中的<em>描述符</em>（descriptor）对象——一个有’’__get__‘’, ‘’__set__‘’和’’__del__‘’方法的对象，Python在运行时对所有关于这个属性的类的实例的操作都咨询它。SQLAlchemy的实现是’’InstrumentedAttribute’’，我们将用另一个例子揭示在此表象之下的内容。我们从一个’’Table’’和用户定义的类开始，建立了一个只有一个字段的映射，和一个定义了到相关类的引用的’’relationship’’：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">user_table = Table(&quot;user&quot;, metadata,</span><br><span class="line">    Column(&apos;id&apos;, Integer, primary_key=True),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">class User(object):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">mapper(User, user_table, properties=&#123;</span><br><span class="line">    &apos;related&apos;:relationship(Address)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>当映射是完整的时候，和这个类相关的对象的结构在图20.11中详细描述。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/mapper-components.png" alt="图20.11：映射剖析"></p><p>这张图展示了SQLAlchemy的一个定义为两层分离的交互的映射，两层分别为用户定义的类和这个类映射到的表元数据。左半张图为class instrumentation，右半张图为SQL和数据库的功能。总体的模式为使用对象的组合来分离行为角色，使用对象继承区分一个角色下的行为差异。</p><p>在class instrumentation这半边，’’ClassManager’’和映射到的类相联系，而一组’’InstrumentedAttribute’’对象和映射到类上的每个属性相联系。’’InstrumentedAttribute’’还是前面提到的Python描述符，在基于类的表达式（如’’User.id==5’’中使用时，产生SQL表达式）。当处理’’User’’的一个实例时，’’InstrumentedAttribute’’将属性的行为委托给一个’’AttributeImpl’’对象——为所表示的数据定制的多个变体之一。</p><p>在映射这半边，’’Mapper’’代表了用户定义的类和一个可select单元（通常是’’Table’’）的关联。’’Mapper’’维护了一组’’MapperProperty’’属性对象，每个属性对象处理一个特定属性的SQL表示。’’MapperProperty’’最常见的变体是’’ColumnProperty’’（表示了一个映射到的字段或SQL表达式）和’’RelationshipProperty’’（表示了到另一个映射器的关联）。</p><p>‘’MapperProperty’’将属性加载行为——包括属性如何在SQL语句中渲染，如何从结果行生成——委派给’’LoadStrategy’’对象。这个对象有多个变体，每个变体决定一个属性的加载行为是<em>推迟</em>（deferred），<em>急切</em>（eager），还是<em>立即</em>（immediate）。映射器配置时会选定一个默认的行为，在查询时可以选择使用其他的策略。’’RelationshipProperty’’还引用了一个’’DependencyProcessor’’，这个类决定映射器间的依赖和属性同步在刷新（flush，具体含义见下一节——译者注）时如何处理。’’DependencyProcessor’’的决定基于和关系尾部(<em>parent</em>)和<em>头部</em>(target)可SELECT部件的关系图形。</p><p>‘’Mapper’’/‘’RelationshipProperty’’结构组成了一个图，其中’’Mapper’’对象是结点，’’RelationshipProperty’’对象是有向边。一旦应用程序定义全了所有的映射器，一个叫做<em>配置</em>(configuration)推迟的“初始化”步骤就开始进行了。初始化功能主要是每个’’RelationshipProperty’’使用，确定它的<em>尾部</em>(parent)和<em>头部</em>(target)映射器间的细节，包括选择’’AttributeImpl’’和’’DependencyProcessor’’。这个图是贯穿整个ORM操作的关键，和很多过程相关：所谓的“连锁反应”(cascade)，定义了操作如何沿着对象路径传播；查询操作中，相关对象和集合都“急切地”一次性加载；以及对象刷新部分，在开始一系列的持久化步骤前，建立所有对象的依赖图。</p><h2 id="20-7-查询和加载行为"><a href="#20-7-查询和加载行为" class="headerlink" title="20.7 查询和加载行为"></a>20.7 查询和加载行为</h2><p>SQLAlchemy通过’’Query’’对象创建所有的对象加载行为。’’Query’’起始的基本状态包括<em>实体</em>（entity），它是被映射的类和（或）用于查询的SQL表达式的列表。它还有一个’’Session’’的引用，代表了到一个或多个数据库的连接，以及关于这些连接上的事务累积下来的缓存数据。下面是一个简单的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sqlalchemy.orm import Session</span><br><span class="line">session = Session(engine)</span><br><span class="line">query = session.query(User)</span><br></pre></td></tr></table></figure><p>我们创建一个会产出’’User’’对象的’’Query’’，并和刚创建的’’Session’’关联起来。’’Query’’提供了一个生成式的构建模式(generative builder pattern)——前面讨论到的’’select’’构件也是这样的方式，一次方法调用会将额外的条件和修饰符关联到一个语句构件上。当在’’Query’’上调用一个迭代的操作时，它构建了一个SQL表达式结构表示一个SELECT，送往数据库，然后将结果集翻译为面向ORM的结果，对应于被查询实体的初始集合。</p><p>‘’Query’’在<em>SQL渲染</em>(SQL rendering)和<em>数据加载</em>(data loading)的这两部分操作之间做了一个艰难的区分。前者指的是构造一个SELECT语句，而后者指的是将SQL结果行翻译为映射到ORM的结构上。实际上，没有SQL渲染这一步，也可以进行数据加载，因为’’Query’’可能会要从用户手写的文本查询翻译到结果。</p><p>一系列主要的’’Mapper’’对象可以看成是一个图，每个字段或拥有’’ColumnProperty’’的SQL表达式看做叶节点，而每个’’RelationshipProperty’’看做是指向另一个’’Mapper’’结点的边。SQL渲染和数据加载都利用了图上的递归下降遍历方法。在每个结点上执行的动作最终是和每个’’MapperProperty’’相关的’’LoaderStrategy’’的工作，它在SQL渲染阶段将字段和连接(join)添加到创建中的SELECT语句中，在数据加载阶段生成处理结果行的Python函数。</p><p>在数据加载阶段生成的Python函数接收一个从数据库中获取的行，结果是改变内存中一个映射属性的状态。这些函数是在检查结果集中第一个到来的行，为一个特定的属性生成的。它们还受加载选项的影响。如果属性不需要加载，就不会生成函数。</p><p>图20.12展示了在<em>连接急切加载</em>(joined eager loading)场景中，几个’’LoaderStrategy’’对象的遍历过程，说明了它们在’’Query’’的’’_compile_context’’方法中连接到一个渲染过的SQL语句。图中还展示了在’’Query’’的’’instansces’’方法中生成<em>行填充</em>(row population)函数的过程，接收结果行，并填充一个对象的属性。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/query-loading.png" alt="图20.12：连接急切加载中loader strategy的遍历"></p><p>SQLAlchemy早期填充结果的方法使用了一个传统的遍历，将固定的对象方法和每个接受行的策略联系起来并对应工作。在0.5版本中第一次引入的可调用加载系统，极大地提升了性能。因为很多和行处理有关的决定只要在最开始做一次，而不是对每行都做一个决定，很多没有作用的函数调用就被消除了。</p><h2 id="20-8-会话-标识映射"><a href="#20-8-会话-标识映射" class="headerlink" title="20.8 会话/标识映射"></a>20.8 会话/标识映射</h2><p>在SQLAlchemy中，’’Session’’对象为ORM的实际使用（即加载和持久化数据）呈现了公共的接口。它提供了对指定的数据库连接进行查询和持久化操作的入口点。</p><p>‘’Session’’除了作为数据库连接的入口，还维护了一个集合的引用，这个集合包含内存中所有与此’’Session’’相关的映射实体。通过这种方式，’’Session’’实现了<em>标识映射</em>(identity map)和<em>工作单元</em>(unit of work)模式——两个由Fowler定义的模式。标识映射为一个特定的’’Session’’维护了一个所有对象的映射，映射的ID在数据库中是唯一的，消除了重复的标识带来的问题。工作单元建立在标识映射上，提供了一个自动化系统，用最高效的方式将所有状态的变动持久化到数据库中。实际的持久化步骤叫做“刷新”(flush)，在现在的SQLAlchemy中，这个步骤通常是自动的。</p><h4 id="开发历史"><a href="#开发历史" class="headerlink" title="开发历史"></a>开发历史</h4><p>‘’Session’’一开始是一个多半隐藏着的系统，负责发送刷新的单一任务。刷新过程包括发送SQL语句到数据库，与工作单元系统跟踪的对象的状态相一致，同步数据库和内存中的状态。刷新一直是SQLAlchemy所做的最复杂的操作之一。</p><p>在早期的版本中，对<em>刷新</em>(flush)的调用是在一个叫’’commit’’的方法之后，这个方法是在一个隐式的、局部于线程的’’objectstore’’对象上的。在SQLAlchemy 0.1中，不需要调用’’Session.add’’，也根本没有显式的’’Session’’概念。用户所做的步骤就是创建映射，创建新对象，修改由查询加载的已存在的对象，然后将所有的变化通过’’objectstore.commit’’命令持久化。操作集合的对象池无条件是模块全局的和线程局部的。</p><p>‘’objectstore.commit’’模型直接吸引了最早的一批用户，但这个模型因为不灵活很快就遇到了困难。新接触现在的SQLAlchemy的用户可能会痛恨一大堆的步骤：为’’Session’’对象定义工厂（可能是注册），将对象一次组织到一个’’Session’’里。但这比早期整个完全是隐式的系统更可取。0.1版本便利的使用模式在现在的SQLAlchemy中仍然广泛存在，会话注册一般是配置为使用线程局部作用域。</p><p>‘’Session’’本身只在SQLAlchemy 0.2中引入，轻率地模仿了Hibernate中的’’Session’’对象。这个版本的特性有集成事务控制,’’Session’’可以通过’’begin’’方法放置到一个事务中，并通过’’commit’’方法完成。’’objectstore.commit’’方法重命名为’’objectstore.flush’’，新的’’Session’’对象可以在任意时刻创建。’’Session’’自身从’’UnitOfWork’’对象中分离出来，后者仍然是一个私有的对象，负责执行实际的刷新操作。</p><p>当刷新过程成为用户显式调用的方法时，SQLAlchemy 0.4系列引入了<em>自动刷新</em>(autoflush)的概念，意思是每次查询之后立即发送刷新。自动刷新的好处是，查询发送的SQL语句可以访问内存的准确状态，因为所有的改变都已经发送过。早期的SQLAlchemy不包含这个特性，因为最常见的使用模式是，刷新语句同时会永久地提交改变。但引入自动刷新后，伴随而来的还有一个叫<em>事务型</em>(transactional)’’Session’’的特性，提供了在事务中可以自动启动一个’’Session’’，并会一直存在到用户显式调用’’commit’’为止。有了这个特性，’’flush’’方法再也不需要提交它刷新的数据，于是可以安全地自动调用。’’Session’’现在提供了通过刷新一步步在内存状态和SQL查询状态之间进行同步的功能，在显式调用’’commit’’之前，不会进行永久的改变。这种行为实际上和Java的Hibernate一模一样。然而，SQLAlchemy是基于Python的Storm ORM的相同行为，在0.3版本中引入这种使用风格的。</p><p>版本0.5引入了<em>事务后消除</em>(post-transaction expiration)，带来了更多的事务集成。默认情况下，每次’’commit’’或’’rollback’’后，所有’’Session’’中的状态都会被消除，在后续的SQL语句重新SELECT数据时再重新生成，或是新事务的上下文中访问未被消除的对象的属性时重新生成。起初，SQLAlchemy建立在SELECT语句无条件地尽量少的发送的假设上。因为这个原因，在提交时消除的行为在后来变慢。然而，它完全解决了包含过期数据’’Session’’的问题，使它可以在事务后用一种简单的方式加载新的数据，而不需要重新构建所有已经加载的对象。早先，这个问题似乎没有合理地解决’’Session’’何时该将当前状态认定为过期并不明显，因此在下一次访问时产生了昂贵的SELECT语句集合。然而，一旦’’Session’’移动到一个“总是在事务中”的模型，事务端的重点就自然成为了数据消除，因为高度隔离的事务的本质就是它直到提交或回滚都看不到新的数据。当然，不同的数据库和配置，事务隔离的方面不同，也可能根本就没有事务。SQLAlchemy的消除模型完全可以接受这些使用模式，开发人员只需要清楚，低隔离层次可能在多个回话共享同一行时，在一个会话中暴露未隔离的改变。这和直接使用两个数据库连接时发生的情况根本没什么不同。</p><h4 id="会话概览"><a href="#会话概览" class="headerlink" title="会话概览"></a>会话概览</h4><p>图20.13展示了一个’’Session’’和它处理的主要结构。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/session-overview.png" alt="图20.13：会话概览"></p><p>面向外部的部分是’’Session’’和用户定义的对象的集合，每个用户定义的对象都是一个映射类的实例。这里我们看到，映射的对象保存了一个到’’InstanceState’’的引用，这个对象记录了ORM的状态，包括即将发生的属性改变和属性消除状态。前面“映射剖析”章节讨论的属性instrumentation，’’InstanceState’’是在其中的实例级部分——与在类级的’’ClassManager’’相对应（前面讲过，映射类及其实例之间是对称的，行为有某种对应关系——译者注）。它代表和类关联的’’AttributeImpl’’对象，维护映射对象的字典的状态（即Python的’’__dict__‘’属性）。</p><h4 id="状态跟踪"><a href="#状态跟踪" class="headerlink" title="状态跟踪"></a>状态跟踪</h4><p>‘’IdentityMap’’是一个从数据库ID到’’InstanceState’’对象的映射，是为叫做<em>persistent</em>的有数据库ID的对象工作的。’’IdentityMap’’的默认实现和’’InstanceState’’一起工作来管理自己的大小，方式是在指向一个实例的所有强引用都删除后，把这个实例也删除——这和Python的’’WeakValueDictionary’’的工作方式是一样的。’’Session’’对所有标记为<em>dirty</em>或<em>deleted</em>的对象，以及标记为<em>new</em>的pending对象，通过创建到这些对象的强引用来保护这些对象免于垃圾回收。所有的强引用都会在刷新后被丢弃。</p><p>‘’InstanceState’’还在维护特定对象的属性“变了啥”中扮演着重要的角色。它使用一个“改变时移动”的系统，将特定属性“从前的”值，在将到来的值赋值到对象当前的字典之前，在存储到一个叫’’committed_state’’的字典中。在刷新时，’’committed_state’’和对象关联的’’__dict__‘’的内容会进行比较，产生每个对象的净改变。</p><p>对于集合的情况，一个单独的’’collections’’包和’’InstrumentedAttribute’’/‘’InstanceState’’系统合作，为一个特定映射对象的集合维护一个净改变的集合。常见的Python类如’’set’’，’’list’’，’’dict’’都在使用前进行继承并根据历史跟踪的增变方法进行扩展。集合系统在0.4版本修订为可扩充的，可以在任何类似集合的对象上使用。</p><h4 id="事务控制"><a href="#事务控制" class="headerlink" title="事务控制"></a>事务控制</h4><p>‘’Session’’的默认使用状态，为所有的操作维护了一个活动事务(open transaction)，当调用’’commit’’或’’rollback’’时结束。’’SessionTransaction’’维护了零到多个’’Connection’’对象的集合，每个对象代表一个在特定数据上活动事务。’’SessionTransaction’’是一个惰性初始化的对象，一开始没有任何数据库的状态。当一个特定的后端需要参与语句执行时，和那个数据库相关的一个’’Connection’’才被加入到’’SessionTransaction’’的连接列表里。虽然一段时间只有一个连接很常见，但有时候会因为’’Table’’，’’Mapper’’相关的配置，或因为操作中的SQL结构，需要为特定的操作使用特定的连接，这样多个连接的场景也能支持。多个连接时如果DBAPI提供了相应功能，也能使用事务的两阶段行为进行协作。</p><h2 id="20-9-工作单元"><a href="#20-9-工作单元" class="headerlink" title="20.9 工作单元"></a>20.9 工作单元</h2><p>‘’Session’’提供的’’flush’’方法把它的工作移交给一个叫做’’unitofwork’’（工作单元）的独立模块。前面已经提到，刷新的过程大概是SQLAlchemy中最复杂的功能。</p><p>工作单元的工作是将一个’’Session’’中的所有<em>pending</em>状态移出到数据库中，并清空’’Session’’的’’new’’，’’dirty’’和’’deleted’’集合。一旦工作完成，’’Session’’在内存中的状态。主要的挑战在于正确决定持久化的步骤，然后按正确的顺序执行。这包括决定INSERT，UPDATE，DELETE语句的列表，包括相关行删除或移动后带来的连锁反应(cascade)。保证UPDATE语句只包含实际修改过的列。在新生成的主键ID可用时，建立“同步”操作将主键列的状态复制到引用的外键列。保证INSERT语句按对象加入’’Session’’中的顺序产生，并尽可能的高效。保证UPDATE和DELETE语句按确定性的顺序产生，减少死锁的可能。</p><h4 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h4><p>工作单元的实现是从一个即兴写出的结构组成的混乱的系统开始的，它的开发可以类比为在没有地图的情况下找到走出森林的路。早期的缺陷和缺少的行为用后扩充的修复解决了。虽然0.5版本进行了一些重要的重构，但直到0.6版本，工作单元变得稳定，可理解，并用大量测试覆盖时，才可以进行彻底的重写。用数周时间考虑一个可以用一致的数据结构驱动的新方法后，用这个新模型进行重写只花了几天的时间，因为这时候思路很容易理解。新实现的行为可以用已有的版本进行细致的交叉验证，也对新的实现很有帮助。这个过程展示出，第一次的迭代不管多么糟糕，只要它提供了一个可工作的模型，就还是有价值的。它还展示出，对子系统的彻底重写经常不止是合适，更是困难系统开发的一个完整的部分。</p><h4 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h4><p>工作单元背后的关键范式是将一系列的行为组装，用一个数据结构进行表示，结点代表单个步骤。在设计模式的说法中这叫做<em>命令模式</em>(command pattern)。在这个结构中，一系列的“命令”使用<em>拓扑排序</em>(topological sort)组织为特定的顺序。拓扑排序是根据<em>偏序</em>(partial ordering)将元素排序的过程，在排序中，只有特定的元素必须在其他元素的前面。图20.14展示了拓扑排序的行为。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/topological-sort.png" alt="图20.14：拓扑排序"></p><p>工作单元基于持久化命令间必须的先后关系构造偏序。这些命令然后经过拓扑排序后按顺序调用。哪个命令在哪个命令之前主要是基于联系起两个’’Mapper’’对象的’’relationship’’推断出——总体上，因为’’relationship’’暗示着一个’’Mapper’’有对另一个的外键依赖，所以认为一个’’Mapper’’依赖于另一个。相似的规则在多对多关联的表中也存在，但这里我们重点关注一对多和多对一的关系。外键依赖。。。但同样重要的是，这个顺序允许在很多平台上只会在INSERT实际发生时生成的主键ID，从一个刚刚执行的INSERT语句的结果中，填到一个将要INSERT的有依赖的行的参数列表中。对于DELETE，使用相反的顺序——有依赖的行先于它们所依赖的行被删除，因为它们外键引用的东西不存在时，它们也不会存在。</p><p>在系统中拓扑排序出现的两个层次，工作单元起到重要作用。第一个层次基于’’Mapper’’间的依赖将持久化步骤组织进桶，也就是很多装着和特定类相对应的对象的桶。第二个层次将零到多个这样的桶分成更小的批，来处理引用循环或自引用的表。图20.15展示了在插入一些’’User’’对象后接着插入’’Address’’对象时生成的“桶”，其中一个中间的步骤将新生成的User主键值拷贝到每个’’Address’’对象的’’user_id’’外键列。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/uow-mapper-buckets.png" alt="图20.15：按mapper组织对象"></p><p>在每个mapper排序的情况下，任意数量的’’User’’和’’Address’’对象都可以刷新，而不会影响步骤的复杂性，或导致需要考虑多少“依赖”。</p><p>排序的第二个层次是在单个mapper的范围内基于对象间的直接依赖组织持久化步骤。这种情况何时会发生的最简单的例子是，有一个包含了到自身的外键依赖的表。表中的特定行需要在同一个表中引用它的另一个行之前插入。另一个例子是一组有<em>循环引用</em>(reference cycle)的表：表A引用表B，表B引用表C，表C又引用表A。一些A的对象必须要在其他对象之前插入，才能允许B和C的对象也插入进来。一个引用自身的表是循环引用的一个特例。</p><p>为了决定哪些操作可以remain in their aggregated，对每个’’Mapper’’桶上，和’’Mapper’’桶分解成的对象的命令的庞大集合，在mapper间存在的依赖集上应用环路检测算法，使用了一个在 <a href="http://neopythonic.blogspot.com/2009/01/detecting-cycles-in-directed-graph.html|Guido" target="_blank" rel="noopener">http://neopythonic.blogspot.com/2009/01/detecting-cycles-in-directed-graph.html|Guido</a> Van Rossum的博客 上找到的环路检测算法的修改版本。涉及到环路的桶就被分解成对象的操作，通过将新的依赖规则从每个对象的桶加入每个mapper的桶，将对象的操作混入mapper的操作的集合。图20.16展示了’’User’’对象的桶分别为单个对象的命令，导致加入了一个从’’User’’到自身的叫做’’contact’’的’’relationship’’。</p><p><img src="https://raw.githubusercontent.com/nettee/SQLAlchemy-survey/master/picture/uow-element-buckets.png" alt="图20.16：将循环引用组织为独立的步骤"></p><p>桶结构的原理是，它允许尽可能多的对共同的语句进行批处理，既减少了Python中需要的步骤数，又可以和DBAPI进行更多的有效交互。有时候用一个Python方法调用就可以执行上千条语句。只有当mappper间的循环引用存在时，才会使用更昂贵的单个对象依赖的模式，但也只是在对象图中需要的部分才使用。</p><h2 id="20-10-结论"><a href="#20-10-结论" class="headerlink" title="20.10 结论"></a>20.10 结论</h2><p>SQLAlchemy从诞生之初就有很高的目标，想成为功能最丰富、最通用的数据库工具。它做到了这一点，并且一直将关注点放在关系型数据库上，认识到用深度、透彻的方式支持关系数据库的实用性是一项大的事业。甚至在现在，我们还不断发现这个事业的范围比以前想象的要大。</p><p>为了从每个领域的功能中提取最有价值的东西，SQLAlchemy打算使用基于组件的方法，提供了很多不同的模块单元，应用程序可以单独使用或是组合起来使用。这个系统的创建、维护和交付都一直是很有挑战的。</p><p>SQLAlchemy打算缓慢发展，这是基于一个理论——系统地、有基础地构建稳定的功能最终会比没有基础地快速发布新功能更有价值。SQLAlchemy用了很长的时间构建出一个一致的、文档齐全的用户故事。但在这个过程中，底层的架构一直领先着一步，导致在一些情况下会出现“时间机器”效应，新功能可以几乎在用户需要它们之前添加进来。</p><p>Python语言是一个很好的宿主语言（如果有些挑剔的话，特别是在性能方面），语言的一致性和极大开放的运行时模型让SQLAlchemy可以比用其他语言写的类似产品有更好的用户体验。</p><p>SQLAlchemy项目希望Python在尽可能广的领域得到广泛深入接受，并且关系数据库的使用也一直生机勃勃。SQLAlchemy的目标是要展示关系数据库，Python，以及经过充分考虑的对象模型都是非常有价值的开发工具。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SQLAlchemy诞生于2005年，是一个Python语言的数据库工具包和对象关系映射(ORM)系统。在一开始，SQLAlchemy是一个提供使用Python数据库API（DBAPI）处理关系数据库的端到端系统。它的核心特性包括顺畅地处理复杂的SQL查询和对象映射和“工作
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Selenium</title>
    <link href="http://blog.ccao.cc/2018/09/28/Selenium/"/>
    <id>http://blog.ccao.cc/2018/09/28/Selenium/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.674Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Selenium-WebDriver中文翻译"><a href="#Selenium-WebDriver中文翻译" class="headerlink" title="Selenium WebDriver中文翻译"></a>Selenium WebDriver中文翻译</h1><p>原文来自《开源软件架构》（The Architecture of Open Source Applications）书中的 “ <a href="http://aosabook.org/en/selenium.html" target="_blank" rel="noopener">http://aosabook.org/en/selenium.html</a> |Selenium WebDriver ”章节。</p><p>Selenium是一个浏览器自动化工具，通常用于编写端到端的web应用测试脚本。正如字面意思，浏览器自动化工具能够自动化对浏览器的控制，因此可用于自动化重复的测试任务。这看上去好像是个能够轻易解决的问题，但是在后面我们将会发现，实现这个功能的背后，做了很多工作。</p><p>在描述Selenium的架构之前，先理解各种相关的项目是如何组合在一起的是有很有帮助的。从较高的层面上来看，Selenium是一套整合了三个工具的工具集。其一，Selenium IDE，是Firefox的一个扩展，支持用户记录和回放测试脚本。但是记录/回放模式较为局限，对很多用户来说并不适用。所以需要第二个工具，Selenium WebDriver，它提供了多种语言的API，可用于进行更多的操纵和构建标准软件开发实践的应用。其三，Selenium Grid，它支持Selenium API控制分布于不同机器上的浏览器实体，并能够并行的运行测试任务。在这个项目中，三个工具简称“IDE”、“WebDriver”、“Grid”。本章将探讨Selenium WebDriver的架构。</p><p>本章撰写于2010年末，Selenium2.0版本外部测试时期。如果你是在这以后阅读这本书，Selenium的架构会有所演进，你会看到本章所描述的架构的    选择是如何被展开。如果你是在这之前阅读这本书，恭喜你！你成功get了一个时光机。你能给我些彩票的中奖号码吗？</p><h2 id="16-1-发展历程"><a href="#16-1-发展历程" class="headerlink" title="16.1. 发展历程"></a>16.1. 发展历程</h2><p>Jason Huggins在2004年开启了Selenium项目，当时他正在ThoughtWorks公司为一个内部的Time and Expenses （T&amp;E）系统工作，这个系统的编写大量的运用了Jacascript。虽然IE浏览器在当时是主流浏览器，ThoughtWorks还是用了多种可选择的浏览器（特别是Mozilla系列），并且当T&amp;E软件不能在他们选择的浏览器上工作时会生成Bug报告。那个时期的开源测试工具，要么只能处理单个浏览器（特别是IE），要么只能处理模拟浏览器（比如HttpUnit）。一个商用工具许可证的花费差不多能花光一个内部小规模项目的有限预算，所以当时没有多少可用的测试工具可供选择。</p><p>由于自动化的困境，测试工作通常都依赖于手动测试。当一个开发队伍非常小或者软件发布非常的频繁时，这种方法不具有可扩展性。另外，要求人们逐句执行一个本可以自动化运行的脚本是对人力资源的一种浪费。更直白的说，对于一个反复的枯燥的任务，人为处理较机器处理来说效率更低且错误更多。手工测试测试不是一个好的选择。</p><p>幸运的是，所有有待进行测试的浏览器都支持Javascript。这解释了为什么Jason和他所在的小组选择了用Javascript来编写一个测试工具，鉴于Javascript是一个能够用于证明应用行为的语言。工具的完成是受到FIT的启发，FIT是一个基于表格的语法被架构在原始的Javascript之上，这种语法能够被编程经验不多的人所使用，它是一种类似于HTML文档的关键字驱动的语法。这个工具一开始叫做“Selenium”,但是后来改称为“Selenium Core”，并且基于Apache 2协议发布于2004年。</p><p>Selenium的表格格式的结构类似于FIT中的Action Fixture。表格中每行分为三列。第一列给出了要执行的命令的名字，第二列通常包含一个元素标示符，第三列包含一个可选值。比如，以下就是如何将一个字符串“Selenium WebDriver”表示为以q命名的元素标示符：</p><figure class="highlight plain"><figcaption><span>name</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">由于Selenium是纯粹用Javascript编写的，为了避免陷入与浏览器安全性策略、Javascript 沙盒（Sandbox）之间的冲突，它的最初设计要求开发者掌握Selenium Core和部署到同一台作为被测试应用的服务器上的测试脚本，这件事对开发人员来说不一定实际且合理。更糟糕的是，即使一个开发者的集成开发环境给他们提供了能够很快操纵代码和浏览一个大型的代码库的能力，对于HTML却没有相关的工具。以上清晰地表明了，维护一个就算只是中型的测试套件都是一件困难又痛苦的事情。</span><br><span class="line">  </span><br><span class="line">要解决上述困难还有其他一些问题，一个HTTP代理模式出世，这个代理模式使得HTTP请求都能被Selenium截获。使用这个代理模式能够回避“同主机源”策略的诸多限制，例如一个浏览器不允许Javascript去调用除了当前页面所在的服务器以外的任何东西，而此代理模式环节了这个策略的首要弱点。这种设计为编写Selenium这个与多种语言捆绑的工具开辟了新方法：它们其实只需要能够发送HTTP请求到一个特定的URL。这个有线格式很多的效仿了Selenium Core基于表格的语法，并且随着基于表格的语法演变成了被称作“Selenese”的语言。由于这种语言绑定是在远端控制浏览器，所以该工具也被称为“Selenium Remote Control”（Selenium远程控制）或“Selenium RC”。</span><br><span class="line">  </span><br><span class="line">当在开发Selenium时，ThoughtWorks公司里正酝酿着另一个浏览器自动化框架——WebDriver。WebDriver的初代源代码发布于2007年初。WebDriver是从一个希望从底层测试工具中分离出端到端测试的项目工程中衍生出来的。通常，这种分离手段是通过适配器（Adapter）模式完成的。WebDriver产生于在多个项目中不断运用这种方法的实践应用，在最初只是一个对HtmlUnit的封装。工具发布后迅速的支持了IE和Firefox浏览器。</span><br><span class="line">  </span><br><span class="line">在WebDriver最初发布时，它和Selenium RC之间存在显著的差异，虽然它们都属于浏览器自动化API的软件领域内的应用。对于用户来说，这两者的显著区别在于Selenium RC提供基于字典的API，它的所有方法在一个类中都是透明的，然而WebDriver的API更加面向对象化。另外，WebDriver只支持Java语言，然而Selenium RC提供共犯的可供选择的语言。还有一个重要的技术上的差异：Selenium Core（RC的基础）在本质上是一个Javascript应用，运行在浏览器安全沙盒内部。WebDriver则试着去把自己绑定到浏览器绑中，以回避浏览器的安全模式，代价是显著增加了框架本身开发工作的成本。</span><br><span class="line">  </span><br><span class="line">在2009年8月，两个项目宣布合并，Selenium WebDriver就是两者合并后的项目。在我写这篇文章时，Selenium WebDriver已经支持了包括Java、C#、Python、Ruby的语言绑定，提供了Chrome、Firefox、IE、Opera还有Android和iPhone上的各种浏览器的支持。它的关联项目，不保存在同一个源代码仓库中，但是与主项目密切合作，例如提供了Perl的语言绑定，在BlackBerry浏览器上的实现，和用来在持续集成的服务器上运行无法正常显示的测试集的“无头”WebKit。原来的Selenium RC所使用的机理仍然保持者，帮助在原来WebDriver不支持的浏览器上提供支持。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">## 16.2. 关于专业术语的题外话 ##</span><br><span class="line"> </span><br><span class="line">不幸的是，Selenium项目使用了很多的术语。回顾一下我们已经提到过的术语：</span><br><span class="line"></span><br><span class="line">  * Selenium Core是原Selenium实现的核心部分，是一个用于控制浏览器的Javascript的脚本集。常简称为“Selenium”或是“Core”。</span><br><span class="line"></span><br><span class="line">  * Selenium RC 是Selenium Core的语言绑定的名字，一般性的却又令人疑惑的简称为“Selenium”或是“RC”。这部分现在已经被Selenium WebDriver所替代，通过将RC的API改名为“Selenium 1.x API”。</span><br><span class="line"></span><br><span class="line">  * Selenium WebDriver与RC的功能相似，且包含了原1.x的绑定件。1.x绑定件指的是语言绑定和个别浏览器控制代码的实现。一般把这部分简称为“WebDriver”，有时也称作Selenium 2. Doubtless，以后将简称为“Selenium”。</span><br><span class="line"></span><br><span class="line">精明的读者会注意到“Selenium”这个称号所指广泛。幸运的是，文章一般都会清楚的表明所指的是哪个Selenium。</span><br><span class="line">  </span><br><span class="line">最后，还有个常用词，我只能用直白的介绍：“driver”是WebDriver的API中的一个特定的实现的名字。例如，Firefox driver，IE driver。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">## 16.3. 架构主题 ##</span><br><span class="line"> </span><br><span class="line">在我们开始理解这些独立的模块是怎么结合在一起之前，我们先要弄明白此项目的架构和开发的重要主题。简明扼要的来说：</span><br><span class="line"></span><br><span class="line">  * 保持低成本</span><br><span class="line">  * 模拟用户</span><br><span class="line">  * 证明driver运行良好…</span><br><span class="line">  * …但你不需要理解一切细节</span><br><span class="line">  * 降低巴士因素(bus factor)</span><br><span class="line">  * 理解Javascript的实现</span><br><span class="line">  * 所有的方法调用都属于RPC调用</span><br><span class="line">  * 我们是一个开源项目</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.1. 保持低成本 ###</span><br><span class="line"> </span><br><span class="line">在Y平台上支持X浏览器，不管在最初的开发还是维护的角度上去考虑，本就是一个昂贵的命题。如果我们能找到在不违反太多其他原则的前提下保持产品的高品质的方法，那么这就是我们所希望走的路线。这种路线最明显地体现在我们尽可能的使用的Javascript编程上，很快你就会了解到。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.2. 模拟用户 ###</span><br><span class="line"> </span><br><span class="line">WebDriver是为了精确模拟用户和web应用交互的方式而设计的。模拟用户输入的一般方式是利用Javascript来综合和触发一系列的事件，在应用的角度上来看这一系列事件和真实用户的交互事件是相同的。这一系列的综合事件(synthesized events)方法困难重重，原因是每个浏览器（有时是同一个浏览器的不同版本）之间相关数值稍有不同就会得到不同的事件集。对于一个复杂的问题，大多数的浏览器出于安全考虑不会允许用户用表单元素（比如文件输入）的方式进行交互。</span><br><span class="line"></span><br><span class="line">WebDriver尽可能的选择在操作系统的层面上使用触发事件的方式。由于这些“原声事件”(native events)不会由浏览器所产生，这个方法回避了在合成事件上的安全问题，同时，因为他们是系统依赖的，一旦在某个特定的平台上的浏览器运行良好，在其他的浏览器上重用代码就相对容易了。悲哀的是，这个方法必须满足两点：WebDriver与浏览器密切绑定在一起，开发团队已找到怎么最好地在浏览器窗口是非选中状态下发送原生事件的方法（因为Selenium的测试脚本的运行需要一些时间，当脚本在运行的时候，设备最好能够执行别的任务）。目前，这意味着原生事件可以在Linux和Windows平台上使用，却不能在Mac OS X上使用。</span><br><span class="line"></span><br><span class="line">不管WebDriver是如何模拟用户输入的，我们在尽可能接近的去模仿用户行为。这与RC相悖，它提供的API在层次上远低于用户操作。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.3. 证明driver运行良好 ###</span><br><span class="line"> </span><br><span class="line">一个十全十美（motherhood and apple pie）的东西，听起来有点理想主义，但是我相信如果它不能运行的话，码代码就无意义了。我们证明driver能够在Selenium项目上运行的方法是，用一套广泛的自动化测试样例集对driver进行测试。通常选用“集成测试”作为样例，要求编译代码并运用与web服务器交互的浏览器，但是我们尽可能的编写“单元测试”作为样例，与集成测试不同的是，“单元测试”不需要全部重新编译就能够运行。目前，准备了大约500个集成样例和250个单元测试样例，覆盖所有浏览器。当我们修复问题和编写新的代码的时候，我们增加了更多的样例，而这些样例更加倾向于单元测试。</span><br><span class="line"></span><br><span class="line">并非所有的测试脚本都能在每一个浏览器上运行。有些脚本是用来测试特殊的功能，这些功能在有些浏览器上可能并不支持，或是这些功能在不同的浏览器上的实现方法不同。例如，样例会包括一些对新的HTML5的特性的测试，然而并非所有的浏览器都支持HTML5。尽管如此，每个主流的桌面浏览器都拥有充分的能够在其上运行的测试样例子集。可以想象，找到一种可以在多个平台上对每个浏览器运行500多个测试脚本的方法是一个重大的挑战，这也是我们所持续奋斗的目标。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.4. 你不需要理解一切细节 ###</span><br><span class="line"> </span><br><span class="line">很少有能够精通和熟悉我们使用的所有的语言和技术的开发者。因此，我们的架构需要帮助开发者专注于他们最擅长的才能，而不需要他们处理不熟悉的代码片段。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.5. 降低巴士因素(bus factor) ###</span><br><span class="line"> </span><br><span class="line">在软件开发者之间有一个（非正式的）概念，叫做“巴士因素”。它是指因为遭遇一些可怕的事情——也许是被公车撞了——而离开了项目组，导致项目在一个阶段内无法继续进行的关键开发者的数目。像浏览器自动化这样复杂的项目巴士因素特别的重要，因此我们的很多架构上的选择是为了尽可能的提高巴士因素的数值。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.6. 理解Javascript的实现 ###</span><br><span class="line"> </span><br><span class="line">WebDriver在没有别的方法控制浏览器的情况下变回使用纯Javascript去驱动浏览器。这意味着我们添加的所有API都要能够与Javascript的实现“相容”。一个具体的例子，HTML5引进了LocalStorage机制，这是在客户端存储结构化的数据的API。这个机制通常在使用了SQLite的浏览器上实现。比较自然的实现是提供能够与底层数据存储关联的数据库，通过类似于JDBC的API。最终，我们决定使用一个密切的模拟了底层Javascript实现的API，因为模拟典型的数据库访问的API与Javascript的实现不相兼容。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.7. 所有的方法调用都属于RPC调用 ###</span><br><span class="line"> </span><br><span class="line">WebDriver控制运行在其他进程里的浏览器。尽管很容易被忽视，但是这意味着每一个它的API调用都是RPC调用，因此该框架的性能受限于网络延迟。在正常运行时，这可能不算特别明显——大多数的操作系统会优化到本地的路由——但是当浏览器和测试代码之间的网络延迟增加时，那些高效的调用会恶化，无论是对于API的设计者还是使用者来说。</span><br><span class="line"></span><br><span class="line">这个设计介绍了API设计的一些张力考虑。一个较大规模的功能粗糙的API，能够通过多重函数调用降低延迟，但是这点会被保持API的性能和易用性所限制。比如，有一些必做的检查来确定一些元素对于一个终端用户是否是可见的。我们不仅需要考虑需要从父元素中推断出来的不同的CSS属性，还需要检查元素的尺寸。API在最低限度下都会逐个检查这些方面。WebDriver把这些检查都合并到单一的&apos;&apos;isDisplayed&apos;&apos;方法中。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.3.8. 最后：这是一个开源软件 ###</span><br><span class="line"> </span><br><span class="line">虽然这一点严格说起来不算是一个架构设计要点，但是需要强调Selenium是一个开源项目。基于希望对一个新的开发者来说尽可能容易的上手的主题，才有了上述所有的特点。我们希望达到以下便于开发的特点：使知识的深度要求尽可能的浅；使用尽可能少的语言；通过自动化测试验证。</span><br><span class="line"></span><br><span class="line">起初这个项目被分为一系列的模块，每个模块代表一个特定的浏览器，还有额外的模块用于通用代码和支持使用代码。每个绑定件的代码树存储在这些模块之下。这个方法对于很多语言来说是有意义的，如Java和C# ，但是对于Ruby和Python的开发人员来说是很痛苦的。这一点在相对代码贡献人数上显著的表现了出来，屈指可数的人有能力并且有兴趣去完成Python和Ruby的绑定件工作。为了解决此问题，在2010年的十月到十一月期间重构了源代码，Ruby和Python代码都存储在各自独立的顶级目录下。这更加契合了这些语言的开源开发者的期望，立即吸引了社区的广泛参与。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">## 16.4. 面对复杂性 ##</span><br><span class="line"> </span><br><span class="line">软件是模块化的。模块是复杂的，作为一个API的设计者，我们需要决定将复杂性置于何处。在一个极端的情况下，我们希望均匀的平衡复杂性，这意味着每个API的使用者需要参与其中的设计。另一个极端的建议，吧复杂性尽可能的放在一个单独的部分。这个单独的部分对于不得不去实现它的人来说是黑暗的恐怖的，但作为交换的是，这个API的使用者虽然不需要了解其中的实现，但是需要为这个复杂性预付一些代价。</span><br><span class="line"></span><br><span class="line">WebDriver的开发者更多学会的是找到一些放置复杂性的地方，而不是均衡复杂性。原因在于我们的使用者，他们特别擅长于在扫了一眼我们列出来的bug清单后，发现一些问题，但是因为他们大多数都不是开发者，所以一个复杂的API效果不会很好。我们力求能够提供一个能够引导用户正确使用的API。例如，考虑一下原始Selenium的API中包括的方法，每个方法都可以用于设置输入元素的值。</span><br><span class="line"></span><br><span class="line">  * type</span><br><span class="line">  * typeKeys</span><br><span class="line">  * typeKeysNative</span><br><span class="line">  * keydown</span><br><span class="line">  * keypress</span><br><span class="line">  * keyup</span><br><span class="line">  * keydownNative</span><br><span class="line">  * keypressNative</span><br><span class="line">  * keyupNative</span><br><span class="line">  * attachFile</span><br><span class="line"></span><br><span class="line">在WebDriver里有一个同等的API:</span><br><span class="line"></span><br><span class="line">  * sendKeys</span><br><span class="line"></span><br><span class="line">就像之前讨论过的，这突出了RC和WebDriver之间主要的哲学上的差异：WebDriver努力去模拟用户，而RC提供的API则式在用户很难甚至不可能涉及到的层面上做处理的。typeKeys和typeKeysNative的不同之处在于：前者总是使用合成事件，而后者试图使用AWT的Robot类来分类键值。遗憾的是，AWT的Robot类只能发送键值给处于选中状态的窗口，而选中的窗口不需要一定是浏览器。相反地，WebDriver的原生事件是直接传送键值到窗口句柄，回避了必须要浏览器窗口处于选中状态的缺点。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.4.1. WebDriver的设计 ###</span><br><span class="line"> </span><br><span class="line">项目组认为WebDriver的API是“面向对象的”。这些接口是明确定义的，并试图保持它们的角色和责任的唯一性，但是我们并没有对每一个可能的HTML标签都建模建立对应的类，我们值提供了单一的WebElement接口。通过沿用这种方法，使用支持自动补全的IDE的开发者们可以根据补全进行下一步。结果就是代码的会话会像这样(JAVA)：</span><br><span class="line"></span><br><span class="line">在这一点上，一个相关的包含13个方法的短列表会出现在界面上。用户选择一个：</span><br></pre></td></tr></table></figure><p>driver.findElement(<user hits="" space="">)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">现在大多数的IDE会显示一些关于方法所期望的参数类型的暗示，在这个例子中，期望一个“By”类型。为“By”对象预设的大量工厂方法被它自己声明成了静态方法。我们的用户很快就能写出这样的一行代码：</span><br></pre></td></tr></table></figure></user></p><p>driver.findElement(By.id(“some_id”));<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;   基于角色的接口</span><br><span class="line">&gt;   想象一个简化的&apos;&apos;Shop&apos;&apos;类。每天，它需要重新进货，并向跟它合作的&apos;&apos;Stockist&apos;&apos;提供新的货物。每个月，它需要支付工资和税。为了讨论的方便，我们想象一下，这里使用一个&apos;&apos;Accountant&apos;&apos;类。一种模拟的方法是这样的</span><br></pre></td></tr></table></figure></p><p>public interface Shop { void addStock(StockItem item, int quantity);<br>Money getSalesTotal(Date startDate, Date endDate); }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;   对于划分Shop、Accountant、Stockist这三个定义之间的界限的时候，我们有两个选择。我们可以像图16.1中的那样，划出一条理论上的分界线。</span><br><span class="line">&gt;   这意味着&apos;&apos;Accountant&apos;&apos;类和&apos;&apos;Stockist&apos;&apos;类都要接受一个&apos;&apos;Shop&apos;&apos;类作为参数传递给他们各自的方法。缺点会计是不一定真的想要堆上架，并且让分销商意识到商店在价格上提高了很多不是一个好的实现。因此，一个更好的分界线是像图16.2那样的，我们需要两个由商店来实现的接口，但是这两个接口明确的定义了商店是一个需要满足会计的分销商的角色。以下是基于角色的接口：</span><br></pre></td></tr></table></figure></p><p>public interface HasBalance { Money getSalesTotal(Date startDate, Date endDate); }<br>public interface Stockable { void addStock(StockItem item, int quantity); }<br>public interface Shop extends HasBalance, Stockable { }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">我发现了&apos;&apos;UnsupportedOperationExceptions&apos;&apos; 的异常抛出，非常令人不愉快，但是需要允许有部分功能能够暴露给一些需要使用这些功能的用户，但是却不会把其余的API暴露给大多数用户。为此，WebDriver管饭使用基于角色的接口。例如，有一个&apos;&apos;JavascriptExecutor&apos;&apos;接口是用于提供在当前页面的上下文中执行Javascript任意块的能力。一个成功的WebDriver映射是一种能够期望它的方法能够有效的接口。</span><br><span class="line"></span><br><span class="line">^![](/cdn/images/aosabook/67.png)</span><br><span class="line"> |    [图16.1：基于Shop的Accountant和Stockist]     |</span><br><span class="line"></span><br><span class="line">^![](/cdn/images/aosabook/68.png)</span><br><span class="line"> |    [图16.2：实现了HasBalance和Stockable接口的Shop]     |</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.4.2. 处理组合爆炸 ###</span><br><span class="line"> </span><br><span class="line">首先，第一个想到的事情是，WebDriver对广泛浏览器和语言的支持显然会很快的遭遇维护成本不断攀升的问题，除非非常小心的处理。对于X个浏览器Y种语言，很容易陷入维护X*Y个实现的困境。</span><br><span class="line"></span><br><span class="line">减少WebDriver所支持的语言是一个减少开销的办法，但是我们不想这样做，有两个原因。第一，当从一个语言转换成另一个语言需要承担认知负担，所以对使用这个框架的用户来说，能够用他们开发时常用语言来编写测试脚本是WebDriver的一大优点。第二，在打你的项目里杂糅多个语言是一个项目组非常不希望的看到的，公司的代码标准和需求一般规定技术的单一性（虽然，好消息是，我认为第二点随着时间的推移越来越不重要了），因此减少所支持的语言的数量不是一个可行的选择。</span><br><span class="line"></span><br><span class="line">减少支持的浏览器数量也不是一个好的选项——当我们淘汰WebDriver中对FireFox2的支持时会发生严重的错误，除非它在浏览器市场中的占有率少于1%，否则我们不会做出淘汰的选择。</span><br><span class="line"></span><br><span class="line">我们仅有可选择的选项是，试图使所有浏览器对于同一个语言绑定件来说都是一样的：他们应该提供一个统一的接口，用来容易的处理各种不同的语言。还有，我们想要语言绑定件自己能够尽可能的易于编词儿，这表明我们希望他们轻便。我们尽可能的向底层驱动器中放入各种逻辑，目的是：支持每个我们未能成功的放入驱动的功能模块是在所有我们支持的语言中实现，这意味着巨大的工作量。</span><br><span class="line"></span><br><span class="line">例如，IE的驱动器成功的把定位和启动IE的责任放入主驱动逻辑中。虽然这导致了驱动器惊人的代码行数，用于创建新实例的语言绑定件归结到单一的方法调用到该驱动。相比之下，Firefox的驱动器未能成功实现这个改变。仅在Java的世界中，这意味着有三个大类用于控制Firefox的配置和启动，加起来大约有1300行代码。这些类在每个希望支持FirefoxDriver的语言绑定件中都是重复的，除非依赖于启动一个Java服务器。这需要大量的额外代码来维护。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">### 16.4.3. WebDriver的设计缺陷 ###</span><br><span class="line"> </span><br><span class="line">决定以这种方式公开功能上的坏处在于，可能要等到有人发现了一个特殊的接口存在，他们才能意识到WebDriver是支持这种类型的功能的；在这样的API中有暴露的损失；当然，当WebDriver是新的，我们可能会花费大量时间仅仅是为了向人们指明一些特殊的接口。我们现在已经在文档上做了很多的努力，随着API被广泛的使用以后，用户就能更轻易地找到他们所需要的信息了。</span><br><span class="line"></span><br><span class="line">有一个我认为我们的API设计的非常差的地方。我们有一个叫做&apos;&apos;RenderedWebElement&apos;&apos;的接口，它包含一个奇怪的方法杂烩，用于查询元素的渲染状态(&apos;&apos;isDisplayed&apos;&apos;, &apos;&apos;getSize&apos;&apos; and &apos;&apos;getLocation&apos;&apos;)、在元素上执行操作（&apos;&apos;hover&apos;&apos;，拖放方法），还有一个便于得到特定的CSS属性值的方法。这个接口存在的原因是，HtmlUnit驱动不会暴露需要的信息，但是Firefox和IE的驱动会。一开始只有第一套方法，但是在我深刻的思考希望这个API该如何发展下去之前，我们就已经增加了其他的方法。这个接口现在已众所周知，所以要把这个API的丑陋的但是已经被广泛使用的一角保留下来，还是要尝试把它删除，是一个艰难的选择。</span><br><span class="line"></span><br><span class="line">从一个实现者的角度来看，与浏览器绑定的太紧也是一个设计的缺陷，虽然这是不可逃避的设计。要支持一个新的浏览器显然需要付出努力，接着要让它正确运行需要付出更多。举一个具体的例子，chrome的驱动器经历了四次的整体重写，IE的驱动器也有三次的主体部分的重写。与浏览器绑定紧密的好处在于能够提供更多的控制。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">## 16.5. 层次与Javascript ##</span><br><span class="line"> </span><br><span class="line">一个浏览器自动化工具本质上是建立在三个动态部件上：</span><br><span class="line"></span><br><span class="line">  * 询问DOM的一种方式</span><br><span class="line">  * 用于执行Javascript的机制</span><br><span class="line">  * 模拟用户输入的一些方法</span><br><span class="line"></span><br><span class="line">本小节主要介绍第一个部分：提供一种询问DOM的机制。浏览器的通用语言是Javascript，所以它应该是一种理想的用来询问DOM的语言。虽然这个选择看上去是显然的，当考虑到Javascript的时候，却导致了一些有趣的挑战和需要平衡的竞争需求。</span><br><span class="line"></span><br><span class="line">像大多数的大型项目一样，Selenium使用了分层结构的库。最底层是Google的Closure Library，它提供的原语和模块化机制允许源文件尽可能的小而集中。往上一层是一个实用函数库，提供了从简单的任务，比如获取一个属性的值，通过判断一个元素对某个终端用户是否可见，到复杂得多的一个动作，比如使用一个合成事件来模拟点击动作。在项目中，这些被视为提供了浏览器自动化的最小单位，因此被称为浏览器自动化原子(Browser Automation Atoms)或原子(atoms)。最后，为了满足WebDriver和Core的API，提供了一个整合了原子的适配器层。</span><br><span class="line"></span><br><span class="line">^![](/cdn/images/aosabook/69.png)</span><br><span class="line"> |    [图16.3：Selenium Javascript库的层次结构]     |</span><br><span class="line"></span><br><span class="line">选择Closure库是由于以下几个原因。最主要的原因是Closure的编译器理解这个库所使用的模块化技术，Closure的编译器是一个针对以Javascript为输出语言的编译器。“编译(Compilation) ”可以像决定文件依赖顺序、链接文件并漂亮的把它们打印出来一样简单，也可以像预先优化和删除死码(dead code)一样复杂。另一个不可否认的优点是，项目组做Javascript这一部分编码的部分成员非常熟悉Closure库。</span><br><span class="line"></span><br><span class="line">由于询问DOM的需求所在，这个代码的“原子”库普遍地使用于整个项目中。对于RC和那些主要用Javascript编写的driver来说，这个库被直接的一般性的编译成了一个统一的脚本。对于用Java编写的driver来说，在WebDriver的适配器层的个别函数的编译被全面优化，生成的Javascript被当做资源包括进JAR包中。对于用C的变体写的driver，比如iPhone和IE的driver，不仅仅是个别的函数的编译被全面优化，生成的输出被转化为固定定义头，根据需求这个头部通过driver的一般Javascript执行机理运行。虽然看上去有点奇怪，但是它使得Javascript不需要在多个位置上暴露源码，就能压入底层driver中。</span><br><span class="line"></span><br><span class="line">由于这些原子的广泛使用，不同浏览器之间行为的一致性可以被确保，且由于这些库使用Javascript便携的，不用提升权限就能执行开发周期，简单又快速。Closure库可以支持动态绑定，因此Selenium的开发者只需要编写一个测试脚本并加载到浏览器中，根据要求修改代码并点击刷新按键。一旦一个测试脚本在一个浏览器中通过测试，就很容易把它加载到别的浏览器中，并且一定能通过。由于Closure库在将浏览器之间的不同之处抽象出来的方面做得很好，虽然知道在每一个支持的浏览器上都持续的运行这些测试套件的构建是很令人安心的，但是这是往往不够的。</span><br><span class="line"></span><br><span class="line">原始的Core和WebDriver有很多代码等同的部分，即在稍微不同的方式下实现了同样的功能的代码。当我们开始实现原子的时候，代码被梳理，试图找到“最佳”的功能。毕竟这两个项目都已经被广泛使用了，并且它们的代码都非常健壮，所以如果把两个项目都丢弃从头开始，是非常浪费且愚蠢的。由于每个原子都被提取了，在会被使用的每个点都被识别出来并转化为使用原子。比如，Firefox的driver中的getAttribute方法从大约50行的代码缩减到6行，包括空行：</span><br></pre></td></tr></table></figure></p><p>FirefoxDriver.prototype.getElementAttribute = function(respond, parameters) {</p><pre><code>var element = Utils.getElementAt(parameters.id, respond.session.getDocument());var attributeName = parameters.name;respond.value = webdriver.element.getAttribute(element, attributeName); respond.send(); };</code></pre> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">上面的第二行到最后一行，就是&apos;&apos;respond.value&apos;&apos;被分配到的地方，使用了原子的WebDriver库。</span><br><span class="line"></span><br><span class="line">原子是这个项目的几个架构主题的一个实际演示。当然，他们倾向于用Javascript来实现API。更好的是，相同的库通过代码库来共享；当一个bug需要通过多个实现来检查并修正时，现在只需要在一个地方修正bug就够了，这减少了修改的成本，提高了稳定性和高效性。原子也让项目的巴士因素的优势增加了。当一个普通的Javascript单元测试脚本可以用来检查修改工作时，加入一个开源项目的障碍比起过去需要了解每个driver是如何实现的要减少很多。</span><br><span class="line"></span><br><span class="line">使用原子还有一个好处。一个模仿了现有的RC实现，但是依赖于Webdriver的层次，对于在受控的情况下寻求迁移到新的WebDriver的API的方法的项目组来说是一个重要的工具。但是在Selenium Core原子化的情况下，可以从它来逐个编译每个函数，这让编写这个模仿层的任务变得更简单更精确。</span><br><span class="line"></span><br><span class="line">不用说，采用这种方法也有缺点。最主要的是，把Javascript编译成C的&apos;&apos;const&apos;&apos;是一件非常奇怪的事，这常常阻挡了想要来写C的新的项目的贡献者。而且，拥有所有浏览器的每个版本，并且愿意把所有的测试脚本在这些浏览器上都运行一遍的开发者非常的稀少，一个可能发生的情况是，有人不小心在一个意想不到的地方引起了复原事件，需要花一些来发现这个问题，特别是当一个连续的构建正处于片状时。</span><br><span class="line"></span><br><span class="line">由于原子照标准在浏览器之间返回值，但还是有可能返回一些意料之外的值。比如，这段HTML代码：</span><br><span class="line"></span><br><span class="line">```&lt;input name=&quot;example&quot; checked&gt;</span><br></pre></td></tr></table></figure><p>‘’checked’’属性的值依赖于使用的浏览器。原子标准化了这一点，还有其他定义在HTML5规范中的布尔属性，只能是”true”或“false”。当这个原子被引入代码库时，我们发现很多地方，人们都在做关于返回值类型应该是什么的浏览器相关的假设。当一个值被固定下来时，我们将要花费很长时间来向大家解释发生了什么，为什么设置这个值。</p><h2 id="16-6-远程的driver，特别是Firefox的driver"><a href="#16-6-远程的driver，特别是Firefox的driver" class="headerlink" title="16.6. 远程的driver，特别是Firefox的driver"></a>16.6. 远程的driver，特别是Firefox的driver</h2><p>远程的WebDriver本来是一个众人称赞的RPC机制。自从我们引进了一个关键的机制，用于减少WebDriver的维护开销，通过提供一个语言绑定件都能编写的统一的接口。尽管我们已经尽可能的把逻辑从语言绑定件中抽取出来，放在driver中，但是当每个driver需要通过一个特殊的协议进行交流时，在语言绑定件中依然需要重复很多的代码。</p><p>当我们需要与运行在程序外的一个浏览器实例进行交流时，都需要使用远程WebDriver协议。设计这个协议需要考虑多方面，大多数是技术方面的问题，但是对于一个开源软件，还需要考虑社会层面上的问题。</p><p>任何的RPC机制都被分为两个部分：传输和解码。我们知道，无论我们怎么实现远程WebDriver协议，我们作为客户端需要在每个我们使用的语言上都支持这两个方面。第一次设计是作为Firefox driver的一部分开发的。</p><p>Mozilla，也包括Firefox的，总是被看作是由它们的开发者所提供多平台的应用程序。为了便于开发，Mozilla创建了一个由Microsoft的COM所启发而成的一个框架，COM由于允许组件和被构建和螺栓连接在一起而被称为XPCOM(跨平台的，COM)。一个XPCOM接口使用IDL声明，并且有C和Javascript语言以及其他语言的语言绑定件。由于XPCOM用于构造火狐，又因为XPCOM有javascript绑定，可以利用XPCOM对象对Firefox扩展。</p><p>普通的Win32 COM允许接口被远程访问。也有计划将这个功能添加到XPCOM，达林·费舍尔增加了一个XPCOM ServerSocket的实施促成了此功能的实现。虽然D-XPCOM计划没有能够实现，但他像一个附录中，残留的基础设施仍然存在。我们注意到这一优势，并在包含所有控制Firefox的逻辑的Firefox定制扩展中，创建了一个非常基本的服务器。使用的协议最初是基于文本和面向行为主，所有的字符串为UTF-2编码。每个请求或响应开始与一个数字，表明在得出请求或应答已发送的结论之前，有多少新行需要记录。至关重要的是，该方案很容易在Javascript实现，因为SeaMonkey（当时Firefox的Javascript引擎）把JavaScript字符串作为内部16位无符号整数存储。</p><p>虽然把玩原始套接字上的自定义编码协议是用来打发时间的一个有趣的方式，但它有几个缺点。自定义的协议没有广泛可用的库，所以它是需要从基层构建起来的，而且是我们希望支持每个语言都要实现一次。这个增加编写的代码的要求，将不太可能让较多的开源贡献者参与新的语言绑定的开发。此外，虽然面向行的协议是很好，但当我们只发送关于基于文本的数据的时候，它将会在我们想发送图像（如屏幕截图）之类的时候带来的问题， </p><p>这个最初的RPC机制很明显很快的就被认为是不实际的。幸运的是，有一个著名的运输是几乎在每一种语言的广泛采用和支持我们想做什么就做什么那就是：HTTP。</p><p>一旦我们决定使用HTTP作为输送机制，也可以提出，下一步需要选择的是，是否使用单一终点（SOAP）或多个端点（REST中的样式）。原Selenese的协议使用单一的终点和在查询字符串有编码的命令和参数。尽管这种方法效果很好，但是“感觉”不对：我们有一个能够在浏览器中连接到远程的webdriver实例，以便于查看服务器状态的愿景。我们最终选择了我们称之为“REST-ish”的方法：使用HTTP的动词来帮助提供，这意味着多个端点的URL，但打破真正的RESTful系统所需的诸多约束，特别是围绕状态和高速缓存能力的定位，主要是因为只有一个定位能够使得该应用程序的存在有意义。</p><p>虽然HTTP可以轻松的支持基于内容类型协商的多种编码数据的方法，我们认为我们需要一个远程的Webdriver协议的实现能够一起工作的规范形式。很明显我们能选择的不多：HTML，XML或JSON。我们很快排除了XML：虽然这是一个完全合理的数据格式，并且几乎每一个语言都有支持它的库，我对于它在开源社区中是否受欢迎的看法是，人们并不喜欢使用它。此外，虽然返回的数据将共用一个共同的“形状”但要添加附加字段是很容易的，而且是完全有可能的。虽然这些扩展可以用XML命名空间来建模，这将开始给客户端代码引入更多的复杂性：这种事情是我们极力避免。 因此XML是一种被放弃了的选择。 HTML也真的不是一个很好的选择，因为我们需要能够定义我们自己的数据格式，虽然嵌入式微格式可能已经被设计出来，并能够像用锤子来敲鸡蛋一样的使用。</p><p>最后一种可能的选择是Javascript Object Notation（JSON）。浏览器可以将字符串转换成一个对象，通过两种方式：直接调用EVAL对象；或者，在最新的浏览器上，可以用最原始的设计来把一个JavaScript对象转化为一个字符串，或反过来转化，安全又无副作用。从实用的角度来看，JSON是一种流行的数据格式，拥有可用于处理几乎所有的语言的库，时尚的年轻人都喜欢使用。一个简单的选择。</p><p>因此，第二代远程WebDriver的协议使用HTTP，因为HTTP的翻译机制和用UTF-8作为默认编码方案对JSON编码。UTF-8被选为默认编码方式，使客户可以很容易地用对Unicode的支持有限的语言编写，因为UTF-8与ASCII向后兼容。发送到服务器的命令使用URL来确定要发送哪些命令，为数组中的命令编码参数。</p><p>例如一个’’WebDriver.get(“<a href="http://www.example.com" target="_blank" rel="noopener">http://www.example.com</a> “)’’的调用对应于一个POST请求的URL编码会话ID并以“/url”结尾，有一个像是{[}’<a href="http://www.example.com" target="_blank" rel="noopener">http://www.example.com</a> ‘{]}的属性数组。返回的结果是一个较为结构化，并有占位符的返回值和错误代码。不就之后，远程协议的第三次迭代出现，它取代了参数要求的阵列命名参数的字典。这有使调试请求变得显著容易的优点，并除去客户误错序参数的可能性，使得系统作为一个整体更健壮。当然，决定使用正常的HTTP错误代码，以表明最合适的方式的一定的返回值和回应；例如，如果用户试图调用一个无任何映射到的URL时，或者当我们想表明“空响应”时。</p><p>远程的WebDriver协议具有两层错误处理，一个用于无效的请求，和一个用于失败的命令。无效的请求的一个例子，对于未在服务器上的资源，或者该资源不理解的动词（例如发送一个DELETE命令到用于处理当前页面的URL中的资源上）。在这种情况下，一个正常的HTTP的4xx响应被发送。对于失败的命令，响应错误代码为500（“内部服务器错误”），并返回的数据中包含的什么地方出了错的更详细的描述。</p><p>当一个响应包含从服务器发送的数据，它需要一个JSON对象的形式：</p><p><strong>关键词描述</strong></p><p>sessionId：服务器所使用的不透明句柄来确定路由会话特定的命令。Status：数字状态代码总结命令的结果。非零值表明命令失败。value响应JSON值。一个响应的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; sessionId: &apos;BD204170-1A52-49C2-A6F8-872D127E7AE8&apos;, status: 7, value: &apos;Unable to locate element with id: foo&apos; &#125;</span><br></pre></td></tr></table></figure><p>如你所见，我们在响应中进行状态码的编码，用一个表示某物已经可怕出差错的一个非零值。 IE的driver是第一次使用状态码，并在有线协议中使用的值反映这些。因为所有错误代码在driver之间是一致的，所以在所有用一个特定的语言辨析的驱动器之间可以共用错误处理码，这使得客户端实施者工作更简单。</p><p>远程服务器的WebDriver简直是一个Java servlet充当多路复用器，路由，接收到合适的webdriver实例的任何命令。它的那种，一个二年级研究生可以写的东西。 Firefox的驱动程序还实现了远程webdriver的协议，它的结构更加有趣，让我们通过跟着请求从语言绑定到后端调用，直到它返回给用户。</p><p>假设我们使用的是Java，而“元素”是WebElement的一个实例，这一切从这里开始：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">element.getAttribute(&quot;row&quot;);</span><br></pre></td></tr></table></figure><p>在内部，元素具有不透明“ID”，服务器端用以确定我们正在谈论哪个元素。为了讨论的方便，我们会想象它的值为“some_opaque_id”。这被编码成一个带有’’Map’’的Java ‘’Command’’ 对象持有（现名为）参数’’id’’用于元素ID，参数’’name’’用于被查询的属性的名称。</p><p>表格中的快速查找表明了正确的URL是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/session/:sessionId/element/:id/attribute/:name</span><br></pre></td></tr></table></figure><p>假设以冒号开始URL的任何部分是一个需要替换的变量。我们已经被赋予了’’id’’和’’name’’参数，并且’’sessionId’’是用于当一台服务器可以同时处理多个会话（其中Firefox的驱动程序不能）时，进行路由的另一种不透明的句柄。此URL通常因此扩展为类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:7055/hub/session/XXX/element/some_opaque_id/attribute/row</span><br></pre></td></tr></table></figure><p>顺便说一句，WebDnriver的远程有线协议最初是与URL模板作为一个RFC草案被提出的同一时间开发的。两个我们指定的URL和URL模板的方案允许变量在URL中进行扩展（因此而得）。可悲的是，虽然URL模板在同一时间提出，但我们在当天较晚时才意识到他们之间的联系，因此它们不是用来形容有线协议。</p><p>因为我们执行的方法是幂等[4]，HTTP的正确的使用方法是GET。我们委托一个Java库，来处理HTTP（Apache的HTTP客户端）调用服务器。</p><p>^<img src="/cdn/images/aosabook/70.png" alt=""><br> |    [图16.4：Firefox的驱动程序体系结构概述]     |</p><p>FireFox的driver被实现为Firefox扩展，其中在图16.4中展示出的基本设计，有点不同寻常，它具有一个嵌入式HTTP服务器。虽然最初我们使用的是一个我们自己已经建立的，写XPCOM的HTTP服务器是不是我们的核心竞争力之一，所以当机会出现，我们用由Mozilla自己写的一个基本的HTTPD取而代之。请求被HTTPD接受后，几乎马上传递给一个’’dispatcher’’对象。</p><p>调度员接管支持的一个已知的URL列表的请求和迭代，试图找到一个能匹配请求的URL。该匹配是通过在客户端的变量插值的知识完成的。一旦找到精确匹配，包括动词使用，一个表示了要执行的命令的JSON对象被构造出来。在我们的例子中，它看起来像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; &apos;name&apos;: &apos;getElementAttribute&apos;, &apos;sessionId&apos;: &#123; &apos;value&apos;: &apos;XXX&apos; &#125;, &apos;parameters&apos;: &#123; &apos;id&apos;: &apos;some_opaque_key&apos;, &apos;name&apos;: &apos;rows&apos; &#125; &#125;</span><br></pre></td></tr></table></figure><p>这是那么作为一个JSON字符串到我们已经编写并命名为CommandProcessor的自定义XPCOM组件的过度。代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var jsonResponseString = JSON.stringify(json);</span><br><span class="line">  var callback = function(jsonResponseString) &#123; var jsonResponse = JSON.parse(jsonResponseString);</span><br><span class="line">  if (jsonResponse.status != ErrorCode.SUCCESS) &#123; response.setStatus(Response.INTERNAL_ERROR); &#125;</span><br><span class="line">  response.setContentType(&apos;application/json&apos;); response.setBody(jsonResponseString); response.commit(); &#125;;</span><br><span class="line">  * Dispatch the command. Components.classes[&apos;@googlecode.com/webdriver/command-processor;1&apos;]. getService(Components.interfaces.nsICommandProcessor). execute(jsonString, callback);</span><br></pre></td></tr></table></figure><p>这里的代码相当多，但其中有两个关键点。首先，把上面的一个对象转换为一个JSON字符串。其次，传递一个回调到出发HTTP响应发送excute方法。</p><p>命令处理器的Execute方法查找“名称”，以确定调用哪个函数，它然后执行。给这个实施函数的第一个参数是一个“’’respond’’”的对象（这么命名是因为它原来只有用于将响应发送回给用户的功能），它不仅封装了可能被发送的可能的值，而且还具有允许响应被回填给用户和机制，以找到DOM的信息。第二个参数是上面看到的’’parameters’’对象的值（在上面的例子中是’’id’’和’’name’’）。这个方案的优点是，每个功能具有一个统一的接口，对应了在客户端使用的结构。这意味着，用于考虑每一侧代码中的思维模型是相似的。这里是’’getAttribute’’的底层实现，已在16.5节看到过：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FirefoxDriver.prototype.getElementAttribute = function(respond, parameters) &#123;</span><br><span class="line">  var element = Utils.getElementAt(parameters.id, respond.session.getDocument());</span><br><span class="line">  var attributeName = parameters.name;</span><br><span class="line">  respond.value = webdriver.element.getAttribute(element, attributeName); respond.send(); &#125;;</span><br></pre></td></tr></table></figure><p>为了使元件的引用一致，第一行简单地查找由不透明的ID在一个高速缓存中提到的元件。在Firefox的driver中，不透明的ID是一个UUID，“告诉缓存”是一个简单的映射。</p><p>该’’getElementAt’’方法还检查是否被引用的元件都已知并且附加到DOM。如果任何检查失败，ID从缓存中删除（如果需要），并抛出一个异常返回给用户。</p><p>倒数第二行利用前面讨论过的浏览器自动化的原子，此时编译为一个单一脚本并加载作为扩展的一部分。</p><p>在最后一行，send方法被调用。这确实一个简单的检查，以确保在它调用提供给执行方法的回调之前，只’’send’’一个响应一次。该响应以一个JSON字符串的形式被发送回用户，它注入一个对象，看起来像这样（假设’’getAttribute’’返回“7”，这意味着该元素未发现）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; &apos;value&apos;: &apos;7&apos;, &apos;status&apos;: 0, &apos;sessionId&apos;: &apos;XXX&apos; &#125;</span><br></pre></td></tr></table></figure><p>Java客户端接着检查状态字段的值。如果该值不为零，它的数值状态代码转换为正确类型的异常并抛出，使用“value”字段帮助设置向用户发送的消息。如果状态是零，“value”字段的值被返回给用户。</p><p>大多数这使得一定的意义，但有一件一个精明的读者都会提出的问题：为什么调度员在调用execute方法之前将它有的对象转换成一个字符串？</p><p>这样做的原因是，Firefox Driver也支持运行用纯的Javascript编写的测试。通常情况下，这将是一个非常难以支持的事情：测试都是在浏览器的JavaScript安全沙箱的上下文中运行，因此可能不能做一系列在测试中有用的事情，如在域或上传文件之间切换。WebDriver的Firefox扩展，于是提供了从沙盒的逃脱的窗口。它通过添加一个’’webdriver’’属性到文档元素宣布了它的存在。WebDriver的Javascript API使用这个作为一个指标，用于添加JSON序列化的命令对象作为文档元素上的’’commad’’属性的值，触发一个自定义的’’webdriverCommand’’事件，和监听同样的元素的’’webdriverResponse’’事件，它在’’response’’属性被设置的时候会被通知。</p><p>这表明，在安装了WebDriver扩展件的Firefox的副本中，浏览网页是一个非常糟糕的主意，因为它使得随便一个人都可以很轻松的远程控制浏览器。</p><p>在幕后，有一个DOM传信者，等待’’webdriverCommand’’读取序列化的JSON对象，并调用命令处理器的Execute方法。这时候，回调是一个简单的设置文档元素的’’response’’ 属性，然后触发预期’’webdriverResponse’’事件。</p><h2 id="翻译参考文献"><a href="#翻译参考文献" class="headerlink" title="翻译参考文献"></a>翻译参考文献</h2><p>[1]  <a href="http://www.ituring.com.cn/article/16152" target="_blank" rel="noopener">http://www.ituring.com.cn/article/16152</a> |卷1：第16章 Selenium WebDriver   作者: <a href="http://www.ituring.com.cn/users/56841" target="_blank" rel="noopener">http://www.ituring.com.cn/users/56841</a> |NullPointer </p><p>[2]  <a href="http://www.infoq.com/cn/news/2011/06/selenium-arch" target="_blank" rel="noopener">http://www.infoq.com/cn/news/2011/06/selenium-arch</a> |开源应用架构之?Selenium WebDriver（上）   作者: <a href="http://www.infoq.com/cn/author/%E5%B4%94%E5%BA%B7" target="_blank" rel="noopener">http://www.infoq.com/cn/author/%E5%B4%94%E5%BA%B7</a> |崔康 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Selenium-WebDriver中文翻译&quot;&gt;&lt;a href=&quot;#Selenium-WebDriver中文翻译&quot; class=&quot;headerlink&quot; title=&quot;Selenium WebDriver中文翻译&quot;&gt;&lt;/a&gt;Selenium WebDriver中文
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Sendmail</title>
    <link href="http://blog.ccao.cc/2018/09/28/Sendmail/"/>
    <id>http://blog.ccao.cc/2018/09/28/Sendmail/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.674Z</updated>
    
    <content type="html"><![CDATA[<p>此章节的 <a href="http://www.aosabook.org/en/sendmail.html|英文原文" target="_blank" rel="noopener">http://www.aosabook.org/en/sendmail.html|英文原文</a> 在 <a href="http://www.ituring.com.cn/minibook/19|图灵社区" target="_blank" rel="noopener">http://www.ituring.com.cn/minibook/19|图灵社区</a> 中没有中文翻译，所以会先行翻译，再发布调研报告。</p><h1 id="Sendmail-中文翻译"><a href="#Sendmail-中文翻译" class="headerlink" title="Sendmail 中文翻译"></a>Sendmail 中文翻译</h1><h4 id="原作者：Eric-Allman"><a href="#原作者：Eric-Allman" class="headerlink" title="原作者：Eric Allman"></a>原作者：Eric Allman</h4><h4 id="译者：徐有健-131220113（翻译比较渣，欢迎大家勘误）"><a href="#译者：徐有健-131220113（翻译比较渣，欢迎大家勘误）" class="headerlink" title="译者：徐有健 131220113（翻译比较渣，欢迎大家勘误）"></a>译者：徐有健 131220113（翻译比较渣，欢迎大家勘误）</h4><p>大多数人把电子邮件这个看作是他们所交互的程序，他们的邮件客户端——在技术上被称为邮件用户代理（MUA）。但是电子邮件另一重要的部分是把邮件从发件人传送到收件人的软件，即邮件传输代理（MTA）。第一个出现在互联网上的MTA是 sendmail，这目前也依旧是最流行的MTA。</p><p>sendmail在互联网正式出现之前就被初次创造出来了。他从1981年——那时因特网还不是明显地要成为不仅仅是拥有几百台主机的学术实验，一直成长到今天——在2011年一月就有了超过8亿台主机，而且成长得格外成功。sendmail一直存在于因特网上简单邮件传输协议（SMTP）最常用的安装启用中。</p><h2 id="17-1-很久很久从前……"><a href="#17-1-很久很久从前……" class="headerlink" title="17.1.很久很久从前……"></a>17.1.很久很久从前……</h2><p>成为后来的sendmail的程序的第一版本写于1980年。起初他只是为了在网络之间传送消息而草草写下的程序。在那时，因特网正处于发展中但没有多少功能。事实上，许多不同种类的网络被提议但是没有一个能够明显脱颖而出被大多数人认可。Arpanet（阿帕网络，互联网前身）使用于美国，因特网作为他的一个升级版本被设计出来。但是，欧洲国家却支持OSI（Open Systems Interconnect开放式系统互联网），而且在一段时间内，OSI显现出将要成功的势头。这些网络都是用来自电话公司的专线网络。在美国，这种专线网络的速度为56Kbps。</p><p>按照使用的电脑数目和连接的人数来看，当时最成功的网络或许是UUCP网络（Unix to Unix Copy Protocol Network复制协议网络）。这是非同寻常的因为他没有集中的中心。在某种意义上，他是一种原始的对等网络（peer-to-peer network）。在当时，对等网络用尽了拨号电话线，有时可用地最快网速大约是9600bps。最快的网络（速度在3Mbps这个级别）是基于施乐公司的以太网（Ethernet），它使用一个叫做XNS（Xerox Network Systems施乐网络系统）的协议，这种协议必须要进行本地安装。</p><p>当时的环境和现在所有的完全不同。电脑的种类多种多样，甚至于到了连8位比特字节都没有完全被一致使用的程度，比如PDP-10（36位字，9位字节），PDP-11（16位字，8位字节），CDC 6000 系列（60位字，6位字符），IBM 360（32位字，8位字节），XDS 940，ICL 470, 和Sigma 7。来自于贝尔实验室的Unix是当时很有前景的平台之一。大多数基于Unix的机器使用16位地址空间。PDP-11是当时主要的Unix平台机器，Data General 8/32和VAX-11/780才刚刚出现。线程也不存在，事实上动态过程的概念还非常新颖（Unix使用了他，但是比较“严肃庄重”的系统就没有，比如IBM’s OS/360）。Unix内核不支持文件上锁（技巧可能是使用文件系统链接）。</p><p> 从某种程度上说，网络普遍是低速的（许多网络基于9600波特的电传线，有钱人或许能使用以太网络，但也只是在本地使用）。伟大的套接字接口还要许多年才能被发明出来。公共秘钥加密也还没有被发明。我们现在所熟知的网络安全在当时是完全不可行的。</p><p>网络邮件已经存在于Unix中了，但也只是草创。当时主要的用户代理是’’/bin/mail’’指令（现在有时指’’binmail’’或者’’v7mail’’），但是有些站点使用其他用户代理，比如伯克利（Berkeley）的’’Mail’’——他事实上明白如何把消息当做个体来对待而不是美其名曰作为’’cat’’程序。所有的用户代理直接读（通常也会写）’’/usr/spool/mail’’。对于消息如何被存储完全没有抽象的概念。</p><p>对本地电子邮件来说，把消息按线路传送至网络的逻辑就是看地址是否包含感叹号（UUCP）或者冒号（BerkNET）。使用阿帕网络的人必须使用一个完全独立的邮件程序。这样的程序不会和其他网络交互，甚至将本地邮件以不同的格式存储在了不同的地方。</p><p>更加有趣的是，事实上这些信息本身也没有标准的格式。获得普遍认同的是在消息开头会有一段标题字段，每个标题字段占一行且标题字段的名字和值会用冒号加以分隔。除此之外，在标题字段的名字和个别字段的格式方面几乎没有标准。比如有些系统使用’’Subj:’’而不是’’Subject:’’，’’Date:’’字段格式不同，有些系统不识别在’’From:’’字段中的全名。除了这些外，被记录在案的往往是模棱两可的或者不完全是在实际使用中的。尤其要指出的是，RFC 733（它意图去描述阿帕网络消息的格式）和那些被实际上用微妙但有时重要的方法去使用的机器不相同，而且它实际上传递消息的方法没有被官方地记录在案（尽管有些RFC机器引用了一些机制，但没有一个做出了定义）。最后结果是，消息传输系统这方面多少感觉像是圣职。</p><p>在1979年，安格尔关系数据库管理项目（也是我的日常工作）获得了美国国防部高级研究计划局（DARPA）的拨款，用这笔拨款，我们连接了一条9600bps的阿帕网络到我们的PDP-11机器上。在当时，这是计算机科学部门唯一的阿帕网络连接，所以每个人都想使用我们的机器来连接上阿帕网络。但是，机器已经负担很重了，所以我们只能开放两个登录接口让部门里的每一个人分享使用。这导致了大量的争论和频繁的冲突。然而我注意到大家最想要的并不是远程登录或者文件传输，而是电子邮件。</p><p>因此，sendmail（最初叫做delivermail）作为使混乱变成一致的一次尝试而诞生了。每一个MUA（邮件用户代理，或邮件客户端）会给delivermail发送命令来发送邮件，而不是搞明白应该如何在需要时发送，这又是也是相矛盾的。delivermail/sendmail 不尝试去描述本地的邮件应该如何被存储或者被发送。他除了在其他程序之间传送邮件之外什么也没干。（但是在我们可以预见的不久后，当SMTP被添加时，这种情况发生了改变。）在某种意义上，它相当是一种将各种各样的邮件系统连接在一起的胶水，而不是独立地成为一个邮件系统。</p><p>在sendmail的发展过程中，阿帕网络转变成了因特网。从线路上低级的数据包到贯穿整个应用协议，这种变化很广泛但是没有立即就发生。sendmail 伴随着标准的变化稳步地进步着，甚至在某些情况下影响着标准。值得注意的是，sendmail存活了下来，甚至随着网络（和如今我们所想的概念相同）规模从几百台主机到成千上万台主机，sendmail变得兴盛繁荣。</p><blockquote><p>另一种网络<br>值得一提另一种完全不同的邮件标准，在当时被提议时被称为X.400，它是ISO/OSI（International Standards Organization/Open Systems Interconnect，国际标准化组织/开放系统互联）的一部分。X.400是一种二进制协议，用ASN.1（Abstract Syntax Notation 1，抽象描述文法）将消息编码，如今仍然使用于一些互联网协议中，例如LDAP（Lightweight Directory Access Protocol，轻量级目录访问协议）。LDAP反而是X.500的简化版本。X.500是X.400使用的目录服务。sendmail没有做任何尝试去直接与X.400兼容，尽管在当时X.400有一些显著有效的网关服务。当时虽然一开始X.400被许多商业合作商采用，但是互联网邮件和SMTP赢得了最终的市场地位。</p></blockquote><h2 id="17-2-设计原则"><a href="#17-2-设计原则" class="headerlink" title="17.2.设计原则"></a>17.2.设计原则</h2><p>当发展sendmail时，我坚持了一些设计原则。所有这些在某种程度上归结为一件事：做的越少越好。这和当时的其他一些拥有更广大的目标和需要更大实现的努力形成了鲜明对比。</p><h4 id="17-2-1-接受一个程序员是有限的"><a href="#17-2-1-接受一个程序员是有限的" class="headerlink" title="17.2.1.接受一个程序员是有限的"></a>17.2.1.接受一个程序员是有限的</h4><p>我把sendmail当做是一个兼职无回报的项目来完成。它被意图使在加州大学伯克利分校的人们更多的可以连接上阿帕网络邮件。关键是在已存在的网络之间传送邮件。这些网络是被当做单机程序而设置的，人们并没有意识到甚至有不止一个网络存在。然而一个兼职程序员修改程序以适应超过一个少量的现存网络是不可实行的。设计需要最小化需要修改的现存代码和需要编写的新代码的数量。这样的约束推动了大部分剩余设计原则的形成。结果是，在大部分情况下，这些设计原则显得十分正确，即使有一个更大的团队。</p><h4 id="17-2-2-不要重新设计用户代理"><a href="#17-2-2-不要重新设计用户代理" class="headerlink" title="17.2.2.不要重新设计用户代理"></a>17.2.2.不要重新设计用户代理</h4><p>邮件用户代理（MUA）是大多数最终用户所认为的“邮件系统”。实际上，它是用来读，写和回复邮件的程序。它和把邮件从发件人传送到收件人的邮件传输代理（MTA）非常不同。当时sendmail被编写时，许多的实现至少部分的结合了这两个功能，所以他们常常一前一后的发展。尝试同时在两方面工作工作量实在太大了，所以sendmail完全去除了用户界面问题：MUA唯一需要修改的是调用sendmail而不是让他们自己寻找路径传输邮件。尤其是已经有了几个用户代理，而且人们对他们如何和邮件交互非常情绪化。尝试同时在两方面工作工作量实在太大了。区别于MTA的MUA已经做得足够聪明了，但是在当时还远远没有行规。</p><h4 id="17-2-3-不要重新设计本地邮件存储库"><a href="#17-2-3-不要重新设计本地邮件存储库" class="headerlink" title="17.2.3.不要重新设计本地邮件存储库"></a>17.2.3.不要重新设计本地邮件存储库</h4><p>本地邮件存储库（信息被存储在此处知道收件人出现阅读了它）还没有被正式标准化。有些站点喜欢把它们存储在一个集中地地方，例如’’/usr/mail’’，’’/var/mail’’，’’/var/spool/mial’’。其他站点喜欢把它们存储在收件人的根目录（举例来说，比如叫做’’.mail’’的文件）。大多数站点让每个信息以一行后面跟了一个空格的“From”来开头（这是一个极其坏的决定，但却是当时的惯例），但是专注于阿帕网络的站点通常把消息以包含了4个control-A字符的一行来区别开来存储。一些站点尝试着把邮箱上锁来避免碰撞冲突，但他们使用不同的上锁惯例（文件上锁的基本功能还没有实现）。简而言之，唯一合理的做法是把本地邮件存储库当做黑盒子来对待。</p><p>在几乎所有的站点，实现本地邮箱的实际原理具体呈现在’’/bin/mail’’中的程序。这个程序把一个相当原始的用户界面，路由选择和存储建设在一个程序中。为了合并sendmail，路由选择的部分被去除并被代替为调用sendmail。一个’’-d’’标记被添加进去来推动最终的邮件传送，也就是它阻止了’’/bin/mail’’调用sendmail去做路由选择。在之后的几年，被用来把消息传送到物理的邮箱的代码被提取出来变成了另一个叫做’’mail.loacl’’的程序。现存的’’/bin/mail’’的程序只包含最少量的发送邮件的框架脚本代码。</p><h4 id="17-2-4-让sendmail适应这个世界，而不是与此相反"><a href="#17-2-4-让sendmail适应这个世界，而不是与此相反" class="headerlink" title="17.2.4.让sendmail适应这个世界，而不是与此相反"></a>17.2.4.让sendmail适应这个世界，而不是与此相反</h4><p>例如UUCP和BerkNET的协议已经作为单独的，有它们各自有时古怪的命令行结构的程序被实现。在某些情况下，他们和sendmail同时被积极的发展着。显然重新实现它们（例如，修改它们以标准化调用惯例）会是令人痛苦不堪的。这直接导致了这项原则————sendmail应该适应这个世界而不是尝试让世界来适应sendmail。</p><h4 id="17-2-5-修改的越少越好"><a href="#17-2-5-修改的越少越好" class="headerlink" title="17.2.5.修改的越少越好"></a>17.2.5.修改的越少越好</h4><p>在发展sendmail的过程中，我尽最大程度可能不去碰我完全没有必要去碰的东西。除了只是没有足够时间来这么做外，当时在伯克利分校有这样一个文化习惯，避开大多数正式代码支持了政策“最后一个碰代码的人就变成负责这个程序的人”（或者简言之，“你碰了它，你就拥有了它”）。尽管根据现在的标准这听起来非常混乱，但在伯克利分校这个没有人被分配全职在Unix上工作的环境中，这确实相当有用。每个人工作在系统中他们各自感兴趣的部分，并且承诺不去碰其余的代码除非是极端情况。</p><h4 id="17-2-6-早点考虑可靠性"><a href="#17-2-6-早点考虑可靠性" class="headerlink" title="17.2.6.早点考虑可靠性"></a>17.2.6.早点考虑可靠性</h4><p>在sendmail之前的邮件系统（包括大多数传输系统）没有极度的关心可靠性。例如，在4.2BSD之前的Unix版本没有本地文件上锁机制，尽管这可以模仿成创建一个临时文件然后把它连接到一个上锁的文件（如果上锁文件已经存在那么连接失败）。但是，有时不同的程序写相同的数据文件不会在如何给文件上锁方面达成一致（举个例子，它们可能会使用不同的上锁文件名或者甚至不做任何尝试给文件上锁）。因此丢失邮件是很正常的事。sendmail采取行动来杜绝邮件丢失的发生（可能因为我的背景是搞数据库的，在数据库方面丢失数据可是个弥天大罪）。</p><h4 id="17-2-7-什么原则被放弃了"><a href="#17-2-7-什么原则被放弃了" class="headerlink" title="17.2.7.什么原则被放弃了"></a>17.2.7.什么原则被放弃了</h4><p>在早期的版本中，有许多东西没有做。我没有尝试着重新构建邮件系统或者重建一个完全的通解：在需求出现时，功能可以被添加。要是没有源代码和编译器，非常早期的版本甚至不打算变的完全可配置（尽管这改变得相当的早）。总的来说，sendmail的做法是：迅速做出一个可能够运行的东西，然后根据需求和随着对问题的更好领悟来增强工作的代码。</p><h2 id="17-3-发展阶段"><a href="#17-3-发展阶段" class="headerlink" title="17.3.发展阶段"></a>17.3.发展阶段</h2><p>和大多数长期存在的软件一样，sendmail分阶段地发展进步，每个阶段都有他自己的主题和感觉。</p><h4 id="17-3-1-第一阶段：delivermail"><a href="#17-3-1-第一阶段：delivermail" class="headerlink" title="17.3.1. 第一阶段：delivermail"></a>17.3.1. 第一阶段：delivermail</h4><p>sendmail的第一个示实例被叫做delivermail。如果不是简单得过分的话，它已经是极其的简单了。它唯一的功能就是把邮件从一个程序传送到另一个程序，尤其是在没有SMTP支持的情况下，所以它从来没有做任何的直接网络连接。排队是不必要的，因为每个网络已经有各自的排队机制了，所以这个程序真的只是个横纵开关。既然delivermail没有直接的网络协议的支持，那么也就么有理由让它作为后台程序来运行——当任意一段消息被提交时，它（delivermail）会被唤醒去按线路发送消息，把它传送到能够实现下一跳转的程序，然后就终止运行。相同的也不用尝试去重新写首部去适应消息要被传送到达的网络。这一般会导致的结果是被传送的消息不能被回复。这种情况非常糟糕，以至于有关于处理邮件地址的一整本书被写出来（这本书被非常适合地叫做<em>!%@:: A Directory of Electronic Mail Addressing &amp; Networks</em> [AF94]）</p><p>在delivermail中所有的配置都被编译在且仅基于每个地址的特殊字符。字符拥有优先权。例如，一个主机的配置可能会寻找一个“@”的标志，如果找到了一个“@”，它会把整个地址发送给一个指定的阿帕网中继主机。否则，它可能会寻找一个冒号，如果找到了一个，它会把消息、指定的主机和用户一起发送给BerNET，然后检查一个表明消息应该转发给指定的UUCP中继的感叹号（“!”）。否则，它会尝试本地传递。这种配置可能最终形如以下：</p><table><thead><tr><th>Input</th><th>Send To {net,host,user}</th></tr></thead><tbody><tr><td>foo@bar</td><td>{Arpanet, bar, foo}</td></tr><tr><td>foo:bar</td><td>{Berknet, foo, bar}</td></tr><tr><td>foo!bar!baz</td><td>{Uucp, foo, bar!baz}</td></tr><tr><td>foo!bar@baz</td><td>{Arpanet, baz, foo!bar}</td></tr></tbody></table><p>注意，地址分隔符在结合性方面有不同，这会产生歧义而且只能采用启发法来解决。例如，上述最后一行的例子在别的站点可以被解析为{Uucp, foo, bar@baz} 。</p><p>配置编译为几个原因：首先，在16位地址空间和有限的内存情况下，解析一个运行环境配置消耗太多的资源；其次，当时的系统是被高度定制的，编译是一个好主意，但只是为了确保你有本地函数库（共享函数库不存在于第六版UNIX中）。</p><p>delivermail随着4.0和4.1版本的BSD传播开来，而且成功得超过了预期；伯克利分校还远不是唯一的有混合网络架构的站点。显然，这需要更多的工作。</p><h4 id="17-3-2-第二阶段：sendmail-3，4和5"><a href="#17-3-2-第二阶段：sendmail-3，4和5" class="headerlink" title="17.3.2. 第二阶段：sendmail 3，4和5"></a>17.3.2. 第二阶段：sendmail 3，4和5</h4><p>版本1和2是以delivermail的名字分布的。在1981年三月，版本3的工作开始了，这将是以sendmail名字发布。在这个时间点上，16位的PDP-11仍处于普遍使用中，但是32位的VAX-11越来越受欢迎，所以很多原来和小地址空间相关的约束条件开始变得宽松起来。</p><p>sendmail的最初目标转换至运行环境配置，允许修改消息来为在不同网络之间转发邮件而提供兼容性，并有进行路由决策的更丰富的语言。所使用的技术本质上是基于原文重写地址（基于令牌而不是字符串），这是当时在一些专家系统中所使用的机制。有临时代码提取和保存任何注释字符串（在括号中）以及在程序改写完成后重新插入它们。同样重要的是能够添加或增大首部区域（例如，添加一个’’Date’’首部字段，或者在已知的情况下把发送者的全名包含在’’From’’首部中）。</p><p>SMTP的发展始于1981年十一月。加州大学伯克利分校的计算机科学研究组（CSRG）得到了DARPA（美国国防部高级研究计划局）的合同去提供一个基于Unix的平台来支持DARPA资助的研究，目的是使项目之间的共享更加方便。TCP/IP协议栈的初始工作是在当时完成的，虽然套接字接口的细节还在不断变化。基本的应用协议，例如Telnet和FTP都完成了，但SMTP尚未实施。事实上，SMTP协议当时还没有完全编写结束；关于邮件应该如何使用一个被创造性地命名为Mail Transfer Protocol（邮件传输协议，MTP）的协议来被发送仍然有巨大的争论议。随着争论愈演愈烈，MTP变得越来越复杂，直到SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）在挫折中被设计出来并或多或少的得到了许可（但直到1982年八月才正式发表）。我正式地工作在安格尔关系数据库管理系统，但因为我对邮件系统的了解比当时伯克利分校的任何人都要深入，所以我被找去加入实现SMTP的项目。</p><p>我最初的想法是创建一个单独的有自己的队列和后台进程的SMTP邮件程序；子系统将依靠sendmail做路由。然而，SMTP的几个特征使得这一想法有些问题。例如，在’’EXPN’’和’’VRFY’’命令需要解析、别名分析和本地地址验证模块的权限。而且，当时我认为如果地址未知那么’’RCPT’’命令立即返回是很重要的，而不是先接受消息，然后之后不得不发送一个发送失败信息。这后来被认为是一个有先见之明的决定。具有讽刺意味的是，后来MTA经常犯这样的错，恶化了垃圾邮件后向散射问题。这些问题促成了将SMTP包含为sendmail本身一部分的决定。</p><p>sendmail 3 分布在4.1a和4.1c版本的BSD（beta版本），sendmail 4分布在4.2版本的BSD，sendmail 5分布在4.3版本的BSD。</p><h4 id="17-3-3-第三阶段：混乱阶段"><a href="#17-3-3-第三阶段：混乱阶段" class="headerlink" title="17.3.3. 第三阶段：混乱阶段"></a>17.3.3. 第三阶段：混乱阶段</h4><p>在我离开伯克利分校去一个初创公司后，我能花在sendmail上的时间急剧减少。但互联网却开始发生严重的爆炸式增长，sendmail也被用在各种新的（大）环境之中。大多数UNIX系统供应商（尤其是Sun、DEC、IBM）创造了他们自己的版本互不兼容的sendmail。也有试图去创建开源版本的，特别是IDA sendmail和KJS。</p><p>IDA sendmail来自林雪平大学。IDA包括了功能扩展来使其在更大环境和全新的配置系统中更容易安装和管理。其中一个主要的新功能是包含dbm（3）数据库地图来支持高度动态网站。在配置文件中使用一个新的语法就可以实现这些功能。这些功能也用于其他许多功能，包括从外部语法映射地址和映射地址到外部语法（例如，以<a href="mailto:john_doe@example.com" target="_blank" rel="noopener">john_doe@example.com</a>的地址发送邮件而不是<a href="mailto:johnd@example.com" target="_blank" rel="noopener">johnd@example.com</a>）和路由。</p><p>King James Sendmail（KJS，由Paul Vixie创造）试图统一已经涌现出来的所有版本的sendmail。不幸的是，它从来没有真正得到足够的牵引力来达到预期。这个时代也被大量的新技术所驱动着进步，这一切都体现在邮件系统的发展过程中。例如，Sun的无盘集群的创造增加了YP（黄页，后来NIS，即网络信息服务）目录服务和NFS，即网络文件系统（the Network File System）。特别是，YP不得不对sendmail来说可见，因为邮件别名存储在YP而不是本地文件。</p><h4 id="17-3-4-第四阶段：sendmail-8"><a href="#17-3-4-第四阶段：sendmail-8" class="headerlink" title="17.3.4. 第四阶段：sendmail 8"></a>17.3.4. 第四阶段：sendmail 8</h4><p>几年后，我作为工作人员回到了伯克利。我的工作是为计算机科学系的研究管理一组安装和支持共享的基础设施。为了成功完成任务，个人研究小组的主要临时环境需要在某些合理的方面被统一。就像早期的互联网，不同的研究组在完全不同的平台上工作，其中一些平台很老旧。总的来说，每个研究小组运行自己的系统，尽管他们中有些管理的很好，他们中的大多数还是深受“延期维修”的困扰。</p><p>在大多数情况下，电子邮件有相似的分段。每个人的邮件地址都是<a href="mailto:&#39;&#39;person@host.berkeley.ed" target="_blank" rel="noopener">&#39;&#39;person@host.berkeley.ed</a>‘’，这个地址的’’host’’是他们办公室中或者他们使用的共享服务器上的工作站（校园网甚至没有内部子域），除了一些特殊的人有以<a href="mailto:&#39;&#39;@berkeley.edu" target="_blank" rel="noopener">&#39;&#39;@berkeley.edu</a>‘’结尾的地址。其目标是交换至内部的子域（因此所有个人主机地址会在’’cs.berkeley.edu’’子域中）和形成一个统一的邮件系统（所以每个人都会有一个<a href="mailto:&#39;&#39;@cs.berkeley.edu" target="_blank" rel="noopener">&#39;&#39;@cs.berkeley.edu</a>‘’结尾的地址）。通过创造一个全新版本的能在全系使用的sendmail使得这个目标轻松地实现。</p><p>我开始研究许多已经变得流行的变异版sendmail。我的意图不是从一个不同的代码库开始写起，而是了解其他变异版所发现的有用的功能。许多这些想法能够在sendmail 8中找到自己的影子，通常情况下这些点子被进行了修饰来使得相似的想法合并或者让它们变得更通用。例如，几个版本的sendmail都能够获取内部数据库的权限，如 dbm（3）或NIS；sendmail 8那他们合并为一个能够处理多类型数据库（或者任意的无数据库转换）的“映射图”机制。相似的，来自IDA sendmail的“泛型”数据库（内部到外部的名称映射）也被合并其中。</p><p>sendmail 8还包括一个使用m4（1）宏处理器的新的配置包。这为的是比sendmail 5的已经大部分程序化的配置包更加的陈述化。也就是说，sendmail 5配置包本质上需要管理员手工布置整个配置文件，这真的只使用了m4的“include”设施作为速记。sendmail 8配置文件允许管理员来声明需要哪些特性，寄件人等，然后m4就会展开最终的配置文件。</p><p>17.7节的大部分内容论述了sendmail 8中的增强性功能。</p><h4 id="17-3-5-第五阶段：商业阶段"><a href="#17-3-5-第五阶段：商业阶段" class="headerlink" title="17.3.5. 第五阶段：商业阶段"></a>17.3.5. 第五阶段：商业阶段</h4><p>随着互联网的发展，sendmail网站数量的扩大，为更大数目的用户群提供支持引发了更多的问题。暂时，我能够设置一组通过电子邮件和新闻组提供免费援助的志愿者（非正式地讲叫做“Sendmail联盟”，又名sendmail.org）来继续下去。但在上世纪90年代末，已经安装的基础已经发展到几乎不可能在志愿者基础上来支持的程度。抱着得到新的资源来维持这些代码的想法，我和一个更有商业头脑的朋友一起创建了sendmail,Inc.。</p><p>虽然商业产品最初大部分基于配置和管理工具，但是许多新的功能被添加到开源MTA来支持商业世界的需要。值得注意的是，公司新增了对如下一些方面的支持：TLS（连接加密）、SMTP认证、网站安全增强，例如拒绝服务保护，最重要的是邮件过滤插件（Milter接口在接下来会讨论）。</p><p>在写这篇文章时，商业产品已扩大到包括一大套基于电子邮件的应用，几乎所有这些应用都是建立公司的头几年对sendmail的功能扩展上。</p><h4 id="17-3-6-sendmail-6和7究竟发生了什么？"><a href="#17-3-6-sendmail-6和7究竟发生了什么？" class="headerlink" title="17.3.6. sendmail 6和7究竟发生了什么？"></a>17.3.6. sendmail 6和7究竟发生了什么？</h4><p>sendmail 6本质上是sendmail 8的beta版本。它从没有被正式发布，但是扩散地相当的广泛。sendmail 7根本不存在。sendmail直接跳到了版本8，因为当1993年6月4.4版本BSD发布时，所有其他为了BSD的分布而写的源文件都被版本8给替换了下来。</p><h2 id="17-4-设计决策"><a href="#17-4-设计决策" class="headerlink" title="17.4. 设计决策"></a>17.4. 设计决策</h2><h4 id="17-4-1-配置文件的语法"><a href="#17-4-1-配置文件的语法" class="headerlink" title="17.4.1. 配置文件的语法"></a>17.4.1. 配置文件的语法</h4><p>配置文件的语法由几个问题驱动。首先，整个应用程序必须放入一个16位的地址空间，所以解析器必须足够小。其次，早期的配置是相当短（只有一页），因此，尽管语法是晦涩的，该文件仍然是可以理解的。然而，随着时间的推移，更多的可操作的决定C代码搬到了配置文件，所以该文件开始变长。配置文件获取了晦涩难解的“美誉”。对许多人来说的一个挫折是把制表符作为有效的语法成分的决策。这是一个从当时的其他系统复制过来的错误，尤其是’’make’’。随着Windows操作系统（剪切和粘贴操作通常没有保留制表符）更多的的被使用，该特定问题变得更加尖锐。</p><p>现在回想起来，随着文件变大，32位的机器获得统治地位，重新考虑语法变得很有意义。曾几何时，我想要这样去做，但最后没有决定去做，因为我不想打破“庞大”的安装基础（在这一点上可能是好几百台机器）的时候。现在回想起来，这是一个错误。我根本就没有意识到安装基础将会增长得大到什么程度，如果我早点修改了语法我能够节省多少时间。另外，当标准稳定下来时，相当数量的一般性问题本可能被推回到C代码库中去，从而简化了配置。</p><p>特别值得注意的是更多的功能是怎么被加入配置文件的。我在SMTP发展的同一时间开发了sendmail。通过将可操作的决定移入到配置文件中，我能够迅速地对设计变化做出回应——通常在24小时内。我认为这提高了SMTP标准，因为它可以很快通过快速变化的被提议的设计来获得可操作经验，但代价仅仅是配置文件变得难以理解。</p><h4 id="17-4-2-重写规则"><a href="#17-4-2-重写规则" class="headerlink" title="17.4.2. 重写规则"></a>17.4.2. 重写规则</h4><p>编写sendmail的时候的一个困难的决定是如何做必要的重写来允许不同网络之间的邮件传输不违反接收网络的标准。邮件的转换需要改变元字符（例如，BerkNET使用冒号作为分隔符，但是这在SMTP地址中并不合法）、重新排列地址成分、添加或删除成分等等。例如，在某些情况下需要做出如下的重写：</p><table><thead><tr><th>From</th><th>To</th></tr></thead><tbody><tr><td>a:foo</td><td><a href="mailto:a.foo@berkeley.edu" target="_blank" rel="noopener">a.foo@berkeley.edu</a></td></tr><tr><td>a!b!c</td><td><a href="mailto:b!c@a.uucp" target="_blank" rel="noopener">b!c@a.uucp</a></td></tr><tr><td>&lt;@a.net,@b.org:<a href="mailto:user@c.com" target="_blank" rel="noopener">user@c.com</a>&gt;</td><td>&lt;@b.org:<a href="mailto:user@c.com" target="_blank" rel="noopener">user@c.com</a>&gt;</td></tr></tbody></table><p>正则表达式是不是一个好选择，因为他们没有很好地支持word边界、引用等等。很快变得显然的是，几乎不可能写出准确的正则表达式，而且更加难以理解。特别是，正则表达式保留了一部分元字符，包括“.”、“*”、“+”、“{[}”和“{]}”，所有这些字符都可以出现在电子邮件地址中。这些可能已经跳出了配置文件的范围，但我认为这很复杂、混乱，而且有点丑陋。（这已经由来自贝尔实验室的UPAS（第八版本Unix的邮件收发程序）尝试过了，但它从来没有流行起来。）相反，扫描阶段对于产生在常规表达式中可以像符号一样被操作的标记是必要的。一个单一的参数描述“操作者的角色”，他们自己既是标记又是标记分隔符，就足够了。空格分隔了标记但不是标记本身。重写规则只是被组织进本质上是子程序的代码中的成对的模式匹配/替换操作。</p><p>取代大量的已经被回避从而失去了他们的“神奇”特性（在正则表达式中被使用）的元字符，我用一个单一与普通字符结合的“escape”字符来表示通配符模式（例如去匹配任意字符）。传统的UNIX系统的方法是使用反斜杠符号，但反斜线符号在一些地址语法中被作为引号字符使用了。结果是，“$”是仅剩的几个没有在一些邮件语法中被用作标点字符的字符之一。</p><p>讽刺的是，一个原始的糟糕决定是关于空白是怎么被使用的事情。空格字符是一个分隔符，就像在大多数的扫描输入中一样，因此它可以被自由在各模式的标记之间使用。然而，原有的配置文件的分布不包括空格，结果导致模式远超过必要地难以理解。考虑下面两个（语义上相同的）模式之间的区别：</p><blockquote><p>$+ + $* @ $+ . $={mydomain}</p></blockquote><blockquote><p>$++$*@$+.$={mydomain}</p></blockquote><h4 id="17-4-3-使用重写来解析"><a href="#17-4-3-使用重写来解析" class="headerlink" title="17.4.3. 使用重写来解析"></a>17.4.3. 使用重写来解析</h4><p>有人建议，sendmail的应该使用传统的基于语法的解析技术来解析地址，而不是重写规则，将重写规则用于地址修改。从表面上看这似乎是有意义的，考虑到该标准定义了使用语法的邮件地址。重用重写规则的主要原因是，在某些情况下，有必要解析首部地址（例如，当从网络接收到一个没有使用正常“信封”的邮件，为了从首部提取收件人）。这样的地址是不容易使用一个LALR（1）解析器，例如YACC，和因需要一定量的先行读取的传统的扫描器。例如，解析地址：<a href="mailto:&#39;&#39;allman@foo.bar.baz.com" target="_blank" rel="noopener">&#39;&#39;allman@foo.bar.baz.com</a> <nowiki><a href="mailto:&#x65;&#x72;&#x69;&#99;&#x40;&#101;&#x78;&#97;&#109;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;" target="_blank" rel="noopener">&#x65;&#x72;&#x69;&#99;&#x40;&#101;&#x78;&#97;&#109;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;</a></nowiki>`需要由任一扫描仪或解析器先行读取。你不可能知道开始的“allman@…”不是一个地址直到看见了“&lt;”。由于LALR（1）解析器只有一个提前的标记，这将必须在扫描仪中来完成，这实质上让这件事变得更加复杂。由于重写规则已经有了任意的回溯（也就是说他们可以向前看任意远），所以重写规则就已经足够了。</p><p>次要原因是，让模式得以识别和修复破损输入是相对容易的。最终原因是，重写已经远足够强大来完成工作，而且重用任何代码都是明智的。</p><p>关于重写规则的一个非同寻常的点是：执行模式匹配时，它对于输入和模式的标记化都是有用的。因此，一个扫描仪同时被用于输入地址和模式本身。这要求扫描仪对不同输入能够调用不同的符号表。</p><h4 id="17-4-4-嵌入SMTP和sendmail的队列"><a href="#17-4-4-嵌入SMTP和sendmail的队列" class="headerlink" title="17.4.4. 嵌入SMTP和sendmail的队列"></a>17.4.4. 嵌入SMTP和sendmail的队列</h4><p>一个“显然”的方式来实现外发（客户端）SMTP本可以被创建为一个外部的邮件收发器，类似于UUCP，但是这将引起一系列其他的问题。例如，队列会在sendmail中还是SMTP客户端模块中被完成？如果它是在sendmail中完成的话，那么消息的任一单独的副本都必须被发送给每个接收者（也就是说，无“捎带”，其中一个单独的连接可以被打开，然后多个’’RCPT’’命令会被发送），否则比可能使用简单的Unix退出代码更加多的通信回路将会变得有必要去传递每个收件人的状态。如果队列在客户模块中被完成，那么它将会有应对大量回复的潜力，尤其，在当时其它网络如XNS仍然是可能的竞争者。此外，将队列包含进入sendmail它本身提供了一个更加简练的处理某些类型的故障的方式，特别是短暂的问题，例如资源枯竭。</p><p>收入（服务器）SMTP涉及一组不同的决策。当时，我忠实的觉得实现’’VRFY’’和’’EXPN’’SMTP指令是非常重要的，这需要别名机制的权限。这将再次需要比可能的使用命令行和退出代码更多的SMTP服务器模块和sendmail之间的协议交换——实际上就是一个类似于SMTP它本身的协议。</p><p>如今我会更倾向于将队列留在sendmail核心中，但将两种SMTP的实现移入其他进程。其中一个原因是为了安全：一旦在服务器端有了一个端口25的开放实例，它不再需要root权限。现代的扩展，如TLS和DKIM签名，使得客户端（因为私钥不应该被未经授权的用户使用）变得更加复杂，但严格来说root访问权限仍然是不必要的。尽管安全问题在这里依然是个问题，如果客户端SMTP作为可以阅读私钥的非root用户运行，从定义上来说该用户具有特殊权限，因此不应与其他网站直接通信。所有这些问题都可以通过一些工作来巧妙地解决。</p><h4 id="17-4-5-队列的实现"><a href="#17-4-5-队列的实现" class="headerlink" title="17.4.5. 队列的实现"></a>17.4.5. 队列的实现</h4><p>Sendmail的遵循了当时的惯例来存储队列文件。实际上，所使用的格式是非常类似于当时的lpr（Lost Packet Recovery，丢包恢复）子系统。每个工作有两个文件，??一个为控制信息，一个为数据。控制文件是每行的第一个字符表示该行意义的纯文本文件。</p><p>当sendmail想要处理队列时，它必须读取所有的控制文件，将相关信息存储在内存中，然后对列表进行排序。在消息相对较少的队列中它运行的很好，但在有10000消息在队列中时开始出现故障。具体地，当目录大到在文件系统中要求间接块时，会出现了严重的可能会减少一个数量级的性能下降。我们可以通过sendmail理解多队列目录来改善这个问题，但是这充其量只是一个敷衍之举。</p><p>可替代的实现方式可以是把所有的控制文件存储在一个数据库文件中。但是我没有这样做，因为在开始编写sendmail时，没有一般可用的数据库包，而当dbm(3)可用时，它有一些缺陷，包括无法回收空间、要求散列在一起的所有关键字装入同一个（512字节）页面、缺少锁。很多年后健壮的数据库软件包才出现。</p><p>另一可替代的实现方法是有一个单独的守护进程来将队列的状态保存在内存中，或许可能会写入日志以允许恢复。考虑到当时相对较低的电子邮件业务流量、在大多数机器上缺乏存储器、相对较高的后台进程成本、实施这样一个进程的复杂性，在当时这似乎并不是很好的折衷办法。</p><p>另一个设计决策是在队列控制文件中存储消息首部而不是存储数据文件。这样的基本原理是，大多数的首部需要从目的地到目的地的相当大的改写（消息可能有一个以上的目的地，所以他们将不得不被多次定制），而且解析报头的成本显得很高，所以将它们以预解析的格式来存储似乎是比较节约资源的。现在回想起来，这不是一个明智的决定，因为我们是以Unix标准格式来存储邮件正文（换行符结尾），而不是以收到它的格式（可以使用换行符，回车/换行，空白回车，或这换行/回车）。随着电子邮件世界的发展以及通过了一些标准，重写的需求减弱了，甚至看似无伤大雅的重写会有风险包含错误。</p><h4 id="17-4-6-接受和修补伪输入"><a href="#17-4-6-接受和修补伪输入" class="headerlink" title="17.4.6. 接受和修补伪输入"></a>17.4.6. 接受和修补伪输入</h4><p>由于sendmail的是在一个多种协议和一些令人不安的书面标准的世界中创造的，我决定无论在什么地方都尽可能的清理损坏的消息。此符合了在RFC中明确表示的“鲁棒性原则”（又名Postel法则，伯斯塔尔法则）。其中一些变化是显而易见的，甚至是必须的。比如，向阿帕网络发送一个UUCP消息，UUCP地址需要被转换为阿帕网络地址。又比如，如果只是让“reply”命令正常工作，线路终端需要在不同平台的约定之间互相转换。等等。还有一些改变不太明显的。比如如果收到的讯息不包含互联网规范要求的’From: ‘头字段，你应该给他添加一个’From: ‘头字段，还是直接传递这个没有’From: ‘头字段的消息，又或是拒绝该消息？当时，我首要的考虑是互操作性，所以sendmail给消息打上补丁，例如，添加’From: ‘头字段。然而，这声称已经使得其他破损的邮件系统能够在他们应该被修补或者是摒弃时得以与世长存。</p><p>我相信在当时我的决定是对，但在今天是有问题的。高度的互操作性对于让邮件流畅通无阻是非常重要的。如果我拒绝了损坏的消息，当时的大多数消息会被拒绝。如果我不修补就让把这些消息传下去，收件人就会收到他们无法答复的邮件，甚至在某些情况下，他们可能不能确定是谁发送了消息，否则这消息又将被其他邮件程序拒绝接收。</p><p>今天标准已经制定好了，并且在大多数情况下这些标准是准确和彻底的。大多数的邮件将被拒绝，或者仍有邮件软件发送损坏的消息的情况已经一去不复返了。这就不必要的给互联网上的其他软件造成了许多问题。</p><h4 id="17-4-7-配置以及M4的使用"><a href="#17-4-7-配置以及M4的使用" class="headerlink" title="17.4.7. 配置以及M4的使用"></a>17.4.7. 配置以及M4的使用</h4><p>在某一个时期我同时给sendmail的配置文件做定期修改，以及个人支持多台机器。由于又大量的不同机器之间的配置文件是一样，使用工具来构建配置文件是值得的。Unix包含有M4宏处理器。它被设计作为编程语言的前端（尤其是RATFOR语言）。最重要的是，它已经“include”的功能，就好像在C语言中的“#include”一样。原始的配置文件几乎不使用超过这个功能和一些小的宏扩展的其他功能。</p><p>IDA的sendmail也用了m4，但是是以显著不同的方式。现在回想起来，我本应该更详细地研究这些原型技术。它们包含了许多巧妙的想法，特别是他们处理引用的方式。</p><p>从sendmail 6开始，m4配置文件被以一个更加陈述式的风格完全重写，而且更小。这使用了相当多的M4处理器的能力，这个在GNU M4的推出微妙地改变了一些语义时是有问题的。</p><p>最初的计划是，M4的配置将遵循80/20法则：他们将会是简单的（因此20％的工作），并且将覆盖80％的情况。这因为两个原因而很快地被打破了。次要原因是，事实是它是相对更容易处理绝大多数的情况，至少在最开始是这样。随着sendmail和世界的发展，这变得更复杂了，特别是一些特性的引入，例如TLS加密和SMTP认证，但这些在更晚的时候才到来。</p><p>最重要的原因是，显而易见的是原始配置文件对于绝大多数人来说太难管理。在本质上，’.cf’（原始）格式已变成了原则上可编辑的汇编代码，但现实中相当不透明。“源代码”是存储’.mc’文件中的一个M4脚本。</p><p>另一个重要的区别是，原始格式的配置文件实际上是一个编程语言。它有程序代码（规则集），子程序调用，参数扩展和循环（但没有goto语句）。语法是模糊的，但在许多方面类似’sed’和’awk’命令，至少在概念上是这样。M4的格式是陈述式的：虽然有可能被降级归为低级原始语言，在实践中这些细节被向用户隐藏。</p><p>目前尚不清楚这一决定是正确还是不正确的。在当时我觉得（现在仍然觉得）配合复杂的系统，它能被用来为构造这个系统的某些部分而实施相当于是领域特定语言（DSL）的功能。然而，将DSL作为一个配制方法学暴露给最终用户本质上是将所有配置系统的尝试转换为了一个编程问题。巨大的能量缘起于此，但是却付出了巨大的代价。</p><h2 id="17-5-其他注意事项"><a href="#17-5-其他注意事项" class="headerlink" title="17.5. 其他注意事项"></a>17.5. 其他注意事项</h2><p>一些其他的体系结构方面的开发要点值得一提。</p><h4 id="17-5-1-关于优化网络规模系统的只言片语"><a href="#17-5-1-关于优化网络规模系统的只言片语" class="headerlink" title="17.5.1. 关于优化网络规模系统的只言片语"></a>17.5.1. 关于优化网络规模系统的只言片语</h4><p>在大多数基于网络的系统中，在客户端和服务器之间存在一些紧张的矛盾。一个客户端的很好的策略对于服务器来说并不好，反之亦然。例如，服务器会尽可能地通过推尽量多的处理任务到客户端，以减少其处理成本，当然客户也做相同的事，但是在相反的方向。例如，一台服务器可能想要在做垃圾邮件处理时保持连接打开，因为这降低了拒绝消息（这在现在是常见的情况）的成本，但客户想尽快断开连接。综观整个系统，也就是说把因特网作为一个整体来看，最佳解决方案是平衡这两个需求。</p><p>已经有使用明确偏向客户端或服务器的策略的MTA的情况。他们只能做到这一点，因为他们有一个相对较小的安装基础。当你的系统被在互联网上的显著部分中使用时，你必须设计好它以平衡双方的负载来优化互联网整体。从事实来看很复杂的是，总是会有MTA彻底向其中一方或另一方倾斜——例如邮件群发系统只关心优化和发送一方。</p><p>当设计结合了双方连接的系统，避免厚此薄彼是非常重要的。请注意，这和通常的客户端和服务器端的不对称形成了鲜明的对比。例如，Web服务器和Web客户端通常不是由同一各小组开发的。</p><h4 id="17-5-2-Milter"><a href="#17-5-2-Milter" class="headerlink" title="17.5.2. Milter"></a>17.5.2. Milter</h4><p>对sendmail最重要的功能添加是milter（<em>mail filter</em>，邮件过滤器）接口。milter允许使用机外插件（例如，他们在一个单独的进程中运行）来处理邮件。这些最初是为反垃圾邮件处理而设计的。milter协议与服务器SMTP协议同步运行。每当接收到一个新的来自客户端的SMTP命令时，sendmail就会使用与来自该命令的信息来调用milter。Milter有机会接受该命令或发出拒绝，从而阻止进入合适该SMTP命令的协议的阶段。Milter被建模为回调，所以当SMTP命令进入时，适当的milter子程序被调用。milter是线程化的，因为它提交一个每个连接上下文指针给每个程序来允许传递状态。</p><p>从理论上讲milter可以作为可加载的模块工作在sendmail的地址空间。我们因为三个原因拒绝这么做。首先，安全问题太重要了：即使sendmail作为一个特殊的非root用户ID来运行，该用户将有权限获得所有其他消息的状态信息。同样的，不可避免的是，有些milter作者会尝试访问内部sendmail的状态。</p><p>其次，我们想要在sendmail和milter之间创建一个防火墙：如果milter崩溃了，我们希望它能够清楚应该由谁负责，以及让（潜在的）邮件继续流出。第三，总的来说，由milter作者自己来调试一个单机的过程要比sendmail简单得多。</p><p>很快变得显而易见的是，milter的有用范围超出了反垃圾邮件处理。事实上，milter.org网站列出了由商业公司和开源组织开发的用于防垃圾邮件，防病毒，存档，内容监控，日志，流量调整等众多类别功能的milter。Postfix邮件添加了对使用相同接口milter的支持。Milters已被证明是sendmail的伟大成就之一。</p><h4 id="17-5-3-发布时刻表"><a href="#17-5-3-发布时刻表" class="headerlink" title="17.5.3. 发布时刻表"></a>17.5.3. 发布时刻表</h4><p>人们在“早发布，经常更新”和“发布稳定的系统”两种观点之间的争论很多。在不同的时代这两种方式都被sendmail使用过。在变化相当重要的时候，我有时一天发布过不止一个版本。我总的理念是在每一个变更之后都发布一个版本。这类似于向公众提供资源管理系统树的访问权限。相比于提供公共源代码树，我个人更喜欢发布新版本。至少某些部分上是这样，因为是我是用一种系在被认为是未经批准的方式来管理资源。对于大的变化，我会在我写代码时检查非运行的快照。如果树是共享的，我会用分支来做快照，但在任何情况下，全世界都可以看到他们，这样会产生相当大的混乱。此外，在创建一个版本发布意味着给它分配一个号码，这使得当查看一个bug报告时能更容易地追踪变化。当然，这需要那个版本发布容易产生，可是实际并非总是如此。</p><p>随着sendmail变得适用于更加关键的生产环境中时，以下变得愈加问题突出：让别人讲清我想在那里供人测试的更新改变和那个真的打算在复杂的实际环境中使用的更新改变之间的差异并不是那么容易。给版本贴上“alpha”或者“bate”的标签稍稍减缓了这个问题，但并没有解决它。其结果是，随着sendmail日渐成熟，它的更新变得不频繁但是版本变化更大。当sendmail被并入一个商业公司时，客户想要既最新又最好的但只是稳定的版本，他们不接受两者是相互矛盾的说法。这时候，这个问题变得尤其尖锐。</p><p>开源开发者的需求和商业产品的需求之间的矛盾永远不会消失。版本发布得又早又频繁有许多优势，尤其是有巨大数目的潜在使用者。他们是勇敢的（有时愚蠢的）测试者，他们以你可能永远不会希望在一个标准的开发版本中复制操作的方式来给予系统压力。但随着一个项目变得成功，它容易变成一个产品（即使该产品是开源和免费的），和项目相比产品有??不同的需求。</p><h2 id="17-6-安全"><a href="#17-6-安全" class="headerlink" title="17.6. 安全"></a>17.6. 安全</h2><p>Sendmail的发展历程十分动荡，但它在安全性方面是明智的。其中的一些是当之无愧的，但有些不是，因为我们的“安全”理念在我们脚下改变了。互联网起初只有一个几千人的用户群，大多数用户是在学术和研究设置领域。当时的互联网在许多方面比我们现在所知的要温和一些。该网络旨在鼓励共享，而不是建防火墙（这是另一个在早期还未出现的概念）。现在的网络是一个危险的，充满敌意的地方，这里充满了垃圾邮件发送者和破坏者。它被越来越多的描述为一个战区，而且在战区充满了平民的伤亡。</p><p>我们很难安全地编写网络服务器，特别是当协议一点也不简单时。几乎所有的程序都至少有一些小问题; 即使是常见的TCP/IP也已经被成功攻击。更高级的实现语言没有找到什么防止攻击的万能方法，甚至自己也有一些弱点。必要的观察短语是“不信任任何输入”，不管它来自哪里。不信任的输入包括次级输入，例如，来自DNS服务器和milter的输入。像大多数早期的网络软件，sendmail在它的早期版本太过于相信外部输入了。</p><p>但是sendmail最大的问题是，早期的版本它运行时是具有root权限的。必要的Root权限可以用来打开SMTP监听套接字，用来读取个人用户的转发信息，并且转交给个人用户的邮箱和主目录。不过，在今天大多数的系统上，邮箱的概念已经从一个系统用户的概念上脱离，这有效地消除了对root权限的需要，除了打开SMTP监听套接字还需要root权限。如今，sendmail能够在处理连接之前放弃root权限，这样消除了对能够支持sendmail的系统环境的担忧。值得注意的是，在那些不直接传递东西给用户的邮箱系统中，sendmail还可以在chroot的环境中运行，从而与更深层次的权限隔离开来。</p><p>不幸的是，当sendmail因为糟糕的安全性而著称时，它开始因为一些和sendmail无关的问题被指责。例如，一个系统管理员使他的’’etc’’目录可写，然后当有人取代了’’/etc/passwd’’文件时指责sendmail。正是类似这样的一些事件导致我们实质性地大幅提高安全性，包括明确检查sendmail访问的文件和目录的来源和模式。这是如此严苛的以至于我们被迫在程序中包含一个’’DontBlameSendmail’’选项来有选择的关闭这些检查。</p><p>还有一些其他方面的安全问题是与保护程序本身的地址空间不相关的。例如，垃圾邮件的兴起也导致了地址收集的兴起。SMTP中的’’VRFY’’和’’EXPN’’命令是分别专门用来验证个人地址和扩大邮件列表中的内容的。这些命令被垃圾邮件的发送者滥用地如此严重，以至于现在大多数网站将其完全关闭。这是不幸的，至少对于’’VRFY’’来说是这样，因为该命令有时被一些反垃圾邮件代理来所谓的发送地址。</p><p>同样，反病毒保护曾一度被作为桌面问题，但是其重要性上升到任何商业级MTA都不得不拥有防病毒检查可用的地步。在现代设置中的其他安全相关的要求包括强制加密敏感数据，数据丢失防护和执行法规要求，例如，HIPPA。</p><p>其中一个sendmail放在心上认真关注的原则是可靠性，每个消息应该要么被发送出去或报告给发件人。但joe-job（一种攻击者伪造邮件返回地址的垃圾邮件，这被许多人视为一个安全问题）的问题引起很多网站关闭退回邮件的创建。如果能够确定故障而SMTP连接仍然是开放的，服务器可以通过使命令失效来报告问题。但是在SMTP连接关闭后，没有有效地址的处理信息将默默地消失。为了公平起见，现在大多数合法的邮件是单跳的，这样问题虽然会被报告，但至少在原则上，已经被世界认可地是，安全的重要性胜过可靠性。</p><h2 id="17-7-Sendmail的演变"><a href="#17-7-Sendmail的演变" class="headerlink" title="17.7. Sendmail的演变"></a>17.7. Sendmail的演变</h2><p>软件如果不能不断地发展来适应这个急剧变化的环境，那么它是无法生存下来的。新硬件技术的出现，推动了操作系统的变化，推动了库和框架的变化，推动了应用程序的变化。如果一个应用程序成功了，这说明它适应了这个问题麻烦源源不断的环境。变化是不可避免的;为了成功你必须接受变化并且拥抱变化。本节介绍一些随着sendmail的演变出现的比较重要的变化。</p><h4 id="17-7-1-配置文件变得更加详细"><a href="#17-7-1-配置文件变得更加详细" class="headerlink" title="17.7.1. 配置文件变得更加详细"></a>17.7.1. 配置文件变得更加详细</h4><p>sendmail的最初配置是相当简洁的。例如，选项和宏的名字都是单个字符。这有三个方面的原因。第一，它使得分析变得非常简单（这在16位的环境中十分重要）。其次，也没有太多的选择，所以想出助记名字并不难。第三，单个字符的公约已经用命令行标志建立了起来。</p><p>同样，重写规则集最初是编号的而不是命名的。也许一开始能够容忍一个小数目的规则集，但随着规则集的数目增多，让他们具有更多的助记名字变得重要。</p><p>随着操作sendmail所在的环境变得更加复杂，也随着16位环境逐步消失，一个更丰富的配置语言变得尤为需要。幸运的是，我们可以以一个向后兼容的方法来做出这些变化。这些变化显著地提高了配置文件的可理解性。</p><h4 id="17-7-2-更多的与其他子系统的连接：大整合"><a href="#17-7-2-更多的与其他子系统的连接：大整合" class="headerlink" title="17.7.2. 更多的与其他子系统的连接：大整合"></a>17.7.2. 更多的与其他子系统的连接：大整合</h4><p>在写sendmail的时候，邮件系统与操作系统的其余部分基本上是隔离的。有一些服务是需要整合的，比如’’/etc/passwd’’和’’/etc/hosts’’的文件。服务交换机还没有被发明出来，目录服务是不存在的，配置文件规模很小并且是手工维护的。</p><p>这一切发生生了迅速改变。其中一个首先被添加的服务是DNS。虽然系统主机查找抽象（’’gethostbyname’’）为查找IP地址功能而服务，电子邮件不得不使用其他的查询服务，如MX。后来，IDA sendmail包括了一个外部的使用dbm(3)文件的数据库查找功能。Sendmail 8 的更新包括，对于一个通用的映射服务,允许其他数据库类型，包括外部数据库和不能通过重写来完成的内部转换（例如给一个地址消除引用）。</p><p>今天，电子邮件系统依赖于许多那些在一般情况下不是为使用电子邮件而专门设计的外部服务。这让sendmail在代码上变得更加抽象。随着越来越多的“活动部件”被添加，这也使得维护邮件系统变得更难了。</p><h4 id="17-7-3-适应一个充满敌意的世界"><a href="#17-7-3-适应一个充满敌意的世界" class="headerlink" title="17.7.3. 适应一个充满敌意的世界"></a>17.7.3. 适应一个充满敌意的世界</h4><p>Sendmail发展于一个在今天的标准看来完全陌生的世界。早期的网络上的用户群大多是相对温和的研究员，尽管有时有恶性的学术政治。Sendmail反映出它被创造的世界，将重点放在尽可能可靠地让邮件被传送通过，即使面对着用户错误。</p><p>今天的世界更加充满敌意。绝大多数的电子邮件是恶意的。一个MTA的目标已经从让邮件传送通过过渡到排除恶意邮件上去了。过滤可能是今天任何MTA的首要任务。这需要sendmail的一些改变。</p><p>例如，许多规则集已经被添加，这是为了允许检查即将传入的SMTP命令行参数来尽早发现问题。在阅读信封时拒收邮件比之后你已经开始阅读整个邮件再拒绝一个邮件要更加节省开销，甚至在为了发送而接收邮件之后才拒绝一个邮件开销更大。在早起，过滤的实现普遍是通过接受该信息，将其传递给一个过滤程序，然后如果消息通过了过滤就把它发送到的sendmail的另一个实例（所谓的“三明治”结构）。这在今天的世界所需的开销实在是太大了。</p><p>同样，sendmail已经从一个TCP/IP连接的普通消费者转变为了更加复杂的存在，它做类似于“偷看”网络输入的事情来看是否在先前的命令已被确认前，发送者就发送命令了。这打破了一些旨在使sendmail适应多种网络类型的以前的抽象概念。今天，这将涉及大量的工作，例如将sendmail连接到一个XNS或DECnet的网络中，由于TCP/IP的知识已经被建为这么多的代码。</p><p>很多配置功能被添加了来处理这个充满敌意的世界，例如对访问表，实时黑名单，地址收集缓解，拒绝服务保护，垃圾邮件过滤这些功能的支持。这极大地复杂化了配置邮件系统的任务，但为了适应当今世界，这一切绝对是必要的。</p><h4 id="17-7-4-新技术的引入"><a href="#17-7-4-新技术的引入" class="headerlink" title="17.7.4. 新技术的引入"></a>17.7.4. 新技术的引入</h4><p>这些年出现了许多新的标准，这需要sendmail做出显著的改变。例如，TLS（加密）的加入需要贯穿大部分代码的显著改变。SMTP流水线需要窥视低级别的TCP/IP数据流以避免死锁。提交端口（587）的加入需要听取多个传入端口能力，包括有取决于到达端口而做出不同的行为的能力。</p><p>其他方面的压力来自于由环境，而不是标准。例如，在邮件过滤器接口的加入是对垃圾邮件的直接反应。虽然邮件过滤器不是一个公布的标准，但这是一个重大的新技术。</p><p>在所有情况下，这些变化以某种方式增强了邮件系统，无论是提高安全性，带来更好的性能，或着带来新的功能。但是，他们都提高了开销，在几乎所有情况下都使得代码库和配置文件变得复杂。</p><h2 id="17-8-假如我今天做它会怎样"><a href="#17-8-假如我今天做它会怎样" class="headerlink" title="17.8. 假如我今天做它会怎样"></a>17.8. 假如我今天做它会怎样</h2><p>事后诸葛亮。有很多事情如果我如今去做会完全不同。有些在当时是无法预见的（例如，垃圾邮件将如何改变我们对电子邮件的看法，现代的工具集会是什么样子等），然而有的却完全是可以预测的。有些只是在我编写sendmail的过程中，我学到了很多有关电子邮件，有关TCP/IP，以及有关编程本身的知识，每个人都随着他们编码而不断成长。</p><p>但也有很多事情我会保持完全一样的做法，有些甚至是与标准的智慧矛盾的。</p><h4 id="17-8-1-那些我会以不同的方式去做的事"><a href="#17-8-1-那些我会以不同的方式去做的事" class="headerlink" title="17.8.1. 那些我会以不同的方式去做的事"></a>17.8.1. 那些我会以不同的方式去做的事</h4><p>或许是我对于sendmail最大的错误就是没有及早认识到它将来会变得多么重要。我有好几次机会向正确的方向轻推世界，但我没有把握住。事实上，在某些情况下，我甚至做出了伤害，例如，没有使sendmail更加严格地对待不好的输入，当它适合这样做的时候。同样，我相当早地认识到配置文件的语法需要修改提升，当时只部署了也许几百个sendmail的实体，但我最终决定不去改变，因为我不希望引起已经安装的用户群太过烦恼。回想起来，早点提升配置文件语法，导致短期疼痛来获取获取一个更好的长远的结果会更好一点。</p><h5 id="第7版Mailbox语法"><a href="#第7版Mailbox语法" class="headerlink" title="第7版Mailbox语法"></a>第7版Mailbox语法</h5><p>这方面的一个例子是第7版mailbox区分消息的方式。他们使用一个行开头“From?”（其中“?”代表ASCII空格字符，编码为0x20）来分隔消息。如果接受到一个消息，它本身在行开头包含单词“From?”，本地mailbox软件会将其转换为“&gt;From?”。在一些但不是所有系统都有的一个细化是要求有一个前面的空行，但这不能被依赖。直到现在，“&gt;From”出现在明显与电子邮件无关的（但显然早晚会被电子邮件处理）令人极其意想不到的地方。回想起来我可能已经把BSD邮件系统转换成使用一个新的语法。（如果我当时使用新的语法的话，）我本会在当时收到用户们的诅咒，但我会替世界解决一堆麻烦。</p><h5 id="语法和配置文件的内容"><a href="#语法和配置文件的内容" class="headerlink" title="语法和配置文件的内容"></a>语法和配置文件的内容</h5><p>也许我在配置文件的语法中最大的错误就是在重写规则中使用制表符（HT,0x09）来区分模式和他的替代者。当时我正在做效仿make，最终在几年后得知make的作者斯图尔特·费尔德曼（Stuart Feldman）认为这是他最大的错误之一。除了在屏幕上的看配置看时并非显而易见，制表符不能在大多数窗口系统中经过剪切和粘贴操作后还能被保留下来。</p><p>虽然我相信重写规则是正确的想法（见下文），但是我会更改配置文件的总体结构。例如，我没有预料到在配置中需要层次结构（例如，不同的SMTP侦听器端口将会设置不同的选项）。设计配置文件的时候没有“标准”格式。今天，我会倾向于使用Apache风格的配置，这样的配置文件足够的干净，整洁，并有足够的表现力——又或许甚至嵌入了语言，如Lua中。</p><p>在开发sendmail的时候，地址空间都很小，协议仍然在不断变化着。把尽可能多的东西放到配置文件中似乎是一个不错的主意。但在今天看来，这像是一个错误：我们有足够的地址空间（对于MTA来说）和相当静态的标准。此外，“配置文件”的一部分是需要在新版本中更新的真正的代码。’’.mc’’的配置文件修复了这个问题，但需要每次升级软件时都重新构建配置文件会是相当痛苦的一件事。一个简单的解决办法是，sendmail将会去读取两个配置文件，一个被隐藏而且在每次新软件发布时被安装，另一个不被隐藏且用作本地配置文件。</p><h5 id="工具的使用"><a href="#工具的使用" class="headerlink" title="工具的使用"></a>工具的使用</h5><p>在如今，有许多新的工具可被利用，例如，配置和构建软件。如果你需要的话工具可以是很好的手段，但是他们也可以是矫枉过正，使得这比必要更难理解系统。例如，当你需要的仅仅是strtok（3）时，你永远不要使用YACC（1）语法。但是重新发明轮子也不是一个好主意。特别地，尽管就算在如今有一些保留我几乎肯定仍然会使用autoconf（地址自动配置协议）。</p><h5 id="向后兼容性"><a href="#向后兼容性" class="headerlink" title="向后兼容性"></a>向后兼容性</h5><p>由于是事后在看，而且已经知道了sendmail会变得无处不在，处于发展的初期我不会如此地担心打破现有的安装。当现行的做法被严重破坏时它应该被修复，不能去适应它。尽管如此，我还是不会对所有的消息格式进行严格的检查。一些问题可以很容易而且安全地忽略或修补。例如，我可能仍然会在邮件中插入一个’’Message-Id’’首部字段如果他没有的话。但是我可能更倾向于如果它没有’’From:’’首部字段就不接收它，而不是尝试从信封中的信息创建一个。</p><h5 id="内部抽象"><a href="#内部抽象" class="headerlink" title="内部抽象"></a>内部抽象</h5><p>有一些内部的抽象我不会再次去尝试，还有一些我想添加。例如，我不会用零结尾字符串，转而选择一个长度/值对。尽管这意味着大部分的标准C语言库变得难以使用。仅此一各安全问题反而使它使它值得使用。相反，我不会试图建立在C语言中处理的异常，但我会创建一个将在整个代码中贯穿使用的一致的状态码系统，而不是按照惯例返回’’null’’、’’false’’或这负数来表示错误。</p><p>我一定会把邮箱名的概念从Unix用户ID抽象成别的概念。在我编写sendmail的时候，模式是你只给Unix用户发送邮件。今天，这是几乎是从来没有的情况，即使在那些使用该模型的系统中，也有一些从不接收电子邮件的系统帐户。</p><h4 id="17-8-2-事情我会做同样的"><a href="#17-8-2-事情我会做同样的" class="headerlink" title="17.8.2. 事情我会做同样的"></a>17.8.2. 事情我会做同样的</h4><p>当然，有些事情工作得很好…</p><h5 id="系统日志"><a href="#系统日志" class="headerlink" title="系统日志"></a>系统日志</h5><p>其中一个来自sendmail的成功项目是系统日志。在编写sendmail时，一个需要记录的程序会有一个它们会去写的特定的文件。这些文件被散落在文件系统中。在当时，要写系统日志是非常困难（UDP还不存在，所以我用一个叫做mpx文件的东西），但这是非常值得的。不过，我想做出一个明确的改变：我会更加注意使记录的消息的语法能被机器解析，从本质上讲，我没有预测到记录监控的存在。</p><h5 id="重写规则"><a href="#重写规则" class="headerlink" title="重写规则"></a>重写规则</h5><p>重写规则已经被很多人所诟病，但我仍然会使用它（尽管也许不是和现在被用的一样多）。使用制表符是一个明显的失误，但鉴于ASCII和电子邮件地址的语法的局限性，一些转义字符大概是需要的。在一般情况下，使用模式替换的范例的概念运作良好而且非常灵活。</p><h5 id="避免不必要的工具"><a href="#避免不必要的工具" class="headerlink" title="避免不必要的工具"></a>避免不必要的工具</h5><p>尽管有上述，我还是会用更多现有的工具，如今我会勉为其难地使用许多可用的运行时间库。在我看来，这些运行时间库大多是那么臃肿以至于很危险。库应该被谨慎地选??择，要平衡重用的优点和使用过于强大的工具来解决一个简单的问题的问题。一个特定的我将避免的工具是XML，至少作为配置的语言我会避免使用它。我相信，它的语法对于它被使用的许多场景来说太过结构复杂了。XML有它被使用的合适的地方，但是如今它被过度使用了。</p><h5 id="用C语言编码"><a href="#用C语言编码" class="headerlink" title="用C语言编码"></a>用C语言编码</h5><p>有些人建议，Java或C++会是更自然的实现语言。尽管C语言有一些众所周知的问题，我仍然会用它作为我的实现语言。这部分是个人的原因：相比于Java或者C++，我更了解C语言。但是我也对大多数面向对象的语言对内存分配所采取的漫不经心的态度感到失望。分配内存有很多性能方面的难以定性的问题。Sendmail在内部适当的部分使用了面向对象的概念（例如，图类的实现），但在我看来，完全的面向对象有些浪费，也有过度的限制。</p><h2 id="17-9-总结"><a href="#17-9-总结" class="headerlink" title="17.9. 总结"></a>17.9. 总结</h2><p>Sendmail邮件传输代理诞生于一个巨大动荡的世界里，一种类似于“西大荒”的存在。这个时候电子邮件是临时的而且当前的邮件标准也是尚未制定。在其间的31年中，“电子邮件问题”已经从仅仅需要可靠地工作变为了在大型邮件和重负载下工作来保护网站免受垃圾邮件和病毒的骚扰，一直到今天变成了大量的基于电子邮件的应用的平台。Sendmail已经演变成被大多数规避风险的企业所接受的主力平台，甚至电子邮件已经从纯文本的人对人的交流发展成为了基础设施的基于多媒体的关键部分。</p><p>成功的原因并不总是显而易见的。使用传统的软件开发方法论来仅仅靠一些业余的开发者来建立一个能够生存下来的甚至在急剧变化的世界中繁荣昌盛的程序是不可能完成的。我希望我已经提供了一些关于sendmail是怎样成功的的见解。</p><p><strong>译者按：全文到此结束，谢谢</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;此章节的 &lt;a href=&quot;http://www.aosabook.org/en/sendmail.html|英文原文&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.aosabook.org/en/sendmail.html|英文原文
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>Sendmail_2</title>
    <link href="http://blog.ccao.cc/2018/09/28/Sendmail_2/"/>
    <id>http://blog.ccao.cc/2018/09/28/Sendmail_2/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.675Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Sendmail-翻译"><a href="#Sendmail-翻译" class="headerlink" title="Sendmail 翻译"></a>Sendmail 翻译</h1><p>原文地址：<a href="http://www.aosabook.org/en/sendmail.html" target="_blank" rel="noopener">http://www.aosabook.org/en/sendmail.html</a></p><p>译者邮箱：<a href="mailto:wdyxhk@hotmail.com" target="_blank" rel="noopener">wdyxhk@hotmail.com</a></p><h2 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h2><p>大多数人认为电子邮件是他们与之互动的的邮件客户端程序，学术上被称为邮件用户代理（MUA），但是电子邮件系统还有另外一个重要组成部分负责将邮件从发送者手中发送到收件人手中，称之为邮件传输代理（MTA）。在互联网上最先被使用的MTA，也是至今为止使用最为广泛的MTA就是sendmail。</p><p>sendmail在因特网存在之前就已经被首先创造出来了。在一开始互联网只是有几百台主机的学术实验衍生物的时候，sendmail的杰出并不显著，到了今天，在互联网拥有8亿台主机的2011年1月，sendmail的成功非比寻常。Senamail至今仍然是互联网上使用最为广泛的网络协议。</p><h2 id="17-1-很久很久之前"><a href="#17-1-很久很久之前" class="headerlink" title="17.1 很久很久之前"></a>17.1 很久很久之前</h2><p>sendmail的初版于1980年写成。它最早用来快速截取在不同网络间传递的信息。在那时，互联网正处于发展时期而功能尚不完善。事实上，许多网络在计划发展时并没有统一的特征。阿帕网首先在美国使用，而互联网被设计为阿帕网的某种形式的升级。但是当时欧洲政府认为OSI的发展更为重要，在当时短时间内OSI看起来确实更加引人关注。OSI和sendmail都依靠从电话公司租赁线路来实现。当时的美国电话线路的速度为56kbps。</p><p>如果依据连接起来的电脑和用户的数目来说，UUCP网络是当时最为成功的网络类型。UUCP不同寻常之处在于在UUCP网络中绝对不存在中央主机这样的概念。从某种意义上来说，UUCP是一种通过电话线路传输的原始的点到点网络。一般来说9600bps大概已经是最快的传输速度了。最快的网络是由施乐公司开发的运行XNS协议的以太网（3 Mbps），但是该以太网缺少了本地客户端就无法运行。</p><p>当时的网络环境与现在的网络环境天差地别。电脑之间的区别度很大，甚至到了不是所有的电脑都支持8-bit字节的程度。这其中包括 PDP-10 (36 bit words, 9 bit bytes), PDP-11 (16 bit words, 8 bit bytes),CDC 6000 系列 (60 bit words, 6 bit characters),IBM 360 (32 bit words, 8 bit bytes),XDS 940, ICL 470 和Sigma 7。当时贝尔实验室开发的Unix是一个非常具有发展潜力的平台。大多数基于Unix的机器都拥有16位的地址空间，当时PDP-11是最主要的Unix机，而Data General 8/32和VAX-11/780才刚刚出现。线程的概念还不存在，事实上，当时动态过程的概念也才刚刚出现（Unix使用了动态过程的思想，但是一些例如IBM’s OS/360的“古典”的系统还未使用）。Unix内核并不支持文件锁（但当时的陷阱触发机制使用了文件链接）。</p><p>从出现开始，网络大多处于低速（许多基于9600波特的TTY线路，真正富有的人才用得起以太网，而且也只能本地使用），令人敬佩的发明套接字技术当时还没有发明出来，公共密钥加密技术同样如此，所以大多数我们今天已知网络安全技术在当时都不适用。</p><p>当时Unix上已经网络邮件已经出现，但是只是被创造用来截取报文。当时最初的用户代理只是形如 /bin/mail的命令行（到今天也有可能是binmail或者v7nail），但是也有些网站使用一些其他的代理，比如Berkeley制作的Mail，你呢个够真正把报文看作是独立的个体而非一整块程序.每种用户代理都会直接读取（常常也会写入） /user/spool/mail，没有怎样将信件真正存储起来的概念。</p><p>当时区别于本地邮件而发送邮件仅仅依靠判断地址是否包含一个感叹号或者冒号。使用阿帕网的用户不得不使用一个完全自成一体，与网络毫无交互的邮件程序，甚至还会将邮件以不同形式储存在不同位置。</p><p>更有趣的是，邮件本身事实上对数据格式并没有统一的标准。只有一个大致的约定，在邮件开头应该有一块标题字段，每一块标题字段应该另起一行，其中标题和内容应该用冒号分割开。不止如此，对于标题字段名字的选择或者是各个子块的语法都几乎没有固定的标准。比如说，有一些邮件系统Subj:取代Subject:，Date：域使用不同的语法规则，还有一些邮件系统并不结合搜From:域内的全名。更夸张的是，什么是documented这条定义总是模糊不清，在实际使用中也常常没有按照概念。尤其是RFC 733（声称定义了阿帕网报文的格式）在实际使用中在一些细节处与它的定义并不相符。造成的结果就是在邮件系统使用过程中遵照的规则有几分玄学的感觉。</p><p>在1979年， the INGRES Relational Database Management Project 计划获得了美国国防部的资助，让我们的PDP-11获得了一条带宽9600dps的阿帕网连线。在当时这是在计算机科学领域唯一一条可用的阿帕网接入口。所以每个人都想获取连接我们主机的权限来连接到阿帕网。然而，这台机器早就满载了，所以我们只能提供2个登录端口供整个机构的人分享，这造成网络环境中出现了大量的争夺和冲突。然而，我注意到大家普遍需要的不是远程接入或者文件传输，而是电子邮件。</p><p>介于这个发现，sendmail（起初叫做delivermail）作为解决网络冲突和混乱的措施出现了。每一个MUA只会调用delivermail程序来发送邮件而不是自己特地去解决如何发送邮件的问题。delivermail/sendmail并没有解决本地如何存储或者发送邮件的问题，它只是从别的程序中将发送邮件的任务提取出来。（当SMTP出现的时候这些都发生了改变，我们很快会谈及这个）。某种意义上来说它只是将不同的邮件系统整合起来而不是本身成为一个邮件系统。</p><p>在sendmail发展过程中，阿帕网也发展为互联网。变化跨度如此之大，从底层传输的数据包到应用协议。sendmail随着网络发展而发展，并且从某些意义上也影响了网络的发展。值得一提的是，sendmail存活了下来并且和网络一起从几百台主机发展到几亿台主机。</p><h2 id="17-2-设计原则"><a href="#17-2-设计原则" class="headerlink" title="17.2 设计原则"></a>17.2 设计原则</h2><p>在开发sendmail的时候，我坚持了一些设计原则。所有设计原则在某些程度上而言可以归纳为一句话：做的越少，做的越好。这与当时致力于更加广泛的目标用途和对更加宏大的计划的需求形成了鲜明的对比。</p><h3 id="17-2-1-接收一个程序员精力终归有限的事实"><a href="#17-2-1-接收一个程序员精力终归有限的事实" class="headerlink" title="17.2.1 接收一个程序员精力终归有限的事实"></a>17.2.1 接收一个程序员精力终归有限的事实</h3><p>我编写sendmail的工作是作为一种无偿的副业，目的是为了是使阿帕网得邮件系统能够更快让加州大学伯克利分校的师生正常使用。这其中的关键就在于让邮件在当前存在的网络之中传播，而这些网络本身并不能识别到有其他的网络存在。改进这样一个不只是并不算小规模的软件仅仅把它当做一种副业是不可行的。设计过程中必须最小化需要改进的已有代码和需要添加的新代码。这个原则驱动形成了余下的设计原则。自从这样的原则被制定之后，在大多数情况下即使有一个更大的工作团队，做的越少，做的越好的原则依旧是正确的。</p><h3 id="17-2-2-不要重新设计用户代理"><a href="#17-2-2-不要重新设计用户代理" class="headerlink" title="17.2.2 不要重新设计用户代理"></a>17.2.2 不要重新设计用户代理</h3><p>一个MUA（邮件用户代理）是用户所能感知到的最终端的“邮件系统”，他们认为这是一个用来读写和回复邮件的程序。这与用来将邮件按照路径从发送方发送到接收方的邮件传输代理（MTA）截然不同。在编写sendmail的时候，许多实现方式是至少部分地将这两个功能连接起来，所以他们通常是一前一后发展的。试图同时开发这两个功能会使工作量过大，所以sendmail完全舍弃了优化用户端口对的问题，对于MUA的唯一改变在于让他们发送邮件不再自己规划路径而是调用sendmail来完成。尤其是当时已经几种MUA并且人们对于他们与邮件系统的交互往往存在不确定性。试图致力于解决两个方面的问题任务量过大。这种将MUA与MTA分隔开考虑的思路在现在已经被大多数人接受，而在当时却是突破常规的。</p><h3 id="17-2-3-不要重新设计本地邮件的存储方式"><a href="#17-2-3-不要重新设计本地邮件的存储方式" class="headerlink" title="17.2.3 不要重新设计本地邮件的存储方式"></a>17.2.3 不要重新设计本地邮件的存储方式</h3><p>本地邮件存储（用来存放接收到的邮件直到收件人来阅读邮件为止）并没有被系统规范过形式。一些网站喜欢将这些邮件存储在计算机的核心位置，比如/usr/mail, /var/mail或者 /var/spool/mail。还有一些网站喜欢将邮件储存在收件人的根目录（比如新建一个名为mail的文件夹）。大多数网站将邮件用“From”后加一串字符作为邮件的起始行（非常差劲的决定，不过在当时成为了一种约定俗成的规则）。但是专注于阿帕网的网站用4个control-A字符作为第一行的开头。还有一些网站致力于将收件箱锁起来来避免冲突，但他们往往使用的是不同的规则约束（当时文件锁定原语还不可用）。简而言之，当时唯一合理的方案是将本地邮件存储结构作为黑盒子。</p><p>几乎所有网站都会把实现本体邮件存储的实际原理呈现在 /bin/mail 程序中。在该程序中整合了一个（相当原始的）用户接口，路由功能和存储功能。为了和sendmail结合，路由功能被去除，取而代之的是对sendmail的调用。加入了一个 -d 标识强制进行最后的发件，等等之类的措施来防止 /bin/mail 直接进行路由。近几年这段代码被提取出来加入到 mail.local 程序中来<br>将邮件发送到物理邮箱之中。而 /bin/mail 程序保存到今天仅仅用来作为最底层的结构来发送邮件。</p><h3 id="17-2-4-让sendmail适应这个世界，而不是反过来"><a href="#17-2-4-让sendmail适应这个世界，而不是反过来" class="headerlink" title="17.2.4 让sendmail适应这个世界，而不是反过来"></a>17.2.4 让sendmail适应这个世界，而不是反过来</h3><p>UUCP和BerkNET一类的协议已经被当做单独的程序运行，有专属的略显古怪的命令行结构。在某些情况下他们与sendmail共同得到发展。重现这些协议功能（比如将他们转变为标准的调用公约）将是令人痛苦的。这直接导致设计sendmail的原则在于将sendmail适应这个世界而不是反其道而行。</p><h3 id="17-2-5-尽可能不做改变"><a href="#17-2-5-尽可能不做改变" class="headerlink" title="17.2.5 尽可能不做改变"></a>17.2.5 尽可能不做改变</h3><p>在研发sendmail的过程中我尽最大的可能尽可能少碰我不需要的东西。另外我也没时间去做额外的事，在当时伯克利分校有这样一种校园文化，反对固有的代码所有权定义从而支持这样一种论调“谁最后一个接触代码谁就对这段代码负责”（简而言之，谁碰了它，谁就拥有它）。尽管这听起来和现代标准格格不入，在当时没有人全心全意研发Unix的伯克利确着实奏效了，每个人只负责他感兴趣的部分并且通常情况下不去碰别的地方。</p><h3 id="17-2-6-提前考虑可靠性"><a href="#17-2-6-提前考虑可靠性" class="headerlink" title="17.2.6 提前考虑可靠性"></a>17.2.6 提前考虑可靠性</h3><p>在sendmail之前的邮件系统（包括大部分邮件传输系统）并没有着重关注可靠性问题。举个例子，4.2BSD版本之前Unix系统没有文件锁机制，尽管这可以通过创建一个临时文件并链接到一个上锁文件模拟（如果上锁文件已存在就会失败）。然而，有时不同的程序构造出的相同数据文件在上锁方式上并未达成一致（他们可能给上锁文件不同的命名，也可能根本不上锁），所以丢失文件不足为奇。sendmail则采取措施防止邮件丢失（可能由于我的专业背景与丢失数据就是大错特错的数据库有关）。</p><h3 id="17-2-7-考虑哪些内容可以暂时抛弃"><a href="#17-2-7-考虑哪些内容可以暂时抛弃" class="headerlink" title="17.2.7 考虑哪些内容可以暂时抛弃"></a>17.2.7 考虑哪些内容可以暂时抛弃</h3><p>在早期版本中很多内容没有实现。我没有试图去重构整个邮件系统或者建立一个通用的解决方案，功能可以再需求出现时再添加。非常早期的版本离开了源代码和编译器甚至都不是可配置的（虽然这很早就修正了）。总的来说，sendmail的运作原理是尽可能快速地运行功能然后再根据需要添加工作代码来让问题更好地得到解决。</p><h2 id="17-3-发展历程"><a href="#17-3-发展历程" class="headerlink" title="17.3 发展历程"></a>17.3 发展历程</h2><p>和很多历时长久的软件一样，sendmail是一步一步发展的，每个发展阶段都有自己的基本主题和用意。</p><h3 id="17-3-1-第一阶段：delivermail"><a href="#17-3-1-第一阶段：delivermail" class="headerlink" title="17.3.1 第一阶段：delivermail"></a>17.3.1 第一阶段：delivermail</h3><p>sendmail的第一个实例被称作delivermail。它简约而不简单。它的基本工作是将意见从一个程序运送到另一个程序。值得一提的是，deliverman不支持SMTP，所以它从不进行任何直接的网络连接。由于每一个网络本身已经拥有队列，所以它并不需要队列系统，这个程序更像是一个纵横开关。既然delivermail不直接支持网络协议，那就不需要将它作为后台程序运行，它只需要在每条报文提交的时候调用，将报文发送到能够进行下一步传递的程序就可以结束使命。同理，delivermail也不需要为了匹配发送的目标网络而重写报文头部。但这通常会导致发送的邮件没有得到回应。这样的情况甚至严重到有人专门写了一本书来讨论电子邮件（叫做《 fittingly, !%@:: A Directory of Electronic Mail Addressing &amp; Networks [AF94]》）。<br>所有dilivermail中的配置是内置的，只对应每个地址中特定的字符。这些字符具有优先级。比如说，搜寻主机配置时可能会直接1搜索“@”符号，一旦找到，就将整条主机地址发送到指定的阿帕网中继主机。不然的话，程序会继续搜索冒号，一旦找到就将报文发送到指定主机指定用户的BerkNET，然后检查感叹号来将报文发送到一台指定的UUCP中继主机，否则就尝试本地网络的传输，这样的设置会导致下列的情况发生。</p><table><thead><tr><th>输入</th><th>{网络制式，主机，用户}</th></tr></thead><tbody><tr><td>foo@bar</td><td>{Arpanet, bar, foo}</td></tr><tr><td>foo:bar</td><td>{Berknet, foo, bar}</td></tr><tr><td>foo!bar!baz</td><td>{Uucp, foo, bar!baz}</td></tr><tr><td>foo!bar@baz</td><td>{Arpanet, baz, foo!bar}</td></tr></tbody></table><p>注意地址分隔符在这之中的不同的结合方式，这导致了只能用启发法分辨的语意模糊，例如最后一个例子其他网站理解为{Uucp, foo, bar@baz}也是合情合理的。</p><p>将配置内置有以下几个原因：首先在仅有16位地址空间和有限的内存空间中使用运行时配置太奢侈，其次，当时的系统高度客制化以至于重新编译更好，只要你本地有函数库（Unix6代时共享库还不存在）。</p><p>Divermail分布在BSD4.0和BSD4.1（加州大学伯克利分校软件）之中，并且超出意料的成功，伯克利分校早就不是仅有的混合网络架构的使用者。显然，还有很多工作等着去做。</p><h3 id="17-3-2-第二阶段：sendmail3-4和5"><a href="#17-3-2-第二阶段：sendmail3-4和5" class="headerlink" title="17.3.2 第二阶段：sendmail3,4和5"></a>17.3.2 第二阶段：sendmail3,4和5</h3><p>sendmail第一版和第二版都以delivermail的名字传播使用，而从1981年3月研发的第三版开始，程序将会使用sendmail的名字。在当时16位机PDP-11仍被广泛使用，但是32位机VAX-11正在越来越受欢迎，因此许多原本地址空间过小形成的限制正在越来越变得宽松。</p><p>sendmail的最初的目的是将程序转变为运行时可配置的程序，允许报文修正来为邮件在不同网络之间传播提供兼容性，对于决定路由也可以有更丰富的语言约束。当时许多专业系统使用的技术本质上是对地址的重写（基于符号而非字符串）。不但有专案法去提取和保存任何在括号里的评论字符串，同时在地址重写完成之后将这些字符串重新插入。能够增加或者增大头区域（例如，添加一块Date头区域或者在From头区域中的发件人的全名包括进来，如果已知的话）。</p><p>SMTP于1981年开始发展。在伯克利大学的计算机科学研究组（CSRG）获得了美国国防部高级研究计划局（DAPRA）研发一个用于支持DAPRA资金调研的基于Unix的平台的合同，意图让工程之间的分享更加容易。对于TCP/IP栈的工作那时刚刚完成，尽管套接字技术当时还在不断变化。像Telnet和FTP这样的底层应用协议已经形成，但是SMTP尚未完全成型。事实上,SMTP协议在当时还未成定案，当时关于如何发送邮件的创造性协议MTP还存在巨大争议。随着争议的持续，MTP变得越来越复杂，直到SMTP或多或少的开始被许可设计（但是知道1982年才被正式出版）。我正式为安格尔关系数据库管理系统工作，但是因为当时在伯克利我比任何人都熟悉邮件系统，我只得说道完善SMTP的是。</p><p>我最初的想法是创建一个独立的拥有自己队列系统和后台程序的SMTP邮件程序，子程序会依附于sendmail来获得路由。然而，SMTP的几个特征使得这个想法存在一些问题。举个例子，EXPN和VRFY命令需要解析，混叠和本地地址验证的权限。而且，当时我认为重要的一点是，RCFT命令如果地址未知应该立即return而不是接收报文然后返回一个发送错误。这在之后被证明是有先见之明的。讽刺的是，之后服务器常常因此出错，使得垃圾邮件的背向散射问题更加恶化。这个问题促使我下决心将SMTP囊括进sendmail本身。</p><p>Sendmail3版本分布在由4.1a到4.1cBSD之间（beta版本），sendmail内嵌在4.2BSD，sendmail则5内嵌在4.3BSD。</p><h3 id="17-3-3-第三阶段：混乱的那几年"><a href="#17-3-3-第三阶段：混乱的那几年" class="headerlink" title="17.3.3 第三阶段：混乱的那几年"></a>17.3.3 第三阶段：混乱的那几年</h3><p>在我离开伯克利到一家新创立的公司之后，我可供自由支配的时间显著的变少了。但是因特网却开始真正的爆炸式发展，sendmail在一个复杂和崭新的环境中被使用。大多数Unix系统供应商（尤其是Sun，DEC和IBM）长砸出了他们自己版本的sendmail并且彼此之间互不相容。当时也有人致力于开发出开源版本，尤其是IDA sendmail和KJS。</p><p>IDA sendmail由林雪平大学创建，IDA包括拓展来使之更加容易在更大的环境和完全不同的系统中安装和工作。一个最主要的特征是IDA包含dbm（3）数据结构图用来支持高度动态的网站。在配置文件中使用一种新的语法是可行的，并且在外部语法中加入包括发送和接受地址结构图的函数功能（例如用地址<a href="mailto:john_doe@example.com" target="_blank" rel="noopener">john_doe@example.com</a>取代johnd@example）并路由。</p><p>King James Sendmail（KJS，由PaulVixie创建）是一次对统一所有已经出现的sendmail版本的尝试。不幸的是，并没有获得足够的支持来取得预期效果。这个时代也被大量的新技术驱动发展，这一切在邮件系统的发展过程都有所体现中。例如，Sun创建无盘集群时增加了YP（黄页，后来的NIS，即网络信息服务）目录服务和NFS，即网络文件系统（the Network File System）。特别是，YP不得不对sendmail来说可见，因为邮件别名存储在YP而不是本地文件。</p><h3 id="17-3-4-第四阶段：sendmail-8"><a href="#17-3-4-第四阶段：sendmail-8" class="headerlink" title="17.3.4 第四阶段：sendmail 8"></a>17.3.4 第四阶段：sendmail 8</h3><p>几年之后，我作为一名工作人员回到了伯克利。我的工作是为计算机科学系的研究管理一组安装和支持共享的基础设施。为了成功完成任务，个人研究小组的主要临时环境需要专案法。就像早期的互联网，不同的研究组在完全不同的平台上工作，其中一些平台很老旧。总的来说，每个研究小组运行自己的系统，尽管有些平台仍然管理完善，他们中的大多数还是因为“拖延维护”而深受困扰。</p><p>在大多数情况下，电子邮件有相似的分段。每个人的邮件地址都是“<a href="mailto:person@host.berkeley.ed" target="_blank" rel="noopener">person@host.berkeley.ed</a>”，这个地址的host是他们办公室中或者他们使用的共享服务器上的工作站的名字（校园网甚至没有内部子域），除了一些特殊的以@berkeley.edu结尾的地址。其目标是交换至内部的子域（因此所有个人主机地址会在cs.berkeley.edu子域中）和形成一个统一的邮件系统（所以每个人都会有一个@cs.berkeley.edu结尾的地址）。通过创造一个全新版本的能在全系使用的sendmail使得这个目标轻松地实现。</p><p>我开始研究许多已经变得流行的变种sendmail。我的意图不是从不同的代码库开始写起，而是了解其他变异版所发现的有用的功能。许多这些想法能够在sendmail 8中找到自己的影子，通常情况下这些点子被进行了修饰来使得相似的想法合并或者让它们变得更通用。例如，几个版本的sendmail都能够获取内部数据库的权限，如 dbm（3）或NIS；sendmail 8那他们合并为一个能够处理多类型数据库（或者任意的无数据库转换）的“映射图”机制。类似的也包含了来自IDA sendmail的“泛型”数据库（内部到外部的名称映射）。</p><p>sendmail 8还包括一个使用m4（1）宏处理器的新的配置文件包。目的是比sendmail 5的已经大部分嵌入程序的配置文件包更加的陈述化。也就是说，sendmail 5配置文件包本质上需要管理员手动配置整个配置文件，这真的仅仅将m4的“include”结构作为一种速记。sendmail 8配置文件允许管理员来声明需要哪些特性，邮件相关地址等，然后m4就会展开最终的配置文件。</p><p>17.7节的大部分内容论述了sendmail 8中的增强性功能。</p><h3 id="17-3-5-第五阶段：投入商业化的那几年"><a href="#17-3-5-第五阶段：投入商业化的那几年" class="headerlink" title="17.3.5 第五阶段：投入商业化的那几年"></a>17.3.5 第五阶段：投入商业化的那几年</h3><p>随着互联网的发展，使用sendmail的网站数量激增，支持前所未有的用户量成为了大问题。一段时间内，我可以设置一组通过电子邮件和新闻组提供无偿帮助的志愿者（非正式地讲叫做“Sendmail联盟”，又名sendmail.org）来继续维护sendmail系统。但在上世纪90年代末，已经安装sendmail的基础设施已经发展到几乎不可能基于志愿者帮助解决的程度。为了得到新的资源来维护这些代码，我和一个更有商业头脑的朋友一起创建了sendmail,Inc.。</p><p>虽然最开始商业产品大部分基于配置和管理工具，但是许多新的功能被添加到开源MTA来支持商业发展的需要。值得一提的是，公司新增了对TLS（连接加密）、SMTP认证、网站安全增强的支持——例如拒绝服务保护，最重要的是邮件过滤插件（Milter接口的问题接下来会讨论）。</p><p>在写这篇文章时，sendmail商业产品已拓展到包括一整套基于电子邮件的应用，几乎所有应用都是建立在公司的开始几年对sendmail的功能扩展的基础上。</p><h3 id="17-3-6-到底sendmail-6和sendmail-7发生了什么"><a href="#17-3-6-到底sendmail-6和sendmail-7发生了什么" class="headerlink" title="17.3.6 到底sendmail 6和sendmail 7发生了什么"></a>17.3.6 到底sendmail 6和sendmail 7发生了什么</h3><p>sendmail 6本质上是sendmail 8的beta版本，从未正式发布过但确实被广泛对的传播和应用。Sendmail 7从未存在过，sendmail直接跳到了版本8是因为所有其他BSD的源文件在BSD4.4于1993年6月发布的时候都碰巧是版本8。</p><h2 id="17-4-设计决策"><a href="#17-4-设计决策" class="headerlink" title="17.4 设计决策"></a>17.4 设计决策</h2><p>sendmail有正确的设计决策，也有开始是正确的，却因为世界的不断变化而成为错误的设计决策，有些至今不能判断是对是错。</p><h3 id="17-4-1-配置文件的语法"><a href="#17-4-1-配置文件的语法" class="headerlink" title="17.4.1 配置文件的语法"></a>17.4.1 配置文件的语法</h3><p>配置文件的语法由两个因素决定。首先整个应用需要适配于16位的地址空间。所以分析程序需要足够小。除此之外，早期的配置应该要尽量少（长度在一页之内）。这样，即使语法是模糊的，文件仍然是可理解的。然而，随着时间流逝，越来越多的操作设定从C语言代码中转移到配置文件中，使得文件开始不断变大。因此，配置文件被认为是晦涩难懂的。对于很多人来说，选择Tab字符作为一个活跃的语法条目就已经是一不能理解的了。当时如果从别的系统中拷贝内容就会发生错误，尤其是make文件，当窗口系统投入使用时，这个问题变得更加严峻（因为剪切粘贴命令通常不会保存Tab）。</p><p>回顾到文件开始变大，32位机开始流行的时候，讲道理是时候开始重新考虑语法问题了。曾经有段时间我心里是这样想的，但是却以为内不想破坏“庞大”的安装基础（当时可能只有几百台机器）而决定不这样做。现在看来这是个错误，我当时并没有意识到安装基础会发展到这么大，也没有意识到如果早些改变语法会让我省下多大的力。并且，当标准固定下来之后，不少普遍设置可以重新放回C语言源代码中，从而简化配置文件。</p><p>特别要注意的是，怎么把更多功能搬进配置文件里。在我改进sendmail的同时，SMTP协议也在不断发展。通过将操作决策搬进配置文件，我能够在24小时之内马上设计出相应改变。我认为这改进了SMTP的标准，因为这让通过制定的设计改变快速获取操作经验成为了可能，代价仅仅是是的配置问价更加难以理解。</p><h3 id="17-4-2-重写规则"><a href="#17-4-2-重写规则" class="headerlink" title="17.4.2 重写规则"></a>17.4.2 重写规则</h3><p>编写sendmail的困难之一在于怎样为了在不违背接受网络的标准的情况下允许报文在不同网络间传递而进行必要的重写。转换过程中需要改变通配符（比如BerkNET使用冒号作为分割，然而在SMTP网络中这是不合法的），重排地址组成，加入或者删除组成部分等等、比如，下面的重写在某些环境下是必要的</p><table><thead><tr><th>Form</th><th>To</th></tr></thead><tbody><tr><td>a:foo</td><td><a href="mailto:a.foo@berkeley.edu" target="_blank" rel="noopener">a.foo@berkeley.edu</a></td></tr><tr><td>a!b!c</td><td><a href="mailto:b!c@a.uucp" target="_blank" rel="noopener">b!c@a.uucp</a></td></tr><tr><td>&lt;@a.net,@b.org:<a href="mailto:user@c.com" target="_blank" rel="noopener">user@c.com</a>&gt;</td><td>&lt;@b.org:<a href="mailto:user@c.com" target="_blank" rel="noopener">user@c.com</a>&gt;</td></tr></tbody></table><p>正则表达式并不是一个好的选择，因为不同的网络对于单词边界，引用等等的支持还不够好。很快就会发现写出精确的、至少可理解的正则表达式几乎是不可能的。尤其是正则表达式保留了很多通配符，包括“.”，“*”，“+”，“{[}”和“{]}”，这些字符都可能出现在邮件地址中。这些在配置文件中可能可以避免，但是我认为这会班的复杂，令人疑惑，并且有一点丑陋。（贝尔实验室的UPAS尝试过了，应用在UNIX8的邮件系统上，但并没有流行起来。）取而代之地，我认为一个扫描的过程是必要的，可以产生类似正则表达式中的字符以供操作。使用一个单独的参数来描述操作符，既作为标记也作为分隔符姐足够了。空格用来分隔符号但本身并不是语法单元。重写规则只是符号的替换与匹配来适应子程序。</p><p>比起许多需要避开才能不影响的通配符（比如在正则表达式内的影响），我选择使用一个“escape”符号来联系原始符号和通配符（比如匹配任意一个单词）。原始的Unix路径使用的是反斜杠，但是反斜杠在一些地址语法中已经被应用为引用符号。结果证明，“$”是为数不多的尚未被其他语法使用的字符之一。</p><p>讽刺的是，一开始的几个错误的决策之一，就是怎样使用空格。就像大部分扫描输入一样，一个空格符是一个分隔符，所以在标识符之间被无限制地使用。然而，初始的分散的配置文件并没有使用空格，导致模式变得不必要的复杂难懂。考虑一下两个予以相同的模式之间的区别:</p><p>‘’$+ + $* @ $+ . $={mydomain}’’</p><p>‘‘$++$*@$+.$={mydomain}’’</p><h3 id="17-4-3-为语法分析重写"><a href="#17-4-3-为语法分析重写" class="headerlink" title="17.4.3 为语法分析重写"></a>17.4.3 为语法分析重写</h3><p>有些人认为sendmail应该使用常规的基于语法的分析技术来分析地址而不是重写规则并且根据规则来修改地址。假如标准是用语法来定义地址，那表面上这种说法看起来有几分道理。重复使用规则重写的主要原因是在许多情况下有必要对标题区域的地址进行语法分析（举个例子，为了在来源网络并没有使用标准的封装的情况下提取出发送者的发送信息）。使用例如YACC的LALR(1)语法分析器和一个传统的扫描器是很难分析这样的地址的，原因在于先行逻辑的具体细节不明确。比如说，扫描这样的地址：<a href="mailto:allman@foo.bar.baz.com" target="_blank" rel="noopener">allman@foo.bar.baz.com</a><nowiki><a href="mailto:&#x65;&#x72;&#105;&#99;&#x40;&#101;&#x78;&#x61;&#109;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#109;" target="_blank" rel="noopener">&#x65;&#x72;&#105;&#99;&#x40;&#101;&#x78;&#x61;&#109;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#109;</a></nowiki> 需要扫描器或者分析器中使用先行逻辑，你不知道一开始的“allman@…”是地址，直到你看见了“&lt;”。出于LALR（1）分析器只能向前分析一步的原因，所以你真能在扫描器中使用先行逻辑，而这本质上是问题复杂化了。既然重写规则已经能够任意步数回溯，就足够了。</p><p>第二个原因在于相比而言重写规则更能识别和修复损坏的输入。除此之外重写足以完成整个工作，而复用代码总是理智的。</p><p>关于重写规则，有一点与众不同：当在进行符号匹配时，标记化输入和模式是有用的。因此，同样的扫描器可以用于扫描输入和模式本身。这需要为不同的输入调用使用不同的符号类型表的扫描器。</p><h3 id="17-4-4-在sendmail中加入SMTP和排队模块"><a href="#17-4-4-在sendmail中加入SMTP和排队模块" class="headerlink" title="17.4.4 在sendmail中加入SMTP和排队模块"></a>17.4.4 在sendmail中加入SMTP和排队模块</h3><p>实现外向SMTP（客户端）的一个“显而易见”方法就是像UUCP一样将它构建成一个外部邮箱收发器。但是事实已经证明了许多问题，例如排队功序列应该在设计在sendmail中还是SMTP模块中？如果把它设计在sendmail中，要么每份报文不得不被发送到各自的容器中（比如说，没有了“背负式装运”，那其中的的一条连结可能保持打开，使得多条’’RCRT’’指令被发出），要么需要一个远比可能使用的Unix退出代码长的回溯路径来传达必须的每个接收器的状态。如果排队序列实在客户端模块中完成，那么接下来就有大量内容需要复制，特别是在当时许多例如XNS的网络仍然具有竞争力。另外，将排队序列加入到sendmail模块中能提供一种更简洁的方式解决某些显著而暂时的问题，比方说资源枯竭。</p><p>传入SMTP（服务器）涉及到很多不同的决策。当时，我觉得原原本本地实现’’VRFY’’和’’EXPN’’指令很重要，这需要使用到别名机制。这会又一次的对比可能使用到的命令行和退出代码更多的用于SMTP服务器和sendmail之间的交换协议提出需求，事实上，就缺一个跟SMTP本身类似的协议。</p><p>时至今日，我会更倾向于选择把排队序列交给sendmail实现，但是把两端SMTP的实现放在其他过程中。一个理由是为了安全性：一旦服务器端获取了开放端口25的实例，那么就已经不再需要获取根权限。现代的拓展，例如TLS和DKIM，签订了复杂的客户端（自从非特权用户无法获取私人秘钥之后），但是严格意义上讲根权限获取仍然是不必要的。虽然安全问题仍然存在，但是如果SMTP客户端作为非根用户权限运行，没人可以访问私人秘钥，只有定义用户拥有特权，因此不应该直接与其他网站通信。所有这些问题都可以巧妙处理。</p><h3 id="17-4-5-队列功能的实现"><a href="#17-4-5-队列功能的实现" class="headerlink" title="17.4.5 队列功能的实现"></a>17.4.5 队列功能的实现</h3><p>Sendmail遵循当时的惯例采用存储队列文件。事实上，采用的格式非常近似于当时的LPR子系统。每个需求都有两个文件，一个用来存储控制信息，另一个用来存放数据。控制文件是一个每一行首字符就能表示每一行含义的纯文本文件。</p><p>在sendmail需要处理队列时就需要阅读所有的控制文件，将相关信息存放在内存中然后对队列进行排序。在队列中只有有限数量的报文时，这样的机制确实有效，但是如果用这样的机制在面对上万个队列报文时就会失效。具体来说，如果目录索引大到可以直接指向文件系统中的的某一个文件时，会有一个与节约的时间处于同一数量级的瓶颈导致最终表现并没有得到优化。改善这个问题的一个可能的路径是使sendmail能偶处理复合队列，但那对黑客来说是最好的消息。</p><p>一个备用方案是将所有控制文件存储在一个数据库文件中。可是最终这个方案并没有成行，原因在于当sendmail开始代码编写的时候，市面上还没有普遍的数据库包可供使用，而当dbm(3)面世时又存在诸多瑕疵，包括无法开辟空间，需要所有的秘钥一起哈希后能存储在一个512字节大小的页面内和缺少锁机制。很长一段时间之内可靠的数据库包都没有出现。</p><p>另一方备用方案是维护一个守护进程来将队列状态保存在内存中，可能还需要记录日志以便恢复。考虑到当时相比而言较低的邮件收发量，大部分终端的内存缺乏，相对较高的后台维护需求和试试这样一个计划的复杂度，看起来在当时也不是一个好的折中计划。</p><p>顶一个涉及决策是讲报文头部存储在队列控制文件中而不是数据文件。基本原理在于大部分报文头部从发出网络到目的网络需要相当大的重写量（报文有时能够拥有多个目的地址，所以需要多次自定义），并且解析报文头的开销很高，所以将它们以预编译格式存储看起来是一条出路。现在回过头来想想这并不是一个好主意，就像以Unix标准格式（以换行符结尾）存储报文主体而不是以接受格式（使用换行符，回车/换行，空回车或者换行/回车）存储。随着email世界的不断发展和标准的不断采纳，重写的需求越来越小，甚至看起来无害的重写规则变得存在风险。</p><h3 id="17-4-6-接受和修复虚假输入"><a href="#17-4-6-接受和修复虚假输入" class="headerlink" title="17.4.6 接受和修复虚假输入"></a>17.4.6 接受和修复虚假输入</h3><p>自从sendmail在多重协议和不断变化的书写标准的环境中被创造出来之后，我决定去清理所有可能的畸形报文。这也符合于RFC 794.中明确提到的“Robustness原则”（也叫做Postel原则）。其中有一些改变是显然的，甚至是必须的：当一封UUCP报文被发送到阿帕网时，UUCP地址需要转化成阿帕网地址，要是允许“reply”命令正确运行，行终结符需要在不同平台使用的结束符之间转换。有一些不是那么显而易见的：如果一封接收到的报文不含有互联网规格要求的’’From:’’报文头，那么是选择添加’’From:’’报文头，还是通过这封没有’’From:’’报文头的报文，又或是拒收这封报文呢？在当时，我主要考虑的是回馈和互动，所以sendmail会修正报文，比如加上’’From:’’报文头。然而，这就要求其他破损的邮件系统在被修复过之后能够长时间的保持不变。</p><p>我确信我的决策在当时是正确的，但时至今日是存在问题的。高度的互动性对于让邮件畅通无阻的传播是非常重要的。如果当时我拒收非标准格式的报文，，那当时大部分邮件都会被拒收。如果我当时让他们通过检测，邮件容器将会接受到他们无法响应的邮件，甚至有时候都不能分辨出发件人——这样的邮件会被其他邮件系统拒收。</p><p>现如今标准已经被制定，对于其中的绝大多数模块来说这样的标准是精确而完整的。不再有大部分邮件被拒收的情况了，即使仍然有邮件软件发送算坏的邮件。这样的软件为互联网上的其他软件制造了不必要的麻烦。</p><h3 id="17-4-7-配置和使用M4"><a href="#17-4-7-配置和使用M4" class="headerlink" title="17.4.7 配置和使用M4"></a>17.4.7 配置和使用M4</h3><p>在一段时间之内我既为sendmail配置文做常规的改进，又以个人名义为许多设备作支持。既然大量不同的终端之间的配置文件是一样的,使用一个工具来构建配置文件可取的。m4宏处理器包含在Unix之中。这是作为编程语言(特别是前端设计)。最重要的是,它有“包括”功能, 就像C语言中的“#include”。使用的原始配置文件拓展了此功能和一些小宏扩展。</p><p>IDA sendmail也使用m4,但使用的是截然不同的方式。现在回想起来，我可能应该更加细致地研究这些原型。他们包含许多好点子,尤其是在他们对引用处理的方式上。</p><p>从sendmail6开始,完全重写m4配置文件使得配置文件声明样式更多，体积更小。对于M4处理器的重度使用,使得GNU M4在引入一些微妙的语义变化时会产生问题。</p><p>原计划是M4配置将遵循80/20规则:他们会简单(大约20%的工作量),并将覆盖80%的病例。这个计划很快就瓦解了,主要有两个原因。较小的一个原因是它确实容易处理绝大多数的情况，至少在刚开始的时候。但随着sendmail和世界的发展,特别是包容的特性如TLS加密和SMTP认证的发展,M4配置越来越力不从心，但这些情况短时间之内并不会到来。</p><p>最重要的原因在于有一个问题愈加明显,原始配置文件对大多数人来说太难了处理。在本质上, ‘’.cf’’ (原始)格式已经成为组成代码的一部分——原则上可编辑,但实际上很不透明。“源代码”是一个脚本存储在m4上的’’.mc’’文件。</p><p>另一个重要的区别是,原始格式配置文件是一个编程语言，包含有过程代码 (规则集)、子程序调用、参数扩展和循环(但没有goto)。 语法是模糊的,但在许多方面很像’’sed’’和’’awk’’命令,在 至少在概念上。m4格式如下声明:尽管它可能下降到低层次的原始语言,但是在实践中这些细节对用户隐藏。</p><p>目前还不清楚,这个决定是正确的或不正确的。 我觉得当时(现在仍然觉得),复杂的系统可以有助于实现相当于一个领域特定语言(DSL)，用于构建系统的某些部分。然而,让终端用户接触到DSL的配置方法作为解决方法基本上把所有配置一个系统的需要的努力汇集成一个编程问题。从中我们最终获得了强大的驱动力，但又维持在一个相对低的消耗。 </p><h2 id="17-5-其他注意事项"><a href="#17-5-其他注意事项" class="headerlink" title="17.5 其他注意事项"></a>17.5 其他注意事项</h2><p>最后还有一些建设和发展sendmail的要点值得一提。</p><h3 id="17-5-1-优化互联网规模"><a href="#17-5-1-优化互联网规模" class="headerlink" title="17.5.1 优化互联网规模"></a>17.5.1 优化互联网规模</h3><p>在大多数基于网络的系统中，客户端和服务器之间往往存在一种矛盾。一个对客户端来说有力的策略，对服务器端可能就是个错误，反之亦然。 例如,如果可能的话服务器会最小化其处理的过程，把尽可能多的操作推回到客户端,当然反过来客户端也是一样。 例如,一个服务器可能希望保持一个开放接口在做垃圾邮件处理拒绝消息时降低成本(最近很常见的一种情况),但是客户想尽可能加快这一过程。遍观整个系统,整体最优解可能就是平衡这两种需求。</p><p>有大量使用MTAs的实例明确支持客户端或服务器。 他们有能力这样做只是因为他们有一个相对较小的安装基础。当你的软件系统被用于互联网上重要的一部分时，你的设计必须平衡双方的之间的负载，所做的努力都是为了保持互联网这个整体。而由于总会有MTAs被曲解为另一个意思，例如,邮件系统只关心优化出口端。</p><p>当设计一个连接双方的系统,重要的是要避免有所偏颇。值得注意的是,这与其他互相对立客户端与服务器端的简历形成了鲜明对比，例如,web服务器和web客户端一般由不同的小组开发。</p><h3 id="17-5-2-Milters"><a href="#17-5-2-Milters" class="headerlink" title="17.5.2 Milters"></a>17.5.2 Milters</h3><p>最重要的一个sendmail的附件是Milter界面(邮件过滤器)。Milter允许使用offboard插件（即单独运行的插件）用来处理邮件。这原本是为反垃圾邮件处理而设计。Milter协议与服务器同步运行SMTP协议。随着每一个新的SMTP命令从客户机接收到,sendmail调用Milter与以及相关指令信息。Milter有机会接受命令或发送一个拒绝指令, 拒绝该阶段的SMTP协议命令。Milter使用回调模型,所以当一个SMTP命令到达时会调用相应的Milter子例程。Milter是螺旋上升的,对每种情况都接入不同的环境来传递状态。</p><p>理论上milters可以在sendmail地址空间中作为可加载模块运行。我们拒绝这样做有三个原因。首先, 安全问题太重要:即使sendmail作为一个独一无二的的非根用户id运行,用户仍然拥有访问其他消息所有状态的权限。同样,不可避免会有一些Milter作者试图访问内部sendmail状态。</p><p>第二,我们想创建一个sendmail和Milter之间的防火墙:如果Milter停止工作,我们希望清楚弄清楚错误源头并且使邮件(仍有可能的情况下)继续传递。 第三,比起吧sendmail作为一个整体，Milter作者更容易调试一个独立的过程。</p><p>显然,这些Milter比反垃圾邮件处理有用得多。事实上,milter.org网站列出了反垃圾邮件、病毒、归档、内容监控、日志记录、交通影响,和许多其他类别,由商业生产公司和开放源码项目的Milter。后加的Mail6增加了使用相同的接口支持Milter。Milter已被证明是sendmail的一个伟大的成功。</p><h3 id="17-5-3-发布时间表"><a href="#17-5-3-发布时间表" class="headerlink" title="17.5.3 发布时间表"></a>17.5.3 发布时间表</h3><p>有一个流行的“release early and often”和“release stable systems”学派之间的争论。sendmail在不同时期分别使用了这两种思想。在软件有极大变化时，我有时一天不止发布一个版本。 我的总体思想是每个变更后都会发布。这类似于提供公共访问源代码管理系统树。我个人喜欢发布版本时提供公共源代码树,至少在某种程度上是因为我使用一种现在看来被认为不能通过的方式管理源程序:对于大的改动,在我编写代码时，我会检查确认无功能快照。如果这棵树是共享的，我会对这些快照使用分支,但在任何情况下,他们是可用的，让世界看到并能创造相当大的混乱。同时,创建一个发布意味着绑定一个版本号,这使得它更容易追踪变化并生成一个错误报告。 当然,这要求发布的版本容易生成, 这并不总是现实的。</p><p>随着sendmail在更加关键的生产环境中被使用，问题开始产生。它并不总是那么容易区分变化,我想要的是让人们在现实状况下对我做的改动进行真正的测试。给版本添加“alpha”或“beta”标签缓解但不解决这个问题。 结果是,sendmail逐渐成熟，走向不那么频繁,但区别更大的版本发布。这成为当务之急，因为当sendmail成为一个商业产品，顾客想要的是最新和最伟大的而且稳定的版本,不会接受这两个不相容的版本。</p><p>开源开发人员需求和商品需求之间的紧张关系永远不会消失。尽早并且频繁发布版本有诸多好处,特别是潜在的巨大的观众中有不少勇敢的(有时是愚蠢的)测试人员对系统进行压力测试的方式，你几乎不可能指望从标准发展进程中有这样的体验。但它往往作为一个项目成功地变成一个产品(即使那个产品是开源和免费的), 比项目比起来，产品有不同的需求。</p><h2 id="17-6-安全性"><a href="#17-6-安全性" class="headerlink" title="17.6 安全性"></a>17.6 安全性</h2><p>Sendmail发展历程和应用环境多变，但在安全性方面一直是保有理智的。其中一些措施的值得的,但有些不是,原因在于我们的“安全”的概念发生了变化。互联网开始的用户基础只有几千人,主要分布在学术和研究领域。当时的互联网在许多方面比我们今天知道的更友善、更温和。网络旨在鼓励分享,而不是构建防火墙(另一个在早期都未出现的概念)。现在的网络是一个危险的,充满敌意的地方,充满了垃圾邮件发送者和破快者。被越来越多的人描述为一个战区,在战区就有平民伤亡。</p><p>我们很难编写网络服务器时保证其安全,特别是当协议并不简单时。几乎所有的项目或多或少有一些小问题,即使常见的TCP/IP也被成功攻破。更高级别的实现语言证明防止攻击并没有灵丹妙药,甚至他们本身都创造出了一些弱点。必要的观察短语是“不信任所有输入”，不管它是从哪里来的，不信任的输入包括二次输入,例如DNS的输入和Milter的输入。像大多数早期的网络软件一样,sendmail的早期版本对输入显得太过信任。</p><p>但sendmail的最大问题是,早期版本运行时sendmail获取了根权限。为了打开SMTP监听套接字,读个别用户的转发信息,并提供个人用户的邮箱和家庭目录，根权限是必须的。然而,对今天的大多数系统，邮箱的概念名字已经脱离系统用户的概念,有效地消除了对根权限的需求，除了打开SMTP监听套接字仍然需要根权限之外。今天sendmail能够在过程连接之前放弃根权限,这么做消除了支持sendnail环境的担忧。值得注意的是,在这些不提供直接提供给用户信息的邮箱系统中,sendmial仍然可以在改变根目录的环境中运行,以便进一步与根权限隔离。</p><p>不幸的是,随着sendmail的安全性低已经广为人知的时候，它开始因为一些无关的问题受到指责。例如,一个系统管理员保持’’etc’’目录可写,然后当有人替换了’’/etc/passwd’’ 文件就开始职责sendmail。这样的事件让我们着手大幅加强安全性,包括明确检查sendmail访问的文件和目录的所有权和模式。甚至由于这么做太过苛刻,我们被迫在设计中包含一个’’DontBlameSendmail’’的可选项来控制这些检查是否开启。</p><p>还有其他方面的安全问题与保护程序的地址空间本身并不相关。例如,垃圾邮件的泛滥推动了收集地址的发展。SMTP中的’’VRFY’’和’’EXPN’’指令是专门设计来验证个人地址和扩大邮件列表的指令。这些都被垃圾邮件发送者严重滥用的命令,导致现在大多数网站禁止这样的指令。这是不幸的,至少对类似’’VRFY’’这样的命令而言，因为这些指令会被一些反垃圾邮件代理用于验证发送地址。</p><p>同样,反病毒保护一度被视为摆在台面上的一个问题,但是其重要性上升到任何商业级MTA都不得不开启防病毒检查的地步。其他现代设置与安全相关的需求包括强制加密敏感数据, 数据丢失保护和执法监管要求,例如,对于健康保险流通与责任法案（HIPPA）。</p><p>早期sendmail另一个着重注意的原则就是可靠性——每条消息要么被交付收件人要么回到发送方。但joe-jobs(攻击者伪造返回地址信息的邮件的手段,被许多人视为安全问题)导致很多网站不再创建回退邮件。如果可以确定问题所在，SMTP连接仍然是开放的,服务器可以以命令失败来报告这个问题,但SMTP连接关闭后，错误消息将解决默默地消失。公平地说, 今天的大多数合法的邮件都是单跳,所以问题信息仍会得到报告,但至少在原则上世界主流认了安全胜过可靠性。</p><h2 id="17-7-Sendmail的演变"><a href="#17-7-Sendmail的演变" class="headerlink" title="17.7 Sendmail的演变"></a>17.7 Sendmail的演变</h2><p>软件如果不能适应这个飞速变化的大环境，那一定是无法存活下来的。新的硬件技术的出现，推动了操作系统、资源库、软件框架和应用程序的发展变化。如果一个软件应用获得成功,它就被用于问题越来越多元化的环境。改变是不可避免的;你必须接受并拥抱变化。本节介绍了一些随着sendmail的演变而产生的重大变化。</p><h3 id="17-7-1-配置变得更加详细精准"><a href="#17-7-1-配置变得更加详细精准" class="headerlink" title="17.7.1 配置变得更加详细精准"></a>17.7.1 配置变得更加详细精准</h3><p>最初的sendmail配置很简洁。例如,选项和宏的名称都是单个字符。这主要出于三个原因。首先,它使解析变得非常简单(处在一个16位的环境之中，这一点很重要)。第二,除此之外选择也不多,所以不是很难想出助记名字。第三,单个字符公约已经确立为命令行标记。</p><p>同样,重写规则集最初用编号代替命名。最初也许容许少量的规则集,但是随着规则集规模扩大，规则集能有更多的助记符也变的更加重要。</p><p>随着sendmail运营的环境变得更加复杂,和16位环境消退,显然需要一种更丰富的配置语言。幸运的是,用向后兼容的方式实现这些变化让这种语言的出现变得可能。这些变化显著提高了配置文件的可理解性。</p><h3 id="17-7-2-与其他子系统的连接更紧密-更广义的整合"><a href="#17-7-2-与其他子系统的连接更紧密-更广义的整合" class="headerlink" title="17.7.2 与其他子系统的连接更紧密:更广义的整合"></a>17.7.2 与其他子系统的连接更紧密:更广义的整合</h3><p>在编写sendmail的时候，邮件时系统在很大程度上是孤立于操作系统的其余部分之外的。然而有一些服务需要集成环境才能运行就比如’’/etc/passwd’’和’’/etc/hosts’’文件。可开关服务还没有被发明出来,目录服务是不存在的,配置文件规模很小并且手动维护。</p><p>因此sendmail需要迅速改变。第一个改变的就是添加DNS的服务。虽然系统主机查找抽象(‘’gethostbyname’’)致力于查找IP地址,邮件必须使用例如MX的其他查询服务。之后,IDA sendmail使用dbm(3)文件来实现外部数据库查询功能。Sendmail 8更新加入了通用映射服务,允许其他数据库类型,包括外部数据库和仅靠重写无法做到的内部转换(如消除引用地址)。</p><p>现在电子邮件系统普遍依赖于许多并非电子邮件专用的外部服务。这使得sendmail在代码层面上更加抽象。而随着“活动部件”越来越多，维护电子邮件系统也变得更加举步维艰。</p><h3 id="17-7-3-去适应一个带有敌意的世界"><a href="#17-7-3-去适应一个带有敌意的世界" class="headerlink" title="17.7.3 去适应一个带有敌意的世界"></a>17.7.3 去适应一个带有敌意的世界</h3><p>Sendmail在一个按现在标准看来似乎完全陌生的世界完成开发。早期网络上尽管有时有恶性的学术政治出现，但用户群体主要是相对良性的研究人员,。Sendmail反映了当时创建它的世界的特点,把重点放在邮件传递的可靠性,哪怕是需要用户错误。</p><p>当今世界更加充满敌意，绝大多数的电子邮件是恶意的。MTA的目标已从邮件保持递送变为去除恶意邮件。过滤邮件可能是现在任何MTA的优先事项，这就要求sendmail做出对应的变化。例如,许多规则集已经被添加用于允许检查对传入的SMTP命令行参数以尽早发现问题。阅读一条消息的信封时拒收邮件要比阅读整个邮件再拒收要大大节约开销，更不用说在发送回应报文时才拒收。在早期通常是过滤的过程是先接受信息,然后通过一个过滤程序,如果通过过滤再发送给另一个sendmail实例( 所谓的“三明治”结构)。这对当今世界的网络环境而言开销太大了。</p><p>同样,sendmail已经从一个相当普通TCP/IP消费者变为更加复杂的成分,通过类似于“窥视”网络输入发件人的行为来确认在之前的命令得到确认之前，当前命令是否已经被发出。这推翻了一些以前旨在令sendmail适应多种网络类型的设计。今天,它将分配相当大的工作量用于连接sendmail到XNS或数据网络,因为TCP/IP已建成的知识涉及到到那么多的代码。</p><p>许多配置功能被添加用于应对这个带有敌意的外部环境,如支持访问表、实时黑名单、地址获取缓解、拒绝服务保护和垃圾邮件过滤。这使得配置一个邮件系统的任务变得大大复杂,但是为了适应当今世界，这些都是必须的。</p><h3 id="17-7-4-加入新技术"><a href="#17-7-4-加入新技术" class="headerlink" title="17.7.4 加入新技术"></a>17.7.4 加入新技术</h3><p>这些年出现了许多新的标准，使得sendmail需要做出显著的变化。例如,为了添加TLS (加密)服务需要做出的修改贯穿整个工程代码。SMTP流水线需要监视底层TCP/IP流以避免死锁。提交的端口(587) 需要监听多个输入端口的能力,包括取决于到达港口做出不同应对的能力。</p><p>其他压力被迫由环境而不是标准。例如,Milter界面是用于直接应对垃圾邮件的。尽管Milter不是出版的标准,但也是一个重要的新技术。</p><p>在不同情况下,这些变化从不同的方面为邮件系统增加了安全,更好的性能或新功能。然而,他们都需要开销,在几乎所有的情况下都使得代码和配置文件更加复杂。</p><h2 id="17-8-如果放到现在我会怎么做？"><a href="#17-8-如果放到现在我会怎么做？" class="headerlink" title="17.8 如果放到现在我会怎么做？"></a>17.8 如果放到现在我会怎么做？</h2><p>不谈事后诸葛亮，如果放到现在编写sendmail，许多事情的处理方式都会有所不同。有些当时无法预知(比如说,垃圾邮件如何改变我们对电子邮件的观感,现代工具集将是什么样子等等),有些完全是可预测的。有些是在编写sendmail的过程我学到的很多关于电子邮件,关于TCP/IP, 和编程本身——每个人都随着自己写的代码而成长。</p><p>但也有很多方面我仍会做出一样的决定,有些甚至矛与所谓标准的智慧相悖。</p><h3 id="17-8-1-我想以不同方式实现的部分"><a href="#17-8-1-我想以不同方式实现的部分" class="headerlink" title="17.8.1 我想以不同方式实现的部分"></a>17.8.1 我想以不同方式实现的部分</h3><p>也许我对sendmail犯的最大的错误就是没有认识到sendmail在将来会变得这是多么重要。我有几次机会推动世界向正确方向发展,但没有把握住它们; 事实上,在某些情况下我做了负面的影响,例如: 没有使sendmail在合适的时候更严格地应对不当输入。同样,在相当早的时候，我就认识到需要改进配置文件的语法，当时可能只有几百个sendmail实例部署,但我最终决定不做改变,因为我不想引起安装用户不必要的痛苦。现在想来，早点改进造成的痛苦是短暂的，产生的好的结果才是长久的。</p><p><strong>第七版Mailbox语法</strong></p><p>这方面的一个例子是第七版Mailbox分割邮件的做法。他们用一个行开始符“From_”( “From_”代表了ASCII空格字符,编码0x20)分离消息。如果接收到消息在一行开始的地方本身包含单词“From_”,本地邮箱软件就会转换为“From_”。对一些但并不是所有的系统而言有一个细化要求，邮件之前需要一个空行,但这不能作为公约被信赖。直到今天，“&gt;From”仍然会出现在非常意想不到的地方，但显然与邮件本身无关(但很明显，电子邮件系统昨晚会处理到)。回想起来我可能已经将BSD邮件系统变为使用新的语法。我本该在当时收到用户抱怨,但我一定替世界解决了一大堆麻烦。</p><p><strong>语法和配置文件的内容</strong></p><p>也许我配置文件的语法犯的最大的错误是在重写规则中使用制表符（HT，0x09）进行模式转换。当时我只是效仿make,在晚些时候得知斯图尔特·费尔德曼，make的作者,也认为是他最大的错误之一。除了在屏幕上观察配置不够明显之外,制表符也存在对于大多数窗口剪切和粘贴都不能保留制表符的缺陷。</p><p>虽然我相信重写规则是正确的(如下文所叙),但我将改变配置文件的总体结构。例如,我没有预料到需要在配置中加入层次结构(比如说，设置不同的选项应对不同的SMTP侦听器端口)。当时的配置文件设计没有“标准”格式。今天,我会倾向于选择使用apache方式，这样的方式足够干净,整洁,同时有足够的表达能力——甚至嵌入到类似Lua这样的语言中。</p><p>在开发sendmail时，地址空间狭小并且协议仍在不断变化。因此把尽可能多的内容加进配置文件似乎是一个好主意。在今天看起来却是个错误:我们有足够的地址空间(MTA)和稳定的标准。此外,“配置文件”是代码的一部分，在新版本需要更新。’’.mc’’ 配置文件修复了这个问题, 但不得不在每次更新软件重建配置，无疑是一种痛苦。一个简单的解决方案是sendmail会读两个配置文件,一个隐藏并在和安装更新时同步，另一个可见的用于本地配置。</p><p><strong>使用的工具</strong></p><p>现如今有许多新的工具——例如在配置和构建软件方面。工具可以在需要时被很好地利用,但他们也可以被滥用,使它对了解系统产生不必要的困难。例如,你需要的只是strtok(3)时，就根本不需要使用 yacc(1)语法。但白费力气从头开始也不是一个好主意。尤其是即使就算在如今有所保留但我几乎肯定仍然会使用autoconf（地址自动配置协议）。</p><p><strong>向后兼容性</strong></p><p>既然是事后诸葛亮,知道了sendmail会变得无处不在,那在早期我就不会太担心打破现有的安装基础。当现实是存在严重缺陷的，那就应该去修正它,而非适应它。即便这样,我还是不会严格检查所有消息格式,有些问题很容易并且安全地被忽略或修补。例如,我可能还会在 无法获取头区域的邮件头部插入一个’’Message_Id’’字段,但我将会更倾向于拒绝没有’’From:’’头区域的邮件: 头字段而不是试图创建一个信封。</p><p><strong>内部的抽象</strong></p><p>有一些内部的抽象,我不会再次尝试,反而我将增加另外一些。例如,我不会使用以null结尾的字符串,而选择长度/值对,尽管这意味着标准C库变得难以使用。光是它蕴含的安全性就值得的一试。相反,我不会尝试构建在C语言中异常处理,但是我想创建一个贯穿这个工程能保持一致的状态代码系统，而不是使用例程返回’’null’’,’’false’’,或者负数表示错误。</p><p>我肯定会将用户邮箱的名称从Unix的用户id中抽象出来。当时我写sendmail时是假设只发送给Unix用户消息的模型。今天,这样的模型不再适用;即使在使用这种模型的系统中,也有系统用户从来没有收到电子邮件。</p><h3 id="17-8-2-我将坚持的设计"><a href="#17-8-2-我将坚持的设计" class="headerlink" title="17.8.2 我将坚持的设计"></a>17.8.2 我将坚持的设计</h3><p>当然,也有一些设计至今运作良好···</p><p><strong>系统日志</strong></p><p>sendmail中一个成功的副产物就是系统日志。在sendmail中需要日志文件去记录一个特定的程序。这些都分散在文件系统中。系统日志在当时很难写(UDP还不存在,所以我使用一个叫做mpx的文件),但这一切都值得。然而,我会做出一个特定的改进:我会花费更多精力注意语法能被及其解析——本质上,我没有能够预测日志监控的产生。</p><p><strong>重写规则</strong></p><p>重写规则一直争议颇多,但我将莹然使用它(尽管可能不是像现在用的这么频繁)。使用制表符是一个明显的错误,但考虑到限制ASCII和电子邮件地址的语法,一些转义字符可能仍然需要。一般来说,使用模式替换概念的范式运行良好并且非常灵活。</p><p><strong>避免不必要的工具</strong></p><p>尽管我上面的发言表明我将使用更多现有的工具,但是我是不愿使用今天的许多可用的运行时库。在我看来,这些运行时库大多是臃肿而危险的。库文件应该小心选择,权衡利弊使用，不能使用过度强大的工具来解决简单的问题。我会避免使用的一个特定的工具是XML,至少 不会用它作为一种配置语言。我认为XML对于当前很多使用它的环境来说语法过于复杂了。XML有它的用武之地,但是现在它是被滥用了。</p><p><strong>用C来编写</strong></p><p>有些人建议一个更自然的实现语言，比如Java或c++。尽管C有一些众所周知的问题,我还是会用它作为我的实现语言。在一定程度上,这是个人因素: 比起Java或c++，我更了解C。但我也对大多数面向对象语言对内存分配的忽视感到失望。分配内存可能产生很多难以定性的性能问题。sendmail内部在适当的地方使用了面向对象的概念(例如,图类的实现),但在我看来，完全面向对象是浪费的，也是过度限制的。</p><h2 id="17-9-总结"><a href="#17-9-总结" class="headerlink" title="17.9 总结"></a>17.9 总结</h2><p>sendmail MTA出生于一个天翻地覆的世界,一种类似于“西大荒”的时间段,电子邮件是新的一种概念，当前的邮件标准都尚未制定。在过去31年“电子邮件问题”也已经从只需要在大数据高负载下可靠地工作转变为保护从垃圾邮件和病毒的攻击下保护站点，直到今天终于被用作一个基于大量电子邮件的应用程序的平台。Sendmail已经演变成一个大量希望避免风险的企业依靠的平台,即便电子邮件已经从纯文本人际传播发展为多媒体任务关键基础设施的一部分。</p><p>成功的原因并非总是显而易见的。在一个快速变化的世界，只有少数兼职开发人员要想编写一个软件程序就不能依赖传统的软件开发方法。我希望我能提供一些sendmail成功的深层原因和经验。</p><hr><p><strong>（全篇完）</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Sendmail-翻译&quot;&gt;&lt;a href=&quot;#Sendmail-翻译&quot; class=&quot;headerlink&quot; title=&quot;Sendmail 翻译&quot;&gt;&lt;/a&gt;Sendmail 翻译&lt;/h1&gt;&lt;p&gt;原文地址：&lt;a href=&quot;http://www.aosabook.
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
  <entry>
    <title>SocialCalc</title>
    <link href="http://blog.ccao.cc/2018/09/28/SocialCalc/"/>
    <id>http://blog.ccao.cc/2018/09/28/SocialCalc/</id>
    <published>2018-09-27T16:00:00.000Z</published>
    <updated>2020-03-05T05:53:45.675Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SocialCalc"><a href="#SocialCalc" class="headerlink" title="SocialCalc"></a>SocialCalc</h1><p>电子表格的历史有超过30年了。第一个电子表格VisiCalc是Dan Bricklin在1978年构思的，并在1979年传播开来。最初的理念是很直接的：一个文本、数字和公式构成的二维表格。公式由普通数学操作符和各种各样函数构成的，并且每个公式可以当做值使用其它当前内容的单元格。</p><p>尽管比喻很简单，但是它有很多应用：会计、发明、罗列管理。可能性是无限的。所有的这些都使得VisiCalc编程第一个个人电脑年代的杀手app。 </p><p>在这几十年来，很多后继者都做出了巨大的提高，像Lotus 1-2-3，但是核心是一样的。大多数电子表格存储成硬盘文件，当被打开编辑的时候表格就载入到内存。在基于文件的模型下，合作是尤其困难的，如下： </p><ul><li><p>每个使用者需要安装一个电子表格编辑器的版本； </p></li><li><p>电子邮件、共享文件夹、或者安装一个微妙的版本控制系统，都被加入到簿记中； </p></li><li><p>改变踪迹是有限的。比如，Excel不保存历史中格式的改变和单元格的注释； </p></li><li><p>在模板中更新格式或者公式，需要对当前使用那个模板的电子表格文件作出艰苦的改变。 </p></li></ul><p>幸运的是，一个新的合作小组模型产生了，并通过优雅的简单化把这些问题解决了。这就是wiki模型，Ward Cunningham在1994年的时候发明它，并且在两千年的早期通过维基百科风靡。 </p><p>wiki模型以主机服务器的网页为特征，而不是文件，不用特别的软件就可以在浏览器编辑。那些超文本网页可以互相容易地连接，甚至包括其它网页的部分，从而构成一个更大的网页。所有参与者观察和编辑最新版本，并且版本历史都被服务器自动地掌握。 </p><p>被wiki模型所激励，Dan Bricklin在2005年开始了WikiCalc的工作。它的目标在于把创作缓解和多人wiki编辑，与熟悉的可视化格式和电子表格的隐喻计算结合起来。</p><h2 id="19-1-WikiCalc"><a href="#19-1-WikiCalc" class="headerlink" title="19.1 WikiCalc"></a>19.1 WikiCalc</h2><p>WikiCalc的第一个版本（图19.1）有许多和其它电子表格区分开的特性。<br>·纯文字、HTML，以及Wiki式的文本标记支持。<br>·Wiki文字包含插入链接、图片，以及和从存储格引用值的功能。<br>·公式存储格可以引用放在其他网站的 WikiCalc 网页里的值。<br>·支持输出到静态网页，以及将动态资料内嵌至其他网页。<br>·存储格能使用 CSS 来改变样式。<br>·记录所有编辑操作，以供稽核纪录。<br>·和Wiki系统一样，保留每一个版本，并可以随时回复<br><img src="/cdn/images/aosabook/8.png" alt="图19.1"></p><p><img src="/cdn/images/aosabook/9.png" alt="图19.2"></p><p><img src="/cdn/images/aosabook/10.png" alt="图19.3"></p><p>WikiCalc 1.0的内部架构（图19.2）和信息流（图19.3）是简单的，但是很强大。从几个小型电子表格组建一个主电子表格的能力，是 WikiCalc 的一大强项。举例来说，每位销售员可以把营业额放在自己的电子表格页面里；然后销售经理可以综合这些资料到该区的电子表格中，之后销售副总再综合各区域的数字，构成主电子表格。 每次电子表格之一被更新了，所有的相关电子表格都能反应这个更新。如果有人想看到更详细的信息，他们只要点击去查看这个电子表格后面的电子表格就好了。这种能力减少了更新数字可能出现的多余或者出错的努力，并且确保了所有信息的视图保持最新状态。<br>为了保证计算数据是最新的，WikiCalc采取了一种”瘦”客户端的设计，保持所有的状态信息在服务器端。每个电子表格在浏览器都用table代表；编辑一个单元格会发送一个ajaxsetcell调用给服务器，并且服务器会告诉浏览器哪个单元格需要更新。<br>不足为奇，这个设计取决于浏览器和服务器间的快速联系。当潜伏因素多的时候，用户将开始注意到”Loading…”消息的频繁出现，就像表格19.4展示的那样。这个对于用户交互地编辑并期待实时看到结果是一个问题。<br><img src="/cdn/images/aosabook/11.png" alt="图19.4"></p><p>此外，因为table元素和电子表格有相同的维度，一个100*100的网格将创造10000DOM项目，这拉长了浏览器的记忆资源，限制了网页大小。 因为这些缺点，虽然WikiCalc作为在本地主机运行的独立服务器是方便使用的，但是当做网页内容管理系统的一部分是不切实际的。 在2006年，Dan Bricklin和Socialtext一起组队开始发展SocialCalc，一个用js并基于一些Perl源代码的WikiCalc的重写。 这次重写目的在于大的分布式的合作，并且寻求展示一个视图并更像一个桌面应用。其它设计目标包括： ·能够处理成千的单元格 ·编辑操作具有快速的转向时间 ·客户端审计追踪和撤销/恢复栈 ·更好地使用js和CSS以提供展示功能 ·支持不同版本的浏览器，尽管相应的js需要更大代价 经过三年的开发和发布许多次测试版之后，Socialtext 在 2009 年发布 SocialCalc 1.0，成功实现了设计目标。现在，让我们来看看 SocialCalc 的系统架构。</p><h2 id="19-2-SocialCalc"><a href="#19-2-SocialCalc" class="headerlink" title="19.2 SocialCalc"></a>19.2 SocialCalc</h2><p><img src="/cdn/images/aosabook/12.png" alt="图19.5"></p><p>图19.5和图19.6分别展示了SocialCalc的界面和类图。相比于WikiCalc，服务器的角色被大大减弱了。它的唯一职责是对HTTP GET进行相应，反馈保存格式的整个表单；一旦浏览器收到数据，所有的计算、变动轨迹和用户交流都在JavaScript中实现。<br><img src="/cdn/images/aosabook/13.png" alt="图19.6"></p><p>Javascript部分是按照MVC风格来设计的，每个类关注一个方面：</p><ul><li><p>Sheet是一个数据模型，代表电子制表软件一个内存结构。它包括了从坐标轴到单元格的字典，每个代表一个单元格。空的单元格不需要条目，因此不占内存。</p></li><li><p>Cell代表一个单元格的内容和格式，一些普遍的属性在表格19.1。</p></li><li><p>RenderContext完成视图，负责把表格转成DOM对象。</p></li><li><p>TableControl是主要的控制器，接受鼠标事件和键盘事件。当它收到视图事件，比如滚动、调整大小，它更新与它相关的RenderContext对象。当它收到影响表单内容的更新事件时，它在指令队列中添加新的指令。</p></li><li><p>SpreadSheetControl是有工具栏、状态栏、对话框、颜色选择器的最高层用户界面。</p></li><li><p>SpreadSheetViewer是一个可选的最高层用户界面，提供只读的交互视图。</p></li></ul><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>datatype</td><td>t</td></tr><tr><td>datavalue</td><td>1Q84</td></tr><tr><td>color</td><td>black</td></tr><tr><td>bgcolor</td><td>white</td></tr><tr><td>font</td><td>italic bold 12pt Ubuntu</td></tr><tr><td>comment</td><td>Ichi-Kyu-Hachi-Yon</td></tr></tbody></table><pre><code>表19.1                                             </code></pre><p>我们采取一种小的基于类的对象系统，包括简单的部分/委托，没有使用继承或者对象的原型。所有符号都被放在SocialCalc.*命名空间，以避免命名冲突。</p><p>每个表格的更新都经历了ScheduleSheetCommand方法，这个方法用指令字符串代表编辑。（一些常用的指令显示在表格19.2中。）嵌在SocialCalc中的应用可能自己定义了多余的命令，定义这些命令的时候需要在SocialCalc.SheetCommandInfo.CmdExtensionCallbacks对象中加入回调函数，并且使用startcmdextensin命令调用它们。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>set</td><td>sheet defaultcolor blue</td></tr><tr><td>set</td><td>A width 100</td></tr><tr><td>set</td><td>A1 value n 42</td></tr><tr><td>set</td><td>A2 text t Hello</td></tr><tr><td>set</td><td>A3 formula A1*2</td></tr><tr><td>set</td><td>A4 empty</td></tr><tr><td>set</td><td>A5 bgcolor green</td></tr><tr><td>merge</td><td>A1:B2</td></tr><tr><td>unmerge</td><td>A1</td></tr><tr><td>erase</td><td>A2</td></tr><tr><td>cut</td><td>A3</td></tr><tr><td>paste</td><td>A4</td></tr><tr><td>copy</td><td>A5</td></tr><tr><td>sort</td><td>A1:B9 A up B down</td></tr><tr><td>name</td><td>define Foo A1:A5</td></tr><tr><td>name</td><td>desc Foo Used in formulas like SUM(Foo)</td></tr><tr><td>name</td><td>delete Foo</td></tr><tr><td>startcmdextension</td><td>UserDefined args</td><td>表19.2</td></tr></tbody></table><h2 id="19-3-Command-Run-loop"><a href="#19-3-Command-Run-loop" class="headerlink" title="19.3 Command Run-loop"></a>19.3 Command Run-loop</h2><p>为了提高响应程度，SocialCalc在背景执行所有的重新计算和DOM更新，所以当引擎在命令队列中处理前面的变动时，用户可以保持对一些单元格进行修改。</p><p><img src="/cdn/images/aosabook/14.png" alt="图19.7"></p><p>当命令正在运行时，TableEditor对象把busy的标志置为true，随后的命令放到defferredCommands队列中，确保一次序列顺序的执行。事件循环图显示在图19.7中，表格对象不停地发送StatusCallback事件，以通知当前命令执行状态的用户，经历下面这四个步骤：</p><ul><li><p>ExecuteCommand: 开始后发送cmdstart，命令完成执行后发送cmdend。如果命令间接改变一个单元格的值，则进入Recalc步骤。否则，如果命令改变了一个或多个屏幕上的单元格，则进入Render步骤。如果不是上述的情况（比如copy命令），则跳转到PositionCalculations步骤。</p></li><li><p>Recalc（按需）：开始后发送calcstart，当检查单元格的从属链时每100ms发送calcorder，当检查完毕时发送calccheckdone，当所有受影响的单元格收到他们的重算值时发送calcfinished。这个步骤的下一个步骤总是Render步骤。</p></li><li><p>Render: 开始后发送schedrender，当<table>元素被更新成格式化的单元格时发送renderdone。这个步骤的下一个总是PositionCalculations步骤。</table></p></li><li><p>PositionCalculations: 开始后发送schedposcalc，在更新完滚动条、当前单元格光标、其它TableEditor的可视成分后发送doneposcalc。</p></li></ul><p>因为所有的命令在执行时都被保存了，我们自然而然地得到所有操作的审查日志。Sheet.CreateAuditString方法提供了一个按新行隔开的字符串作为审查追踪，每个命令都是一个单独行。</p><p>ExecuteSheetCommand对每个执行过的命令创建了撤销命令。举个例子，如果单元格A1包括“Foo”，并且用户执行set A1 text Bar，那么撤销命令set A1 text Foo被放到撤销栈中。如果用户点击撤销，那么撤销命令把A2恢复到它原来的值。</p><h2 id="19-4-Table-Editor"><a href="#19-4-Table-Editor" class="headerlink" title="19.4 Table Editor"></a>19.4 Table Editor</h2><p>现在让我们看看TableEditor层次。它计算了屏幕上RenderContext坐标，并且通过两个TableControl管理水平/垂直滚动条。</p><p><img src="/cdn/images/aosabook/15.png" alt="图19.8"></p><p>在视图层次，由RenderContext类处理，并且与WikiCalc设计不同。我们不是把每个单元格映射到&lt;td&gt;元素，而是简单地创建一个固定大小的&lt;table&gt;来适应浏览器的可视范围，并且用&lt;td&gt;元素预先构建。</p><p>当用户通过滚动条滑动表单时，我们动态更新预先画好的&lt;td&gt;元素的innerHTML。这个意味着在很多普遍情况下，我们不必创建或者毁坏&lt;tr&gt;或者&lt;td&gt;元素，这个极大地提高了相应速度。</p><p>因为RenderContext只实施可视区域。表单对象的大小可以很大，也不会影响操作。</p><p>TableEditor也包括一个CellHandles对象，这个实现了当前编辑单元格的右下角的填充/移动/滑动菜单，即ECell，如图19.9所示。</p><p><img src="/cdn/images/aosabook/16.png" alt="图19.9"></p><p>输入框由两个类管理：InputBox和InputEcho。前者管理网格上的编辑行，后者展示及时更新的预览层，覆盖ECell的内容（图19.10）。</p><p><img src="/cdn/images/aosabook/17.png" alt="图19.10"></p><p>通常，SocialCalc引擎当打开一个表单进行编辑时和将它存回服务器时，仅需要与服务器通信。出于这个目的，Sheet.ParseSheetSave方法将一个保存格式的字符串转成一个Sheet对象，Sheet.CreateSheetSave方法将Sheet对象转成存储格式。</p><p>范式可能通过URL链接指到远程电子表格。recalc命令重新获取外部被引用的电子表格，用Sheet.ParseSheetSave把它们转化，并把它们存储到暂存区中，使得用户引用相同远端表格中的其它单元格的内容，而不用再次获取它的内容。</p><h2 id="19-5-Save-Format"><a href="#19-5-Save-Format" class="headerlink" title="19.5 Save Format"></a>19.5 Save Format</h2><p>存储格式是标准的MIME 多部分/混合形式，包括四个纯文本、UTF-8编码的部分组成，每个部分包括新的换行、冒号分隔的数据域。这些部分包括：</p><ul><li>meta部分罗列了其它部分的类型。</li><li>sheet部分罗列了每个单元格的格式和内容，每个纵列的宽度（非默认格式的情况）、表格的默认格式，以及表格中使用的字体、颜色、边框。</li><li>可选择的edit部分保存TableEditor的编辑状态，包括ECell上一个位置，列/行的固定大小。</li><li>可选择的audit部分包括了在之前编辑的历史运行命令。<br>举个例子，图19.11显示了一个有三个单元格的表格，1874位于A1并且是ECell，A2中是式子2^2*43，A3中以粗体形式显示了计算式SUM(Foo)，表示从A1到A2的Foo范围。<br><img src="/cdn/images/aosabook/18.png" alt="图19.11"></li></ul><p>表格序列化的存储形式就像这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">socialcalc:version:1.0</span><br><span class="line">MIME-Version: 1.0</span><br><span class="line">Content-Type: multipart/mixed; boundary=SocialCalcSpreadsheetControlSave</span><br><span class="line">--SocialCalcSpreadsheetControlSave</span><br><span class="line">Content-type: text/plain; charset=UTF-8</span><br><span class="line"></span><br><span class="line"># SocialCalc Spreadsheet Control Save</span><br><span class="line">version:1.0</span><br><span class="line">part:sheet</span><br><span class="line">part:edit</span><br><span class="line">part:audit</span><br><span class="line">--SocialCalcSpreadsheetControlSave</span><br><span class="line">Content-type: text/plain; charset=UTF-8</span><br><span class="line"></span><br><span class="line">version:1.5</span><br><span class="line">cell:A1:v:1874</span><br><span class="line">cell:A2:vtf:n:172:2^2*43</span><br><span class="line">cell:A3:vtf:n:2046:SUM(Foo):f:1</span><br><span class="line">sheet:c:1:r:3</span><br><span class="line">font:1:normal bold * *</span><br><span class="line">name:FOO::A1\cA2</span><br><span class="line">--SocialCalcSpreadsheetControlSave</span><br><span class="line">Content-type: text/plain; charset=UTF-8</span><br><span class="line"></span><br><span class="line">version:1.0</span><br><span class="line">rowpane:0:1:14</span><br><span class="line">colpane:0:1:16</span><br><span class="line">ecell:A1</span><br><span class="line">--SocialCalcSpreadsheetControlSave</span><br><span class="line">Content-type: text/plain; charset=UTF-8</span><br><span class="line"></span><br><span class="line">set A1 value n 1874</span><br><span class="line">set A2 formula 2^2*43</span><br><span class="line">name define Foo A1:A2</span><br><span class="line">set A3 formula SUM(Foo)</span><br><span class="line">--SocialCalcSpreadsheetControlSave--</span><br></pre></td></tr></table></figure></p><p>这个形式设计得易于阅读，也相对容易程序化地产生，这使得Drupal的Sheetnode插件使用PHP在这个形式和其它流行的表格形式之前的转换成为可能，比如Ecel和OpenDocument。<br>现在我们知道了如何在SocialCalc的部分配合到一起，现在我们看看两个现实生活中的扩展SocialCalc的例子。</p><h2 id="19-6-Rich-text-Editing"><a href="#19-6-Rich-text-Editing" class="headerlink" title="19.6 Rich-text Editing"></a>19.6 Rich-text Editing</h2><p>第一个例子是用wiki笔记提升SocialCalc的文本单元格，在表格编辑器中展示它丰富的文本。<br><img src="/cdn/images/aosabook/19.png" alt="图19.12"></p><p>在SocialCalc 1.0之后的版本中添加了这个特征，用统一的语法解决了插入图片、链接、文本标记的广泛要求。既然Socialtext已经有一个开源的wiki平台，自然地重复使用了SocialCalc的语法。<br>为了完成这个，我们需要给text-wiki的textvalueformat提供特定的格式，用它改变文本单元格的默认形式。<br>什么是textvalueformat？继续往下看。</p><h3 id="19-6-1-Types-and-Formats"><a href="#19-6-1-Types-and-Formats" class="headerlink" title="19.6.1 Types and Formats"></a>19.6.1 Types and Formats</h3><p>在SocialCalc中，每个单元格都有一个datatype和一个valuetype. 包含文本或者数字的数据单元格对应文本型/数字型的值类型，并且公式单元格有datatype = “f”大概产生数字型或者文本型的值。<br>回忆绘制步骤，Sheet对象从每个单元格产生HTML。它通过考察每个单元格的valuetype:如果以t开头，那么单元格的textvalueformat属性决定了如何产生；如果以n开头，那么nontextvalueformat属性被使用。<br>但是，如果单元格的textvalueformat或者nontextvalueformat属性没有准确定义，那么默认的形式可从它的valuetype中查找，如图19.13所示。<br><img src="/cdn/images/aosabook/20.png" alt="图19.13"></p><p>对text-wiki值格式的支持在SocialCalc.format_text_for_display中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if (SocialCalc.Callbacks.expand_wiki &amp;&amp; /^text-wiki/.test(valueformat)) &#123;</span><br><span class="line">    // do general wiki markup</span><br><span class="line">    displayvalue = SocialCalc.Callbacks.expand_wiki(</span><br><span class="line">        displayvalue, sheetobj, linkstyle, valueformat</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>不是把wiki-to-HTML扩展器内联到format_text_for_display，而是在SocialCalc.Callbacks中定义了一个新的hook。这是SocialCalc编码体系中推荐的形式，它通过用不同方式扩展wikitext，保持无需此特性的嵌入器的兼容性，提高了模块性。          </p><h3 id="19-6-2-Rendering-Wikitext"><a href="#19-6-2-Rendering-Wikitext" class="headerlink" title="19.6.2 Rendering Wikitext"></a>19.6.2 Rendering Wikitext</h3><p>接着，我们将使用Wikiwyg（脚注1），一个提供了wikitext和HTML之间两种转换的js库。<br>我们通过取得单元格的文本内容，通过Wikiwyg的parser和HTML的emitter来定义expand_wiki函数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var parser = new Document.Parser.Wikitext();</span><br><span class="line">var emitter = new Document.Emitter.HTML();</span><br><span class="line">SocialCalc.Callbacks.expand_wiki = function(val) &#123;</span><br><span class="line">    /* Convert val from Wikitext to HTML*/</span><br><span class="line">    return parser.parse(val, emitter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>最后一个步骤关于在表单初始化后加入set sheet defaulttextvalueformat text-wiki命令的执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/* We assume there&apos;s a &lt;div id=&quot;tableeditor&quot;/&gt; in the DOM already */</span><br><span class="line">var spreadsheet = new SocialCalc.SpreadsheetControl();</span><br><span class="line">spreadsheet.InitializeSpreadsheetControl(&quot;tableeditor&quot;, 0, 0, 0);</span><br><span class="line">spreadsheet.ExecuteCommand(&apos;set sheet defaulttextvalueformat text-wiki&apos;);</span><br></pre></td></tr></table></figure></p><p>合起来，绘制步骤如图19.14工作。<br><img src="/cdn/images/aosabook/21.png" alt="图19.14">  </p><p>就这样，提高后的SocialCalc现在支持一系列丰富的wiki标注语法：<br><img src="/cdn/images/aosabook/22.png" alt=""></p><p>试着在A1单元格键入<em>bold</em> <em>italic</em> <code>monospace</code>，你将看到绘制的丰富的文本显示（图19.15）。<br><img src="/cdn/images/aosabook/23.png" alt="图19.15"></p><h2 id="19-7-Real-time-Collaboration"><a href="#19-7-Real-time-Collaboration" class="headerlink" title="19.7 Real-time Collaboration"></a>19.7 Real-time Collaboration</h2><p>下面的例子是探索在共享表单上多用户、实时编辑。这个在一开始看起来有些复杂，但是多亏了SocialCallc的模块化设计，我们需要做的就是给每位在线用户向其他参与者传播他们的命令。<br>为了区分局部命令和远程命令，我们给ScheduleSheetCommands加入了一个isRemote的变量:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SocialCalc.ScheduleSheetCommands = function(sheet, cmdstr, saveundo, isRemote) &#123;</span><br><span class="line">   if (SocialCalc.Callbacks.broadcast &amp;&amp; !isRemote) &#123;</span><br><span class="line">       SocialCalc.Callbacks.broadcast(&apos;execute&apos;, &#123;</span><br><span class="line">           cmdstr: cmdstr, saveundo: saveundo</span><br><span class="line">       &#125;);</span><br><span class="line">   &#125;</span><br><span class="line">    /* …original ScheduleSheetCommands code here… */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>现在我们需要做的就是定义一个合适的SocialCalc.Callbacks.broadcast回调函数。一旦它在适当的地方，相同的命令将在连接到同一个表单的所有的用户端执行。<br>当这个特征在2009年在OLPC(One Laptop Per Child(注释2))上由SEETA’s Sugar Labs实现，broadcast函数建立在XPCOM 上，用D-Bus/Telepathy，一种OLPC/Sugar网络的标准传播（见图19.16）。<br><img src="/cdn/images/aosabook/24.png" alt="图19.16">   </p><p>工作起来很合理，使得XO实例在同一个Sugar网络上可以在一个普通的SocialCalc表单上合作。但是，这对Mozilla/XPCOM浏览器平台和D-Bus/Telepathy信息平台都是特定的。</p><h3 id="19-7-1-Cross-browser-Transport"><a href="#19-7-1-Cross-browser-Transport" class="headerlink" title="19.7.1 Cross-browser Transport"></a>19.7.1 Cross-browser Transport</h3><p>为了实现跨浏览器和跨操作系统，我们使用Web::Hippie的框架，一个高等级的使用方便JQuery捆绑的JSON-over-WebSocket的抽象，当WebSocket不空闲时使用MXHR（Multipart XML HTTP Request(注释5)）作为稍后的传输机制。<br>对于有Adobe Flash插件但是没有原生WebSocket支持的浏览器，我们使用web_socket.js项目的WebSocket的Flash模拟器，这一班比MXHR更快更可靠。这个操作流显示在图19.17中。<br><img src="/cdn/images/aosabook/25.png" alt="图19.17"></p><p>在客户端SocialCalc.Callbacks.broadcast函数如下定义：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">var hpipe = new Hippie.Pipe();</span><br><span class="line"></span><br><span class="line">SocialCalc.Callbacks.broadcast = function(type, data) &#123;</span><br><span class="line">    hpipe.send(&#123; type: type, data: data &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">$(hpipe).bind(&quot;message.execute&quot;, function (e, d) &#123;</span><br><span class="line">    var sheet = SocialCalc.CurrentSpreadsheetControlObject.context.sheetobj;</span><br><span class="line">    sheet.ScheduleSheetCommands(</span><br><span class="line">        d.data.cmdstr, d.data.saveundo, true // isRemote = true</span><br><span class="line">    );</span><br><span class="line">    break;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><p>尽管这个工作起来很好，仍然有两个存留的问题要处理。</p><h3 id="19-7-2-Conflict-Resolution"><a href="#19-7-2-Conflict-Resolution" class="headerlink" title="19.7.2. Conflict Resolution"></a>19.7.2. Conflict Resolution</h3><p>第一个问题是命令执行顺序的竞争条件：如果用户A和用户B同时执行了影响相同单元格的操作，接受和执行其他用户传播的命令，他们最终将处于不同的状态，如图19.18.<br><img src="/cdn/images/aosabook/26.png" alt="图19.18"></p><p>我们可以使用SocialCalc内置的undo/redo机制来处理这个问题，如图19.19显示。<br><img src="/cdn/images/aosabook/27.png" alt="图19.19">                                                               </p><p>这个处理冲突的过程如下。当客户传播一个指令时，它向队列添加这个指令。当客户接收到一个指令时， 检查远程指令和队列。<br>如果队列为空，则执行远程指令。如果远程指令和队列里的一个指令相同，则去掉队列里的这个指令。<br>否则，客户检查是否有队列里的指令和接受到的指令之间的冲突。如果有冲突指令，客户先撤销这些命令，并标记它们用于之后的恢复。在撤销冲突指令后，远程指令照常执行。<br>当从服务器接受到标记恢复的指令时，客户再次执行它，并把它从队列里面删去。</p><h3 id="19-7-3-Remote-Cursors"><a href="#19-7-3-Remote-Cursors" class="headerlink" title="19.7.3 Remote Cursors"></a>19.7.3 Remote Cursors</h3><p>尽管竞争条件的问题解决了，重写正由其它用户编辑的单元格仍然未达到最佳标准。一个简单的提升是每个客户都向其他用户广播它的鼠标位置，这样每个人都能知道哪些单元格正在被使用。<br>为了实现这个想法，我们给MoveECellCallback事件添加了另一个broadcast句柄：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">editor.MoveECellCallback.broadcast = function(e) &#123;</span><br><span class="line">    hpipe.send(&#123;</span><br><span class="line">        type: &apos;ecell&apos;,</span><br><span class="line">        data: e.ecell.coord</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">$(hpipe).bind(&quot;message.ecell&quot;, function (e, d) &#123;</span><br><span class="line">    var cr = SocialCalc.coordToCr(d.data);</span><br><span class="line">    var cell = SocialCalc.GetEditorCellElement(editor, cr.row, cr.col);</span><br><span class="line">    // …decorate cell with styles specific to the remote user(s) on it…</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><p>为了标记表单中的单元格焦点，常见的使用有颜色的边框。但是，一个单元格可能已经定义了它自己的边框属性，边框是单色的，在一个单元格上只能代表一个光标。<br>因此，在支持CSS3的浏览器上，我们使用box-shadow特性来代表同一个单元格上的重复的同伴光标：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/* Two cursors on the same cell */</span><br><span class="line">box-shadow: inset 0 0 0 4px red, inset 0 0 0 2px green;</span><br></pre></td></tr></table></figure></p><p>图19.20显示了如果四个人在同一个表单上编辑时的显示：<br><img src="/cdn/images/aosabook/28.png" alt="图19.20">                       </p><h2 id="19-8-Lesson-Learned"><a href="#19-8-Lesson-Learned" class="headerlink" title="19.8 Lesson Learned"></a>19.8 Lesson Learned</h2><p>在2009年10月19号VisiCalc最初版本发行30周年之际，发行了SocialCalc 1.0。在DanBricklin的指导下与我同事合作开发Socialtext的经历是弥足珍贵的，我将分享我在那段时间学到的内容。</p><h3 id="19-8-1-Chief-Designer-with-a-Clear-Vision"><a href="#19-8-1-Chief-Designer-with-a-Clear-Vision" class="headerlink" title="19.8.1. Chief Designer with a Clear Vision"></a>19.8.1. Chief Designer with a Clear Vision</h3><p>在[[<a href="http://aosabook.org/en/bib1.html#bib:brooks:design|Bro10]]" target="_blank" rel="noopener">http://aosabook.org/en/bib1.html#bib:brooks:design|Bro10]]</a> 中，Fred Brooks提出，当构建复杂系统时，专注于连贯的设计理念，而不是派生的表示，沟通会更加直接。根据Brooks所说，这样的连贯设计理念的规划最好由一个人专注：既然概念的完整是伟大设计中最重要的特性，并且完整的概念来自一人或少数人，明智的管理者会大胆委托有天赋的首席设计师。<br>在SocialCalc的范例中，有Tracy Ruggles作为我们的首席用户体验设计师是整个项目到达共享构想的关键。既然潜在的SocialCalc引擎具有延展性，功能变更的想法也很真实。Tracy沟通使用设计框架的能力使我们以用户觉得直接的方式展现了功能。</p><h3 id="19-8-2-Wikis-for-Project-Continuity"><a href="#19-8-2-Wikis-for-Project-Continuity" class="headerlink" title="19.8.2. Wikis for Project Continuity"></a>19.8.2. Wikis for Project Continuity</h3><p>在我加入SocialCalc项目之前，已经有了超过两年的设计和发展，但是我能够跟上并在一个星期内开始给项目作出贡献，这是由于所有东西都在wiki里。从最早的设计笔记到最近的浏览器支持矩阵，整个过程都在wiki和SocialCalc电子表格中记录了。<br>阅读项目的工作空间让我很快地和其他人到达同一进度，并且不需要新项目成员传统的手把手的适应期。<br>这在传统的开源项目中不太可能，大多数沟通在IRC和邮件列表，wiki只是用于记录和资源链接。作为一个新人，从非结构的IRC记录和邮件文件夹中重建文本是更加艰难的。</p><h3 id="19-8-3-Embrace-Time-Zone-Differences"><a href="#19-8-3-Embrace-Time-Zone-Differences" class="headerlink" title="19.8.3. Embrace Time Zone Differences"></a>19.8.3. Embrace Time Zone Differences</h3><p>Ruby on Rails的创建人David Heinemeier Hansson曾经评论分布式团队的益处，当他刚开始加入37signals的时候，“Copenhagen和Chicage之间的七个时区说明我们在很少阻隔的情况下做出很多工作。”我们在SocialCalc的开发也是这样，Taipei和Palo Alto之间有九个时区。<br>我们经常在24小时内完成一个完整的“设计-开发-QA”反馈环，每个方面花费了一个人在其时区的8小时。这不同步的合作让我们生成自我解释的作品（设计框架、代码、测试），这大大提高了我们之间的信任。</p><h3 id="19-8-4-Optimize-for-Fun"><a href="#19-8-4-Optimize-for-Fun" class="headerlink" title="19.8.4. Optimize for Fun"></a>19.8.4. Optimize for Fun</h3><p>我在2006年CONISLI会议主旨中，总结了我领导一个团队完成Perl6语言的经历。在它们之中，有Roadmap,Forgiveness&gt;Permission,Remove deadlocks,Seek ideas,not consensus,Sketch ideas with code，都在小型的分布式团队中特别相关。<br>当发挥SocialCalc时，我们注重在团队成员中普及知识，这样没有人会变成一个瓶颈。<br>此外，我们通过综合供选择的代码探索设计空间处理冲突，当一个更好的设计出现时我们不害怕更换原型。<br>这些文化特性帮助我们培养信任和情谊，尽管缺少面对面的交流，争执降到最小化，使得SocialCalc的工作有很多乐趣。</p><h3 id="19-8-5-Drive-Development-with-Story-Tests"><a href="#19-8-5-Drive-Development-with-Story-Tests" class="headerlink" title="19.8.5. Drive Development with Story Tests"></a>19.8.5. Drive Development with Story Tests</h3><p>在加入Socialtext之前，我已经提倡过“interleave tests with the specification”处理方式，这个可以在Perl 6说明书里面看到，我们用官方测试标注了语言说明。Ken Pier和Matt Heusser，SocialCalc品质保证团队的两个人，让我开阔了眼界，知道了这个怎么推进到下一个层次，把测试推进到可执行说明的方式。<br>在GR09的章节16里，Matt解释了我们的故事-测试推动的发展过程，如下：<br>“工作的最基础的单元时“故事”，它是一个轻量要求文档。一个故事包括了一个特征的简要说明，并包含了完成故事需要考虑的例子，我们把这些例子叫做“接受测试”，并用简明英语描述。<br>在故事最初的剪辑中，产品主人坚信创造接受测试，这些在代码编辑之前将被开发者和测试者讨论。”<br>这些故事测试被翻译成wiki测试，一个基于表格的启发自Ward CunninghamFIT框架的说明语言，推动自动化的测试框架，比如Test::WWW::Mechanize和Test::WWW::Selenium。<br>故事测试作为普遍语言表达和衡量要求的好处，很难说明。它减少误解，也减少了我们每月发行的退化。</p><h3 id="19-8-6-Open-Source-With-CPAL"><a href="#19-8-6-Open-Source-With-CPAL" class="headerlink" title="19.8.6. Open Source With CPAL"></a>19.8.6. Open Source With CPAL</h3><p>最后，我们给SocialCalc选择的开源模型，从中有意思的经验教训。<br>Socialtext给SocialCalc创造了Common Public Attribution License。基于Mozilla Public License，设计CPAL来允许原作者在软件使用者界面上显示属性，并且有一个网络使用条款，当网络上有衍生工作时共享条款。<br>在Open Source Initiative和Free Software Foundation的准许之后，我们看到出名的网站比如Facebook和Reddit在CPAL发行了他们平台的源代码，这是非常鼓舞人的举动。<br>因为CPAL是一个“软弱著作”条款，发行者可以自由地把它和其它免费软件结合，只需要发行对SocialCalc的更改。这个使得多种多样的社区能够采取SocialCalc，使它变得极好。<br>这个开源的电子表格引擎有许多有趣的可能性。如果你找到一个方式把SocialCalc植入你最喜欢的项目，我们特别高兴听到这个消息。</p><h2 id="Footnotes"><a href="#Footnotes" class="headerlink" title="Footnotes"></a>Footnotes</h2><ol><li><p><a href="https://github.com/audreyt/wikiwyg-js" target="_blank" rel="noopener">https://github.com/audreyt/wikiwyg-js</a></p></li><li><p><a href="http://one.laptop.org/" target="_blank" rel="noopener">http://one.laptop.org/</a></p></li><li><p><a href="http://seeta.in/wiki/index.php?title=Collaboration_in_SocialCalc" target="_blank" rel="noopener">http://seeta.in/wiki/index.php?title=Collaboration_in_SocialCalc</a></p></li><li><p><a href="http://search.cpan.org/dist/Web-Hippie/" target="_blank" rel="noopener">http://search.cpan.org/dist/Web-Hippie/</a></p></li><li><p><a href="http://about.digg.com/blog/duistream-and-mxhr" target="_blank" rel="noopener">http://about.digg.com/blog/duistream-and-mxhr</a></p></li><li><p><a href="https://github.com/gimite/web-socket-js" target="_blank" rel="noopener">https://github.com/gimite/web-socket-js</a></p></li><li><p><a href="http://perlcabal.org/syn/S02.html" target="_blank" rel="noopener">http://perlcabal.org/syn/S02.html</a></p></li><li><p><a href="http://fit.c2.com/" target="_blank" rel="noopener">http://fit.c2.com/</a></p></li><li><p><a href="http://search.cpan.org/dist/Test-WWW-Mechanize/" target="_blank" rel="noopener">http://search.cpan.org/dist/Test-WWW-Mechanize/</a></p></li></ol><p>10.<a href="http://search.cpan.org/dist/Test-WWW-Selenium/" target="_blank" rel="noopener">http://search.cpan.org/dist/Test-WWW-Selenium/</a></p><p>11.<a href="https://www.socialtext.net/open/?cpal" target="_blank" rel="noopener">https://www.socialtext.net/open/?cpal</a></p><p>12.<a href="http://opensource.org/" target="_blank" rel="noopener">http://opensource.org/</a></p><p>13.<a href="http://www.fsf.org" target="_blank" rel="noopener">http://www.fsf.org</a></p><p>14.<a href="https://github.com/facebook/platform" target="_blank" rel="noopener">https://github.com/facebook/platform</a></p><p>15.<a href="https://github.com/reddit/reddit" target="_blank" rel="noopener">https://github.com/reddit/reddit</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SocialCalc&quot;&gt;&lt;a href=&quot;#SocialCalc&quot; class=&quot;headerlink&quot; title=&quot;SocialCalc&quot;&gt;&lt;/a&gt;SocialCalc&lt;/h1&gt;&lt;p&gt;电子表格的历史有超过30年了。第一个电子表格VisiCalc是Dan Bri
      
    
    </summary>
    
    
    
      <category term="aosabook" scheme="http://blog.ccao.cc/tags/aosabook/"/>
    
  </entry>
  
</feed>
